{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 20:41:10.593547: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-21 20:41:11.137799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers, models\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, RandomFlip, RandomBrightness, RandomZoom, RandomContrast, RandomTranslation, Dropout, BatchNormalization, AvgPool2D\n",
    "from keras.applications import VGG16, EfficientNetV2L, InceptionResNetV2\n",
    "from keras import callbacks, backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14326830828269907"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.load('Xtrain_Classification1.npy')\n",
    "y=np.load('ytrain_Classification1.npy')\n",
    "first_time = True\n",
    "len(np.where(y==1)[0])/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 16)                37648     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,802\n",
      "Trainable params: 37,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.4260 - accuracy: 0.8525 - val_loss: 0.3908 - val_accuracy: 0.8609\n",
      "Epoch 2/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8557 - val_loss: 0.3774 - val_accuracy: 0.8609\n",
      "Epoch 3/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8557 - val_loss: 0.3319 - val_accuracy: 0.8609\n",
      "Epoch 4/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8557 - val_loss: 0.3253 - val_accuracy: 0.8609\n",
      "Epoch 5/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8559 - val_loss: 0.3337 - val_accuracy: 0.8617\n",
      "Epoch 6/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8557 - val_loss: 0.3166 - val_accuracy: 0.8625\n",
      "Epoch 7/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8553 - val_loss: 0.3159 - val_accuracy: 0.8609\n",
      "Epoch 8/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8559 - val_loss: 0.3174 - val_accuracy: 0.8585\n",
      "Epoch 9/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8551 - val_loss: 0.3213 - val_accuracy: 0.8601\n",
      "Epoch 10/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8555 - val_loss: 0.3154 - val_accuracy: 0.8601\n",
      "Epoch 11/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8555 - val_loss: 0.3123 - val_accuracy: 0.8625\n",
      "Epoch 12/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8541 - val_loss: 0.3165 - val_accuracy: 0.8593\n",
      "Epoch 13/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8561 - val_loss: 0.3874 - val_accuracy: 0.8625\n",
      "Epoch 14/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8559 - val_loss: 0.3107 - val_accuracy: 0.8625\n",
      "Epoch 15/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8557 - val_loss: 0.3884 - val_accuracy: 0.8617\n",
      "Epoch 16/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8555 - val_loss: 0.3087 - val_accuracy: 0.8593\n",
      "Epoch 17/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8563 - val_loss: 0.3251 - val_accuracy: 0.8617\n",
      "Epoch 18/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8563 - val_loss: 0.3183 - val_accuracy: 0.8625\n",
      "Epoch 19/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8561 - val_loss: 0.3229 - val_accuracy: 0.8633\n",
      "Epoch 20/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8571 - val_loss: 0.3097 - val_accuracy: 0.8633\n",
      "Epoch 21/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8539 - val_loss: 0.3172 - val_accuracy: 0.8641\n",
      "Epoch 22/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8551 - val_loss: 0.3052 - val_accuracy: 0.8641\n",
      "Epoch 23/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8565 - val_loss: 0.3173 - val_accuracy: 0.8665\n",
      "Epoch 24/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8565 - val_loss: 0.3031 - val_accuracy: 0.8657\n",
      "Epoch 25/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8567 - val_loss: 0.3036 - val_accuracy: 0.8633\n",
      "Epoch 26/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8591 - val_loss: 0.3121 - val_accuracy: 0.8633\n",
      "Epoch 27/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8541 - val_loss: 0.3101 - val_accuracy: 0.8625\n",
      "Epoch 28/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8567 - val_loss: 0.3072 - val_accuracy: 0.8633\n",
      "Epoch 29/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8575 - val_loss: 0.3046 - val_accuracy: 0.8633\n",
      "Epoch 30/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8581 - val_loss: 0.3030 - val_accuracy: 0.8641\n",
      "Epoch 31/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8609 - val_loss: 0.3217 - val_accuracy: 0.8633\n",
      "Epoch 32/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8595 - val_loss: 0.3255 - val_accuracy: 0.8577\n",
      "Epoch 33/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8565 - val_loss: 0.3204 - val_accuracy: 0.8633\n",
      "Epoch 34/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8631 - val_loss: 0.3002 - val_accuracy: 0.8641\n",
      "Epoch 35/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8589 - val_loss: 0.2978 - val_accuracy: 0.8697\n",
      "Epoch 36/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8633 - val_loss: 0.3008 - val_accuracy: 0.8649\n",
      "Epoch 37/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8607 - val_loss: 0.2982 - val_accuracy: 0.8729\n",
      "Epoch 38/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8625 - val_loss: 0.3186 - val_accuracy: 0.8649\n",
      "Epoch 39/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8611 - val_loss: 0.3242 - val_accuracy: 0.8569\n",
      "Epoch 40/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8593 - val_loss: 0.3114 - val_accuracy: 0.8641\n",
      "Epoch 41/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8609 - val_loss: 0.3029 - val_accuracy: 0.8721\n",
      "Epoch 42/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8581 - val_loss: 0.2988 - val_accuracy: 0.8689\n",
      "Epoch 43/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8647 - val_loss: 0.3115 - val_accuracy: 0.8633\n",
      "Epoch 44/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8585 - val_loss: 0.3154 - val_accuracy: 0.8665\n",
      "Epoch 45/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8617 - val_loss: 0.3002 - val_accuracy: 0.8673\n",
      "Epoch 46/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8629 - val_loss: 0.3152 - val_accuracy: 0.8633\n",
      "Epoch 47/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8587 - val_loss: 0.2964 - val_accuracy: 0.8689\n",
      "Epoch 48/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8583 - val_loss: 0.3098 - val_accuracy: 0.8633\n",
      "Epoch 49/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8617 - val_loss: 0.3061 - val_accuracy: 0.8609\n",
      "Epoch 50/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8611 - val_loss: 0.3006 - val_accuracy: 0.8689\n",
      "Epoch 51/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8615 - val_loss: 0.3036 - val_accuracy: 0.8633\n",
      "Epoch 52/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8611 - val_loss: 0.3098 - val_accuracy: 0.8689\n",
      "Epoch 53/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8607 - val_loss: 0.3118 - val_accuracy: 0.8641\n",
      "Epoch 54/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8597 - val_loss: 0.3370 - val_accuracy: 0.8649\n",
      "Epoch 55/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8637 - val_loss: 0.2949 - val_accuracy: 0.8697\n",
      "Epoch 56/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8601 - val_loss: 0.3031 - val_accuracy: 0.8641\n",
      "Epoch 57/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8625 - val_loss: 0.2973 - val_accuracy: 0.8673\n",
      "Epoch 58/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8591 - val_loss: 0.3071 - val_accuracy: 0.8633\n",
      "Epoch 59/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8611 - val_loss: 0.2957 - val_accuracy: 0.8681\n",
      "Epoch 60/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8615 - val_loss: 0.3051 - val_accuracy: 0.8681\n",
      "Epoch 61/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8649 - val_loss: 0.3058 - val_accuracy: 0.8641\n",
      "Epoch 62/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8605 - val_loss: 0.3283 - val_accuracy: 0.8633\n",
      "Epoch 63/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8619 - val_loss: 0.2977 - val_accuracy: 0.8697\n",
      "Epoch 64/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8637 - val_loss: 0.3057 - val_accuracy: 0.8665\n",
      "Epoch 65/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8637 - val_loss: 0.2963 - val_accuracy: 0.8705\n",
      "Epoch 66/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8603 - val_loss: 0.3318 - val_accuracy: 0.8625\n",
      "Epoch 67/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8623 - val_loss: 0.3112 - val_accuracy: 0.8569\n",
      "Epoch 68/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8621 - val_loss: 0.3201 - val_accuracy: 0.8569\n",
      "Epoch 69/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8649 - val_loss: 0.3036 - val_accuracy: 0.8665\n",
      "Epoch 70/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8615 - val_loss: 0.3133 - val_accuracy: 0.8673\n",
      "Epoch 71/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8629 - val_loss: 0.3009 - val_accuracy: 0.8689\n",
      "Epoch 72/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8639 - val_loss: 0.2954 - val_accuracy: 0.8689\n",
      "Epoch 73/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8641 - val_loss: 0.3256 - val_accuracy: 0.8521\n",
      "Epoch 74/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8665 - val_loss: 0.3152 - val_accuracy: 0.8665\n",
      "Epoch 75/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8637 - val_loss: 0.3336 - val_accuracy: 0.8433\n",
      "Epoch 76/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8623 - val_loss: 0.3035 - val_accuracy: 0.8673\n",
      "Epoch 77/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8631 - val_loss: 0.2942 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8687 - val_loss: 0.3304 - val_accuracy: 0.8625\n",
      "Epoch 79/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8657 - val_loss: 0.3432 - val_accuracy: 0.8425\n",
      "Epoch 80/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8655 - val_loss: 0.2978 - val_accuracy: 0.8673\n",
      "Epoch 81/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8617 - val_loss: 0.3217 - val_accuracy: 0.8633\n",
      "Epoch 82/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8637 - val_loss: 0.2974 - val_accuracy: 0.8665\n",
      "Epoch 83/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8649 - val_loss: 0.3473 - val_accuracy: 0.8441\n",
      "Epoch 84/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8621 - val_loss: 0.3032 - val_accuracy: 0.8673\n",
      "Epoch 85/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8641 - val_loss: 0.3222 - val_accuracy: 0.8649\n",
      "Epoch 86/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8629 - val_loss: 0.3323 - val_accuracy: 0.8489\n",
      "Epoch 87/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8605 - val_loss: 0.3050 - val_accuracy: 0.8641\n",
      "Epoch 88/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8637 - val_loss: 0.2952 - val_accuracy: 0.8729\n",
      "Epoch 89/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8661 - val_loss: 0.2936 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8643 - val_loss: 0.2951 - val_accuracy: 0.8689\n",
      "Epoch 91/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8685 - val_loss: 0.3034 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8663 - val_loss: 0.3063 - val_accuracy: 0.8617\n",
      "Epoch 93/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8595 - val_loss: 0.2978 - val_accuracy: 0.8705\n",
      "Epoch 94/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8657 - val_loss: 0.3494 - val_accuracy: 0.8617\n",
      "Epoch 95/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8639 - val_loss: 0.3125 - val_accuracy: 0.8625\n",
      "Epoch 96/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8653 - val_loss: 0.2935 - val_accuracy: 0.8737\n",
      "Epoch 97/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8673 - val_loss: 0.3204 - val_accuracy: 0.8641\n",
      "Epoch 98/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8607 - val_loss: 0.3027 - val_accuracy: 0.8689\n",
      "Epoch 99/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8641 - val_loss: 0.2939 - val_accuracy: 0.8729\n",
      "Epoch 100/100\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8643 - val_loss: 0.2926 - val_accuracy: 0.8729\n"
     ]
    }
   ],
   "source": [
    "batch_size=20\n",
    "epochs=100\n",
    "lr=0.005\n",
    "image = (x[3,:]).astype('float32')/255.0\n",
    "train_images = (x).astype('float32')/255.0\n",
    "train_labels = to_categorical(y,2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2)\n",
    "\n",
    "model_MLP = models.Sequential()\n",
    "model_MLP.add(Dense(16,activation = 'relu',input_dim = 2352))\n",
    "model_MLP.add(Dense(8,activation = 'relu'))\n",
    "model_MLP.add(Dense(2,activation = 'softmax'))\n",
    "\n",
    "model_MLP.summary()\n",
    "\n",
    "adam = optimizers.Adam(learning_rate = lr)\n",
    "model_MLP.compile(optimizer = adam,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_mlp = model_MLP.fit(x = X_train,y=y_train,epochs = epochs,batch_size=batch_size,validation_data = (X_val,y_val),verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_mlp.history['accuracy']\n",
    "val_acc = history_mlp.history['val_accuracy']\n",
    "loss = history_mlp.history['loss']\n",
    "val_loss = history_mlp.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc'),\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss'),\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#x = np.load('Xtrain_Classification1.npy')\n",
    "#test_images = (x).astype('float32')/255.0\n",
    "#results_MLP = np.argmax(model_MLP.predict(test_images),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,378\n",
      "Trainable params: 93,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 19:43:53.960877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-17 19:43:53.975417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-17 19:43:53.975558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-17 19:43:53.976238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-17 19:43:53.976402: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-17 19:43:53.976578: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-17 19:43:54.381701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-17 19:43:54.381839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-17 19:43:54.381982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-17 19:43:54.382063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5046 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:05:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TrainBalancedAccuracyCallback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ricardo/Desktop/AAut/scripts/task3/task3.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ricardo/Desktop/AAut/scripts/task3/task3.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model_cnn\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ricardo/Desktop/AAut/scripts/task3/task3.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model_cnn\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m optimizers\u001b[39m.\u001b[39mRMSprop(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ricardo/Desktop/AAut/scripts/task3/task3.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m               loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ricardo/Desktop/AAut/scripts/task3/task3.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mTruePositives(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtp\u001b[39m\u001b[39m'\u001b[39m), keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFalsePositives(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfp\u001b[39m\u001b[39m'\u001b[39m), keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mTrueNegatives(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtn\u001b[39m\u001b[39m'\u001b[39m), keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFalseNegatives(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfn\u001b[39m\u001b[39m'\u001b[39m),[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ricardo/Desktop/AAut/scripts/task3/task3.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m history_cnn \u001b[39m=\u001b[39m model_cnn\u001b[39m.\u001b[39mfit(x \u001b[39m=\u001b[39m X_train ,y\u001b[39m=\u001b[39my_train ,epochs \u001b[39m=\u001b[39m epochs ,batch_size\u001b[39m=\u001b[39mbatch_size ,validation_data \u001b[39m=\u001b[39m (X_val,y_val) ,verbose \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, callbacks\u001b[39m=\u001b[39m[TrainBalancedAccuracyCallback(), ValBalancedAccuracyCallback()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainBalancedAccuracyCallback' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size=20\n",
    "epochs=100\n",
    "train_images = (x).astype('float32')/255.0\n",
    "train_labels = to_categorical(y,2)\n",
    "train_images = np.reshape(train_images, (6254,28,28,3))\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "model_cnn = models.Sequential()\n",
    "model_cnn.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model_cnn.add(MaxPooling2D((2,2)))\n",
    "model_cnn.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D((2,2)))\n",
    "model_cnn.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(64, activation = 'relu'))\n",
    "model_cnn.add(Dense(2, activation = 'softmax'))\n",
    "model_cnn.summary()\n",
    "\n",
    "model_cnn.compile(optimizer = optimizers.RMSprop(learning_rate=1e-4),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=[keras.metrics.TruePositives(name='tp'), keras.metrics.FalsePositives(name='fp'), keras.metrics.TrueNegatives(name='tn'), keras.metrics.FalseNegatives(name='fn'),['accuracy']])\n",
    "history_cnn = model_cnn.fit(x = X_train ,y=y_train ,epochs = epochs ,batch_size=batch_size ,validation_data = (X_val,y_val) ,verbose = 1, callbacks=[TrainBalancedAccuracyCallback(), ValBalancedAccuracyCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_cnn.history['accuracy']\n",
    "val_acc = history_cnn.history['val_accuracy']\n",
    "loss = history_cnn.history['loss']\n",
    "val_loss = history_cnn.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc'),\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss'),\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#x = np.load('Xtrain_Classification1.npy')\n",
    "#test_images = (x).astype('float32')/255.0\n",
    "#results_MLP = np.argmax(model_MLP.predict(test_images),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentate_melanoma_data(melanoma_images, X_mela, y_mela, num_mela):\n",
    "  zoom_data = models.Sequential([\n",
    "    RandomZoom(height_factor=0.2, fill_mode='nearest'),\n",
    "  ])\n",
    "  bright_data = models.Sequential([\n",
    "    RandomBrightness(factor=0.3, value_range=[0.0, 1.0]),\n",
    "  ])\n",
    "  translation_data = models.Sequential([\n",
    "    RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode='nearest'),\n",
    "  ])\n",
    "\n",
    "  augmented_images = tf.image.flip_left_right(melanoma_images)\n",
    "  X_mela = np.vstack([X_mela, augmented_images])\n",
    "  y_mela = np.hstack((y_mela, np.ones(len(augmented_images,))))\n",
    "  augmented_images = zoom_data(melanoma_images).numpy()\n",
    "  X_mela = np.vstack([X_mela, augmented_images])\n",
    "  y_mela = np.hstack((y_mela, np.ones(len(augmented_images,))))\n",
    "  augmented_images = bright_data(melanoma_images).numpy()\n",
    "  X_mela = np.vstack([X_mela, augmented_images])\n",
    "  y_mela = np.hstack((y_mela, np.ones(len(augmented_images,))))\n",
    "  augmented_images = translation_data(melanoma_images).numpy()\n",
    "  X_mela = np.vstack([X_mela, augmented_images])\n",
    "  y_mela = np.hstack((y_mela, np.ones(len(augmented_images,))))  \n",
    "\n",
    "  num_mela = len(y_mela)\n",
    "\n",
    "  return num_mela, X_mela, y_mela\n",
    "\n",
    "def augmentate_all_data(all_images, all_labels):\n",
    "  all_labels_aug = np.empty((1,), dtype=np.int8)\n",
    "  all_images_aug = np.empty((1,28,28,3), dtype=np.float32)\n",
    "\n",
    "  contrast_data = models.Sequential([\n",
    "    RandomContrast(factor=0.2),\n",
    "  ])\n",
    "  augmented_images = contrast_data(all_images).numpy()\n",
    "  all_images_aug = np.vstack([all_images_aug, augmented_images])\n",
    "  all_labels_aug = np.hstack((all_labels_aug, all_labels))\n",
    "  rotated_90 = tf.image.rot90(all_images)\n",
    "  all_images_aug = np.vstack([all_images_aug, rotated_90])\n",
    "  all_labels_aug = np.hstack((all_labels_aug, all_labels))\n",
    "  rotated_180 = tf.image.rot90((all_images), k=2)\n",
    "  all_images_aug = np.vstack([all_images_aug, rotated_180])\n",
    "  all_labels_aug = np.hstack((all_labels_aug, all_labels))\n",
    "  rotated_270 = tf.image.rot90((all_images), k=3)\n",
    "  all_images_aug = np.vstack([all_images_aug, rotated_270])\n",
    "  all_labels_aug = np.hstack((all_labels_aug, all_labels))\n",
    "  \n",
    "  all_images_aug = all_images_aug[1:]\n",
    "  all_labels_aug = all_labels_aug[1:]\n",
    "\n",
    "  return all_images_aug, all_labels_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positives(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    return tf.reduce_sum(tf.cast(tf.math.logical_and(y_true[:, 1] == 1, y_pred[:, 1] == 1), tf.float32))\n",
    "\n",
    "def false_positives(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    return tf.reduce_sum(tf.cast(tf.math.logical_and(y_true[:, 1] == 0, y_pred[:, 1] == 1), tf.float32))\n",
    "\n",
    "def true_negatives(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    return tf.reduce_sum(tf.cast(tf.math.logical_and(y_true[:, 0] == 1, y_pred[:, 0] == 1), tf.float32))\n",
    "\n",
    "def false_negatives(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    return tf.reduce_sum(tf.cast(tf.math.logical_and(y_true[:, 0] == 0, y_pred[:, 0] == 1), tf.float32))\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    tp = true_positives(y_true, y_pred)\n",
    "    tn = true_negatives(y_true, y_pred)\n",
    "    fp = false_positives(y_true, y_pred)\n",
    "    fn = false_negatives(y_true, y_pred)\n",
    "    \n",
    "    numerator = tp * (tn + fp) + tn * (tp + fn)\n",
    "    denominator = (tn + fp) * (tp + fn)\n",
    "    \n",
    "    return numerator / (2*denominator + K.epsilon())\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    tp = true_positives(y_true, y_pred)\n",
    "    fp = false_positives(y_true, y_pred)\n",
    "    \n",
    "    return tp / (tp + fp + K.epsilon())\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    tp = true_positives(y_true, y_pred)\n",
    "    fn = false_negatives(y_true, y_pred)\n",
    "    \n",
    "    return tp / (tp + fn + K.epsilon())\n",
    "\n",
    "\n",
    "# class TrainingAccuracyCallback(tf.keras.callbacks.Callback):\n",
    "#     def __init__(self, **kargs):\n",
    "#         super(TrainingAccuracyCallback, self).__init__(**kargs)\n",
    "        \n",
    "#     def on_train_begin(self, logs=None):\n",
    "#         self.train_accuracy = []\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         train_accuracy = self.model.evaluate(self.model.validation_data[0], self.model.validation_data[1], verbose=0)[1]\n",
    "#         self.train_accuracy.append(train_accuracy)\n",
    "#         print(f\" - Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# class TrainBalancedAccuracyCallback(callbacks.Callback):\n",
    "\n",
    "#     def __init__(self, **kargs):\n",
    "#         super(TrainBalancedAccuracyCallback, self).__init__(**kargs)\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "#         train_sensitivity = logs['tp'] / (logs['tp'] + logs['fn'])\n",
    "#         train_specificity = logs['tn'] / (logs['tn'] + logs['fp'])\n",
    "#         logs['train_sensitivity'] = train_sensitivity\n",
    "#         logs['train_specificity'] = train_specificity\n",
    "#         logs['train_balacc'] = (train_sensitivity + train_specificity) / 2\n",
    "#         print(' train_balacc', logs['train_balacc'])\n",
    "    \n",
    "# class ValBalancedAccuracyCallback(callbacks.Callback):\n",
    "\n",
    "#     def __init__(self, **kargs):\n",
    "#         super(ValBalancedAccuracyCallback, self).__init__(**kargs)\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "#         val_sensitivity = logs['val_tp'] / (logs['val_tp'] + logs['val_fn'])\n",
    "#         val_specificity = logs['val_tn'] / (logs['val_tn'] + logs['val_fp'])\n",
    "#         logs['val_sensitivity'] = val_sensitivity\n",
    "#         logs['val_specificity'] = val_specificity\n",
    "#         logs['val_balacc'] = (val_sensitivity + val_specificity) / 2\n",
    "#         print(' val_balacc', logs['val_balacc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_nevu_mela(x, y):\n",
    "    train_images = (x).astype('float32')/255.0\n",
    "\n",
    "    nevu_images = train_images[y == 0]\n",
    "    melanoma_images = train_images[y == 1]\n",
    "\n",
    "    y_nevu = y[y == 0]\n",
    "    y_mela = y[y == 1]\n",
    "\n",
    "    num_nevu = len((y_nevu))\n",
    "    num_mela = len((y_mela))\n",
    "\n",
    "    nevu_images = np.reshape(nevu_images, (num_nevu,28,28,3))\n",
    "    melanoma_images = np.reshape(melanoma_images, (num_mela,28,28,3))\n",
    "\n",
    "    return num_nevu, num_mela, nevu_images, melanoma_images, y_nevu, y_mela\n",
    "\n",
    "def augmentate_melanoma_data(melanoma_images, X_mela, y_mela, num_mela):\n",
    "  zoom_data = models.Sequential([\n",
    "    RandomZoom(height_factor=0.2, fill_mode='nearest'),\n",
    "  ])\n",
    "  bright_data = models.Sequential([\n",
    "    RandomBrightness(factor=0.3, value_range=[0.0, 1.0]),\n",
    "  ])\n",
    "  translation_data = models.Sequential([\n",
    "    RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode='nearest'),\n",
    "  ])\n",
    "\n",
    "  augmented_images = tf.image.flip_left_right(melanoma_images)\n",
    "  X_mela = np.vstack([X_mela, augmented_images])\n",
    "  y_mela = np.hstack((y_mela, np.ones(len(augmented_images,))))\n",
    "  augmented_images = zoom_data(melanoma_images).numpy()\n",
    "  X_mela = np.vstack([X_mela, augmented_images])\n",
    "  y_mela = np.hstack((y_mela, np.ones(len(augmented_images,))))\n",
    "  augmented_images = bright_data(melanoma_images).numpy()\n",
    "  X_mela = np.vstack([X_mela, augmented_images])\n",
    "  y_mela = np.hstack((y_mela, np.ones(len(augmented_images,))))\n",
    "  augmented_images = translation_data(melanoma_images).numpy()\n",
    "  X_mela = np.vstack([X_mela, augmented_images])\n",
    "  y_mela = np.hstack((y_mela, np.ones(len(augmented_images,))))  \n",
    "\n",
    "  num_mela = len(y_mela)\n",
    "\n",
    "  return num_mela, X_mela, y_mela\n",
    "\n",
    "def augmentate_all_data(all_images, all_labels):\n",
    "  all_labels_aug = np.empty((1,), dtype=np.int8)\n",
    "  all_images_aug = np.empty((1,28,28,3), dtype=np.float32)\n",
    "\n",
    "  contrast_data = models.Sequential([\n",
    "    RandomContrast(factor=0.2),\n",
    "  ])\n",
    "  augmented_images = contrast_data(all_images).numpy()\n",
    "  all_images_aug = np.vstack([all_images_aug, augmented_images])\n",
    "  all_labels_aug = np.hstack((all_labels_aug, all_labels))\n",
    "  rotated_90 = tf.image.rot90(all_images)\n",
    "  all_images_aug = np.vstack([all_images_aug, rotated_90])\n",
    "  all_labels_aug = np.hstack((all_labels_aug, all_labels))\n",
    "  rotated_180 = tf.image.rot90((all_images), k=2)\n",
    "  all_images_aug = np.vstack([all_images_aug, rotated_180])\n",
    "  all_labels_aug = np.hstack((all_labels_aug, all_labels))\n",
    "  rotated_270 = tf.image.rot90((all_images), k=3)\n",
    "  all_images_aug = np.vstack([all_images_aug, rotated_270])\n",
    "  all_labels_aug = np.hstack((all_labels_aug, all_labels))\n",
    "  \n",
    "  all_images_aug = all_images_aug[1:]\n",
    "  all_labels_aug = all_labels_aug[1:]\n",
    "\n",
    "  return all_images_aug, all_labels_aug\n",
    "\n",
    "\n",
    "num_nevu, num_mela, nevu_images, melanoma_images, y_nevu, y_mela = split_nevu_mela(x, y)\n",
    "\n",
    "X_nevu_train, X_nevu_val, y_nevu_train, y_nevu_val = train_test_split(nevu_images, y_nevu, test_size=0.3, random_state=0)\n",
    "X_mela_train, X_mela_val, y_mela_train, y_mela_val = train_test_split(melanoma_images, y_mela, test_size=0.3, random_state=0)\n",
    "num_mela, X_mela_train, y_mela_train = augmentate_melanoma_data(melanoma_images, X_mela_train, y_mela_train, num_mela)\n",
    "\n",
    "X_train = np.vstack([X_mela_train, X_nevu_train])\n",
    "X_val = np.vstack([X_mela_val, X_nevu_val])\n",
    "y_train = np.hstack((y_mela_train, y_nevu_train))\n",
    "y_val = np.hstack((y_mela_val, y_nevu_val)) \n",
    "\n",
    "X_train, y_train = augmentate_all_data(X_train, y_train)\n",
    "X_val, y_val = augmentate_all_data(X_val, y_val)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=0)\n",
    "\n",
    "print(f\"Percentage of Melanoma in train data is {len(np.where(y_train==1)[0])/len(y_train)*100:2.2f}%\")\n",
    "print(f\"Percentage of Melanoma in val data is {len(np.where(y_val==1)[0])/len(y_val)*100:2.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_data(history_cnn, prev_history):\n",
    "    val_balanced_acc = history_cnn.history['val_balanced_accuracy']\n",
    "    prev_val_balanced_acc = prev_history.history['val_balanced_accuracy']\n",
    "\n",
    "    if len(val_balanced_acc) > len(prev_val_balanced_acc):\n",
    "        epochs = range(1, len(prev_val_balanced_acc) + 1)\n",
    "    else:\n",
    "        epochs = range(1, len(val_balanced_acc) + 1)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(epochs, val_balanced_acc[:max(epochs)], 'r-', label='This CNN')\n",
    "    plt.plot(epochs, prev_val_balanced_acc[:max(epochs)], 'b', label='Prev CNN'),\n",
    "    plt.title('Balanced Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # acc = history_cnn.history['train_acc']\n",
    "    # val_acc = history_cnn.history['val_accuracy']\n",
    "    # prev_acc = prev_history.history['train_accuracy']\n",
    "    # prev_val_acc = prev_history.history['val_accuracy']\n",
    "\n",
    "    # loss = history_cnn.history['loss']\n",
    "    # val_loss = history_cnn.history['val_loss']\n",
    "    # prev_loss = prev_history.history['loss']\n",
    "    # prev_val_loss = prev_history.history['val_loss']\n",
    "\n",
    "    # fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "    # ax1.plot(epochs, acc, 'ro', label='Training acc')\n",
    "    # ax1.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    # ax1.set_title('This CNN')\n",
    "    # ax1.legend()\n",
    "    # # ax1.set_xlim([0,300])\n",
    "    # ax1.set_ylim([0.4,1])\n",
    "    # ax2.plot(epochs, prev_acc, 'bo', label='Training acc')\n",
    "    # ax2.plot(epochs, prev_val_acc, 'b', label='Validation acc')\n",
    "    # ax2.set_title('Prev CNN')\n",
    "    # ax2.legend()\n",
    "    # ax2.set_xlim([0,300])\n",
    "    # ax2.set_ylim([0.4,1])\n",
    "    # fig1.suptitle('Training and Validation Accuracy')\n",
    "\n",
    "    # fig2, (ax3, ax4) = plt.subplots(1, 2, figsize=(12,6))\n",
    "    # ax3.plot(epochs, loss, 'ro', label='Training loss')\n",
    "    # ax3.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    # ax3.set_title('This CNN')\n",
    "    # ax3.legend()\n",
    "    # # ax3.set_xlim([0,300])\n",
    "    # ax3.set_ylim([0,4])\n",
    "    # ax4.plot(epochs, prev_loss, 'bo', label='Training loss')\n",
    "    # ax4.plot(epochs, prev_val_loss, 'b', label='Validation loss')\n",
    "    # ax4.set_title('Prev CNN')\n",
    "    # ax4.legend()\n",
    "    # # ax4.set_xlim([0,300])\n",
    "    # ax4.set_ylim([0,4])\n",
    "    # fig2.suptitle('Training and Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN_model(kernel_size):\n",
    "    model_cnn = models.Sequential()\n",
    "    model_cnn.add(Conv2D(32, kernel_size, padding='same', activation='relu', input_shape=(28, 28, 3)))\n",
    "    model_cnn.add(BatchNormalization())\n",
    "    model_cnn.add(Conv2D(32, kernel_size, activation='relu'))\n",
    "    model_cnn.add(AvgPool2D(pool_size=(2, 2)))\n",
    "    model_cnn.add(Dropout(0.25))\n",
    "    model_cnn.add(Conv2D(64, kernel_size, padding='same', activation='relu'))\n",
    "    model_cnn.add(BatchNormalization())\n",
    "    model_cnn.add(Conv2D(64, kernel_size, activation='relu'))\n",
    "    model_cnn.add(AvgPool2D(pool_size=(2, 2)))\n",
    "    model_cnn.add(Dropout(0.25))\n",
    "    model_cnn.add(Flatten())\n",
    "    model_cnn.add(Dense(1600, activation='relu'))\n",
    "    model_cnn.add(Dropout(0.5))\n",
    "    model_cnn.add(Dense(2, activation='softmax'))\n",
    "    model_cnn.summary()\n",
    "\n",
    "    model_cnn.compile(optimizer = optimizers.Adam(learning_rate=1e-3),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics=[balanced_accuracy, precision, recall,['accuracy']])\n",
    "    return model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               802944    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 930,754\n",
      "Trainable params: 930,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 18:42:06.164063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-10-19 18:42:06.571354: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-10-19 18:42:06.572975: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2023-10-19 18:42:06.572984: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2023-10-19 18:42:06.573040: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:317] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-10-19 18:42:06.900949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - ETA: 0s - loss: 52.5558 - tp: 4803.0000 - fp: 4855.0000 - tn: 4803.0000 - fn: 4855.0000 - accuracy: 0.4973 train_balacc 0.49730793124870576\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 6s 574ms/step - loss: 52.5558 - tp: 4803.0000 - fp: 4855.0000 - tn: 4803.0000 - fn: 4855.0000 - accuracy: 0.4973 - val_loss: 0.6822 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.4973 - train_specificity: 0.4973 - train_balacc: 0.4973 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 2/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7823 - tp: 4975.0000 - fp: 3787.0000 - tn: 4975.0000 - fn: 3787.0000 - accuracy: 0.5678 train_balacc 0.5658521433008905\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.6410 - tp: 5465.0000 - fp: 4193.0000 - tn: 5465.0000 - fn: 4193.0000 - accuracy: 0.5659 - val_loss: 0.6945 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5659 - train_specificity: 0.5659 - train_balacc: 0.5659 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 3/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6988 - tp: 4338.0000 - fp: 4424.0000 - tn: 4338.0000 - fn: 4424.0000 - accuracy: 0.4951 train_balacc 0.4985504245185339\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6983 - tp: 4815.0000 - fp: 4843.0000 - tn: 4815.0000 - fn: 4843.0000 - accuracy: 0.4986 - val_loss: 0.6939 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.4986 - train_specificity: 0.4986 - train_balacc: 0.4986 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 4/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6911 - tp: 4662.0000 - fp: 4100.0000 - tn: 4662.0000 - fn: 4100.0000 - accuracy: 0.5321 train_balacc 0.5329260716504453\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6910 - tp: 5147.0000 - fp: 4511.0000 - tn: 5147.0000 - fn: 4511.0000 - accuracy: 0.5329 - val_loss: 0.6912 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5329 - train_specificity: 0.5329 - train_balacc: 0.5329 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 5/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6864 - tp: 4846.0000 - fp: 3916.0000 - tn: 4846.0000 - fn: 3916.0000 - accuracy: 0.5531 train_balacc 0.5518740940153241\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6864 - tp: 5330.0000 - fp: 4328.0000 - tn: 5330.0000 - fn: 4328.0000 - accuracy: 0.5519 - val_loss: 0.6891 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5519 - train_specificity: 0.5519 - train_balacc: 0.5519 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 6/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6913 - tp: 4632.0000 - fp: 4130.0000 - tn: 4632.0000 - fn: 4130.0000 - accuracy: 0.5286 train_balacc 0.5315800372747981\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6904 - tp: 5134.0000 - fp: 4524.0000 - tn: 5134.0000 - fn: 4524.0000 - accuracy: 0.5316 - val_loss: 0.6866 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5316 - train_specificity: 0.5316 - train_balacc: 0.5316 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 7/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6808 - tp: 4984.0000 - fp: 3778.0000 - tn: 4984.0000 - fn: 3778.0000 - accuracy: 0.5688 train_balacc 0.5695796231103748\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6803 - tp: 5501.0000 - fp: 4157.0000 - tn: 5501.0000 - fn: 4157.0000 - accuracy: 0.5696 - val_loss: 0.7024 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5696 - train_specificity: 0.5696 - train_balacc: 0.5696 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 8/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6851 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5432801822323462\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6858 - tp: 5247.0000 - fp: 4411.0000 - tn: 5247.0000 - fn: 4411.0000 - accuracy: 0.5433 - val_loss: 0.7122 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5433 - train_specificity: 0.5433 - train_balacc: 0.5433 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 9/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6853 - tp: 4832.0000 - fp: 3930.0000 - tn: 4832.0000 - fn: 3930.0000 - accuracy: 0.5515 train_balacc 0.550735141851315\n",
      " val_balacc 0.6777777777777778\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6845 - tp: 5319.0000 - fp: 4339.0000 - tn: 5319.0000 - fn: 4339.0000 - accuracy: 0.5507 - val_loss: 0.6718 - val_tp: 122.0000 - val_fp: 58.0000 - val_tn: 122.0000 - val_fn: 58.0000 - val_accuracy: 0.6778 - train_sensitivity: 0.5507 - train_specificity: 0.5507 - train_balacc: 0.5507 - val_sensitivity: 0.6778 - val_specificity: 0.6778 - val_balacc: 0.6778\n",
      "Epoch 10/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6853 - tp: 5151.0000 - fp: 3611.0000 - tn: 5151.0000 - fn: 3611.0000 - accuracy: 0.5879 train_balacc 0.5833505901843031\n",
      " val_balacc 0.4888888888888889\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6846 - tp: 5634.0000 - fp: 4024.0000 - tn: 5634.0000 - fn: 4024.0000 - accuracy: 0.5834 - val_loss: 0.6845 - val_tp: 88.0000 - val_fp: 92.0000 - val_tn: 88.0000 - val_fn: 92.0000 - val_accuracy: 0.4889 - train_sensitivity: 0.5834 - train_specificity: 0.5834 - train_balacc: 0.5834 - val_sensitivity: 0.4889 - val_specificity: 0.4889 - val_balacc: 0.4889\n",
      "Epoch 11/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6674 - tp: 5105.0000 - fp: 3657.0000 - tn: 5105.0000 - fn: 3657.0000 - accuracy: 0.5826 train_balacc 0.5894595154276248\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6670 - tp: 5693.0000 - fp: 3965.0000 - tn: 5693.0000 - fn: 3965.0000 - accuracy: 0.5895 - val_loss: 0.7603 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5895 - train_specificity: 0.5895 - train_balacc: 0.5895 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 12/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7040 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5472147442534686\n",
      " val_balacc 0.5444444444444444\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7006 - tp: 5285.0000 - fp: 4373.0000 - tn: 5285.0000 - fn: 4373.0000 - accuracy: 0.5472 - val_loss: 0.6749 - val_tp: 98.0000 - val_fp: 82.0000 - val_tn: 98.0000 - val_fn: 82.0000 - val_accuracy: 0.5444 - train_sensitivity: 0.5472 - train_specificity: 0.5472 - train_balacc: 0.5472 - val_sensitivity: 0.5444 - val_specificity: 0.5444 - val_balacc: 0.5444\n",
      "Epoch 13/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6632 - tp: 5502.0000 - fp: 3260.0000 - tn: 5502.0000 - fn: 3260.0000 - accuracy: 0.6279 train_balacc 0.6204183060675088\n",
      " val_balacc 0.48333333333333334\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6672 - tp: 5992.0000 - fp: 3666.0000 - tn: 5992.0000 - fn: 3666.0000 - accuracy: 0.6204 - val_loss: 0.6834 - val_tp: 87.0000 - val_fp: 93.0000 - val_tn: 87.0000 - val_fn: 93.0000 - val_accuracy: 0.4833 - train_sensitivity: 0.6204 - train_specificity: 0.6204 - train_balacc: 0.6204 - val_sensitivity: 0.4833 - val_specificity: 0.4833 - val_balacc: 0.4833\n",
      "Epoch 14/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.8994 - tp: 4445.0000 - fp: 4317.0000 - tn: 4445.0000 - fn: 4317.0000 - accuracy: 0.5073 train_balacc 0.5125284738041003\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.8770 - tp: 4950.0000 - fp: 4708.0000 - tn: 4950.0000 - fn: 4708.0000 - accuracy: 0.5125 - val_loss: 0.6818 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5125 - train_specificity: 0.5125 - train_balacc: 0.5125 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 15/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6617 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5460757920894596\n",
      " val_balacc 0.5111111111111111\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6772 - tp: 5274.0000 - fp: 4384.0000 - tn: 5274.0000 - fn: 4384.0000 - accuracy: 0.5461 - val_loss: 0.6890 - val_tp: 92.0000 - val_fp: 88.0000 - val_tn: 92.0000 - val_fn: 88.0000 - val_accuracy: 0.5111 - train_sensitivity: 0.5461 - train_specificity: 0.5461 - train_balacc: 0.5461 - val_sensitivity: 0.5111 - val_specificity: 0.5111 - val_balacc: 0.5111\n",
      "Epoch 16/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6906 - tp: 4475.0000 - fp: 4287.0000 - tn: 4475.0000 - fn: 4287.0000 - accuracy: 0.5107 train_balacc 0.5138745081797473\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6903 - tp: 4963.0000 - fp: 4695.0000 - tn: 4963.0000 - fn: 4695.0000 - accuracy: 0.5139 - val_loss: 0.6900 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5139 - train_specificity: 0.5139 - train_balacc: 0.5139 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 17/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6828 - tp: 4765.0000 - fp: 3997.0000 - tn: 4765.0000 - fn: 3997.0000 - accuracy: 0.5438 train_balacc 0.5502174363222199\n",
      " val_balacc 0.5277777777777778\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6817 - tp: 5314.0000 - fp: 4344.0000 - tn: 5314.0000 - fn: 4344.0000 - accuracy: 0.5502 - val_loss: 0.6701 - val_tp: 95.0000 - val_fp: 85.0000 - val_tn: 95.0000 - val_fn: 85.0000 - val_accuracy: 0.5278 - train_sensitivity: 0.5502 - train_specificity: 0.5502 - train_balacc: 0.5502 - val_sensitivity: 0.5278 - val_specificity: 0.5278 - val_balacc: 0.5278\n",
      "Epoch 18/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6636 - tp: 5307.0000 - fp: 3455.0000 - tn: 5307.0000 - fn: 3455.0000 - accuracy: 0.6057 train_balacc 0.5982605094222406\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6739 - tp: 5778.0000 - fp: 3880.0000 - tn: 5778.0000 - fn: 3880.0000 - accuracy: 0.5983 - val_loss: 3.2492 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5983 - train_specificity: 0.5983 - train_balacc: 0.5983 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 19/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 2.1304 - tp: 4294.0000 - fp: 4468.0000 - tn: 4294.0000 - fn: 4468.0000 - accuracy: 0.4901 train_balacc 0.49420169807413544\n",
      " val_balacc 0.5777777777777777\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.0066 - tp: 4773.0000 - fp: 4885.0000 - tn: 4773.0000 - fn: 4885.0000 - accuracy: 0.4942 - val_loss: 0.6876 - val_tp: 104.0000 - val_fp: 76.0000 - val_tn: 104.0000 - val_fn: 76.0000 - val_accuracy: 0.5778 - train_sensitivity: 0.4942 - train_specificity: 0.4942 - train_balacc: 0.4942 - val_sensitivity: 0.5778 - val_specificity: 0.5778 - val_balacc: 0.5778\n",
      "Epoch 20/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6846 - tp: 4813.0000 - fp: 3949.0000 - tn: 4813.0000 - fn: 3949.0000 - accuracy: 0.5493 train_balacc 0.550320977428039\n",
      " val_balacc 0.5777777777777777\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6842 - tp: 5315.0000 - fp: 4343.0000 - tn: 5315.0000 - fn: 4343.0000 - accuracy: 0.5503 - val_loss: 0.6829 - val_tp: 104.0000 - val_fp: 76.0000 - val_tn: 104.0000 - val_fn: 76.0000 - val_accuracy: 0.5778 - train_sensitivity: 0.5503 - train_specificity: 0.5503 - train_balacc: 0.5503 - val_sensitivity: 0.5778 - val_specificity: 0.5778 - val_balacc: 0.5778\n",
      "Epoch 21/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6829 - tp: 4802.0000 - fp: 3960.0000 - tn: 4802.0000 - fn: 3960.0000 - accuracy: 0.5480 train_balacc 0.5492855663698488\n",
      " val_balacc 0.65\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6814 - tp: 5305.0000 - fp: 4353.0000 - tn: 5305.0000 - fn: 4353.0000 - accuracy: 0.5493 - val_loss: 0.6570 - val_tp: 117.0000 - val_fp: 63.0000 - val_tn: 117.0000 - val_fn: 63.0000 - val_accuracy: 0.6500 - train_sensitivity: 0.5493 - train_specificity: 0.5493 - train_balacc: 0.5493 - val_sensitivity: 0.6500 - val_specificity: 0.6500 - val_balacc: 0.6500\n",
      "Epoch 22/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6590 - tp: 5234.0000 - fp: 3528.0000 - tn: 5234.0000 - fn: 3528.0000 - accuracy: 0.5974 train_balacc 0.5858355767239594\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6702 - tp: 5658.0000 - fp: 4000.0000 - tn: 5658.0000 - fn: 4000.0000 - accuracy: 0.5858 - val_loss: 0.6928 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5858 - train_specificity: 0.5858 - train_balacc: 0.5858 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 23/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6679 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5458687098778215\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6668 - tp: 5272.0000 - fp: 4386.0000 - tn: 5272.0000 - fn: 4386.0000 - accuracy: 0.5459 - val_loss: 0.6481 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5459 - train_specificity: 0.5459 - train_balacc: 0.5459 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 24/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6531 - tp: 4779.0000 - fp: 3983.0000 - tn: 4779.0000 - fn: 3983.0000 - accuracy: 0.5454 train_balacc 0.5427624767032512\n",
      " val_balacc 0.49444444444444446\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6573 - tp: 5242.0000 - fp: 4416.0000 - tn: 5242.0000 - fn: 4416.0000 - accuracy: 0.5428 - val_loss: 0.6935 - val_tp: 89.0000 - val_fp: 91.0000 - val_tn: 89.0000 - val_fn: 91.0000 - val_accuracy: 0.4944 - train_sensitivity: 0.5428 - train_specificity: 0.5428 - train_balacc: 0.5428 - val_sensitivity: 0.4944 - val_specificity: 0.4944 - val_balacc: 0.4944\n",
      "Epoch 25/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4950.0000 - fp: 3812.0000 - tn: 4950.0000 - fn: 3812.0000 - accuracy: 0.5649 train_balacc 0.5697867053220128\n",
      " val_balacc 0.5277777777777778\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6876 - tp: 5503.0000 - fp: 4155.0000 - tn: 5503.0000 - fn: 4155.0000 - accuracy: 0.5698 - val_loss: 0.6864 - val_tp: 95.0000 - val_fp: 85.0000 - val_tn: 95.0000 - val_fn: 85.0000 - val_accuracy: 0.5278 - train_sensitivity: 0.5698 - train_specificity: 0.5698 - train_balacc: 0.5698 - val_sensitivity: 0.5278 - val_specificity: 0.5278 - val_balacc: 0.5278\n",
      "Epoch 26/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7023 - tp: 4838.0000 - fp: 3924.0000 - tn: 4838.0000 - fn: 3924.0000 - accuracy: 0.5522 train_balacc 0.55125284738041\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.7014 - tp: 5324.0000 - fp: 4334.0000 - tn: 5324.0000 - fn: 4334.0000 - accuracy: 0.5513 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5513 - train_specificity: 0.5513 - train_balacc: 0.5513 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 27/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6883 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5455580865603644\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6879 - tp: 5269.0000 - fp: 4389.0000 - tn: 5269.0000 - fn: 4389.0000 - accuracy: 0.5456 - val_loss: 0.6948 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5456 - train_specificity: 0.5456 - train_balacc: 0.5456 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 28/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6844 - tp: 4756.0000 - fp: 4006.0000 - tn: 4756.0000 - fn: 4006.0000 - accuracy: 0.5428 train_balacc 0.5419341478566991\n",
      " val_balacc 0.5888888888888889\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6846 - tp: 5234.0000 - fp: 4424.0000 - tn: 5234.0000 - fn: 4424.0000 - accuracy: 0.5419 - val_loss: 0.6773 - val_tp: 106.0000 - val_fp: 74.0000 - val_tn: 106.0000 - val_fn: 74.0000 - val_accuracy: 0.5889 - train_sensitivity: 0.5419 - train_specificity: 0.5419 - train_balacc: 0.5419 - val_sensitivity: 0.5889 - val_specificity: 0.5889 - val_balacc: 0.5889\n",
      "Epoch 29/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7001 - tp: 4960.0000 - fp: 3802.0000 - tn: 4960.0000 - fn: 3802.0000 - accuracy: 0.5661 train_balacc 0.5625388279146821\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6993 - tp: 5433.0000 - fp: 4225.0000 - tn: 5433.0000 - fn: 4225.0000 - accuracy: 0.5625 - val_loss: 0.6984 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5625 - train_specificity: 0.5625 - train_balacc: 0.5625 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 30/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6805 - tp: 4870.0000 - fp: 3892.0000 - tn: 4870.0000 - fn: 3892.0000 - accuracy: 0.5558 train_balacc 0.5540484572375233\n",
      " val_balacc 0.5444444444444444\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6810 - tp: 5351.0000 - fp: 4307.0000 - tn: 5351.0000 - fn: 4307.0000 - accuracy: 0.5540 - val_loss: 0.6876 - val_tp: 98.0000 - val_fp: 82.0000 - val_tn: 98.0000 - val_fn: 82.0000 - val_accuracy: 0.5444 - train_sensitivity: 0.5540 - train_specificity: 0.5540 - train_balacc: 0.5540 - val_sensitivity: 0.5444 - val_specificity: 0.5444 - val_balacc: 0.5444\n",
      "Epoch 31/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6842 - tp: 4860.0000 - fp: 3902.0000 - tn: 4860.0000 - fn: 3902.0000 - accuracy: 0.5547 train_balacc 0.5529095050735142\n",
      " val_balacc 0.5777777777777777\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6842 - tp: 5340.0000 - fp: 4318.0000 - tn: 5340.0000 - fn: 4318.0000 - accuracy: 0.5529 - val_loss: 0.6872 - val_tp: 104.0000 - val_fp: 76.0000 - val_tn: 104.0000 - val_fn: 76.0000 - val_accuracy: 0.5778 - train_sensitivity: 0.5529 - train_specificity: 0.5529 - train_balacc: 0.5529 - val_sensitivity: 0.5778 - val_specificity: 0.5778 - val_balacc: 0.5778\n",
      "Epoch 32/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6836 - tp: 4742.0000 - fp: 4020.0000 - tn: 4742.0000 - fn: 4020.0000 - accuracy: 0.5412 train_balacc 0.541002277904328\n",
      " val_balacc 0.6111111111111112\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6835 - tp: 5225.0000 - fp: 4433.0000 - tn: 5225.0000 - fn: 4433.0000 - accuracy: 0.5410 - val_loss: 0.6793 - val_tp: 110.0000 - val_fp: 70.0000 - val_tn: 110.0000 - val_fn: 70.0000 - val_accuracy: 0.6111 - train_sensitivity: 0.5410 - train_specificity: 0.5410 - train_balacc: 0.5410 - val_sensitivity: 0.6111 - val_specificity: 0.6111 - val_balacc: 0.6111\n",
      "Epoch 33/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6564 - tp: 4958.0000 - fp: 3804.0000 - tn: 4958.0000 - fn: 3804.0000 - accuracy: 0.5659 train_balacc 0.561192793539035\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6651 - tp: 5420.0000 - fp: 4238.0000 - tn: 5420.0000 - fn: 4238.0000 - accuracy: 0.5612 - val_loss: 0.9764 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5612 - train_specificity: 0.5612 - train_balacc: 0.5612 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 34/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7847 - tp: 4816.0000 - fp: 3946.0000 - tn: 4816.0000 - fn: 3946.0000 - accuracy: 0.5496 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7758 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6896 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 35/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6814 - tp: 4813.0000 - fp: 3949.0000 - tn: 4813.0000 - fn: 3949.0000 - accuracy: 0.5493 train_balacc 0.5475253675709256\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6812 - tp: 5288.0000 - fp: 4370.0000 - tn: 5288.0000 - fn: 4370.0000 - accuracy: 0.5475 - val_loss: 0.7035 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5475 - train_specificity: 0.5475 - train_balacc: 0.5475 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 36/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6845 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5484572375232968\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6842 - tp: 5297.0000 - fp: 4361.0000 - tn: 5297.0000 - fn: 4361.0000 - accuracy: 0.5485 - val_loss: 0.6928 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5485 - train_specificity: 0.5485 - train_balacc: 0.5485 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 37/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6846 - tp: 4829.0000 - fp: 3933.0000 - tn: 4829.0000 - fn: 3933.0000 - accuracy: 0.5511 train_balacc 0.5520811762269621\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6850 - tp: 5332.0000 - fp: 4326.0000 - tn: 5332.0000 - fn: 4326.0000 - accuracy: 0.5521 - val_loss: 0.6858 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5521 - train_specificity: 0.5521 - train_balacc: 0.5521 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 38/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6873 - tp: 4816.0000 - fp: 3946.0000 - tn: 4816.0000 - fn: 3946.0000 - accuracy: 0.5496 train_balacc 0.5500103541105819\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6862 - tp: 5312.0000 - fp: 4346.0000 - tn: 5312.0000 - fn: 4346.0000 - accuracy: 0.5500 - val_loss: 0.7043 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5500 - train_specificity: 0.5500 - train_balacc: 0.5500 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 39/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4816.0000 - fp: 3946.0000 - tn: 4816.0000 - fn: 3946.0000 - accuracy: 0.5496 train_balacc 0.551563470697867\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6887 - tp: 5327.0000 - fp: 4331.0000 - tn: 5327.0000 - fn: 4331.0000 - accuracy: 0.5516 - val_loss: 0.6819 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5516 - train_specificity: 0.5516 - train_balacc: 0.5516 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 40/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6747 - tp: 4811.0000 - fp: 3951.0000 - tn: 4811.0000 - fn: 3951.0000 - accuracy: 0.5491 train_balacc 0.5451439221370884\n",
      " val_balacc 0.5277777777777778\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6765 - tp: 5265.0000 - fp: 4393.0000 - tn: 5265.0000 - fn: 4393.0000 - accuracy: 0.5451 - val_loss: 0.6901 - val_tp: 95.0000 - val_fp: 85.0000 - val_tn: 95.0000 - val_fn: 85.0000 - val_accuracy: 0.5278 - train_sensitivity: 0.5451 - train_specificity: 0.5451 - train_balacc: 0.5451 - val_sensitivity: 0.5278 - val_specificity: 0.5278 - val_balacc: 0.5278\n",
      "Epoch 41/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6863 - tp: 5076.0000 - fp: 3686.0000 - tn: 5076.0000 - fn: 3686.0000 - accuracy: 0.5793 train_balacc 0.5780699937875337\n",
      " val_balacc 0.6333333333333333\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6861 - tp: 5583.0000 - fp: 4075.0000 - tn: 5583.0000 - fn: 4075.0000 - accuracy: 0.5781 - val_loss: 0.6786 - val_tp: 114.0000 - val_fp: 66.0000 - val_tn: 114.0000 - val_fn: 66.0000 - val_accuracy: 0.6333 - train_sensitivity: 0.5781 - train_specificity: 0.5781 - train_balacc: 0.5781 - val_sensitivity: 0.6333 - val_specificity: 0.6333 - val_balacc: 0.6333\n",
      "Epoch 42/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6788 - tp: 5416.0000 - fp: 3346.0000 - tn: 5416.0000 - fn: 3346.0000 - accuracy: 0.6181 train_balacc 0.612031476496169\n",
      " val_balacc 0.5666666666666667\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6796 - tp: 5911.0000 - fp: 3747.0000 - tn: 5911.0000 - fn: 3747.0000 - accuracy: 0.6120 - val_loss: 0.6831 - val_tp: 102.0000 - val_fp: 78.0000 - val_tn: 102.0000 - val_fn: 78.0000 - val_accuracy: 0.5667 - train_sensitivity: 0.6120 - train_specificity: 0.6120 - train_balacc: 0.6120 - val_sensitivity: 0.5667 - val_specificity: 0.5667 - val_balacc: 0.5667\n",
      "Epoch 43/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6778 - tp: 5352.0000 - fp: 3410.0000 - tn: 5352.0000 - fn: 3410.0000 - accuracy: 0.6108 train_balacc 0.6043694346655623\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6774 - tp: 5837.0000 - fp: 3821.0000 - tn: 5837.0000 - fn: 3821.0000 - accuracy: 0.6044 - val_loss: 0.7490 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.6044 - train_specificity: 0.6044 - train_balacc: 0.6044 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 44/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 2.9101 - tp: 4417.0000 - fp: 4345.0000 - tn: 4417.0000 - fn: 4345.0000 - accuracy: 0.5041 train_balacc 0.5088009939946159\n",
      " val_balacc 0.5166666666666667\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.7039 - tp: 4914.0000 - fp: 4744.0000 - tn: 4914.0000 - fn: 4744.0000 - accuracy: 0.5088 - val_loss: 0.6931 - val_tp: 93.0000 - val_fp: 87.0000 - val_tn: 93.0000 - val_fn: 87.0000 - val_accuracy: 0.5167 - train_sensitivity: 0.5088 - train_specificity: 0.5088 - train_balacc: 0.5088 - val_sensitivity: 0.5167 - val_specificity: 0.5167 - val_balacc: 0.5167\n",
      "Epoch 45/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4758.0000 - fp: 4004.0000 - tn: 4758.0000 - fn: 4004.0000 - accuracy: 0.5430 train_balacc 0.5436943466556223\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6889 - tp: 5251.0000 - fp: 4407.0000 - tn: 5251.0000 - fn: 4407.0000 - accuracy: 0.5437 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5437 - train_specificity: 0.5437 - train_balacc: 0.5437 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 46/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4800.0000 - fp: 3962.0000 - tn: 4800.0000 - fn: 3962.0000 - accuracy: 0.5478 train_balacc 0.5465934976185546\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6888 - tp: 5279.0000 - fp: 4379.0000 - tn: 5279.0000 - fn: 4379.0000 - accuracy: 0.5466 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5466 - train_specificity: 0.5466 - train_balacc: 0.5466 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 47/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6882 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5473182853592876\n",
      " val_balacc 0.5111111111111111\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6880 - tp: 5286.0000 - fp: 4372.0000 - tn: 5286.0000 - fn: 4372.0000 - accuracy: 0.5473 - val_loss: 0.6873 - val_tp: 92.0000 - val_fp: 88.0000 - val_tn: 92.0000 - val_fn: 88.0000 - val_accuracy: 0.5111 - train_sensitivity: 0.5473 - train_specificity: 0.5473 - train_balacc: 0.5473 - val_sensitivity: 0.5111 - val_specificity: 0.5111 - val_balacc: 0.5111\n",
      "Epoch 48/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 2.6889 - tp: 4533.0000 - fp: 4229.0000 - tn: 4533.0000 - fn: 4229.0000 - accuracy: 0.5173 train_balacc 0.520811762269621\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.5030 - tp: 5030.0000 - fp: 4628.0000 - tn: 5030.0000 - fn: 4628.0000 - accuracy: 0.5208 - val_loss: 0.6958 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5208 - train_specificity: 0.5208 - train_balacc: 0.5208 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 49/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7014 - tp: 4589.0000 - fp: 4173.0000 - tn: 4589.0000 - fn: 4173.0000 - accuracy: 0.5237 train_balacc 0.5249534065023814\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7007 - tp: 5070.0000 - fp: 4588.0000 - tn: 5070.0000 - fn: 4588.0000 - accuracy: 0.5250 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5250 - train_specificity: 0.5250 - train_balacc: 0.5250 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 50/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6906 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5458687098778215\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6903 - tp: 5272.0000 - fp: 4386.0000 - tn: 5272.0000 - fn: 4386.0000 - accuracy: 0.5459 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5459 - train_specificity: 0.5459 - train_balacc: 0.5459 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 51/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6875 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5473182853592876\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6871 - tp: 5286.0000 - fp: 4372.0000 - tn: 5286.0000 - fn: 4372.0000 - accuracy: 0.5473 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5473 - train_specificity: 0.5473 - train_balacc: 0.5473 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 52/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 4.8936 - tp: 4407.0000 - fp: 4355.0000 - tn: 4407.0000 - fn: 4355.0000 - accuracy: 0.5030 train_balacc 0.5067301718782357\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.5033 - tp: 4894.0000 - fp: 4764.0000 - tn: 4894.0000 - fn: 4764.0000 - accuracy: 0.5067 - val_loss: 0.6988 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5067 - train_specificity: 0.5067 - train_balacc: 0.5067 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 53/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6880 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5464899565127356\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6876 - tp: 5278.0000 - fp: 4380.0000 - tn: 5278.0000 - fn: 4380.0000 - accuracy: 0.5465 - val_loss: 0.6902 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5465 - train_specificity: 0.5465 - train_balacc: 0.5465 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 54/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6836 - tp: 4878.0000 - fp: 3884.0000 - tn: 4878.0000 - fn: 3884.0000 - accuracy: 0.5567 train_balacc 0.5573617726237317\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6834 - tp: 5383.0000 - fp: 4275.0000 - tn: 5383.0000 - fn: 4275.0000 - accuracy: 0.5574 - val_loss: 0.7738 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5574 - train_specificity: 0.5574 - train_balacc: 0.5574 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 55/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7058 - tp: 5066.0000 - fp: 3696.0000 - tn: 5066.0000 - fn: 3696.0000 - accuracy: 0.5782 train_balacc 0.5812797680679229\n",
      " val_balacc 0.6055555555555555\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7025 - tp: 5614.0000 - fp: 4044.0000 - tn: 5614.0000 - fn: 4044.0000 - accuracy: 0.5813 - val_loss: 0.7052 - val_tp: 109.0000 - val_fp: 71.0000 - val_tn: 109.0000 - val_fn: 71.0000 - val_accuracy: 0.6056 - train_sensitivity: 0.5813 - train_specificity: 0.5813 - train_balacc: 0.5813 - val_sensitivity: 0.6056 - val_specificity: 0.6056 - val_balacc: 0.6056\n",
      "Epoch 56/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7134 - tp: 4913.0000 - fp: 3849.0000 - tn: 4913.0000 - fn: 3849.0000 - accuracy: 0.5607 train_balacc 0.5590184303168357\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7105 - tp: 5399.0000 - fp: 4259.0000 - tn: 5399.0000 - fn: 4259.0000 - accuracy: 0.5590 - val_loss: 0.6872 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5590 - train_specificity: 0.5590 - train_balacc: 0.5590 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 57/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6684 - tp: 4874.0000 - fp: 3888.0000 - tn: 4874.0000 - fn: 3888.0000 - accuracy: 0.5563 train_balacc 0.5590184303168357\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6695 - tp: 5399.0000 - fp: 4259.0000 - tn: 5399.0000 - fn: 4259.0000 - accuracy: 0.5590 - val_loss: 0.7949 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5590 - train_specificity: 0.5590 - train_balacc: 0.5590 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 58/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7084 - tp: 5094.0000 - fp: 3668.0000 - tn: 5094.0000 - fn: 3668.0000 - accuracy: 0.5814 train_balacc 0.5808656036446469\n",
      " val_balacc 0.5055555555555555\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7058 - tp: 5610.0000 - fp: 4048.0000 - tn: 5610.0000 - fn: 4048.0000 - accuracy: 0.5809 - val_loss: 0.6988 - val_tp: 91.0000 - val_fp: 89.0000 - val_tn: 91.0000 - val_fn: 89.0000 - val_accuracy: 0.5056 - train_sensitivity: 0.5809 - train_specificity: 0.5809 - train_balacc: 0.5809 - val_sensitivity: 0.5056 - val_specificity: 0.5056 - val_balacc: 0.5056\n",
      "Epoch 59/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6843 - tp: 4895.0000 - fp: 3867.0000 - tn: 4895.0000 - fn: 3867.0000 - accuracy: 0.5587 train_balacc 0.5566369848829985\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6841 - tp: 5376.0000 - fp: 4282.0000 - tn: 5376.0000 - fn: 4282.0000 - accuracy: 0.5566 - val_loss: 4.1649 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5566 - train_specificity: 0.5566 - train_balacc: 0.5566 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 60/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 2.6342 - tp: 4348.0000 - fp: 4414.0000 - tn: 4348.0000 - fn: 4414.0000 - accuracy: 0.4962 train_balacc 0.4987575067301719\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.4538 - tp: 4817.0000 - fp: 4841.0000 - tn: 4817.0000 - fn: 4841.0000 - accuracy: 0.4988 - val_loss: 0.6958 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.4988 - train_specificity: 0.4988 - train_balacc: 0.4988 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 61/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6822 - tp: 4785.0000 - fp: 3977.0000 - tn: 4785.0000 - fn: 3977.0000 - accuracy: 0.5461 train_balacc 0.5459722509836406\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6823 - tp: 5273.0000 - fp: 4385.0000 - tn: 5273.0000 - fn: 4385.0000 - accuracy: 0.5460 - val_loss: 0.6881 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5460 - train_specificity: 0.5460 - train_balacc: 0.5460 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 62/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6825 - tp: 4799.0000 - fp: 3963.0000 - tn: 4799.0000 - fn: 3963.0000 - accuracy: 0.5477 train_balacc 0.5474218264651066\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6831 - tp: 5287.0000 - fp: 4371.0000 - tn: 5287.0000 - fn: 4371.0000 - accuracy: 0.5474 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5474 - train_specificity: 0.5474 - train_balacc: 0.5474 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 63/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6848 - tp: 4886.0000 - fp: 3876.0000 - tn: 4886.0000 - fn: 3876.0000 - accuracy: 0.5576 train_balacc 0.5638848622903293\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6838 - tp: 5446.0000 - fp: 4212.0000 - tn: 5446.0000 - fn: 4212.0000 - accuracy: 0.5639 - val_loss: 0.7978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5639 - train_specificity: 0.5639 - train_balacc: 0.5639 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 64/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7829 - tp: 4421.0000 - fp: 4341.0000 - tn: 4421.0000 - fn: 4341.0000 - accuracy: 0.5046 train_balacc 0.5071443363015117\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7744 - tp: 4898.0000 - fp: 4760.0000 - tn: 4898.0000 - fn: 4760.0000 - accuracy: 0.5071 - val_loss: 0.6989 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5071 - train_specificity: 0.5071 - train_balacc: 0.5071 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 65/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6879 - tp: 4801.0000 - fp: 3961.0000 - tn: 4801.0000 - fn: 3961.0000 - accuracy: 0.5479 train_balacc 0.5487678608407538\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6876 - tp: 5300.0000 - fp: 4358.0000 - tn: 5300.0000 - fn: 4358.0000 - accuracy: 0.5488 - val_loss: 0.6945 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5488 - train_specificity: 0.5488 - train_balacc: 0.5488 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 66/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6748 - tp: 4820.0000 - fp: 3942.0000 - tn: 4820.0000 - fn: 3942.0000 - accuracy: 0.5501 train_balacc 0.5496997307931248\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6738 - tp: 5309.0000 - fp: 4349.0000 - tn: 5309.0000 - fn: 4349.0000 - accuracy: 0.5497 - val_loss: 0.7920 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5497 - train_specificity: 0.5497 - train_balacc: 0.5497 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 67/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 1.4735 - tp: 4412.0000 - fp: 4350.0000 - tn: 4412.0000 - fn: 4350.0000 - accuracy: 0.5035 train_balacc 0.5059018430316836\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.4010 - tp: 4886.0000 - fp: 4772.0000 - tn: 4886.0000 - fn: 4772.0000 - accuracy: 0.5059 - val_loss: 0.6985 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5059 - train_specificity: 0.5059 - train_balacc: 0.5059 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 68/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6879 - tp: 4836.0000 - fp: 3926.0000 - tn: 4836.0000 - fn: 3926.0000 - accuracy: 0.5519 train_balacc 0.551149306274591\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6880 - tp: 5323.0000 - fp: 4335.0000 - tn: 5323.0000 - fn: 4335.0000 - accuracy: 0.5511 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5511 - train_specificity: 0.5511 - train_balacc: 0.5511 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 69/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6842 - tp: 4910.0000 - fp: 3852.0000 - tn: 4910.0000 - fn: 3852.0000 - accuracy: 0.5604 train_balacc 0.5600538413750259\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6843 - tp: 5409.0000 - fp: 4249.0000 - tn: 5409.0000 - fn: 4249.0000 - accuracy: 0.5601 - val_loss: 1.4817 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5601 - train_specificity: 0.5601 - train_balacc: 0.5601 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 70/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 1.3191 - tp: 4535.0000 - fp: 4227.0000 - tn: 4535.0000 - fn: 4227.0000 - accuracy: 0.5176 train_balacc 0.5195692689997929\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.2608 - tp: 5018.0000 - fp: 4640.0000 - tn: 5018.0000 - fn: 4640.0000 - accuracy: 0.5196 - val_loss: 0.6990 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5196 - train_specificity: 0.5196 - train_balacc: 0.5196 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 71/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6869 - tp: 4813.0000 - fp: 3949.0000 - tn: 4813.0000 - fn: 3949.0000 - accuracy: 0.5493 train_balacc 0.5465934976185546\n",
      " val_balacc 0.5333333333333333\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6876 - tp: 5279.0000 - fp: 4379.0000 - tn: 5279.0000 - fn: 4379.0000 - accuracy: 0.5466 - val_loss: 0.6872 - val_tp: 96.0000 - val_fp: 84.0000 - val_tn: 96.0000 - val_fn: 84.0000 - val_accuracy: 0.5333 - train_sensitivity: 0.5466 - train_specificity: 0.5466 - train_balacc: 0.5466 - val_sensitivity: 0.5333 - val_specificity: 0.5333 - val_balacc: 0.5333\n",
      "Epoch 72/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6814 - tp: 5071.0000 - fp: 3691.0000 - tn: 5071.0000 - fn: 3691.0000 - accuracy: 0.5787 train_balacc 0.5794160281631808\n",
      " val_balacc 0.6833333333333333\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6804 - tp: 5596.0000 - fp: 4062.0000 - tn: 5596.0000 - fn: 4062.0000 - accuracy: 0.5794 - val_loss: 0.6540 - val_tp: 123.0000 - val_fp: 57.0000 - val_tn: 123.0000 - val_fn: 57.0000 - val_accuracy: 0.6833 - train_sensitivity: 0.5794 - train_specificity: 0.5794 - train_balacc: 0.5794 - val_sensitivity: 0.6833 - val_specificity: 0.6833 - val_balacc: 0.6833\n",
      "Epoch 73/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6924 - tp: 4977.0000 - fp: 3785.0000 - tn: 4977.0000 - fn: 3785.0000 - accuracy: 0.5680 train_balacc 0.5666804721474425\n",
      " val_balacc 0.5111111111111111\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6916 - tp: 5473.0000 - fp: 4185.0000 - tn: 5473.0000 - fn: 4185.0000 - accuracy: 0.5667 - val_loss: 0.6872 - val_tp: 92.0000 - val_fp: 88.0000 - val_tn: 92.0000 - val_fn: 88.0000 - val_accuracy: 0.5111 - train_sensitivity: 0.5667 - train_specificity: 0.5667 - train_balacc: 0.5667 - val_sensitivity: 0.5111 - val_specificity: 0.5111 - val_balacc: 0.5111\n",
      "Epoch 74/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6741 - tp: 5039.0000 - fp: 3723.0000 - tn: 5039.0000 - fn: 3723.0000 - accuracy: 0.5751 train_balacc 0.5778629115758956\n",
      " val_balacc 0.5222222222222223\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6737 - tp: 5581.0000 - fp: 4077.0000 - tn: 5581.0000 - fn: 4077.0000 - accuracy: 0.5779 - val_loss: 0.6892 - val_tp: 94.0000 - val_fp: 86.0000 - val_tn: 94.0000 - val_fn: 86.0000 - val_accuracy: 0.5222 - train_sensitivity: 0.5779 - train_specificity: 0.5779 - train_balacc: 0.5779 - val_sensitivity: 0.5222 - val_specificity: 0.5222 - val_balacc: 0.5222\n",
      "Epoch 75/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6702 - tp: 5182.0000 - fp: 3580.0000 - tn: 5182.0000 - fn: 3580.0000 - accuracy: 0.5914 train_balacc 0.5946365707185752\n",
      " val_balacc 0.7111111111111111\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6693 - tp: 5743.0000 - fp: 3915.0000 - tn: 5743.0000 - fn: 3915.0000 - accuracy: 0.5946 - val_loss: 0.6297 - val_tp: 128.0000 - val_fp: 52.0000 - val_tn: 128.0000 - val_fn: 52.0000 - val_accuracy: 0.7111 - train_sensitivity: 0.5946 - train_specificity: 0.5946 - train_balacc: 0.5946 - val_sensitivity: 0.7111 - val_specificity: 0.7111 - val_balacc: 0.7111\n",
      "Epoch 76/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6872 - tp: 5244.0000 - fp: 3518.0000 - tn: 5244.0000 - fn: 3518.0000 - accuracy: 0.5985 train_balacc 0.591840960861462\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6879 - tp: 5716.0000 - fp: 3942.0000 - tn: 5716.0000 - fn: 3942.0000 - accuracy: 0.5918 - val_loss: 0.6983 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5918 - train_specificity: 0.5918 - train_balacc: 0.5918 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 77/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6863 - tp: 4785.0000 - fp: 3977.0000 - tn: 4785.0000 - fn: 3977.0000 - accuracy: 0.5461 train_balacc 0.5468005798301926\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6868 - tp: 5281.0000 - fp: 4377.0000 - tn: 5281.0000 - fn: 4377.0000 - accuracy: 0.5468 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5468 - train_specificity: 0.5468 - train_balacc: 0.5468 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 78/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6867 - tp: 4798.0000 - fp: 3964.0000 - tn: 4798.0000 - fn: 3964.0000 - accuracy: 0.5476 train_balacc 0.5476289086767446\n",
      " val_balacc 0.46111111111111114\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6853 - tp: 5289.0000 - fp: 4369.0000 - tn: 5289.0000 - fn: 4369.0000 - accuracy: 0.5476 - val_loss: 0.8258 - val_tp: 83.0000 - val_fp: 97.0000 - val_tn: 83.0000 - val_fn: 97.0000 - val_accuracy: 0.4611 - train_sensitivity: 0.5476 - train_specificity: 0.5476 - train_balacc: 0.5476 - val_sensitivity: 0.4611 - val_specificity: 0.4611 - val_balacc: 0.4611\n",
      "Epoch 79/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7433 - tp: 4714.0000 - fp: 4048.0000 - tn: 4714.0000 - fn: 4048.0000 - accuracy: 0.5380 train_balacc 0.5361358459308345\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7393 - tp: 5178.0000 - fp: 4480.0000 - tn: 5178.0000 - fn: 4480.0000 - accuracy: 0.5361 - val_loss: 0.7023 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5361 - train_specificity: 0.5361 - train_balacc: 0.5361 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 80/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4816.0000 - fp: 3946.0000 - tn: 4816.0000 - fn: 3946.0000 - accuracy: 0.5496 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6962 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 81/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6897 - tp: 4747.0000 - fp: 4015.0000 - tn: 4747.0000 - fn: 4015.0000 - accuracy: 0.5418 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 82/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4800.0000 - fp: 3962.0000 - tn: 4800.0000 - fn: 3962.0000 - accuracy: 0.5478 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 83/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4793.0000 - fp: 3969.0000 - tn: 4793.0000 - fn: 3969.0000 - accuracy: 0.5470 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 84/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 85/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4784.0000 - fp: 3978.0000 - tn: 4784.0000 - fn: 3978.0000 - accuracy: 0.5460 train_balacc 0.5455580865603644\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5269.0000 - fp: 4389.0000 - tn: 5269.0000 - fn: 4389.0000 - accuracy: 0.5456 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5456 - train_specificity: 0.5456 - train_balacc: 0.5456 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 86/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 87/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4764.0000 - fp: 3998.0000 - tn: 4764.0000 - fn: 3998.0000 - accuracy: 0.5437 train_balacc 0.5455580865603644\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5269.0000 - fp: 4389.0000 - tn: 5269.0000 - fn: 4389.0000 - accuracy: 0.5456 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5456 - train_specificity: 0.5456 - train_balacc: 0.5456 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 88/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6878 - tp: 4812.0000 - fp: 3950.0000 - tn: 4812.0000 - fn: 3950.0000 - accuracy: 0.5492 train_balacc 0.5434872644439842\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6984 - tp: 5249.0000 - fp: 4409.0000 - tn: 5249.0000 - fn: 4409.0000 - accuracy: 0.5435 - val_loss: 0.6988 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5435 - train_specificity: 0.5435 - train_balacc: 0.5435 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 89/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6985 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 90/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6950 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 91/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7301 - tp: 4576.0000 - fp: 4186.0000 - tn: 4576.0000 - fn: 4186.0000 - accuracy: 0.5223 train_balacc 0.5246427831849244\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7270 - tp: 5067.0000 - fp: 4591.0000 - tn: 5067.0000 - fn: 4591.0000 - accuracy: 0.5246 - val_loss: 0.6932 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5246 - train_specificity: 0.5246 - train_balacc: 0.5246 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 92/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.8964 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5459722509836406\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.8768 - tp: 5273.0000 - fp: 4385.0000 - tn: 5273.0000 - fn: 4385.0000 - accuracy: 0.5460 - val_loss: 0.9780 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5460 - train_specificity: 0.5460 - train_balacc: 0.5460 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 93/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.9613 - tp: 4559.0000 - fp: 4203.0000 - tn: 4559.0000 - fn: 4203.0000 - accuracy: 0.5203 train_balacc 0.5239179954441914\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.9356 - tp: 5060.0000 - fp: 4598.0000 - tn: 5060.0000 - fn: 4598.0000 - accuracy: 0.5239 - val_loss: 0.7087 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5239 - train_specificity: 0.5239 - train_balacc: 0.5239 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 94/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6910 - tp: 4866.0000 - fp: 3896.0000 - tn: 4866.0000 - fn: 3896.0000 - accuracy: 0.5554 train_balacc 0.5576723959411887\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6902 - tp: 5386.0000 - fp: 4272.0000 - tn: 5386.0000 - fn: 4272.0000 - accuracy: 0.5577 - val_loss: 0.7007 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5577 - train_specificity: 0.5577 - train_balacc: 0.5577 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 95/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7156 - tp: 5023.0000 - fp: 3739.0000 - tn: 5023.0000 - fn: 3739.0000 - accuracy: 0.5733 train_balacc 0.5687512942638228\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7136 - tp: 5493.0000 - fp: 4165.0000 - tn: 5493.0000 - fn: 4165.0000 - accuracy: 0.5688 - val_loss: 0.6988 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5688 - train_specificity: 0.5688 - train_balacc: 0.5688 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 96/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5456616276661834\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5270.0000 - fp: 4388.0000 - tn: 5270.0000 - fn: 4388.0000 - accuracy: 0.5457 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5457 - train_specificity: 0.5457 - train_balacc: 0.5457 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 97/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6856 - tp: 4779.0000 - fp: 3983.0000 - tn: 4779.0000 - fn: 3983.0000 - accuracy: 0.5454 train_balacc 0.5455580865603644\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6851 - tp: 5269.0000 - fp: 4389.0000 - tn: 5269.0000 - fn: 4389.0000 - accuracy: 0.5456 - val_loss: 0.6907 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5456 - train_specificity: 0.5456 - train_balacc: 0.5456 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 98/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6720 - tp: 4812.0000 - fp: 3950.0000 - tn: 4812.0000 - fn: 3950.0000 - accuracy: 0.5492 train_balacc 0.5461793331952786\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6811 - tp: 5275.0000 - fp: 4383.0000 - tn: 5275.0000 - fn: 4383.0000 - accuracy: 0.5462 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5462 - train_specificity: 0.5462 - train_balacc: 0.5462 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 99/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4787.0000 - fp: 3975.0000 - tn: 4787.0000 - fn: 3975.0000 - accuracy: 0.5463 train_balacc 0.5479395319942016\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6881 - tp: 5292.0000 - fp: 4366.0000 - tn: 5292.0000 - fn: 4366.0000 - accuracy: 0.5479 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5479 - train_specificity: 0.5479 - train_balacc: 0.5479 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 100/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6841 - tp: 4877.0000 - fp: 3885.0000 - tn: 4877.0000 - fn: 3885.0000 - accuracy: 0.5566 train_balacc 0.5489749430523918\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.1892 - tp: 5302.0000 - fp: 4356.0000 - tn: 5302.0000 - fn: 4356.0000 - accuracy: 0.5490 - val_loss: 0.7014 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5490 - train_specificity: 0.5490 - train_balacc: 0.5490 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 101/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6904 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5459722509836406\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6902 - tp: 5273.0000 - fp: 4385.0000 - tn: 5273.0000 - fn: 4385.0000 - accuracy: 0.5460 - val_loss: 0.6986 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5460 - train_specificity: 0.5460 - train_balacc: 0.5460 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 102/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4791.0000 - fp: 3971.0000 - tn: 4791.0000 - fn: 3971.0000 - accuracy: 0.5468 train_balacc 0.5463864154069166\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6888 - tp: 5277.0000 - fp: 4381.0000 - tn: 5277.0000 - fn: 4381.0000 - accuracy: 0.5464 - val_loss: 0.6985 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5464 - train_specificity: 0.5464 - train_balacc: 0.5464 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 103/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6883 - tp: 4808.0000 - fp: 3954.0000 - tn: 4808.0000 - fn: 3954.0000 - accuracy: 0.5487 train_balacc 0.5462828743010976\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6888 - tp: 5276.0000 - fp: 4382.0000 - tn: 5276.0000 - fn: 4382.0000 - accuracy: 0.5463 - val_loss: 0.6983 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5463 - train_specificity: 0.5463 - train_balacc: 0.5463 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 104/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6880 - tp: 4819.0000 - fp: 3943.0000 - tn: 4819.0000 - fn: 3943.0000 - accuracy: 0.5500 train_balacc 0.5466970387243736\n",
      " val_balacc 0.5055555555555555\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6887 - tp: 5280.0000 - fp: 4378.0000 - tn: 5280.0000 - fn: 4378.0000 - accuracy: 0.5467 - val_loss: 0.6912 - val_tp: 91.0000 - val_fp: 89.0000 - val_tn: 91.0000 - val_fn: 89.0000 - val_accuracy: 0.5056 - train_sensitivity: 0.5467 - train_specificity: 0.5467 - train_balacc: 0.5467 - val_sensitivity: 0.5056 - val_specificity: 0.5056 - val_balacc: 0.5056\n",
      "Epoch 105/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6835 - tp: 5076.0000 - fp: 3686.0000 - tn: 5076.0000 - fn: 3686.0000 - accuracy: 0.5793 train_balacc 0.5737212673431352\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6846 - tp: 5541.0000 - fp: 4117.0000 - tn: 5541.0000 - fn: 4117.0000 - accuracy: 0.5737 - val_loss: 0.6983 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5737 - train_specificity: 0.5737 - train_balacc: 0.5737 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 106/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4799.0000 - fp: 3963.0000 - tn: 4799.0000 - fn: 3963.0000 - accuracy: 0.5477 train_balacc 0.5472147442534686\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6885 - tp: 5285.0000 - fp: 4373.0000 - tn: 5285.0000 - fn: 4373.0000 - accuracy: 0.5472 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5472 - train_specificity: 0.5472 - train_balacc: 0.5472 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 107/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6878 - tp: 4805.0000 - fp: 3957.0000 - tn: 4805.0000 - fn: 3957.0000 - accuracy: 0.5484 train_balacc 0.5475253675709256\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6880 - tp: 5288.0000 - fp: 4370.0000 - tn: 5288.0000 - fn: 4370.0000 - accuracy: 0.5475 - val_loss: 0.6955 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5475 - train_specificity: 0.5475 - train_balacc: 0.5475 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 108/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6827 - tp: 4902.0000 - fp: 3860.0000 - tn: 4902.0000 - fn: 3860.0000 - accuracy: 0.5595 train_balacc 0.5581901014702837\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6837 - tp: 5391.0000 - fp: 4267.0000 - tn: 5391.0000 - fn: 4267.0000 - accuracy: 0.5582 - val_loss: 0.6986 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5582 - train_specificity: 0.5582 - train_balacc: 0.5582 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 109/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6858 - tp: 4851.0000 - fp: 3911.0000 - tn: 4851.0000 - fn: 3911.0000 - accuracy: 0.5536 train_balacc 0.5519776351211431\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6860 - tp: 5331.0000 - fp: 4327.0000 - tn: 5331.0000 - fn: 4327.0000 - accuracy: 0.5520 - val_loss: 0.6951 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5520 - train_specificity: 0.5520 - train_balacc: 0.5520 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 110/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7211 - tp: 4824.0000 - fp: 3938.0000 - tn: 4824.0000 - fn: 3938.0000 - accuracy: 0.5506 train_balacc 0.5468005798301926\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.7185 - tp: 5281.0000 - fp: 4377.0000 - tn: 5281.0000 - fn: 4377.0000 - accuracy: 0.5468 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5468 - train_specificity: 0.5468 - train_balacc: 0.5468 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 111/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6846 - tp: 4861.0000 - fp: 3901.0000 - tn: 4861.0000 - fn: 3901.0000 - accuracy: 0.5548 train_balacc 0.5448332988196314\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.0992 - tp: 5262.0000 - fp: 4396.0000 - tn: 5262.0000 - fn: 4396.0000 - accuracy: 0.5448 - val_loss: 0.6988 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5448 - train_specificity: 0.5448 - train_balacc: 0.5448 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 112/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4770.0000 - fp: 3992.0000 - tn: 4770.0000 - fn: 3992.0000 - accuracy: 0.5444 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6987 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 113/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4768.0000 - fp: 3994.0000 - tn: 4768.0000 - fn: 3994.0000 - accuracy: 0.5442 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6987 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 114/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6986 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 115/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6985 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 116/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.8731 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 117/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7954 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7855 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 118/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 119/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4765.0000 - fp: 3997.0000 - tn: 4765.0000 - fn: 3997.0000 - accuracy: 0.5438 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 120/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 121/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6883 - tp: 4808.0000 - fp: 3954.0000 - tn: 4808.0000 - fn: 3954.0000 - accuracy: 0.5487 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 122/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4779.0000 - fp: 3983.0000 - tn: 4779.0000 - fn: 3983.0000 - accuracy: 0.5454 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 123/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4771.0000 - fp: 3991.0000 - tn: 4771.0000 - fn: 3991.0000 - accuracy: 0.5445 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 124/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 125/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5455580865603644\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6889 - tp: 5269.0000 - fp: 4389.0000 - tn: 5269.0000 - fn: 4389.0000 - accuracy: 0.5456 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5456 - train_specificity: 0.5456 - train_balacc: 0.5456 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 126/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4795.0000 - fp: 3967.0000 - tn: 4795.0000 - fn: 3967.0000 - accuracy: 0.5472 train_balacc 0.5455580865603644\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6889 - tp: 5269.0000 - fp: 4389.0000 - tn: 5269.0000 - fn: 4389.0000 - accuracy: 0.5456 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5456 - train_specificity: 0.5456 - train_balacc: 0.5456 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 127/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 128/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4766.0000 - fp: 3996.0000 - tn: 4766.0000 - fn: 3996.0000 - accuracy: 0.5439 train_balacc 0.5455580865603644\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6889 - tp: 5269.0000 - fp: 4389.0000 - tn: 5269.0000 - fn: 4389.0000 - accuracy: 0.5456 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5456 - train_specificity: 0.5456 - train_balacc: 0.5456 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 129/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4802.0000 - fp: 3960.0000 - tn: 4802.0000 - fn: 3960.0000 - accuracy: 0.5480 train_balacc 0.5455580865603644\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6889 - tp: 5269.0000 - fp: 4389.0000 - tn: 5269.0000 - fn: 4389.0000 - accuracy: 0.5456 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5456 - train_specificity: 0.5456 - train_balacc: 0.5456 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 130/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5455580865603644\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6889 - tp: 5269.0000 - fp: 4389.0000 - tn: 5269.0000 - fn: 4389.0000 - accuracy: 0.5456 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5456 - train_specificity: 0.5456 - train_balacc: 0.5456 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 131/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5458687098778215\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6887 - tp: 5272.0000 - fp: 4386.0000 - tn: 5272.0000 - fn: 4386.0000 - accuracy: 0.5459 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5459 - train_specificity: 0.5459 - train_balacc: 0.5459 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 132/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6881 - tp: 4802.0000 - fp: 3960.0000 - tn: 4802.0000 - fn: 3960.0000 - accuracy: 0.5480 train_balacc 0.5466970387243736\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6883 - tp: 5280.0000 - fp: 4378.0000 - tn: 5280.0000 - fn: 4378.0000 - accuracy: 0.5467 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5467 - train_specificity: 0.5467 - train_balacc: 0.5467 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 133/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7105 - tp: 4657.0000 - fp: 4105.0000 - tn: 4657.0000 - fn: 4105.0000 - accuracy: 0.5315 train_balacc 0.5336508593911783\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7081 - tp: 5154.0000 - fp: 4504.0000 - tn: 5154.0000 - fn: 4504.0000 - accuracy: 0.5337 - val_loss: 0.6874 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5337 - train_specificity: 0.5337 - train_balacc: 0.5337 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 134/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.9792 - tp: 4794.0000 - fp: 3968.0000 - tn: 4794.0000 - fn: 3968.0000 - accuracy: 0.5471 train_balacc 0.5459722509836406\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.9524 - tp: 5273.0000 - fp: 4385.0000 - tn: 5273.0000 - fn: 4385.0000 - accuracy: 0.5460 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5460 - train_specificity: 0.5460 - train_balacc: 0.5460 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 135/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4788.0000 - fp: 3974.0000 - tn: 4788.0000 - fn: 3974.0000 - accuracy: 0.5465 train_balacc 0.5468005798301926\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6883 - tp: 5281.0000 - fp: 4377.0000 - tn: 5281.0000 - fn: 4377.0000 - accuracy: 0.5468 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5468 - train_specificity: 0.5468 - train_balacc: 0.5468 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 136/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6910 - tp: 4621.0000 - fp: 4141.0000 - tn: 4621.0000 - fn: 4141.0000 - accuracy: 0.5274 train_balacc 0.5288879685235038\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6909 - tp: 5108.0000 - fp: 4550.0000 - tn: 5108.0000 - fn: 4550.0000 - accuracy: 0.5289 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5289 - train_specificity: 0.5289 - train_balacc: 0.5289 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 137/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6874 - tp: 4800.0000 - fp: 3962.0000 - tn: 4800.0000 - fn: 3962.0000 - accuracy: 0.5478 train_balacc 0.5486643197349348\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6873 - tp: 5299.0000 - fp: 4359.0000 - tn: 5299.0000 - fn: 4359.0000 - accuracy: 0.5487 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5487 - train_specificity: 0.5487 - train_balacc: 0.5487 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 138/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6848 - tp: 4873.0000 - fp: 3889.0000 - tn: 4873.0000 - fn: 3889.0000 - accuracy: 0.5562 train_balacc 0.55125284738041\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6855 - tp: 5324.0000 - fp: 4334.0000 - tn: 5324.0000 - fn: 4334.0000 - accuracy: 0.5513 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5513 - train_specificity: 0.5513 - train_balacc: 0.5513 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 139/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6848 - tp: 4847.0000 - fp: 3915.0000 - tn: 4847.0000 - fn: 3915.0000 - accuracy: 0.5532 train_balacc 0.5524953406502382\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6849 - tp: 5336.0000 - fp: 4322.0000 - tn: 5336.0000 - fn: 4322.0000 - accuracy: 0.5525 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5525 - train_specificity: 0.5525 - train_balacc: 0.5525 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 140/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6844 - tp: 4851.0000 - fp: 3911.0000 - tn: 4851.0000 - fn: 3911.0000 - accuracy: 0.5536 train_balacc 0.551563470697867\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6846 - tp: 5327.0000 - fp: 4331.0000 - tn: 5327.0000 - fn: 4331.0000 - accuracy: 0.5516 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5516 - train_specificity: 0.5516 - train_balacc: 0.5516 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 141/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6847 - tp: 4820.0000 - fp: 3942.0000 - tn: 4820.0000 - fn: 3942.0000 - accuracy: 0.5501 train_balacc 0.5524953406502382\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6842 - tp: 5336.0000 - fp: 4322.0000 - tn: 5336.0000 - fn: 4322.0000 - accuracy: 0.5525 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5525 - train_specificity: 0.5525 - train_balacc: 0.5525 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 142/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6836 - tp: 4862.0000 - fp: 3900.0000 - tn: 4862.0000 - fn: 3900.0000 - accuracy: 0.5549 train_balacc 0.5537378339200663\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6839 - tp: 5348.0000 - fp: 4310.0000 - tn: 5348.0000 - fn: 4310.0000 - accuracy: 0.5537 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5537 - train_specificity: 0.5537 - train_balacc: 0.5537 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 143/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6840 - tp: 4861.0000 - fp: 3901.0000 - tn: 4861.0000 - fn: 3901.0000 - accuracy: 0.5548 train_balacc 0.5535307517084282\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6843 - tp: 5346.0000 - fp: 4312.0000 - tn: 5346.0000 - fn: 4312.0000 - accuracy: 0.5535 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5535 - train_specificity: 0.5535 - train_balacc: 0.5535 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 144/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6827 - tp: 4993.0000 - fp: 3769.0000 - tn: 4993.0000 - fn: 3769.0000 - accuracy: 0.5698 train_balacc 0.5684406709463657\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6829 - tp: 5490.0000 - fp: 4168.0000 - tn: 5490.0000 - fn: 4168.0000 - accuracy: 0.5684 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5684 - train_specificity: 0.5684 - train_balacc: 0.5684 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 145/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6828 - tp: 4860.0000 - fp: 3902.0000 - tn: 4860.0000 - fn: 3902.0000 - accuracy: 0.5547 train_balacc 0.5544626216607993\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6831 - tp: 5355.0000 - fp: 4303.0000 - tn: 5355.0000 - fn: 4303.0000 - accuracy: 0.5545 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5545 - train_specificity: 0.5545 - train_balacc: 0.5545 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 146/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6832 - tp: 4843.0000 - fp: 3919.0000 - tn: 4843.0000 - fn: 3919.0000 - accuracy: 0.5527 train_balacc 0.5543590805549803\n",
      " val_balacc 0.5111111111111111\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6827 - tp: 5354.0000 - fp: 4304.0000 - tn: 5354.0000 - fn: 4304.0000 - accuracy: 0.5544 - val_loss: 0.7022 - val_tp: 92.0000 - val_fp: 88.0000 - val_tn: 92.0000 - val_fn: 88.0000 - val_accuracy: 0.5111 - train_sensitivity: 0.5544 - train_specificity: 0.5544 - train_balacc: 0.5544 - val_sensitivity: 0.5111 - val_specificity: 0.5111 - val_balacc: 0.5111\n",
      "Epoch 147/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6900 - tp: 4868.0000 - fp: 3894.0000 - tn: 4868.0000 - fn: 3894.0000 - accuracy: 0.5556 train_balacc 0.5566369848829985\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6894 - tp: 5376.0000 - fp: 4282.0000 - tn: 5376.0000 - fn: 4282.0000 - accuracy: 0.5566 - val_loss: 0.6953 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5566 - train_specificity: 0.5566 - train_balacc: 0.5566 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 148/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6814 - tp: 4933.0000 - fp: 3829.0000 - tn: 4933.0000 - fn: 3829.0000 - accuracy: 0.5630 train_balacc 0.5590184303168357\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7138 - tp: 5399.0000 - fp: 4259.0000 - tn: 5399.0000 - fn: 4259.0000 - accuracy: 0.5590 - val_loss: 0.7012 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5590 - train_specificity: 0.5590 - train_balacc: 0.5590 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 149/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6847 - tp: 4847.0000 - fp: 3915.0000 - tn: 4847.0000 - fn: 3915.0000 - accuracy: 0.5532 train_balacc 0.551667011803686\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6850 - tp: 5328.0000 - fp: 4330.0000 - tn: 5328.0000 - fn: 4330.0000 - accuracy: 0.5517 - val_loss: 0.7007 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5517 - train_specificity: 0.5517 - train_balacc: 0.5517 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 150/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6834 - tp: 4971.0000 - fp: 3791.0000 - tn: 4971.0000 - fn: 3791.0000 - accuracy: 0.5673 train_balacc 0.5660592255125285\n",
      " val_balacc 0.4777777777777778\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6832 - tp: 5467.0000 - fp: 4191.0000 - tn: 5467.0000 - fn: 4191.0000 - accuracy: 0.5661 - val_loss: 0.7064 - val_tp: 86.0000 - val_fp: 94.0000 - val_tn: 86.0000 - val_fn: 94.0000 - val_accuracy: 0.4778 - train_sensitivity: 0.5661 - train_specificity: 0.5661 - train_balacc: 0.5661 - val_sensitivity: 0.4778 - val_specificity: 0.4778 - val_balacc: 0.4778\n",
      "Epoch 151/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6990 - tp: 4813.0000 - fp: 3949.0000 - tn: 4813.0000 - fn: 3949.0000 - accuracy: 0.5493 train_balacc 0.5519776351211431\n",
      " val_balacc 0.5166666666666667\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6975 - tp: 5331.0000 - fp: 4327.0000 - tn: 5331.0000 - fn: 4327.0000 - accuracy: 0.5520 - val_loss: 0.6869 - val_tp: 93.0000 - val_fp: 87.0000 - val_tn: 93.0000 - val_fn: 87.0000 - val_accuracy: 0.5167 - train_sensitivity: 0.5520 - train_specificity: 0.5520 - train_balacc: 0.5520 - val_sensitivity: 0.5167 - val_specificity: 0.5167 - val_balacc: 0.5167\n",
      "Epoch 152/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6791 - tp: 5020.0000 - fp: 3742.0000 - tn: 5020.0000 - fn: 3742.0000 - accuracy: 0.5729 train_balacc 0.5752743839304204\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6782 - tp: 5556.0000 - fp: 4102.0000 - tn: 5556.0000 - fn: 4102.0000 - accuracy: 0.5753 - val_loss: 0.6850 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5753 - train_specificity: 0.5753 - train_balacc: 0.5753 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 153/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6858 - tp: 4933.0000 - fp: 3829.0000 - tn: 4933.0000 - fn: 3829.0000 - accuracy: 0.5630 train_balacc 0.5549803271898944\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6876 - tp: 5360.0000 - fp: 4298.0000 - tn: 5360.0000 - fn: 4298.0000 - accuracy: 0.5550 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5550 - train_specificity: 0.5550 - train_balacc: 0.5550 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 154/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6799 - tp: 4871.0000 - fp: 3891.0000 - tn: 4871.0000 - fn: 3891.0000 - accuracy: 0.5559 train_balacc 0.5586042658935597\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6788 - tp: 5395.0000 - fp: 4263.0000 - tn: 5395.0000 - fn: 4263.0000 - accuracy: 0.5586 - val_loss: 18.4197 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5586 - train_specificity: 0.5586 - train_balacc: 0.5586 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 155/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 10.2686 - tp: 4355.0000 - fp: 4407.0000 - tn: 4355.0000 - fn: 4407.0000 - accuracy: 0.4970 train_balacc 0.5018637399047422\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 9.3798 - tp: 4847.0000 - fp: 4811.0000 - tn: 4847.0000 - fn: 4811.0000 - accuracy: 0.5019 - val_loss: 0.6994 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5019 - train_specificity: 0.5019 - train_balacc: 0.5019 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 156/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4768.0000 - fp: 3994.0000 - tn: 4768.0000 - fn: 3994.0000 - accuracy: 0.5442 train_balacc 0.5471112031476496\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6879 - tp: 5284.0000 - fp: 4374.0000 - tn: 5284.0000 - fn: 4374.0000 - accuracy: 0.5471 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5471 - train_specificity: 0.5471 - train_balacc: 0.5471 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 157/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4767.0000 - fp: 3995.0000 - tn: 4767.0000 - fn: 3995.0000 - accuracy: 0.5441 train_balacc 0.5471112031476496\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6879 - tp: 5284.0000 - fp: 4374.0000 - tn: 5284.0000 - fn: 4374.0000 - accuracy: 0.5471 - val_loss: 0.6996 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5471 - train_specificity: 0.5471 - train_balacc: 0.5471 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 158/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6871 - tp: 4796.0000 - fp: 3965.0000 - tn: 4797.0000 - fn: 3966.0000 - accuracy: 0.5474 train_balacc 0.5497515013460343\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6867 - tp: 5309.0000 - fp: 4348.0000 - tn: 5310.0000 - fn: 4349.0000 - accuracy: 0.5497 - val_loss: 0.6962 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5497 - train_specificity: 0.5498 - train_balacc: 0.5498 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 159/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6852 - tp: 4845.0000 - fp: 3917.0000 - tn: 4845.0000 - fn: 3917.0000 - accuracy: 0.5530 train_balacc 0.5525988817560572\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6855 - tp: 5337.0000 - fp: 4321.0000 - tn: 5337.0000 - fn: 4321.0000 - accuracy: 0.5526 - val_loss: 0.6950 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5526 - train_specificity: 0.5526 - train_balacc: 0.5526 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 160/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6843 - tp: 4970.0000 - fp: 3792.0000 - tn: 4970.0000 - fn: 3792.0000 - accuracy: 0.5672 train_balacc 0.5640919445019673\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6850 - tp: 5448.0000 - fp: 4210.0000 - tn: 5448.0000 - fn: 4210.0000 - accuracy: 0.5641 - val_loss: 0.7597 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5641 - train_specificity: 0.5641 - train_balacc: 0.5641 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 161/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7174 - tp: 4830.0000 - fp: 3932.0000 - tn: 4830.0000 - fn: 3932.0000 - accuracy: 0.5512 train_balacc 0.5534272106026092\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7136 - tp: 5345.0000 - fp: 4313.0000 - tn: 5345.0000 - fn: 4313.0000 - accuracy: 0.5534 - val_loss: 0.6951 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5534 - train_specificity: 0.5534 - train_balacc: 0.5534 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 162/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6791 - tp: 4963.0000 - fp: 3799.0000 - tn: 4963.0000 - fn: 3799.0000 - accuracy: 0.5664 train_balacc 0.572064609650031\n",
      " val_balacc 0.5333333333333333\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6783 - tp: 5525.0000 - fp: 4133.0000 - tn: 5525.0000 - fn: 4133.0000 - accuracy: 0.5721 - val_loss: 0.6978 - val_tp: 96.0000 - val_fp: 84.0000 - val_tn: 96.0000 - val_fn: 84.0000 - val_accuracy: 0.5333 - train_sensitivity: 0.5721 - train_specificity: 0.5721 - train_balacc: 0.5721 - val_sensitivity: 0.5333 - val_specificity: 0.5333 - val_balacc: 0.5333\n",
      "Epoch 163/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7213 - tp: 4606.0000 - fp: 4156.0000 - tn: 4606.0000 - fn: 4156.0000 - accuracy: 0.5257 train_balacc 0.5293021329467799\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7178 - tp: 5112.0000 - fp: 4546.0000 - tn: 5112.0000 - fn: 4546.0000 - accuracy: 0.5293 - val_loss: 0.7032 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5293 - train_specificity: 0.5293 - train_balacc: 0.5293 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 164/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6881 - tp: 4804.0000 - fp: 3958.0000 - tn: 4804.0000 - fn: 3958.0000 - accuracy: 0.5483 train_balacc 0.55125284738041\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6871 - tp: 5324.0000 - fp: 4334.0000 - tn: 5324.0000 - fn: 4334.0000 - accuracy: 0.5513 - val_loss: 0.7028 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5513 - train_specificity: 0.5513 - train_balacc: 0.5513 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 165/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6866 - tp: 4826.0000 - fp: 3936.0000 - tn: 4826.0000 - fn: 3936.0000 - accuracy: 0.5508 train_balacc 0.5522882584386001\n",
      " val_balacc 0.49444444444444446\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6860 - tp: 5334.0000 - fp: 4324.0000 - tn: 5334.0000 - fn: 4324.0000 - accuracy: 0.5523 - val_loss: 0.7027 - val_tp: 89.0000 - val_fp: 91.0000 - val_tn: 89.0000 - val_fn: 91.0000 - val_accuracy: 0.4944 - train_sensitivity: 0.5523 - train_specificity: 0.5523 - train_balacc: 0.5523 - val_sensitivity: 0.4944 - val_specificity: 0.4944 - val_balacc: 0.4944\n",
      "Epoch 166/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6849 - tp: 4867.0000 - fp: 3895.0000 - tn: 4867.0000 - fn: 3895.0000 - accuracy: 0.5555 train_balacc 0.5530130461793332\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6854 - tp: 5341.0000 - fp: 4317.0000 - tn: 5341.0000 - fn: 4317.0000 - accuracy: 0.5530 - val_loss: 0.7597 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5530 - train_specificity: 0.5530 - train_balacc: 0.5530 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 167/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7653 - tp: 4564.0000 - fp: 4198.0000 - tn: 4564.0000 - fn: 4198.0000 - accuracy: 0.5209 train_balacc 0.5246427831849244\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7578 - tp: 5067.0000 - fp: 4591.0000 - tn: 5067.0000 - fn: 4591.0000 - accuracy: 0.5246 - val_loss: 0.7023 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5246 - train_specificity: 0.5246 - train_balacc: 0.5246 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 168/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5485607786291158\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6882 - tp: 5298.0000 - fp: 4360.0000 - tn: 5298.0000 - fn: 4360.0000 - accuracy: 0.5486 - val_loss: 0.7017 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5486 - train_specificity: 0.5486 - train_balacc: 0.5486 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 169/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6876 - tp: 4820.0000 - fp: 3942.0000 - tn: 4820.0000 - fn: 3942.0000 - accuracy: 0.5501 train_balacc 0.5494926485814868\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6877 - tp: 5307.0000 - fp: 4351.0000 - tn: 5307.0000 - fn: 4351.0000 - accuracy: 0.5495 - val_loss: 0.7009 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5495 - train_specificity: 0.5495 - train_balacc: 0.5495 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 170/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6869 - tp: 4821.0000 - fp: 3941.0000 - tn: 4821.0000 - fn: 3941.0000 - accuracy: 0.5502 train_balacc 0.550320977428039\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6868 - tp: 5315.0000 - fp: 4343.0000 - tn: 5315.0000 - fn: 4343.0000 - accuracy: 0.5503 - val_loss: 0.7002 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5503 - train_specificity: 0.5503 - train_balacc: 0.5503 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 171/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6836 - tp: 4886.0000 - fp: 3876.0000 - tn: 4886.0000 - fn: 3876.0000 - accuracy: 0.5576 train_balacc 0.5532201283909712\n",
      " val_balacc 0.5333333333333333\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6844 - tp: 5343.0000 - fp: 4315.0000 - tn: 5343.0000 - fn: 4315.0000 - accuracy: 0.5532 - val_loss: 0.6918 - val_tp: 96.0000 - val_fp: 84.0000 - val_tn: 96.0000 - val_fn: 84.0000 - val_accuracy: 0.5333 - train_sensitivity: 0.5532 - train_specificity: 0.5532 - train_balacc: 0.5532 - val_sensitivity: 0.5333 - val_specificity: 0.5333 - val_balacc: 0.5333\n",
      "Epoch 172/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.8841 - tp: 4236.0000 - fp: 4526.0000 - tn: 4236.0000 - fn: 4526.0000 - accuracy: 0.4835 train_balacc 0.4881963139366328\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.8676 - tp: 4715.0000 - fp: 4943.0000 - tn: 4715.0000 - fn: 4943.0000 - accuracy: 0.4882 - val_loss: 0.7017 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.4882 - train_specificity: 0.4882 - train_balacc: 0.4882 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 173/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6932 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6926 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.7014 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 174/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6924 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6922 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.7009 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 175/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6900 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6902 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.7003 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 176/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6911 - tp: 4763.0000 - fp: 3999.0000 - tn: 4763.0000 - fn: 3999.0000 - accuracy: 0.5436 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6906 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.7000 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 177/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6911 - tp: 4788.0000 - fp: 3974.0000 - tn: 4788.0000 - fn: 3974.0000 - accuracy: 0.5465 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6912 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6995 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 178/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4769.0000 - fp: 3993.0000 - tn: 4769.0000 - fn: 3993.0000 - accuracy: 0.5443 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6992 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 179/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6988 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 180/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4793.0000 - fp: 3969.0000 - tn: 4793.0000 - fn: 3969.0000 - accuracy: 0.5470 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 181/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4763.0000 - fp: 3999.0000 - tn: 4763.0000 - fn: 3999.0000 - accuracy: 0.5436 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6983 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 182/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 183/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4800.0000 - fp: 3962.0000 - tn: 4800.0000 - fn: 3962.0000 - accuracy: 0.5478 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 184/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4761.0000 - fp: 4001.0000 - tn: 4761.0000 - fn: 4001.0000 - accuracy: 0.5434 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 185/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4784.0000 - fp: 3978.0000 - tn: 4784.0000 - fn: 3978.0000 - accuracy: 0.5460 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 186/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4767.0000 - fp: 3995.0000 - tn: 4767.0000 - fn: 3995.0000 - accuracy: 0.5441 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 187/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4768.0000 - fp: 3994.0000 - tn: 4768.0000 - fn: 3994.0000 - accuracy: 0.5442 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6980 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 188/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4791.0000 - fp: 3971.0000 - tn: 4791.0000 - fn: 3971.0000 - accuracy: 0.5468 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 189/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4774.0000 - fp: 3988.0000 - tn: 4774.0000 - fn: 3988.0000 - accuracy: 0.5449 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7093 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6959 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 190/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6895 - tp: 4759.0000 - fp: 4003.0000 - tn: 4759.0000 - fn: 4003.0000 - accuracy: 0.5431 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6892 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6962 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 191/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4766.0000 - fp: 3996.0000 - tn: 4766.0000 - fn: 3996.0000 - accuracy: 0.5439 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 192/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 193/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4801.0000 - fp: 3961.0000 - tn: 4801.0000 - fn: 3961.0000 - accuracy: 0.5479 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 194/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4802.0000 - fp: 3960.0000 - tn: 4802.0000 - fn: 3960.0000 - accuracy: 0.5480 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6963 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 195/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 196/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4788.0000 - fp: 3974.0000 - tn: 4788.0000 - fn: 3974.0000 - accuracy: 0.5465 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 197/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4794.0000 - fp: 3968.0000 - tn: 4794.0000 - fn: 3968.0000 - accuracy: 0.5471 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 198/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 199/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6883 - tp: 4805.0000 - fp: 3957.0000 - tn: 4805.0000 - fn: 3957.0000 - accuracy: 0.5484 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 200/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4793.0000 - fp: 3969.0000 - tn: 4793.0000 - fn: 3969.0000 - accuracy: 0.5470 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 201/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 202/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4796.0000 - fp: 3966.0000 - tn: 4796.0000 - fn: 3966.0000 - accuracy: 0.5474 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 203/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4779.0000 - fp: 3983.0000 - tn: 4779.0000 - fn: 3983.0000 - accuracy: 0.5454 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 204/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4785.0000 - fp: 3977.0000 - tn: 4785.0000 - fn: 3977.0000 - accuracy: 0.5461 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 205/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4770.0000 - fp: 3992.0000 - tn: 4770.0000 - fn: 3992.0000 - accuracy: 0.5444 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 206/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4794.0000 - fp: 3968.0000 - tn: 4794.0000 - fn: 3968.0000 - accuracy: 0.5471 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 207/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 208/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4760.0000 - fp: 4002.0000 - tn: 4760.0000 - fn: 4002.0000 - accuracy: 0.5433 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6980 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 209/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 210/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6880 - tp: 4815.0000 - fp: 3947.0000 - tn: 4815.0000 - fn: 3947.0000 - accuracy: 0.5495 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 211/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4753.0000 - fp: 4009.0000 - tn: 4753.0000 - fn: 4009.0000 - accuracy: 0.5425 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 212/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4762.0000 - fp: 4000.0000 - tn: 4762.0000 - fn: 4000.0000 - accuracy: 0.5435 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 213/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6978 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 214/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6889 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 215/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6897 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6896 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 216/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 217/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4758.0000 - fp: 4004.0000 - tn: 4758.0000 - fn: 4004.0000 - accuracy: 0.5430 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 218/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6896 - tp: 4769.0000 - fp: 3993.0000 - tn: 4769.0000 - fn: 3993.0000 - accuracy: 0.5443 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6894 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 219/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4765.0000 - fp: 3997.0000 - tn: 4765.0000 - fn: 3997.0000 - accuracy: 0.5438 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 220/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6888 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6757 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 221/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 2.1695 - tp: 4798.0000 - fp: 3964.0000 - tn: 4798.0000 - fn: 3964.0000 - accuracy: 0.5476 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.0325 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6958 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 222/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4764.0000 - fp: 3998.0000 - tn: 4764.0000 - fn: 3998.0000 - accuracy: 0.5437 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6892 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6960 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 223/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6961 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 224/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4796.0000 - fp: 3966.0000 - tn: 4796.0000 - fn: 3966.0000 - accuracy: 0.5474 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6961 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 225/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4787.0000 - fp: 3975.0000 - tn: 4787.0000 - fn: 3975.0000 - accuracy: 0.5463 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6962 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 226/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6963 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 227/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 228/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 229/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4761.0000 - fp: 4001.0000 - tn: 4761.0000 - fn: 4001.0000 - accuracy: 0.5434 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 230/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4796.0000 - fp: 3966.0000 - tn: 4796.0000 - fn: 3966.0000 - accuracy: 0.5474 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 231/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4761.0000 - fp: 4001.0000 - tn: 4761.0000 - fn: 4001.0000 - accuracy: 0.5434 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 232/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 233/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 234/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 235/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 236/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6898 - tp: 4740.0000 - fp: 4022.0000 - tn: 4740.0000 - fn: 4022.0000 - accuracy: 0.5410 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6980 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 237/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 238/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4770.0000 - fp: 3992.0000 - tn: 4770.0000 - fn: 3992.0000 - accuracy: 0.5444 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 239/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4793.0000 - fp: 3969.0000 - tn: 4793.0000 - fn: 3969.0000 - accuracy: 0.5470 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 240/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 241/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4785.0000 - fp: 3977.0000 - tn: 4785.0000 - fn: 3977.0000 - accuracy: 0.5461 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 242/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4767.0000 - fp: 3995.0000 - tn: 4767.0000 - fn: 3995.0000 - accuracy: 0.5441 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 243/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 244/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 245/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4774.0000 - fp: 3988.0000 - tn: 4774.0000 - fn: 3988.0000 - accuracy: 0.5449 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 246/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 247/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 248/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6895 - tp: 4755.0000 - fp: 4007.0000 - tn: 4755.0000 - fn: 4007.0000 - accuracy: 0.5427 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 249/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4779.0000 - fp: 3983.0000 - tn: 4779.0000 - fn: 3983.0000 - accuracy: 0.5454 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 250/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4784.0000 - fp: 3978.0000 - tn: 4784.0000 - fn: 3978.0000 - accuracy: 0.5460 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 251/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4796.0000 - fp: 3966.0000 - tn: 4796.0000 - fn: 3966.0000 - accuracy: 0.5474 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 252/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 253/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 254/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 255/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 256/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4762.0000 - fp: 4000.0000 - tn: 4762.0000 - fn: 4000.0000 - accuracy: 0.5435 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 257/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4764.0000 - fp: 3998.0000 - tn: 4764.0000 - fn: 3998.0000 - accuracy: 0.5437 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6984 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 258/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4791.0000 - fp: 3971.0000 - tn: 4791.0000 - fn: 3971.0000 - accuracy: 0.5468 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 259/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 260/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4763.0000 - fp: 3999.0000 - tn: 4763.0000 - fn: 3999.0000 - accuracy: 0.5436 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 261/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4767.0000 - fp: 3995.0000 - tn: 4767.0000 - fn: 3995.0000 - accuracy: 0.5441 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 262/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 263/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 264/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4769.0000 - fp: 3993.0000 - tn: 4769.0000 - fn: 3993.0000 - accuracy: 0.5443 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 265/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4779.0000 - fp: 3983.0000 - tn: 4779.0000 - fn: 3983.0000 - accuracy: 0.5454 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 266/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4797.0000 - fp: 3965.0000 - tn: 4797.0000 - fn: 3965.0000 - accuracy: 0.5475 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 267/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4807.0000 - fp: 3955.0000 - tn: 4807.0000 - fn: 3955.0000 - accuracy: 0.5486 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6962 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 268/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4810.0000 - fp: 3952.0000 - tn: 4810.0000 - fn: 3952.0000 - accuracy: 0.5490 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6959 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 269/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4765.0000 - fp: 3997.0000 - tn: 4765.0000 - fn: 3997.0000 - accuracy: 0.5438 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 270/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4774.0000 - fp: 3988.0000 - tn: 4774.0000 - fn: 3988.0000 - accuracy: 0.5449 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 271/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 272/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4784.0000 - fp: 3978.0000 - tn: 4784.0000 - fn: 3978.0000 - accuracy: 0.5460 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 273/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4799.0000 - fp: 3963.0000 - tn: 4799.0000 - fn: 3963.0000 - accuracy: 0.5477 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 274/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 275/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 276/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6896 - tp: 4754.0000 - fp: 4008.0000 - tn: 4754.0000 - fn: 4008.0000 - accuracy: 0.5426 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 277/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4774.0000 - fp: 3988.0000 - tn: 4774.0000 - fn: 3988.0000 - accuracy: 0.5449 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 278/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 279/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 280/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 281/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4784.0000 - fp: 3978.0000 - tn: 4784.0000 - fn: 3978.0000 - accuracy: 0.5460 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 282/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4791.0000 - fp: 3971.0000 - tn: 4791.0000 - fn: 3971.0000 - accuracy: 0.5468 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 283/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6896 - tp: 4750.0000 - fp: 4012.0000 - tn: 4750.0000 - fn: 4012.0000 - accuracy: 0.5421 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 284/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6896 - tp: 4755.0000 - fp: 4007.0000 - tn: 4755.0000 - fn: 4007.0000 - accuracy: 0.5427 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6984 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 285/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4789.0000 - fp: 3973.0000 - tn: 4789.0000 - fn: 3973.0000 - accuracy: 0.5466 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 286/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4787.0000 - fp: 3975.0000 - tn: 4787.0000 - fn: 3975.0000 - accuracy: 0.5463 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 287/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 288/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4761.0000 - fp: 4001.0000 - tn: 4761.0000 - fn: 4001.0000 - accuracy: 0.5434 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6980 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 289/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4774.0000 - fp: 3988.0000 - tn: 4774.0000 - fn: 3988.0000 - accuracy: 0.5449 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 290/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4785.0000 - fp: 3977.0000 - tn: 4785.0000 - fn: 3977.0000 - accuracy: 0.5461 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 291/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4768.0000 - fp: 3994.0000 - tn: 4768.0000 - fn: 3994.0000 - accuracy: 0.5442 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 292/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 293/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 294/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6895 - tp: 4755.0000 - fp: 4007.0000 - tn: 4755.0000 - fn: 4007.0000 - accuracy: 0.5427 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6985 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 295/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 296/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4789.0000 - fp: 3973.0000 - tn: 4789.0000 - fn: 3973.0000 - accuracy: 0.5466 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 297/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 298/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 299/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4791.0000 - fp: 3971.0000 - tn: 4791.0000 - fn: 3971.0000 - accuracy: 0.5468 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 300/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 301/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4795.0000 - fp: 3967.0000 - tn: 4795.0000 - fn: 3967.0000 - accuracy: 0.5472 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 302/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 303/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4771.0000 - fp: 3991.0000 - tn: 4771.0000 - fn: 3991.0000 - accuracy: 0.5445 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 304/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 305/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6896 - tp: 4750.0000 - fp: 4012.0000 - tn: 4750.0000 - fn: 4012.0000 - accuracy: 0.5421 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 306/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4785.0000 - fp: 3977.0000 - tn: 4785.0000 - fn: 3977.0000 - accuracy: 0.5461 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 307/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 308/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 309/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6895 - tp: 4754.0000 - fp: 4008.0000 - tn: 4754.0000 - fn: 4008.0000 - accuracy: 0.5426 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 310/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4807.0000 - fp: 3955.0000 - tn: 4807.0000 - fn: 3955.0000 - accuracy: 0.5486 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 311/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4771.0000 - fp: 3991.0000 - tn: 4771.0000 - fn: 3991.0000 - accuracy: 0.5445 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 312/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4785.0000 - fp: 3977.0000 - tn: 4785.0000 - fn: 3977.0000 - accuracy: 0.5461 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 313/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 314/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4768.0000 - fp: 3994.0000 - tn: 4768.0000 - fn: 3994.0000 - accuracy: 0.5442 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 315/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4766.0000 - fp: 3996.0000 - tn: 4766.0000 - fn: 3996.0000 - accuracy: 0.5439 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6980 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 316/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4801.0000 - fp: 3961.0000 - tn: 4801.0000 - fn: 3961.0000 - accuracy: 0.5479 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 317/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 318/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4784.0000 - fp: 3978.0000 - tn: 4784.0000 - fn: 3978.0000 - accuracy: 0.5460 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 319/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 320/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4801.0000 - fp: 3961.0000 - tn: 4801.0000 - fn: 3961.0000 - accuracy: 0.5479 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 321/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4795.0000 - fp: 3967.0000 - tn: 4795.0000 - fn: 3967.0000 - accuracy: 0.5472 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6963 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 322/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4797.0000 - fp: 3965.0000 - tn: 4797.0000 - fn: 3965.0000 - accuracy: 0.5475 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6962 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 323/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 324/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4768.0000 - fp: 3994.0000 - tn: 4768.0000 - fn: 3994.0000 - accuracy: 0.5442 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 325/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 326/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 327/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 328/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6880 - tp: 4829.0000 - fp: 3933.0000 - tn: 4829.0000 - fn: 3933.0000 - accuracy: 0.5511 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 329/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 330/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4795.0000 - fp: 3967.0000 - tn: 4795.0000 - fn: 3967.0000 - accuracy: 0.5472 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 331/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 332/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4788.0000 - fp: 3974.0000 - tn: 4788.0000 - fn: 3974.0000 - accuracy: 0.5465 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 333/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6895 - tp: 4757.0000 - fp: 4005.0000 - tn: 4757.0000 - fn: 4005.0000 - accuracy: 0.5429 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 334/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4771.0000 - fp: 3991.0000 - tn: 4771.0000 - fn: 3991.0000 - accuracy: 0.5445 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 335/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 336/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 337/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4800.0000 - fp: 3962.0000 - tn: 4800.0000 - fn: 3962.0000 - accuracy: 0.5478 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 338/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4769.0000 - fp: 3993.0000 - tn: 4769.0000 - fn: 3993.0000 - accuracy: 0.5443 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 339/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 340/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4796.0000 - fp: 3966.0000 - tn: 4796.0000 - fn: 3966.0000 - accuracy: 0.5474 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 341/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4774.0000 - fp: 3988.0000 - tn: 4774.0000 - fn: 3988.0000 - accuracy: 0.5449 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 342/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4764.0000 - fp: 3998.0000 - tn: 4764.0000 - fn: 3998.0000 - accuracy: 0.5437 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 343/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 344/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4804.0000 - fp: 3958.0000 - tn: 4804.0000 - fn: 3958.0000 - accuracy: 0.5483 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 345/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4806.0000 - fp: 3956.0000 - tn: 4806.0000 - fn: 3956.0000 - accuracy: 0.5485 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6961 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 346/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 347/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 348/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 349/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4771.0000 - fp: 3991.0000 - tn: 4771.0000 - fn: 3991.0000 - accuracy: 0.5445 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 350/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4789.0000 - fp: 3973.0000 - tn: 4789.0000 - fn: 3973.0000 - accuracy: 0.5466 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 351/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4771.0000 - fp: 3991.0000 - tn: 4771.0000 - fn: 3991.0000 - accuracy: 0.5445 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 352/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 353/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4763.0000 - fp: 3999.0000 - tn: 4763.0000 - fn: 3999.0000 - accuracy: 0.5436 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 354/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4802.0000 - fp: 3960.0000 - tn: 4802.0000 - fn: 3960.0000 - accuracy: 0.5480 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 355/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4801.0000 - fp: 3961.0000 - tn: 4801.0000 - fn: 3961.0000 - accuracy: 0.5479 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 356/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4765.0000 - fp: 3997.0000 - tn: 4765.0000 - fn: 3997.0000 - accuracy: 0.5438 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 357/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4802.0000 - fp: 3960.0000 - tn: 4802.0000 - fn: 3960.0000 - accuracy: 0.5480 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 358/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4787.0000 - fp: 3975.0000 - tn: 4787.0000 - fn: 3975.0000 - accuracy: 0.5463 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 359/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4789.0000 - fp: 3973.0000 - tn: 4789.0000 - fn: 3973.0000 - accuracy: 0.5466 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 360/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6895 - tp: 4756.0000 - fp: 4006.0000 - tn: 4756.0000 - fn: 4006.0000 - accuracy: 0.5428 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 361/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6883 - tp: 4814.0000 - fp: 3948.0000 - tn: 4814.0000 - fn: 3948.0000 - accuracy: 0.5494 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 362/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4811.0000 - fp: 3951.0000 - tn: 4811.0000 - fn: 3951.0000 - accuracy: 0.5491 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6963 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 363/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4801.0000 - fp: 3961.0000 - tn: 4801.0000 - fn: 3961.0000 - accuracy: 0.5479 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6962 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 364/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 365/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 366/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 367/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4808.0000 - fp: 3954.0000 - tn: 4808.0000 - fn: 3954.0000 - accuracy: 0.5487 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 368/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4760.0000 - fp: 4002.0000 - tn: 4760.0000 - fn: 4002.0000 - accuracy: 0.5433 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 369/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6898 - tp: 4743.0000 - fp: 4019.0000 - tn: 4743.0000 - fn: 4019.0000 - accuracy: 0.5413 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 370/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4794.0000 - fp: 3968.0000 - tn: 4794.0000 - fn: 3968.0000 - accuracy: 0.5471 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 371/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4805.0000 - fp: 3957.0000 - tn: 4805.0000 - fn: 3957.0000 - accuracy: 0.5484 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 372/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4765.0000 - fp: 3997.0000 - tn: 4765.0000 - fn: 3997.0000 - accuracy: 0.5438 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 373/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4797.0000 - fp: 3965.0000 - tn: 4797.0000 - fn: 3965.0000 - accuracy: 0.5475 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 374/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4767.0000 - fp: 3995.0000 - tn: 4767.0000 - fn: 3995.0000 - accuracy: 0.5441 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 375/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4799.0000 - fp: 3963.0000 - tn: 4799.0000 - fn: 3963.0000 - accuracy: 0.5477 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 376/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4800.0000 - fp: 3962.0000 - tn: 4800.0000 - fn: 3962.0000 - accuracy: 0.5478 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 377/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4787.0000 - fp: 3975.0000 - tn: 4787.0000 - fn: 3975.0000 - accuracy: 0.5463 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 378/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 379/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 380/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 381/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4789.0000 - fp: 3973.0000 - tn: 4789.0000 - fn: 3973.0000 - accuracy: 0.5466 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 382/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4785.0000 - fp: 3977.0000 - tn: 4785.0000 - fn: 3977.0000 - accuracy: 0.5461 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 383/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 384/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4769.0000 - fp: 3993.0000 - tn: 4769.0000 - fn: 3993.0000 - accuracy: 0.5443 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 385/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4771.0000 - fp: 3991.0000 - tn: 4771.0000 - fn: 3991.0000 - accuracy: 0.5445 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 386/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 387/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6896 - tp: 4750.0000 - fp: 4012.0000 - tn: 4750.0000 - fn: 4012.0000 - accuracy: 0.5421 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 388/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 389/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4797.0000 - fp: 3965.0000 - tn: 4797.0000 - fn: 3965.0000 - accuracy: 0.5475 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 390/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4766.0000 - fp: 3996.0000 - tn: 4766.0000 - fn: 3996.0000 - accuracy: 0.5439 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 391/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4770.0000 - fp: 3992.0000 - tn: 4770.0000 - fn: 3992.0000 - accuracy: 0.5444 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 392/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4788.0000 - fp: 3974.0000 - tn: 4788.0000 - fn: 3974.0000 - accuracy: 0.5465 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 393/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4784.0000 - fp: 3978.0000 - tn: 4784.0000 - fn: 3978.0000 - accuracy: 0.5460 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 394/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4805.0000 - fp: 3957.0000 - tn: 4805.0000 - fn: 3957.0000 - accuracy: 0.5484 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6964 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 395/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4762.0000 - fp: 4000.0000 - tn: 4762.0000 - fn: 4000.0000 - accuracy: 0.5435 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 396/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 397/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4762.0000 - fp: 4000.0000 - tn: 4762.0000 - fn: 4000.0000 - accuracy: 0.5435 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 398/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6896 - tp: 4753.0000 - fp: 4009.0000 - tn: 4753.0000 - fn: 4009.0000 - accuracy: 0.5425 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6983 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 399/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4794.0000 - fp: 3968.0000 - tn: 4794.0000 - fn: 3968.0000 - accuracy: 0.5471 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 400/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 401/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 402/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4760.0000 - fp: 4002.0000 - tn: 4760.0000 - fn: 4002.0000 - accuracy: 0.5433 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6980 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 403/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4805.0000 - fp: 3957.0000 - tn: 4805.0000 - fn: 3957.0000 - accuracy: 0.5484 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 404/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 405/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 406/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 407/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6895 - tp: 4756.0000 - fp: 4006.0000 - tn: 4756.0000 - fn: 4006.0000 - accuracy: 0.5428 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 408/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 409/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 410/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4810.0000 - fp: 3952.0000 - tn: 4810.0000 - fn: 3952.0000 - accuracy: 0.5490 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 411/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4771.0000 - fp: 3991.0000 - tn: 4771.0000 - fn: 3991.0000 - accuracy: 0.5445 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 412/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 413/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4794.0000 - fp: 3968.0000 - tn: 4794.0000 - fn: 3968.0000 - accuracy: 0.5471 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 414/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 415/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 416/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4766.0000 - fp: 3996.0000 - tn: 4766.0000 - fn: 3996.0000 - accuracy: 0.5439 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 417/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 418/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4779.0000 - fp: 3983.0000 - tn: 4779.0000 - fn: 3983.0000 - accuracy: 0.5454 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 419/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 420/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4770.0000 - fp: 3992.0000 - tn: 4770.0000 - fn: 3992.0000 - accuracy: 0.5444 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6980 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 421/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 422/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4764.0000 - fp: 3998.0000 - tn: 4764.0000 - fn: 3998.0000 - accuracy: 0.5437 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 423/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 424/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4770.0000 - fp: 3992.0000 - tn: 4770.0000 - fn: 3992.0000 - accuracy: 0.5444 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 425/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4784.0000 - fp: 3978.0000 - tn: 4784.0000 - fn: 3978.0000 - accuracy: 0.5460 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 426/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 427/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 428/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4799.0000 - fp: 3963.0000 - tn: 4799.0000 - fn: 3963.0000 - accuracy: 0.5477 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 429/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4774.0000 - fp: 3988.0000 - tn: 4774.0000 - fn: 3988.0000 - accuracy: 0.5449 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 430/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4787.0000 - fp: 3975.0000 - tn: 4787.0000 - fn: 3975.0000 - accuracy: 0.5463 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 431/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4782.0000 - fp: 3980.0000 - tn: 4782.0000 - fn: 3980.0000 - accuracy: 0.5458 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6892 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 432/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4769.0000 - fp: 3993.0000 - tn: 4769.0000 - fn: 3993.0000 - accuracy: 0.5443 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 433/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 434/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4799.0000 - fp: 3963.0000 - tn: 4799.0000 - fn: 3963.0000 - accuracy: 0.5477 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 435/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 436/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4776.0000 - fp: 3986.0000 - tn: 4776.0000 - fn: 3986.0000 - accuracy: 0.5451 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 437/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4795.0000 - fp: 3967.0000 - tn: 4795.0000 - fn: 3967.0000 - accuracy: 0.5472 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 438/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4762.0000 - fp: 4000.0000 - tn: 4762.0000 - fn: 4000.0000 - accuracy: 0.5435 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6977 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 439/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6884 - tp: 4808.0000 - fp: 3954.0000 - tn: 4808.0000 - fn: 3954.0000 - accuracy: 0.5487 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 440/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4801.0000 - fp: 3961.0000 - tn: 4801.0000 - fn: 3961.0000 - accuracy: 0.5479 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 441/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4798.0000 - fp: 3964.0000 - tn: 4798.0000 - fn: 3964.0000 - accuracy: 0.5476 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6963 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 442/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4773.0000 - fp: 3989.0000 - tn: 4773.0000 - fn: 3989.0000 - accuracy: 0.5447 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 443/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 444/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4787.0000 - fp: 3975.0000 - tn: 4787.0000 - fn: 3975.0000 - accuracy: 0.5463 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 445/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4769.0000 - fp: 3993.0000 - tn: 4769.0000 - fn: 3993.0000 - accuracy: 0.5443 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 446/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4762.0000 - fp: 4000.0000 - tn: 4762.0000 - fn: 4000.0000 - accuracy: 0.5435 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 447/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4774.0000 - fp: 3988.0000 - tn: 4774.0000 - fn: 3988.0000 - accuracy: 0.5449 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6979 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 448/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4763.0000 - fp: 3999.0000 - tn: 4763.0000 - fn: 3999.0000 - accuracy: 0.5436 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 449/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 450/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 451/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6883 - tp: 4812.0000 - fp: 3950.0000 - tn: 4812.0000 - fn: 3950.0000 - accuracy: 0.5492 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 452/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 453/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 454/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 455/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6896 - tp: 4751.0000 - fp: 4011.0000 - tn: 4751.0000 - fn: 4011.0000 - accuracy: 0.5422 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 456/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4792.0000 - fp: 3970.0000 - tn: 4792.0000 - fn: 3970.0000 - accuracy: 0.5469 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 457/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4794.0000 - fp: 3968.0000 - tn: 4794.0000 - fn: 3968.0000 - accuracy: 0.5471 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 458/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4788.0000 - fp: 3974.0000 - tn: 4788.0000 - fn: 3974.0000 - accuracy: 0.5465 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 459/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4784.0000 - fp: 3978.0000 - tn: 4784.0000 - fn: 3978.0000 - accuracy: 0.5460 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 460/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 461/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4762.0000 - fp: 4000.0000 - tn: 4762.0000 - fn: 4000.0000 - accuracy: 0.5435 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 462/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6974 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 463/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4763.0000 - fp: 3999.0000 - tn: 4763.0000 - fn: 3999.0000 - accuracy: 0.5436 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 464/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6895 - tp: 4758.0000 - fp: 4004.0000 - tn: 4758.0000 - fn: 4004.0000 - accuracy: 0.5430 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6984 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 465/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6893 - tp: 4770.0000 - fp: 3992.0000 - tn: 4770.0000 - fn: 3992.0000 - accuracy: 0.5444 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6982 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 466/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 467/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6894 - tp: 4762.0000 - fp: 4000.0000 - tn: 4762.0000 - fn: 4000.0000 - accuracy: 0.5435 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6981 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 468/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4795.0000 - fp: 3967.0000 - tn: 4795.0000 - fn: 3967.0000 - accuracy: 0.5472 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 469/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4788.0000 - fp: 3974.0000 - tn: 4788.0000 - fn: 3974.0000 - accuracy: 0.5465 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 470/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4799.0000 - fp: 3963.0000 - tn: 4799.0000 - fn: 3963.0000 - accuracy: 0.5477 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 471/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4797.0000 - fp: 3965.0000 - tn: 4797.0000 - fn: 3965.0000 - accuracy: 0.5475 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6963 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 472/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 473/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4804.0000 - fp: 3958.0000 - tn: 4804.0000 - fn: 3958.0000 - accuracy: 0.5483 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6963 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 474/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4772.0000 - fp: 3990.0000 - tn: 4772.0000 - fn: 3990.0000 - accuracy: 0.5446 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 475/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4769.0000 - fp: 3993.0000 - tn: 4769.0000 - fn: 3993.0000 - accuracy: 0.5443 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 476/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4771.0000 - fp: 3991.0000 - tn: 4771.0000 - fn: 3991.0000 - accuracy: 0.5445 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6978 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 477/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6976 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 478/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6883 - tp: 4812.0000 - fp: 3950.0000 - tn: 4812.0000 - fn: 3950.0000 - accuracy: 0.5492 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 479/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 480/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4783.0000 - fp: 3979.0000 - tn: 4783.0000 - fn: 3979.0000 - accuracy: 0.5459 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 481/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 482/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4791.0000 - fp: 3971.0000 - tn: 4791.0000 - fn: 3971.0000 - accuracy: 0.5468 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6968 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 483/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4780.0000 - fp: 3982.0000 - tn: 4780.0000 - fn: 3982.0000 - accuracy: 0.5455 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 484/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6975 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 485/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 486/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6889 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6969 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 487/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6972 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 488/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4796.0000 - fp: 3966.0000 - tn: 4796.0000 - fn: 3966.0000 - accuracy: 0.5474 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 489/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4778.0000 - fp: 3984.0000 - tn: 4778.0000 - fn: 3984.0000 - accuracy: 0.5453 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 490/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6887 - tp: 4793.0000 - fp: 3969.0000 - tn: 4793.0000 - fn: 3969.0000 - accuracy: 0.5470 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6966 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 491/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6891 - tp: 4775.0000 - fp: 3987.0000 - tn: 4775.0000 - fn: 3987.0000 - accuracy: 0.5450 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6973 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 492/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4781.0000 - fp: 3981.0000 - tn: 4781.0000 - fn: 3981.0000 - accuracy: 0.5457 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6971 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 493/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4799.0000 - fp: 3963.0000 - tn: 4799.0000 - fn: 3963.0000 - accuracy: 0.5477 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 494/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4802.0000 - fp: 3960.0000 - tn: 4802.0000 - fn: 3960.0000 - accuracy: 0.5480 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6962 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 495/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4786.0000 - fp: 3976.0000 - tn: 4786.0000 - fn: 3976.0000 - accuracy: 0.5462 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 496/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6890 - tp: 4779.0000 - fp: 3983.0000 - tn: 4779.0000 - fn: 3983.0000 - accuracy: 0.5454 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6970 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 497/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6888 - tp: 4790.0000 - fp: 3972.0000 - tn: 4790.0000 - fn: 3972.0000 - accuracy: 0.5467 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6890 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6967 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 498/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6886 - tp: 4802.0000 - fp: 3960.0000 - tn: 4802.0000 - fn: 3960.0000 - accuracy: 0.5480 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6962 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 499/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6885 - tp: 4815.0000 - fp: 3947.0000 - tn: 4815.0000 - fn: 3947.0000 - accuracy: 0.5495 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6959 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n",
      "Epoch 500/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6892 - tp: 4777.0000 - fp: 3985.0000 - tn: 4777.0000 - fn: 3985.0000 - accuracy: 0.5452 train_balacc 0.5454545454545454\n",
      " val_balacc 0.5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6891 - tp: 5268.0000 - fp: 4390.0000 - tn: 5268.0000 - fn: 4390.0000 - accuracy: 0.5455 - val_loss: 0.6965 - val_tp: 90.0000 - val_fp: 90.0000 - val_tn: 90.0000 - val_fn: 90.0000 - val_accuracy: 0.5000 - train_sensitivity: 0.5455 - train_specificity: 0.5455 - train_balacc: 0.5455 - val_sensitivity: 0.5000 - val_specificity: 0.5000 - val_balacc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 4381\n",
    "y_labels = to_categorical(y_train, 2)\n",
    "X_val = np.reshape(X_val, (len(X_val),28,28,3))\n",
    "y_val_labels = to_categorical(y_val, 2)\n",
    "model_cnn = models.Sequential()\n",
    "model_cnn.add(Conv2D(32, (5,5), padding='same', activation='relu', input_shape=(28,28,3)))\n",
    "model_cnn.add(MaxPooling2D((2,2)))\n",
    "model_cnn.add(Conv2D(64, (5,5), padding='same', activation='relu'))\n",
    "model_cnn.add(MaxPooling2D((2,2)))\n",
    "model_cnn.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128, activation = 'relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(2, activation = 'softmax'))\n",
    "model_cnn.summary()\n",
    "\n",
    "model_cnn.compile(optimizer = optimizers.RMSprop(learning_rate=5e-3),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=[keras.metrics.TruePositives(name='tp'), keras.metrics.FalsePositives(name='fp'), keras.metrics.TrueNegatives(name='tn'), keras.metrics.FalseNegatives(name='fn'),['accuracy']])\n",
    "history_cnn = model_cnn.fit(x = X_train ,y=y_labels ,epochs = epochs ,batch_size=batch_size ,validation_data = (X_val,y_val_labels) ,verbose = 1,\n",
    "                             callbacks=[TrainBalancedAccuracyCallback(), ValBalancedAccuracyCallback()])#, keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('best_mode.h5')\n",
    "X_test = np.load('Xtest_Classification1.npy')\n",
    "X_test = np.reshape((X_test).astype('float32')/255.0,(len(X_test),28,28,3))\n",
    "y_test = best_model.predict(X_test)\n",
    "print(f\"Percentage of Melanoma predictions is {np.count_nonzero(y_test[:,1] > 0.5)/len(y_test)*100:2.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nevu, num_mela, nevu_images, melanoma_images, y_nevu, y_mela = split_nevu_mela(x, y)\n",
    "\n",
    "X_nevu_train, X_nevu_val, y_nevu_train, y_nevu_val = train_test_split(nevu_images, y_nevu, test_size=num_mela*0.15/num_nevu, random_state=0)\n",
    "X_mela_train, X_mela_val, y_mela_train, y_mela_val = train_test_split(melanoma_images, y_mela, test_size=0.15, random_state=0)\n",
    "num_mela, X_mela_train, y_mela_train = augmentate_melanoma_data(melanoma_images, X_mela_train, y_mela_train, num_mela)\n",
    "\n",
    "X_train = np.vstack([X_mela_train, X_nevu_train])\n",
    "X_val = np.vstack([X_mela_val, X_nevu_val])\n",
    "y_train = np.hstack((y_mela_train, y_nevu_train))\n",
    "y_val = np.hstack((y_mela_val, y_nevu_val))\n",
    "\n",
    "# X_train, y_train = augmentate_all_data(X_train, y_train, X_train, y_train) #result got worse\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=0)\n",
    "\n",
    "print(f\"Percentage of Melanoma in train data is {len(np.where(y_train==1)[0])/len(y_train)*100:2.2f}%\")\n",
    "print(f\"Percentage of Melanoma in val data is {len(np.where(y_val==1)[0])/len(y_val)*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Melanoma in train data is 52.90%\n",
      "Percentage of Melanoma in val data is 14.33%\n"
     ]
    }
   ],
   "source": [
    "num_nevu, num_mela, nevu_images, melanoma_images, y_nevu, y_mela = split_nevu_mela(x, y)\n",
    "\n",
    "X_nevu_train, X_nevu_val, y_nevu_train, y_nevu_val = train_test_split(nevu_images, y_nevu, test_size=0.3, random_state=0)\n",
    "X_mela_train, X_mela_val, y_mela_train, y_mela_val = train_test_split(melanoma_images, y_mela, test_size=0.3, random_state=0)\n",
    "num_mela, X_mela_train, y_mela_train = augmentate_melanoma_data(melanoma_images, X_mela_train, y_mela_train, num_mela)\n",
    "\n",
    "X_train = np.vstack([X_mela_train, X_nevu_train])\n",
    "X_val = np.vstack([X_mela_val, X_nevu_val])\n",
    "y_train = np.hstack((y_mela_train, y_nevu_train))\n",
    "y_val = np.hstack((y_mela_val, y_nevu_val)) \n",
    "\n",
    "X_train, y_train = augmentate_all_data(X_train, y_train)\n",
    "X_val, y_val = augmentate_all_data(X_val, y_val)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=0)\n",
    "\n",
    "print(f\"Percentage of Melanoma in train data is {len(np.where(y_train==1)[0])/len(y_train)*100:2.2f}%\")\n",
    "print(f\"Percentage of Melanoma in val data is {len(np.where(y_val==1)[0])/len(y_val)*100:2.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fliph_data = models.Sequential([\n",
    "RandomFlip(\"horizontal_and_vertical\"),\n",
    "])\n",
    "zoom_data = models.Sequential([\n",
    "RandomZoom(height_factor=0.2, fill_mode='nearest'),\n",
    "])\n",
    "bright_data = models.Sequential([\n",
    "RandomBrightness(factor=0.3, value_range=[0.0, 1.0]),\n",
    "])\n",
    "translation_data = models.Sequential([\n",
    "RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode='nearest'),\n",
    "])\n",
    "\n",
    "for i in range(1000):\n",
    "    rotated_90 = tf.image.rot90(tf.convert_to_tensor(X_train[0])).numpy()\n",
    "    rotated_180 = tf.image.rot90(tf.convert_to_tensor(X_train[0]), k=2).numpy()\n",
    "    rotated_270 = tf.image.rot90(tf.convert_to_tensor(X_train[0]), k=3).numpy()\n",
    "    flip = tf.image.flip_left_right(X_train[0])\n",
    "    zoom = zoom_data(X_train[0]).numpy()\n",
    "    bright = bright_data(X_train[0]).numpy()\n",
    "    trans = translation_data(X_train[0]).numpy()\n",
    "    if np.array_equal(rotated_90, X_train[0]):\n",
    "        print('True_90')\n",
    "    if np.array_equal(rotated_180, X_train[0]):\n",
    "        print('True_180')\n",
    "    if np.array_equal(rotated_270, X_train[0]):\n",
    "        print('True_270')\n",
    "    if np.array_equal(flip, X_train[0]):\n",
    "        print('True_f')\n",
    "    if np.array_equal(zoom, X_train[0]):\n",
    "        print('True_z')\n",
    "    if np.array_equal(bright, X_train[0]):\n",
    "        print('True_b')\n",
    "    if np.array_equal(trans, X_train[0]):\n",
    "        print('True_t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = None\n",
    "i2 = None\n",
    "for image in X_train:\n",
    "    for image1 in X_val:\n",
    "        if np.array_equal(image, image1):\n",
    "            i1 = image\n",
    "            i2 = image1\n",
    "            break\n",
    "    if i1 is not None:\n",
    "        break\n",
    "if i1 or i2 is not None:\n",
    "    plt.imshow(i1)\n",
    "    plt.figure(2)\n",
    "    plt.imshow(i2)\n",
    "else:\n",
    "    print('No images repeated found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('y_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " average_pooling2d_26 (Avera  (None, 13, 13, 32)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 13, 13, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d_27 (Avera  (None, 5, 5, 64)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1600)              2561600   \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 3202      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,630,754\n",
      "Trainable params: 2,630,562\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "batch_size = 150\n",
    "y_labels = to_categorical(y_train, 2)\n",
    "X_val = np.reshape(X_val, (len(X_val),28,28,3))\n",
    "y_val_labels = to_categorical(y_val, 2)\n",
    "model_cnn = create_CNN_model((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.0341 - balanced_accuracy: 0.9884 - precision: 0.9883 - recall: 0.9899 - accuracy: 0.9884\n",
      "Epoch 1: val_balanced_accuracy improved from -inf to 0.91462, saving model to cnn_model.h5\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0341 - balanced_accuracy: 0.9884 - precision: 0.9883 - recall: 0.9899 - accuracy: 0.9884 - val_loss: 0.6813 - val_balanced_accuracy: 0.9146 - val_precision: 0.5190 - val_recall: 0.9848 - val_accuracy: 0.8619\n",
      "Epoch 2/300\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.0267 - balanced_accuracy: 0.9906 - precision: 0.9901 - recall: 0.9922 - accuracy: 0.9906\n",
      "Epoch 2: val_balanced_accuracy did not improve from 0.91462\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0267 - balanced_accuracy: 0.9907 - precision: 0.9901 - recall: 0.9922 - accuracy: 0.9906 - val_loss: 0.7545 - val_balanced_accuracy: 0.9104 - val_precision: 0.5073 - val_recall: 0.9832 - val_accuracy: 0.8555\n",
      "Epoch 3/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0303 - balanced_accuracy: 0.9894 - precision: 0.9895 - recall: 0.9906 - accuracy: 0.9895\n",
      "Epoch 3: val_balanced_accuracy improved from 0.91462 to 0.92956, saving model to cnn_model.h5\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0303 - balanced_accuracy: 0.9895 - precision: 0.9897 - recall: 0.9906 - accuracy: 0.9895 - val_loss: 0.5446 - val_balanced_accuracy: 0.9296 - val_precision: 0.5663 - val_recall: 0.9866 - val_accuracy: 0.8864\n",
      "Epoch 4/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0287 - balanced_accuracy: 0.9900 - precision: 0.9897 - recall: 0.9917 - accuracy: 0.9901\n",
      "Epoch 4: val_balanced_accuracy did not improve from 0.92956\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0286 - balanced_accuracy: 0.9900 - precision: 0.9897 - recall: 0.9916 - accuracy: 0.9901 - val_loss: 0.6317 - val_balanced_accuracy: 0.9219 - val_precision: 0.5460 - val_recall: 0.9828 - val_accuracy: 0.8760\n",
      "Epoch 5/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0257 - balanced_accuracy: 0.9909 - precision: 0.9903 - recall: 0.9925 - accuracy: 0.9909\n",
      "Epoch 5: val_balanced_accuracy did not improve from 0.92956\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0254 - balanced_accuracy: 0.9910 - precision: 0.9904 - recall: 0.9927 - accuracy: 0.9911 - val_loss: 0.6410 - val_balanced_accuracy: 0.9163 - val_precision: 0.5297 - val_recall: 0.9809 - val_accuracy: 0.8676\n",
      "Epoch 6/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0308 - balanced_accuracy: 0.9896 - precision: 0.9894 - recall: 0.9911 - accuracy: 0.9897\n",
      "Epoch 6: val_balanced_accuracy did not improve from 0.92956\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0311 - balanced_accuracy: 0.9895 - precision: 0.9894 - recall: 0.9909 - accuracy: 0.9896 - val_loss: 0.7837 - val_balanced_accuracy: 0.9164 - val_precision: 0.5176 - val_recall: 0.9893 - val_accuracy: 0.8617\n",
      "Epoch 7/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0279 - balanced_accuracy: 0.9900 - precision: 0.9899 - recall: 0.9911 - accuracy: 0.9900\n",
      "Epoch 7: val_balanced_accuracy did not improve from 0.92956\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0279 - balanced_accuracy: 0.9900 - precision: 0.9900 - recall: 0.9911 - accuracy: 0.9900 - val_loss: 0.6951 - val_balanced_accuracy: 0.9269 - val_precision: 0.5379 - val_recall: 1.0000 - val_accuracy: 0.8720\n",
      "Epoch 8/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0300 - balanced_accuracy: 0.9904 - precision: 0.9899 - recall: 0.9920 - accuracy: 0.9904\n",
      "Epoch 8: val_balanced_accuracy did not improve from 0.92956\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0301 - balanced_accuracy: 0.9904 - precision: 0.9901 - recall: 0.9920 - accuracy: 0.9905 - val_loss: 0.7155 - val_balanced_accuracy: 0.9219 - val_precision: 0.5287 - val_recall: 0.9947 - val_accuracy: 0.8675\n",
      "Epoch 9/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0252 - balanced_accuracy: 0.9908 - precision: 0.9901 - recall: 0.9927 - accuracy: 0.9908\n",
      "Epoch 9: val_balanced_accuracy improved from 0.92956 to 0.93383, saving model to cnn_model.h5\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0250 - balanced_accuracy: 0.9909 - precision: 0.9903 - recall: 0.9928 - accuracy: 0.9909 - val_loss: 0.6395 - val_balanced_accuracy: 0.9338 - val_precision: 0.5655 - val_recall: 0.9981 - val_accuracy: 0.8856\n",
      "Epoch 10/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0274 - balanced_accuracy: 0.9908 - precision: 0.9911 - recall: 0.9916 - accuracy: 0.9908\n",
      "Epoch 10: val_balanced_accuracy did not improve from 0.93383\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0276 - balanced_accuracy: 0.9907 - precision: 0.9909 - recall: 0.9915 - accuracy: 0.9907 - val_loss: 0.5686 - val_balanced_accuracy: 0.9103 - val_precision: 0.5472 - val_recall: 0.9552 - val_accuracy: 0.8759\n",
      "Epoch 11/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0287 - balanced_accuracy: 0.9905 - precision: 0.9903 - recall: 0.9920 - accuracy: 0.9906\n",
      "Epoch 11: val_balanced_accuracy did not improve from 0.93383\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0284 - balanced_accuracy: 0.9905 - precision: 0.9903 - recall: 0.9921 - accuracy: 0.9907 - val_loss: 0.5080 - val_balanced_accuracy: 0.9264 - val_precision: 0.6001 - val_recall: 0.9613 - val_accuracy: 0.8994\n",
      "Epoch 12/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0300 - balanced_accuracy: 0.9898 - precision: 0.9896 - recall: 0.9913 - accuracy: 0.9899\n",
      "Epoch 12: val_balanced_accuracy did not improve from 0.93383\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0299 - balanced_accuracy: 0.9899 - precision: 0.9898 - recall: 0.9914 - accuracy: 0.9900 - val_loss: 0.9284 - val_balanced_accuracy: 0.8525 - val_precision: 0.4739 - val_recall: 0.8700 - val_accuracy: 0.8371\n",
      "Epoch 13/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0278 - balanced_accuracy: 0.9910 - precision: 0.9909 - recall: 0.9924 - accuracy: 0.9912\n",
      "Epoch 13: val_balanced_accuracy did not improve from 0.93383\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0278 - balanced_accuracy: 0.9911 - precision: 0.9910 - recall: 0.9924 - accuracy: 0.9912 - val_loss: 0.7610 - val_balanced_accuracy: 0.9008 - val_precision: 0.5056 - val_recall: 0.9613 - val_accuracy: 0.8546\n",
      "Epoch 14/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0305 - balanced_accuracy: 0.9901 - precision: 0.9899 - recall: 0.9915 - accuracy: 0.9901\n",
      "Epoch 14: val_balanced_accuracy did not improve from 0.93383\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0310 - balanced_accuracy: 0.9899 - precision: 0.9899 - recall: 0.9912 - accuracy: 0.9900 - val_loss: 0.6592 - val_balanced_accuracy: 0.9170 - val_precision: 0.5299 - val_recall: 0.9829 - val_accuracy: 0.8673\n",
      "Epoch 15/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0311 - balanced_accuracy: 0.9894 - precision: 0.9892 - recall: 0.9909 - accuracy: 0.9894\n",
      "Epoch 15: val_balanced_accuracy did not improve from 0.93383\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0314 - balanced_accuracy: 0.9893 - precision: 0.9888 - recall: 0.9910 - accuracy: 0.9893 - val_loss: 0.8544 - val_balanced_accuracy: 0.8981 - val_precision: 0.4964 - val_recall: 0.9628 - val_accuracy: 0.8488\n",
      "Epoch 16/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0260 - balanced_accuracy: 0.9911 - precision: 0.9910 - recall: 0.9922 - accuracy: 0.9911\n",
      "Epoch 16: val_balanced_accuracy improved from 0.93383 to 0.93566, saving model to cnn_model.h5\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0263 - balanced_accuracy: 0.9911 - precision: 0.9908 - recall: 0.9923 - accuracy: 0.9911 - val_loss: 0.5678 - val_balanced_accuracy: 0.9357 - val_precision: 0.5890 - val_recall: 0.9878 - val_accuracy: 0.8964\n",
      "Epoch 17/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0276 - balanced_accuracy: 0.9909 - precision: 0.9906 - recall: 0.9923 - accuracy: 0.9910\n",
      "Epoch 17: val_balanced_accuracy did not improve from 0.93566\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0274 - balanced_accuracy: 0.9911 - precision: 0.9907 - recall: 0.9925 - accuracy: 0.9911 - val_loss: 0.5713 - val_balanced_accuracy: 0.9238 - val_precision: 0.5857 - val_recall: 0.9625 - val_accuracy: 0.8940\n",
      "Epoch 18/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0228 - balanced_accuracy: 0.9926 - precision: 0.9922 - recall: 0.9941 - accuracy: 0.9927\n",
      "Epoch 18: val_balanced_accuracy did not improve from 0.93566\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0225 - balanced_accuracy: 0.9928 - precision: 0.9924 - recall: 0.9942 - accuracy: 0.9928 - val_loss: 0.7385 - val_balanced_accuracy: 0.9086 - val_precision: 0.5284 - val_recall: 0.9639 - val_accuracy: 0.8665\n",
      "Epoch 19/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0292 - balanced_accuracy: 0.9900 - precision: 0.9901 - recall: 0.9909 - accuracy: 0.9900\n",
      "Epoch 19: val_balanced_accuracy did not improve from 0.93566\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0300 - balanced_accuracy: 0.9898 - precision: 0.9901 - recall: 0.9907 - accuracy: 0.9899 - val_loss: 0.5178 - val_balanced_accuracy: 0.9342 - val_precision: 0.5931 - val_recall: 0.9823 - val_accuracy: 0.8980\n",
      "Epoch 20/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0324 - balanced_accuracy: 0.9892 - precision: 0.9892 - recall: 0.9907 - accuracy: 0.9893\n",
      "Epoch 20: val_balanced_accuracy did not improve from 0.93566\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0322 - balanced_accuracy: 0.9893 - precision: 0.9893 - recall: 0.9907 - accuracy: 0.9893 - val_loss: 0.5628 - val_balanced_accuracy: 0.8914 - val_precision: 0.5745 - val_recall: 0.8944 - val_accuracy: 0.8872\n",
      "Epoch 21/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0317 - balanced_accuracy: 0.9901 - precision: 0.9898 - recall: 0.9914 - accuracy: 0.9901\n",
      "Epoch 21: val_balanced_accuracy did not improve from 0.93566\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0317 - balanced_accuracy: 0.9900 - precision: 0.9899 - recall: 0.9912 - accuracy: 0.9900 - val_loss: 0.6196 - val_balanced_accuracy: 0.9301 - val_precision: 0.5502 - val_recall: 0.9988 - val_accuracy: 0.8787\n",
      "Epoch 22/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0254 - balanced_accuracy: 0.9917 - precision: 0.9914 - recall: 0.9930 - accuracy: 0.9917\n",
      "Epoch 22: val_balanced_accuracy did not improve from 0.93566\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0253 - balanced_accuracy: 0.9918 - precision: 0.9915 - recall: 0.9930 - accuracy: 0.9918 - val_loss: 0.6479 - val_balanced_accuracy: 0.8900 - val_precision: 0.5511 - val_recall: 0.9043 - val_accuracy: 0.8776\n",
      "Epoch 23/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0283 - balanced_accuracy: 0.9903 - precision: 0.9901 - recall: 0.9919 - accuracy: 0.9904\n",
      "Epoch 23: val_balanced_accuracy did not improve from 0.93566\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0283 - balanced_accuracy: 0.9904 - precision: 0.9902 - recall: 0.9919 - accuracy: 0.9904 - val_loss: 0.8533 - val_balanced_accuracy: 0.9224 - val_precision: 0.5281 - val_recall: 0.9966 - val_accuracy: 0.8668\n",
      "Epoch 24/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0272 - balanced_accuracy: 0.9906 - precision: 0.9909 - recall: 0.9914 - accuracy: 0.9907\n",
      "Epoch 24: val_balanced_accuracy did not improve from 0.93566\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0271 - balanced_accuracy: 0.9907 - precision: 0.9909 - recall: 0.9915 - accuracy: 0.9907 - val_loss: 0.6399 - val_balanced_accuracy: 0.9292 - val_precision: 0.5616 - val_recall: 0.9891 - val_accuracy: 0.8843\n",
      "Epoch 25/300\n",
      "206/213 [============================>.] - ETA: 0s - loss: 0.0270 - balanced_accuracy: 0.9906 - precision: 0.9904 - recall: 0.9919 - accuracy: 0.9906\n",
      "Epoch 25: val_balanced_accuracy did not improve from 0.93566\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0273 - balanced_accuracy: 0.9906 - precision: 0.9903 - recall: 0.9920 - accuracy: 0.9906 - val_loss: 0.5942 - val_balanced_accuracy: 0.9345 - val_precision: 0.5739 - val_recall: 0.9942 - val_accuracy: 0.8897\n",
      "Epoch 26/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0263 - balanced_accuracy: 0.9913 - precision: 0.9913 - recall: 0.9925 - accuracy: 0.9914\n",
      "Epoch 26: val_balanced_accuracy improved from 0.93566 to 0.93780, saving model to cnn_model.h5\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0262 - balanced_accuracy: 0.9913 - precision: 0.9914 - recall: 0.9924 - accuracy: 0.9914 - val_loss: 0.5994 - val_balanced_accuracy: 0.9378 - val_precision: 0.5827 - val_recall: 0.9971 - val_accuracy: 0.8933\n",
      "Epoch 27/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0235 - balanced_accuracy: 0.9917 - precision: 0.9922 - recall: 0.9923 - accuracy: 0.9918\n",
      "Epoch 27: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0234 - balanced_accuracy: 0.9918 - precision: 0.9923 - recall: 0.9924 - accuracy: 0.9919 - val_loss: 0.8013 - val_balanced_accuracy: 0.9134 - val_precision: 0.5246 - val_recall: 0.9772 - val_accuracy: 0.8653\n",
      "Epoch 28/300\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.0273 - balanced_accuracy: 0.9910 - precision: 0.9915 - recall: 0.9915 - accuracy: 0.9911\n",
      "Epoch 28: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0273 - balanced_accuracy: 0.9910 - precision: 0.9915 - recall: 0.9915 - accuracy: 0.9911 - val_loss: 0.7325 - val_balanced_accuracy: 0.8444 - val_precision: 0.5318 - val_recall: 0.8107 - val_accuracy: 0.8663\n",
      "Epoch 29/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0242 - balanced_accuracy: 0.9919 - precision: 0.9922 - recall: 0.9924 - accuracy: 0.9919\n",
      "Epoch 29: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0241 - balanced_accuracy: 0.9920 - precision: 0.9923 - recall: 0.9923 - accuracy: 0.9919 - val_loss: 0.5723 - val_balanced_accuracy: 0.9376 - val_precision: 0.5771 - val_recall: 0.9993 - val_accuracy: 0.8914\n",
      "Epoch 30/300\n",
      "206/213 [============================>.] - ETA: 0s - loss: 0.0243 - balanced_accuracy: 0.9919 - precision: 0.9920 - recall: 0.9926 - accuracy: 0.9919\n",
      "Epoch 30: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0240 - balanced_accuracy: 0.9919 - precision: 0.9920 - recall: 0.9926 - accuracy: 0.9919 - val_loss: 0.6576 - val_balanced_accuracy: 0.9307 - val_precision: 0.5536 - val_recall: 0.9978 - val_accuracy: 0.8804\n",
      "Epoch 31/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0274 - balanced_accuracy: 0.9908 - precision: 0.9903 - recall: 0.9924 - accuracy: 0.9908\n",
      "Epoch 31: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0279 - balanced_accuracy: 0.9908 - precision: 0.9904 - recall: 0.9921 - accuracy: 0.9908 - val_loss: 0.7981 - val_balanced_accuracy: 0.9015 - val_precision: 0.5176 - val_recall: 0.9551 - val_accuracy: 0.8607\n",
      "Epoch 32/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0320 - balanced_accuracy: 0.9904 - precision: 0.9901 - recall: 0.9920 - accuracy: 0.9905\n",
      "Epoch 32: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0328 - balanced_accuracy: 0.9902 - precision: 0.9901 - recall: 0.9917 - accuracy: 0.9905 - val_loss: 0.6737 - val_balanced_accuracy: 0.9289 - val_precision: 0.5663 - val_recall: 0.9858 - val_accuracy: 0.8860\n",
      "Epoch 33/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0312 - balanced_accuracy: 0.9901 - precision: 0.9900 - recall: 0.9913 - accuracy: 0.9901\n",
      "Epoch 33: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0313 - balanced_accuracy: 0.9900 - precision: 0.9900 - recall: 0.9912 - accuracy: 0.9900 - val_loss: 0.5872 - val_balanced_accuracy: 0.9366 - val_precision: 0.5715 - val_recall: 1.0000 - val_accuracy: 0.8891\n",
      "Epoch 34/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0253 - balanced_accuracy: 0.9914 - precision: 0.9912 - recall: 0.9926 - accuracy: 0.9914\n",
      "Epoch 34: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0253 - balanced_accuracy: 0.9914 - precision: 0.9911 - recall: 0.9926 - accuracy: 0.9913 - val_loss: 0.8197 - val_balanced_accuracy: 0.9002 - val_precision: 0.5027 - val_recall: 0.9643 - val_accuracy: 0.8515\n",
      "Epoch 35/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0219 - balanced_accuracy: 0.9926 - precision: 0.9925 - recall: 0.9936 - accuracy: 0.9927\n",
      "Epoch 35: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0217 - balanced_accuracy: 0.9927 - precision: 0.9925 - recall: 0.9937 - accuracy: 0.9927 - val_loss: 1.0114 - val_balanced_accuracy: 0.8884 - val_precision: 0.4718 - val_recall: 0.9617 - val_accuracy: 0.8330\n",
      "Epoch 36/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0254 - balanced_accuracy: 0.9917 - precision: 0.9914 - recall: 0.9928 - accuracy: 0.9917\n",
      "Epoch 36: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0253 - balanced_accuracy: 0.9916 - precision: 0.9912 - recall: 0.9930 - accuracy: 0.9917 - val_loss: 0.6419 - val_balanced_accuracy: 0.9123 - val_precision: 0.5575 - val_recall: 0.9525 - val_accuracy: 0.8812\n",
      "Epoch 37/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0282 - balanced_accuracy: 0.9903 - precision: 0.9903 - recall: 0.9916 - accuracy: 0.9904\n",
      "Epoch 37: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0281 - balanced_accuracy: 0.9904 - precision: 0.9904 - recall: 0.9917 - accuracy: 0.9905 - val_loss: 0.7312 - val_balanced_accuracy: 0.9226 - val_precision: 0.5337 - val_recall: 0.9922 - val_accuracy: 0.8704\n",
      "Epoch 38/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0271 - balanced_accuracy: 0.9910 - precision: 0.9909 - recall: 0.9924 - accuracy: 0.9911\n",
      "Epoch 38: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0271 - balanced_accuracy: 0.9910 - precision: 0.9909 - recall: 0.9926 - accuracy: 0.9911 - val_loss: 0.7052 - val_balanced_accuracy: 0.9249 - val_precision: 0.5326 - val_recall: 0.9983 - val_accuracy: 0.8700\n",
      "Epoch 39/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0255 - balanced_accuracy: 0.9913 - precision: 0.9910 - recall: 0.9927 - accuracy: 0.9913\n",
      "Epoch 39: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0257 - balanced_accuracy: 0.9912 - precision: 0.9908 - recall: 0.9927 - accuracy: 0.9912 - val_loss: 0.6086 - val_balanced_accuracy: 0.9152 - val_precision: 0.5733 - val_recall: 0.9495 - val_accuracy: 0.8889\n",
      "Epoch 40/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0293 - balanced_accuracy: 0.9907 - precision: 0.9906 - recall: 0.9918 - accuracy: 0.9907\n",
      "Epoch 40: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0294 - balanced_accuracy: 0.9907 - precision: 0.9905 - recall: 0.9919 - accuracy: 0.9907 - val_loss: 0.5831 - val_balanced_accuracy: 0.9321 - val_precision: 0.5572 - val_recall: 0.9988 - val_accuracy: 0.8821\n",
      "Epoch 41/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0259 - balanced_accuracy: 0.9912 - precision: 0.9911 - recall: 0.9925 - accuracy: 0.9913\n",
      "Epoch 41: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0260 - balanced_accuracy: 0.9911 - precision: 0.9910 - recall: 0.9924 - accuracy: 0.9912 - val_loss: 0.6176 - val_balanced_accuracy: 0.9343 - val_precision: 0.5682 - val_recall: 0.9970 - val_accuracy: 0.8875\n",
      "Epoch 42/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0250 - balanced_accuracy: 0.9919 - precision: 0.9912 - recall: 0.9934 - accuracy: 0.9919\n",
      "Epoch 42: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0249 - balanced_accuracy: 0.9918 - precision: 0.9911 - recall: 0.9935 - accuracy: 0.9919 - val_loss: 0.6205 - val_balanced_accuracy: 0.9310 - val_precision: 0.5635 - val_recall: 0.9924 - val_accuracy: 0.8848\n",
      "Epoch 43/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0237 - balanced_accuracy: 0.9928 - precision: 0.9926 - recall: 0.9940 - accuracy: 0.9929\n",
      "Epoch 43: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0239 - balanced_accuracy: 0.9927 - precision: 0.9926 - recall: 0.9940 - accuracy: 0.9928 - val_loss: 0.6188 - val_balanced_accuracy: 0.9243 - val_precision: 0.5600 - val_recall: 0.9793 - val_accuracy: 0.8825\n",
      "Epoch 44/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0285 - balanced_accuracy: 0.9911 - precision: 0.9907 - recall: 0.9925 - accuracy: 0.9911\n",
      "Epoch 44: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0284 - balanced_accuracy: 0.9912 - precision: 0.9907 - recall: 0.9925 - accuracy: 0.9911 - val_loss: 0.8215 - val_balanced_accuracy: 0.9223 - val_precision: 0.5215 - val_recall: 1.0000 - val_accuracy: 0.8641\n",
      "Epoch 45/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0219 - balanced_accuracy: 0.9927 - precision: 0.9922 - recall: 0.9938 - accuracy: 0.9928\n",
      "Epoch 45: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0217 - balanced_accuracy: 0.9928 - precision: 0.9924 - recall: 0.9938 - accuracy: 0.9928 - val_loss: 0.5649 - val_balanced_accuracy: 0.9293 - val_precision: 0.5830 - val_recall: 0.9763 - val_accuracy: 0.8937\n",
      "Epoch 46/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0225 - balanced_accuracy: 0.9924 - precision: 0.9927 - recall: 0.9930 - accuracy: 0.9924\n",
      "Epoch 46: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0225 - balanced_accuracy: 0.9925 - precision: 0.9928 - recall: 0.9931 - accuracy: 0.9925 - val_loss: 0.5979 - val_balanced_accuracy: 0.9322 - val_precision: 0.5757 - val_recall: 0.9878 - val_accuracy: 0.8903\n",
      "Epoch 47/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0253 - balanced_accuracy: 0.9916 - precision: 0.9919 - recall: 0.9924 - accuracy: 0.9916\n",
      "Epoch 47: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0257 - balanced_accuracy: 0.9912 - precision: 0.9915 - recall: 0.9920 - accuracy: 0.9915 - val_loss: 0.6781 - val_balanced_accuracy: 0.9268 - val_precision: 0.5502 - val_recall: 0.9915 - val_accuracy: 0.8781\n",
      "Epoch 48/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0241 - balanced_accuracy: 0.9925 - precision: 0.9921 - recall: 0.9937 - accuracy: 0.9925\n",
      "Epoch 48: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0241 - balanced_accuracy: 0.9924 - precision: 0.9921 - recall: 0.9935 - accuracy: 0.9924 - val_loss: 0.6062 - val_balanced_accuracy: 0.9305 - val_precision: 0.5703 - val_recall: 0.9872 - val_accuracy: 0.8877\n",
      "Epoch 49/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0249 - balanced_accuracy: 0.9918 - precision: 0.9915 - recall: 0.9931 - accuracy: 0.9918\n",
      "Epoch 49: val_balanced_accuracy did not improve from 0.93780\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0254 - balanced_accuracy: 0.9917 - precision: 0.9914 - recall: 0.9929 - accuracy: 0.9917 - val_loss: 0.5917 - val_balanced_accuracy: 0.8656 - val_precision: 0.5761 - val_recall: 0.8345 - val_accuracy: 0.8856\n",
      "Epoch 50/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0264 - balanced_accuracy: 0.9916 - precision: 0.9918 - recall: 0.9924 - accuracy: 0.9916\n",
      "Epoch 50: val_balanced_accuracy improved from 0.93780 to 0.94045, saving model to cnn_model.h5\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0261 - balanced_accuracy: 0.9917 - precision: 0.9920 - recall: 0.9924 - accuracy: 0.9917 - val_loss: 0.5814 - val_balanced_accuracy: 0.9404 - val_precision: 0.6008 - val_recall: 0.9926 - val_accuracy: 0.9012\n",
      "Epoch 51/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0234 - balanced_accuracy: 0.9928 - precision: 0.9927 - recall: 0.9934 - accuracy: 0.9927\n",
      "Epoch 51: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0234 - balanced_accuracy: 0.9928 - precision: 0.9927 - recall: 0.9933 - accuracy: 0.9927 - val_loss: 0.5711 - val_balanced_accuracy: 0.8767 - val_precision: 0.5802 - val_recall: 0.8506 - val_accuracy: 0.8957\n",
      "Epoch 52/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0232 - balanced_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9935 - accuracy: 0.9924\n",
      "Epoch 52: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0237 - balanced_accuracy: 0.9921 - precision: 0.9920 - recall: 0.9934 - accuracy: 0.9923 - val_loss: 0.8386 - val_balanced_accuracy: 0.9208 - val_precision: 0.5266 - val_recall: 0.9937 - val_accuracy: 0.8661\n",
      "Epoch 53/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0236 - balanced_accuracy: 0.9922 - precision: 0.9920 - recall: 0.9933 - accuracy: 0.9922\n",
      "Epoch 53: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0237 - balanced_accuracy: 0.9919 - precision: 0.9915 - recall: 0.9934 - accuracy: 0.9921 - val_loss: 0.6364 - val_balanced_accuracy: 0.9269 - val_precision: 0.5698 - val_recall: 0.9793 - val_accuracy: 0.8873\n",
      "Epoch 54/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0246 - balanced_accuracy: 0.9918 - precision: 0.9915 - recall: 0.9931 - accuracy: 0.9918\n",
      "Epoch 54: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0245 - balanced_accuracy: 0.9919 - precision: 0.9916 - recall: 0.9931 - accuracy: 0.9919 - val_loss: 0.7922 - val_balanced_accuracy: 0.9202 - val_precision: 0.5330 - val_recall: 0.9875 - val_accuracy: 0.8696\n",
      "Epoch 55/300\n",
      "206/213 [============================>.] - ETA: 0s - loss: 0.0245 - balanced_accuracy: 0.9923 - precision: 0.9921 - recall: 0.9936 - accuracy: 0.9924\n",
      "Epoch 55: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0244 - balanced_accuracy: 0.9921 - precision: 0.9918 - recall: 0.9936 - accuracy: 0.9923 - val_loss: 0.7147 - val_balanced_accuracy: 0.9284 - val_precision: 0.5436 - val_recall: 0.9994 - val_accuracy: 0.8752\n",
      "Epoch 56/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0223 - balanced_accuracy: 0.9921 - precision: 0.9928 - recall: 0.9926 - accuracy: 0.9922\n",
      "Epoch 56: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0222 - balanced_accuracy: 0.9921 - precision: 0.9928 - recall: 0.9927 - accuracy: 0.9922 - val_loss: 0.7993 - val_balanced_accuracy: 0.9243 - val_precision: 0.5344 - val_recall: 0.9966 - val_accuracy: 0.8701\n",
      "Epoch 57/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0232 - balanced_accuracy: 0.9924 - precision: 0.9923 - recall: 0.9933 - accuracy: 0.9923\n",
      "Epoch 57: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0232 - balanced_accuracy: 0.9922 - precision: 0.9922 - recall: 0.9932 - accuracy: 0.9923 - val_loss: 0.5896 - val_balanced_accuracy: 0.9382 - val_precision: 0.5820 - val_recall: 0.9979 - val_accuracy: 0.8934\n",
      "Epoch 58/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0212 - balanced_accuracy: 0.9928 - precision: 0.9928 - recall: 0.9937 - accuracy: 0.9929\n",
      "Epoch 58: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0212 - balanced_accuracy: 0.9928 - precision: 0.9927 - recall: 0.9938 - accuracy: 0.9928 - val_loss: 0.7256 - val_balanced_accuracy: 0.9242 - val_precision: 0.5385 - val_recall: 0.9931 - val_accuracy: 0.8723\n",
      "Epoch 59/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0257 - balanced_accuracy: 0.9920 - precision: 0.9916 - recall: 0.9932 - accuracy: 0.9919\n",
      "Epoch 59: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0254 - balanced_accuracy: 0.9921 - precision: 0.9918 - recall: 0.9931 - accuracy: 0.9920 - val_loss: 0.7908 - val_balanced_accuracy: 0.8953 - val_precision: 0.5190 - val_recall: 0.9385 - val_accuracy: 0.8616\n",
      "Epoch 60/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0263 - balanced_accuracy: 0.9915 - precision: 0.9917 - recall: 0.9923 - accuracy: 0.9915\n",
      "Epoch 60: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0262 - balanced_accuracy: 0.9915 - precision: 0.9916 - recall: 0.9923 - accuracy: 0.9916 - val_loss: 0.6405 - val_balanced_accuracy: 0.9314 - val_precision: 0.5625 - val_recall: 0.9941 - val_accuracy: 0.8844\n",
      "Epoch 61/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0251 - balanced_accuracy: 0.9922 - precision: 0.9923 - recall: 0.9931 - accuracy: 0.9922\n",
      "Epoch 61: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0250 - balanced_accuracy: 0.9921 - precision: 0.9920 - recall: 0.9932 - accuracy: 0.9921 - val_loss: 0.8490 - val_balanced_accuracy: 0.9180 - val_precision: 0.5189 - val_recall: 0.9930 - val_accuracy: 0.8617\n",
      "Epoch 62/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0224 - balanced_accuracy: 0.9930 - precision: 0.9930 - recall: 0.9938 - accuracy: 0.9930\n",
      "Epoch 62: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0226 - balanced_accuracy: 0.9930 - precision: 0.9930 - recall: 0.9938 - accuracy: 0.9930 - val_loss: 0.5810 - val_balanced_accuracy: 0.9195 - val_precision: 0.5832 - val_recall: 0.9543 - val_accuracy: 0.8928\n",
      "Epoch 63/300\n",
      "211/213 [============================>.] - ETA: 0s - loss: 0.0223 - balanced_accuracy: 0.9930 - precision: 0.9929 - recall: 0.9936 - accuracy: 0.9929\n",
      "Epoch 63: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0222 - balanced_accuracy: 0.9930 - precision: 0.9929 - recall: 0.9937 - accuracy: 0.9929 - val_loss: 0.6804 - val_balanced_accuracy: 0.9310 - val_precision: 0.5615 - val_recall: 0.9936 - val_accuracy: 0.8840\n",
      "Epoch 64/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0237 - balanced_accuracy: 0.9925 - precision: 0.9922 - recall: 0.9936 - accuracy: 0.9925\n",
      "Epoch 64: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0234 - balanced_accuracy: 0.9926 - precision: 0.9923 - recall: 0.9937 - accuracy: 0.9926 - val_loss: 0.6129 - val_balanced_accuracy: 0.9347 - val_precision: 0.5698 - val_recall: 0.9967 - val_accuracy: 0.8883\n",
      "Epoch 65/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0234 - balanced_accuracy: 0.9929 - precision: 0.9928 - recall: 0.9939 - accuracy: 0.9930\n",
      "Epoch 65: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0232 - balanced_accuracy: 0.9928 - precision: 0.9927 - recall: 0.9940 - accuracy: 0.9930 - val_loss: 0.6337 - val_balanced_accuracy: 0.9354 - val_precision: 0.5707 - val_recall: 0.9988 - val_accuracy: 0.8879\n",
      "Epoch 66/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0264 - balanced_accuracy: 0.9918 - precision: 0.9919 - recall: 0.9927 - accuracy: 0.9918\n",
      "Epoch 66: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0262 - balanced_accuracy: 0.9919 - precision: 0.9918 - recall: 0.9927 - accuracy: 0.9919 - val_loss: 0.9078 - val_balanced_accuracy: 0.9098 - val_precision: 0.5087 - val_recall: 0.9804 - val_accuracy: 0.8564\n",
      "Epoch 67/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0277 - balanced_accuracy: 0.9914 - precision: 0.9918 - recall: 0.9919 - accuracy: 0.9915\n",
      "Epoch 67: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0274 - balanced_accuracy: 0.9916 - precision: 0.9919 - recall: 0.9921 - accuracy: 0.9916 - val_loss: 0.6334 - val_balanced_accuracy: 0.9334 - val_precision: 0.5713 - val_recall: 0.9934 - val_accuracy: 0.8883\n",
      "Epoch 68/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0245 - balanced_accuracy: 0.9924 - precision: 0.9922 - recall: 0.9934 - accuracy: 0.9924\n",
      "Epoch 68: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0244 - balanced_accuracy: 0.9925 - precision: 0.9922 - recall: 0.9936 - accuracy: 0.9925 - val_loss: 0.6780 - val_balanced_accuracy: 0.9314 - val_precision: 0.5571 - val_recall: 0.9978 - val_accuracy: 0.8819\n",
      "Epoch 69/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0261 - balanced_accuracy: 0.9917 - precision: 0.9919 - recall: 0.9927 - accuracy: 0.9917\n",
      "Epoch 69: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0260 - balanced_accuracy: 0.9916 - precision: 0.9916 - recall: 0.9928 - accuracy: 0.9917 - val_loss: 0.7501 - val_balanced_accuracy: 0.9218 - val_precision: 0.5386 - val_recall: 0.9870 - val_accuracy: 0.8727\n",
      "Epoch 70/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0240 - balanced_accuracy: 0.9927 - precision: 0.9929 - recall: 0.9933 - accuracy: 0.9927\n",
      "Epoch 70: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0240 - balanced_accuracy: 0.9928 - precision: 0.9930 - recall: 0.9933 - accuracy: 0.9927 - val_loss: 0.7177 - val_balanced_accuracy: 0.9290 - val_precision: 0.5480 - val_recall: 0.9972 - val_accuracy: 0.8780\n",
      "Epoch 71/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0251 - balanced_accuracy: 0.9917 - precision: 0.9917 - recall: 0.9928 - accuracy: 0.9917\n",
      "Epoch 71: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0249 - balanced_accuracy: 0.9918 - precision: 0.9917 - recall: 0.9930 - accuracy: 0.9918 - val_loss: 0.8777 - val_balanced_accuracy: 0.9118 - val_precision: 0.5104 - val_recall: 0.9841 - val_accuracy: 0.8571\n",
      "Epoch 72/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0199 - balanced_accuracy: 0.9933 - precision: 0.9927 - recall: 0.9946 - accuracy: 0.9933\n",
      "Epoch 72: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0199 - balanced_accuracy: 0.9932 - precision: 0.9927 - recall: 0.9945 - accuracy: 0.9932 - val_loss: 0.6652 - val_balanced_accuracy: 0.9334 - val_precision: 0.5771 - val_recall: 0.9889 - val_accuracy: 0.8914\n",
      "Epoch 73/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0228 - balanced_accuracy: 0.9931 - precision: 0.9935 - recall: 0.9936 - accuracy: 0.9932\n",
      "Epoch 73: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0235 - balanced_accuracy: 0.9931 - precision: 0.9933 - recall: 0.9937 - accuracy: 0.9931 - val_loss: 0.8234 - val_balanced_accuracy: 0.8991 - val_precision: 0.5016 - val_recall: 0.9601 - val_accuracy: 0.8526\n",
      "Epoch 74/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0245 - balanced_accuracy: 0.9928 - precision: 0.9927 - recall: 0.9936 - accuracy: 0.9928\n",
      "Epoch 74: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0248 - balanced_accuracy: 0.9927 - precision: 0.9925 - recall: 0.9935 - accuracy: 0.9927 - val_loss: 0.6000 - val_balanced_accuracy: 0.9005 - val_precision: 0.5598 - val_recall: 0.9159 - val_accuracy: 0.8905\n",
      "Epoch 75/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0231 - balanced_accuracy: 0.9927 - precision: 0.9930 - recall: 0.9931 - accuracy: 0.9927\n",
      "Epoch 75: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0229 - balanced_accuracy: 0.9928 - precision: 0.9930 - recall: 0.9932 - accuracy: 0.9927 - val_loss: 0.7011 - val_balanced_accuracy: 0.9273 - val_precision: 0.5432 - val_recall: 0.9973 - val_accuracy: 0.8748\n",
      "Epoch 76/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0193 - balanced_accuracy: 0.9941 - precision: 0.9941 - recall: 0.9947 - accuracy: 0.9941\n",
      "Epoch 76: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0192 - balanced_accuracy: 0.9941 - precision: 0.9940 - recall: 0.9948 - accuracy: 0.9941 - val_loss: 0.7451 - val_balanced_accuracy: 0.9268 - val_precision: 0.5411 - val_recall: 0.9978 - val_accuracy: 0.8736\n",
      "Epoch 77/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0177 - balanced_accuracy: 0.9943 - precision: 0.9939 - recall: 0.9952 - accuracy: 0.9942\n",
      "Epoch 77: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0180 - balanced_accuracy: 0.9941 - precision: 0.9937 - recall: 0.9951 - accuracy: 0.9941 - val_loss: 0.7764 - val_balanced_accuracy: 0.9208 - val_precision: 0.5310 - val_recall: 0.9894 - val_accuracy: 0.8692\n",
      "Epoch 78/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0176 - balanced_accuracy: 0.9938 - precision: 0.9935 - recall: 0.9948 - accuracy: 0.9938\n",
      "Epoch 78: val_balanced_accuracy did not improve from 0.94045\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0177 - balanced_accuracy: 0.9938 - precision: 0.9936 - recall: 0.9946 - accuracy: 0.9939 - val_loss: 0.5956 - val_balanced_accuracy: 0.9217 - val_precision: 0.5763 - val_recall: 0.9631 - val_accuracy: 0.8899\n",
      "Epoch 79/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0181 - balanced_accuracy: 0.9937 - precision: 0.9934 - recall: 0.9947 - accuracy: 0.9937\n",
      "Epoch 79: val_balanced_accuracy improved from 0.94045 to 0.94166, saving model to cnn_model.h5\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0182 - balanced_accuracy: 0.9938 - precision: 0.9935 - recall: 0.9947 - accuracy: 0.9938 - val_loss: 0.5649 - val_balanced_accuracy: 0.9417 - val_precision: 0.5953 - val_recall: 0.9978 - val_accuracy: 0.8996\n",
      "Epoch 80/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0203 - balanced_accuracy: 0.9933 - precision: 0.9932 - recall: 0.9941 - accuracy: 0.9933\n",
      "Epoch 80: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0204 - balanced_accuracy: 0.9934 - precision: 0.9932 - recall: 0.9942 - accuracy: 0.9933 - val_loss: 0.8954 - val_balanced_accuracy: 0.9099 - val_precision: 0.5002 - val_recall: 0.9885 - val_accuracy: 0.8507\n",
      "Epoch 81/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0211 - balanced_accuracy: 0.9930 - precision: 0.9928 - recall: 0.9940 - accuracy: 0.9930\n",
      "Epoch 81: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0214 - balanced_accuracy: 0.9928 - precision: 0.9927 - recall: 0.9938 - accuracy: 0.9930 - val_loss: 0.6601 - val_balanced_accuracy: 0.9354 - val_precision: 0.5773 - val_recall: 0.9942 - val_accuracy: 0.8913\n",
      "Epoch 82/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0189 - balanced_accuracy: 0.9938 - precision: 0.9939 - recall: 0.9944 - accuracy: 0.9938\n",
      "Epoch 82: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0190 - balanced_accuracy: 0.9936 - precision: 0.9938 - recall: 0.9943 - accuracy: 0.9938 - val_loss: 0.8131 - val_balanced_accuracy: 0.9299 - val_precision: 0.5474 - val_recall: 1.0000 - val_accuracy: 0.8775\n",
      "Epoch 83/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0205 - balanced_accuracy: 0.9934 - precision: 0.9934 - recall: 0.9943 - accuracy: 0.9935\n",
      "Epoch 83: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0210 - balanced_accuracy: 0.9933 - precision: 0.9932 - recall: 0.9943 - accuracy: 0.9934 - val_loss: 0.7698 - val_balanced_accuracy: 0.9206 - val_precision: 0.5473 - val_recall: 0.9778 - val_accuracy: 0.8773\n",
      "Epoch 84/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0191 - balanced_accuracy: 0.9940 - precision: 0.9938 - recall: 0.9948 - accuracy: 0.9940\n",
      "Epoch 84: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0192 - balanced_accuracy: 0.9939 - precision: 0.9938 - recall: 0.9948 - accuracy: 0.9939 - val_loss: 0.6819 - val_balanced_accuracy: 0.9313 - val_precision: 0.5599 - val_recall: 0.9953 - val_accuracy: 0.8832\n",
      "Epoch 85/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0198 - balanced_accuracy: 0.9937 - precision: 0.9935 - recall: 0.9945 - accuracy: 0.9937\n",
      "Epoch 85: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0200 - balanced_accuracy: 0.9937 - precision: 0.9934 - recall: 0.9945 - accuracy: 0.9937 - val_loss: 0.7679 - val_balanced_accuracy: 0.9239 - val_precision: 0.5296 - val_recall: 0.9989 - val_accuracy: 0.8677\n",
      "Epoch 86/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0258 - balanced_accuracy: 0.9924 - precision: 0.9923 - recall: 0.9933 - accuracy: 0.9923\n",
      "Epoch 86: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0258 - balanced_accuracy: 0.9923 - precision: 0.9921 - recall: 0.9933 - accuracy: 0.9923 - val_loss: 0.5181 - val_balanced_accuracy: 0.9365 - val_precision: 0.6012 - val_recall: 0.9837 - val_accuracy: 0.9010\n",
      "Epoch 87/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0229 - balanced_accuracy: 0.9923 - precision: 0.9920 - recall: 0.9935 - accuracy: 0.9924\n",
      "Epoch 87: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0230 - balanced_accuracy: 0.9923 - precision: 0.9919 - recall: 0.9936 - accuracy: 0.9923 - val_loss: 0.7337 - val_balanced_accuracy: 0.9310 - val_precision: 0.5533 - val_recall: 0.9988 - val_accuracy: 0.8803\n",
      "Epoch 88/300\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.0212 - balanced_accuracy: 0.9929 - precision: 0.9924 - recall: 0.9943 - accuracy: 0.9930\n",
      "Epoch 88: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0212 - balanced_accuracy: 0.9929 - precision: 0.9924 - recall: 0.9944 - accuracy: 0.9930 - val_loss: 0.7524 - val_balanced_accuracy: 0.9230 - val_precision: 0.5260 - val_recall: 0.9992 - val_accuracy: 0.8659\n",
      "Epoch 89/300\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.0212 - balanced_accuracy: 0.9933 - precision: 0.9933 - recall: 0.9940 - accuracy: 0.9932\n",
      "Epoch 89: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0212 - balanced_accuracy: 0.9933 - precision: 0.9933 - recall: 0.9940 - accuracy: 0.9932 - val_loss: 1.0230 - val_balanced_accuracy: 0.8885 - val_precision: 0.4814 - val_recall: 0.9525 - val_accuracy: 0.8398\n",
      "Epoch 90/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0227 - balanced_accuracy: 0.9927 - precision: 0.9932 - recall: 0.9932 - accuracy: 0.9928\n",
      "Epoch 90: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0228 - balanced_accuracy: 0.9925 - precision: 0.9928 - recall: 0.9931 - accuracy: 0.9926 - val_loss: 1.0316 - val_balanced_accuracy: 0.9086 - val_precision: 0.4917 - val_recall: 0.9915 - val_accuracy: 0.8464\n",
      "Epoch 91/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0235 - balanced_accuracy: 0.9927 - precision: 0.9927 - recall: 0.9935 - accuracy: 0.9928\n",
      "Epoch 91: val_balanced_accuracy did not improve from 0.94166\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0236 - balanced_accuracy: 0.9927 - precision: 0.9928 - recall: 0.9934 - accuracy: 0.9927 - val_loss: 0.6589 - val_balanced_accuracy: 0.9325 - val_precision: 0.5606 - val_recall: 0.9980 - val_accuracy: 0.8832\n",
      "Epoch 92/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0207 - balanced_accuracy: 0.9932 - precision: 0.9931 - recall: 0.9941 - accuracy: 0.9933\n",
      "Epoch 92: val_balanced_accuracy improved from 0.94166 to 0.94374, saving model to cnn_model.h5\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0208 - balanced_accuracy: 0.9932 - precision: 0.9931 - recall: 0.9941 - accuracy: 0.9933 - val_loss: 0.5521 - val_balanced_accuracy: 0.9437 - val_precision: 0.6086 - val_recall: 0.9953 - val_accuracy: 0.9050\n",
      "Epoch 93/300\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.0201 - balanced_accuracy: 0.9934 - precision: 0.9934 - recall: 0.9939 - accuracy: 0.9936\n",
      "Epoch 93: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0201 - balanced_accuracy: 0.9934 - precision: 0.9934 - recall: 0.9939 - accuracy: 0.9936 - val_loss: 0.6741 - val_balanced_accuracy: 0.9373 - val_precision: 0.5747 - val_recall: 1.0000 - val_accuracy: 0.8905\n",
      "Epoch 94/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0208 - balanced_accuracy: 0.9936 - precision: 0.9929 - recall: 0.9952 - accuracy: 0.9937\n",
      "Epoch 94: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0206 - balanced_accuracy: 0.9937 - precision: 0.9930 - recall: 0.9953 - accuracy: 0.9938 - val_loss: 0.6782 - val_balanced_accuracy: 0.9315 - val_precision: 0.5571 - val_recall: 0.9976 - val_accuracy: 0.8821\n",
      "Epoch 95/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0223 - balanced_accuracy: 0.9929 - precision: 0.9930 - recall: 0.9934 - accuracy: 0.9929\n",
      "Epoch 95: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0226 - balanced_accuracy: 0.9928 - precision: 0.9929 - recall: 0.9933 - accuracy: 0.9928 - val_loss: 0.6459 - val_balanced_accuracy: 0.9354 - val_precision: 0.5796 - val_recall: 0.9913 - val_accuracy: 0.8933\n",
      "Epoch 96/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0233 - balanced_accuracy: 0.9921 - precision: 0.9923 - recall: 0.9929 - accuracy: 0.9922\n",
      "Epoch 96: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0239 - balanced_accuracy: 0.9918 - precision: 0.9921 - recall: 0.9927 - accuracy: 0.9921 - val_loss: 0.9952 - val_balanced_accuracy: 0.9067 - val_precision: 0.4938 - val_recall: 0.9854 - val_accuracy: 0.8475\n",
      "Epoch 97/300\n",
      "206/213 [============================>.] - ETA: 0s - loss: 0.0226 - balanced_accuracy: 0.9926 - precision: 0.9925 - recall: 0.9937 - accuracy: 0.9927\n",
      "Epoch 97: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0225 - balanced_accuracy: 0.9927 - precision: 0.9927 - recall: 0.9938 - accuracy: 0.9928 - val_loss: 0.8708 - val_balanced_accuracy: 0.9167 - val_precision: 0.5211 - val_recall: 0.9878 - val_accuracy: 0.8631\n",
      "Epoch 98/300\n",
      "206/213 [============================>.] - ETA: 0s - loss: 0.0165 - balanced_accuracy: 0.9945 - precision: 0.9948 - recall: 0.9948 - accuracy: 0.9945\n",
      "Epoch 98: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0165 - balanced_accuracy: 0.9945 - precision: 0.9948 - recall: 0.9947 - accuracy: 0.9944 - val_loss: 0.8469 - val_balanced_accuracy: 0.9253 - val_precision: 0.5358 - val_recall: 0.9978 - val_accuracy: 0.8709\n",
      "Epoch 99/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0197 - balanced_accuracy: 0.9936 - precision: 0.9932 - recall: 0.9948 - accuracy: 0.9937\n",
      "Epoch 99: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0199 - balanced_accuracy: 0.9936 - precision: 0.9933 - recall: 0.9947 - accuracy: 0.9936 - val_loss: 0.5792 - val_balanced_accuracy: 0.9348 - val_precision: 0.5882 - val_recall: 0.9865 - val_accuracy: 0.8957\n",
      "Epoch 100/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0188 - balanced_accuracy: 0.9940 - precision: 0.9941 - recall: 0.9946 - accuracy: 0.9940\n",
      "Epoch 100: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0187 - balanced_accuracy: 0.9941 - precision: 0.9941 - recall: 0.9945 - accuracy: 0.9940 - val_loss: 0.6743 - val_balanced_accuracy: 0.9394 - val_precision: 0.5870 - val_recall: 0.9972 - val_accuracy: 0.8960\n",
      "Epoch 101/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0188 - balanced_accuracy: 0.9936 - precision: 0.9932 - recall: 0.9948 - accuracy: 0.9936\n",
      "Epoch 101: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0193 - balanced_accuracy: 0.9934 - precision: 0.9932 - recall: 0.9945 - accuracy: 0.9935 - val_loss: 0.6359 - val_balanced_accuracy: 0.9397 - val_precision: 0.5884 - val_recall: 0.9976 - val_accuracy: 0.8964\n",
      "Epoch 102/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0183 - balanced_accuracy: 0.9944 - precision: 0.9944 - recall: 0.9951 - accuracy: 0.9944\n",
      "Epoch 102: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0181 - balanced_accuracy: 0.9944 - precision: 0.9943 - recall: 0.9951 - accuracy: 0.9944 - val_loss: 0.8840 - val_balanced_accuracy: 0.9206 - val_precision: 0.5188 - val_recall: 0.9988 - val_accuracy: 0.8621\n",
      "Epoch 103/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0213 - balanced_accuracy: 0.9927 - precision: 0.9929 - recall: 0.9934 - accuracy: 0.9927\n",
      "Epoch 103: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0213 - balanced_accuracy: 0.9927 - precision: 0.9929 - recall: 0.9933 - accuracy: 0.9926 - val_loss: 0.7544 - val_balanced_accuracy: 0.9226 - val_precision: 0.5236 - val_recall: 0.9988 - val_accuracy: 0.8655\n",
      "Epoch 104/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0212 - balanced_accuracy: 0.9928 - precision: 0.9923 - recall: 0.9943 - accuracy: 0.9929\n",
      "Epoch 104: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0214 - balanced_accuracy: 0.9929 - precision: 0.9924 - recall: 0.9942 - accuracy: 0.9929 - val_loss: 0.6609 - val_balanced_accuracy: 0.9325 - val_precision: 0.5634 - val_recall: 0.9957 - val_accuracy: 0.8851\n",
      "Epoch 105/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0177 - balanced_accuracy: 0.9936 - precision: 0.9934 - recall: 0.9946 - accuracy: 0.9936\n",
      "Epoch 105: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0181 - balanced_accuracy: 0.9936 - precision: 0.9934 - recall: 0.9945 - accuracy: 0.9936 - val_loss: 0.8463 - val_balanced_accuracy: 0.9252 - val_precision: 0.5343 - val_recall: 0.9988 - val_accuracy: 0.8700\n",
      "Epoch 106/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0219 - balanced_accuracy: 0.9930 - precision: 0.9931 - recall: 0.9936 - accuracy: 0.9930\n",
      "Epoch 106: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0216 - balanced_accuracy: 0.9931 - precision: 0.9932 - recall: 0.9937 - accuracy: 0.9931 - val_loss: 0.8514 - val_balanced_accuracy: 0.9240 - val_precision: 0.5302 - val_recall: 0.9978 - val_accuracy: 0.8688\n",
      "Epoch 107/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0172 - balanced_accuracy: 0.9942 - precision: 0.9946 - recall: 0.9945 - accuracy: 0.9943\n",
      "Epoch 107: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0173 - balanced_accuracy: 0.9942 - precision: 0.9946 - recall: 0.9946 - accuracy: 0.9943 - val_loss: 0.7244 - val_balanced_accuracy: 0.9318 - val_precision: 0.5611 - val_recall: 0.9960 - val_accuracy: 0.8839\n",
      "Epoch 108/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0213 - balanced_accuracy: 0.9938 - precision: 0.9940 - recall: 0.9941 - accuracy: 0.9937\n",
      "Epoch 108: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0213 - balanced_accuracy: 0.9938 - precision: 0.9939 - recall: 0.9942 - accuracy: 0.9937 - val_loss: 0.9052 - val_balanced_accuracy: 0.9135 - val_precision: 0.5118 - val_recall: 0.9881 - val_accuracy: 0.8574\n",
      "Epoch 109/300\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.0174 - balanced_accuracy: 0.9939 - precision: 0.9938 - recall: 0.9946 - accuracy: 0.9939\n",
      "Epoch 109: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0182 - balanced_accuracy: 0.9935 - precision: 0.9937 - recall: 0.9941 - accuracy: 0.9938 - val_loss: 0.7449 - val_balanced_accuracy: 0.9325 - val_precision: 0.5594 - val_recall: 0.9990 - val_accuracy: 0.8827\n",
      "Epoch 110/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0200 - balanced_accuracy: 0.9936 - precision: 0.9932 - recall: 0.9946 - accuracy: 0.9936\n",
      "Epoch 110: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0204 - balanced_accuracy: 0.9935 - precision: 0.9932 - recall: 0.9944 - accuracy: 0.9935 - val_loss: 0.8934 - val_balanced_accuracy: 0.9246 - val_precision: 0.5349 - val_recall: 0.9960 - val_accuracy: 0.8709\n",
      "Epoch 111/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0194 - balanced_accuracy: 0.9940 - precision: 0.9937 - recall: 0.9953 - accuracy: 0.9941\n",
      "Epoch 111: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0194 - balanced_accuracy: 0.9939 - precision: 0.9936 - recall: 0.9952 - accuracy: 0.9941 - val_loss: 0.7029 - val_balanced_accuracy: 0.9319 - val_precision: 0.5770 - val_recall: 0.9864 - val_accuracy: 0.8909\n",
      "Epoch 112/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0208 - balanced_accuracy: 0.9936 - precision: 0.9935 - recall: 0.9945 - accuracy: 0.9936\n",
      "Epoch 112: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0207 - balanced_accuracy: 0.9936 - precision: 0.9935 - recall: 0.9944 - accuracy: 0.9936 - val_loss: 0.6410 - val_balanced_accuracy: 0.9250 - val_precision: 0.5705 - val_recall: 0.9746 - val_accuracy: 0.8879\n",
      "Epoch 113/300\n",
      "206/213 [============================>.] - ETA: 0s - loss: 0.0166 - balanced_accuracy: 0.9943 - precision: 0.9943 - recall: 0.9950 - accuracy: 0.9943\n",
      "Epoch 113: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0165 - balanced_accuracy: 0.9943 - precision: 0.9943 - recall: 0.9950 - accuracy: 0.9943 - val_loss: 0.8117 - val_balanced_accuracy: 0.9247 - val_precision: 0.5370 - val_recall: 0.9948 - val_accuracy: 0.8720\n",
      "Epoch 114/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0235 - balanced_accuracy: 0.9926 - precision: 0.9923 - recall: 0.9936 - accuracy: 0.9926\n",
      "Epoch 114: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0239 - balanced_accuracy: 0.9924 - precision: 0.9923 - recall: 0.9933 - accuracy: 0.9925 - val_loss: 0.6578 - val_balanced_accuracy: 0.9391 - val_precision: 0.5847 - val_recall: 0.9981 - val_accuracy: 0.8949\n",
      "Epoch 115/300\n",
      "206/213 [============================>.] - ETA: 0s - loss: 0.0244 - balanced_accuracy: 0.9929 - precision: 0.9927 - recall: 0.9938 - accuracy: 0.9929\n",
      "Epoch 115: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0241 - balanced_accuracy: 0.9930 - precision: 0.9928 - recall: 0.9938 - accuracy: 0.9930 - val_loss: 0.7451 - val_balanced_accuracy: 0.9223 - val_precision: 0.5594 - val_recall: 0.9745 - val_accuracy: 0.8828\n",
      "Epoch 116/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0199 - balanced_accuracy: 0.9939 - precision: 0.9935 - recall: 0.9949 - accuracy: 0.9939\n",
      "Epoch 116: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0198 - balanced_accuracy: 0.9938 - precision: 0.9934 - recall: 0.9950 - accuracy: 0.9938 - val_loss: 0.6965 - val_balanced_accuracy: 0.9325 - val_precision: 0.5598 - val_recall: 0.9969 - val_accuracy: 0.8844\n",
      "Epoch 117/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0207 - balanced_accuracy: 0.9934 - precision: 0.9930 - recall: 0.9945 - accuracy: 0.9934\n",
      "Epoch 117: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0207 - balanced_accuracy: 0.9932 - precision: 0.9929 - recall: 0.9944 - accuracy: 0.9933 - val_loss: 0.7703 - val_balanced_accuracy: 0.9152 - val_precision: 0.5365 - val_recall: 0.9627 - val_accuracy: 0.8816\n",
      "Epoch 118/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0207 - balanced_accuracy: 0.9937 - precision: 0.9939 - recall: 0.9943 - accuracy: 0.9937\n",
      "Epoch 118: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0208 - balanced_accuracy: 0.9937 - precision: 0.9938 - recall: 0.9943 - accuracy: 0.9937 - val_loss: 1.0170 - val_balanced_accuracy: 0.8803 - val_precision: 0.4783 - val_recall: 0.9355 - val_accuracy: 0.8379\n",
      "Epoch 119/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0192 - balanced_accuracy: 0.9942 - precision: 0.9939 - recall: 0.9951 - accuracy: 0.9942\n",
      "Epoch 119: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0192 - balanced_accuracy: 0.9942 - precision: 0.9939 - recall: 0.9952 - accuracy: 0.9942 - val_loss: 0.9560 - val_balanced_accuracy: 0.9122 - val_precision: 0.4986 - val_recall: 0.9955 - val_accuracy: 0.8498\n",
      "Epoch 120/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0187 - balanced_accuracy: 0.9942 - precision: 0.9939 - recall: 0.9953 - accuracy: 0.9943\n",
      "Epoch 120: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0190 - balanced_accuracy: 0.9941 - precision: 0.9937 - recall: 0.9950 - accuracy: 0.9941 - val_loss: 0.7025 - val_balanced_accuracy: 0.9284 - val_precision: 0.5669 - val_recall: 0.9855 - val_accuracy: 0.8853\n",
      "Epoch 121/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0165 - balanced_accuracy: 0.9945 - precision: 0.9943 - recall: 0.9954 - accuracy: 0.9945\n",
      "Epoch 121: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0163 - balanced_accuracy: 0.9946 - precision: 0.9944 - recall: 0.9954 - accuracy: 0.9945 - val_loss: 0.6676 - val_balanced_accuracy: 0.9204 - val_precision: 0.5544 - val_recall: 0.9732 - val_accuracy: 0.8804\n",
      "Epoch 122/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0195 - balanced_accuracy: 0.9940 - precision: 0.9941 - recall: 0.9947 - accuracy: 0.9940\n",
      "Epoch 122: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0194 - balanced_accuracy: 0.9941 - precision: 0.9942 - recall: 0.9947 - accuracy: 0.9941 - val_loss: 0.6642 - val_balanced_accuracy: 0.9368 - val_precision: 0.5771 - val_recall: 0.9969 - val_accuracy: 0.8917\n",
      "Epoch 123/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0184 - balanced_accuracy: 0.9943 - precision: 0.9942 - recall: 0.9951 - accuracy: 0.9943\n",
      "Epoch 123: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0185 - balanced_accuracy: 0.9941 - precision: 0.9939 - recall: 0.9952 - accuracy: 0.9943 - val_loss: 0.8006 - val_balanced_accuracy: 0.9155 - val_precision: 0.5205 - val_recall: 0.9853 - val_accuracy: 0.8629\n",
      "Epoch 124/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0197 - balanced_accuracy: 0.9939 - precision: 0.9939 - recall: 0.9948 - accuracy: 0.9940\n",
      "Epoch 124: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0202 - balanced_accuracy: 0.9937 - precision: 0.9936 - recall: 0.9946 - accuracy: 0.9938 - val_loss: 0.6838 - val_balanced_accuracy: 0.9380 - val_precision: 0.5803 - val_recall: 0.9988 - val_accuracy: 0.8924\n",
      "Epoch 125/300\n",
      "206/213 [============================>.] - ETA: 0s - loss: 0.0154 - balanced_accuracy: 0.9950 - precision: 0.9951 - recall: 0.9955 - accuracy: 0.9950\n",
      "Epoch 125: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0154 - balanced_accuracy: 0.9950 - precision: 0.9952 - recall: 0.9955 - accuracy: 0.9950 - val_loss: 0.8444 - val_balanced_accuracy: 0.9167 - val_precision: 0.5270 - val_recall: 0.9839 - val_accuracy: 0.8659\n",
      "Epoch 126/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0156 - balanced_accuracy: 0.9949 - precision: 0.9947 - recall: 0.9958 - accuracy: 0.9949\n",
      "Epoch 126: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0158 - balanced_accuracy: 0.9947 - precision: 0.9945 - recall: 0.9955 - accuracy: 0.9948 - val_loss: 0.6753 - val_balanced_accuracy: 0.9304 - val_precision: 0.5682 - val_recall: 0.9881 - val_accuracy: 0.8869\n",
      "Epoch 127/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0212 - balanced_accuracy: 0.9931 - precision: 0.9930 - recall: 0.9941 - accuracy: 0.9932\n",
      "Epoch 127: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0211 - balanced_accuracy: 0.9931 - precision: 0.9931 - recall: 0.9941 - accuracy: 0.9932 - val_loss: 0.6248 - val_balanced_accuracy: 0.9351 - val_precision: 0.5701 - val_recall: 0.9978 - val_accuracy: 0.8881\n",
      "Epoch 128/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0181 - balanced_accuracy: 0.9939 - precision: 0.9939 - recall: 0.9943 - accuracy: 0.9938\n",
      "Epoch 128: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0183 - balanced_accuracy: 0.9939 - precision: 0.9939 - recall: 0.9944 - accuracy: 0.9938 - val_loss: 0.6410 - val_balanced_accuracy: 0.9388 - val_precision: 0.5889 - val_recall: 0.9955 - val_accuracy: 0.8964\n",
      "Epoch 129/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0209 - balanced_accuracy: 0.9938 - precision: 0.9937 - recall: 0.9947 - accuracy: 0.9938\n",
      "Epoch 129: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0208 - balanced_accuracy: 0.9938 - precision: 0.9936 - recall: 0.9948 - accuracy: 0.9939 - val_loss: 0.7557 - val_balanced_accuracy: 0.9267 - val_precision: 0.5484 - val_recall: 0.9920 - val_accuracy: 0.8779\n",
      "Epoch 130/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0157 - balanced_accuracy: 0.9947 - precision: 0.9944 - recall: 0.9956 - accuracy: 0.9947\n",
      "Epoch 130: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0156 - balanced_accuracy: 0.9947 - precision: 0.9943 - recall: 0.9957 - accuracy: 0.9948 - val_loss: 0.7379 - val_balanced_accuracy: 0.9219 - val_precision: 0.5546 - val_recall: 0.9767 - val_accuracy: 0.8803\n",
      "Epoch 131/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0191 - balanced_accuracy: 0.9940 - precision: 0.9939 - recall: 0.9947 - accuracy: 0.9940\n",
      "Epoch 131: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0191 - balanced_accuracy: 0.9940 - precision: 0.9940 - recall: 0.9946 - accuracy: 0.9940 - val_loss: 0.7384 - val_balanced_accuracy: 0.9172 - val_precision: 0.5224 - val_recall: 0.9874 - val_accuracy: 0.8643\n",
      "Epoch 132/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0197 - balanced_accuracy: 0.9937 - precision: 0.9936 - recall: 0.9946 - accuracy: 0.9937\n",
      "Epoch 132: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0197 - balanced_accuracy: 0.9937 - precision: 0.9935 - recall: 0.9947 - accuracy: 0.9938 - val_loss: 0.6603 - val_balanced_accuracy: 0.9391 - val_precision: 0.5864 - val_recall: 0.9965 - val_accuracy: 0.8961\n",
      "Epoch 133/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0202 - balanced_accuracy: 0.9935 - precision: 0.9937 - recall: 0.9940 - accuracy: 0.9935\n",
      "Epoch 133: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0203 - balanced_accuracy: 0.9935 - precision: 0.9937 - recall: 0.9941 - accuracy: 0.9935 - val_loss: 0.8817 - val_balanced_accuracy: 0.9270 - val_precision: 0.5385 - val_recall: 0.9988 - val_accuracy: 0.8733\n",
      "Epoch 134/300\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0183 - balanced_accuracy: 0.9942 - precision: 0.9945 - recall: 0.9946 - accuracy: 0.9942\n",
      "Epoch 134: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0179 - balanced_accuracy: 0.9943 - precision: 0.9946 - recall: 0.9947 - accuracy: 0.9943 - val_loss: 0.8490 - val_balanced_accuracy: 0.9276 - val_precision: 0.5459 - val_recall: 0.9953 - val_accuracy: 0.8769\n",
      "Epoch 135/300\n",
      "206/213 [============================>.] - ETA: 0s - loss: 0.0196 - balanced_accuracy: 0.9938 - precision: 0.9933 - recall: 0.9947 - accuracy: 0.9937\n",
      "Epoch 135: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0195 - balanced_accuracy: 0.9938 - precision: 0.9934 - recall: 0.9947 - accuracy: 0.9938 - val_loss: 0.9341 - val_balanced_accuracy: 0.9050 - val_precision: 0.5077 - val_recall: 0.9703 - val_accuracy: 0.8556\n",
      "Epoch 136/300\n",
      "205/213 [===========================>..] - ETA: 0s - loss: 0.0181 - balanced_accuracy: 0.9942 - precision: 0.9942 - recall: 0.9949 - accuracy: 0.9942\n",
      "Epoch 136: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0181 - balanced_accuracy: 0.9942 - precision: 0.9943 - recall: 0.9948 - accuracy: 0.9943 - val_loss: 0.6199 - val_balanced_accuracy: 0.9365 - val_precision: 0.5932 - val_recall: 0.9875 - val_accuracy: 0.8981\n",
      "Epoch 137/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0176 - balanced_accuracy: 0.9943 - precision: 0.9943 - recall: 0.9951 - accuracy: 0.9944\n",
      "Epoch 137: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0176 - balanced_accuracy: 0.9943 - precision: 0.9943 - recall: 0.9950 - accuracy: 0.9943 - val_loss: 0.6375 - val_balanced_accuracy: 0.9397 - val_precision: 0.5899 - val_recall: 0.9961 - val_accuracy: 0.8974\n",
      "Epoch 138/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0169 - balanced_accuracy: 0.9949 - precision: 0.9947 - recall: 0.9958 - accuracy: 0.9950\n",
      "Epoch 138: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0170 - balanced_accuracy: 0.9949 - precision: 0.9947 - recall: 0.9956 - accuracy: 0.9950 - val_loss: 0.6779 - val_balanced_accuracy: 0.9375 - val_precision: 0.5770 - val_recall: 0.9988 - val_accuracy: 0.8917\n",
      "Epoch 139/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0210 - balanced_accuracy: 0.9939 - precision: 0.9937 - recall: 0.9946 - accuracy: 0.9939\n",
      "Epoch 139: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0210 - balanced_accuracy: 0.9938 - precision: 0.9936 - recall: 0.9947 - accuracy: 0.9938 - val_loss: 0.6993 - val_balanced_accuracy: 0.9214 - val_precision: 0.5501 - val_recall: 0.9786 - val_accuracy: 0.8784\n",
      "Epoch 140/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0174 - balanced_accuracy: 0.9945 - precision: 0.9946 - recall: 0.9951 - accuracy: 0.9945\n",
      "Epoch 140: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0174 - balanced_accuracy: 0.9946 - precision: 0.9946 - recall: 0.9951 - accuracy: 0.9945 - val_loss: 0.9080 - val_balanced_accuracy: 0.9027 - val_precision: 0.5054 - val_recall: 0.9654 - val_accuracy: 0.8552\n",
      "Epoch 141/300\n",
      "209/213 [============================>.] - ETA: 0s - loss: 0.0152 - balanced_accuracy: 0.9950 - precision: 0.9950 - recall: 0.9957 - accuracy: 0.9951\n",
      "Epoch 141: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0151 - balanced_accuracy: 0.9951 - precision: 0.9951 - recall: 0.9957 - accuracy: 0.9951 - val_loss: 0.6432 - val_balanced_accuracy: 0.9405 - val_precision: 0.5936 - val_recall: 0.9969 - val_accuracy: 0.8984\n",
      "Epoch 142/300\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0211 - balanced_accuracy: 0.9930 - precision: 0.9929 - recall: 0.9941 - accuracy: 0.9931\n",
      "Epoch 142: val_balanced_accuracy did not improve from 0.94374\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0213 - balanced_accuracy: 0.9930 - precision: 0.9928 - recall: 0.9941 - accuracy: 0.9930 - val_loss: 0.6425 - val_balanced_accuracy: 0.9390 - val_precision: 0.5917 - val_recall: 0.9936 - val_accuracy: 0.8977\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This CNN: [0.9389765858650208, 0.9405283331871033, 0.9026938080787659, 0.9214475154876709, 0.9375113844871521, 0.9397206902503967, 0.9365209937095642, 0.9050343632698059, 0.9276226758956909, 0.9269917607307434, 0.939117431640625, 0.9171680212020874, 0.9218975305557251, 0.9266918301582336, 0.9387526512145996, 0.9350923299789429, 0.9303864240646362, 0.9166849851608276, 0.9379681348800659, 0.9155190587043762, 0.9368013143539429, 0.9204188585281372, 0.9284396171569824, 0.9122448563575745, 0.8803302049636841, 0.9151544570922852, 0.9324960708618164, 0.9223349094390869, 0.9391058087348938, 0.9246973991394043, 0.9250494241714478, 0.931921660900116, 0.9245612025260925, 0.9324838519096375, 0.9134697914123535, 0.9318260550498962, 0.923991858959198, 0.9252088665962219, 0.9325423836708069, 0.9225856065750122, 0.9206357002258301, 0.9397333264350891, 0.9393967390060425, 0.9348126649856567, 0.9253451228141785, 0.9167265892028809, 0.9066645503044128, 0.9353587627410889, 0.9315391778945923, 0.9373471736907959, 0.9437391757965088, 0.9324547052383423, 0.9085861444473267, 0.8884671330451965, 0.9230024218559265, 0.9310156106948853, 0.9365097284317017, 0.9239295721054077, 0.9312605261802673, 0.9206252098083496, 0.9299322366714478, 0.9354364275932312, 0.9098561406135559, 0.9416623711585999, 0.9216831922531128, 0.920775294303894, 0.9268136024475098, 0.9272969365119934, 0.9005191922187805, 0.899055540561676, 0.9333575963973999, 0.9117678999900818, 0.9290464520454407, 0.921762228012085, 0.9314166307449341, 0.9333716034889221, 0.9097933173179626, 0.9353582262992859, 0.9346897006034851, 0.9310015439987183, 0.9195346236228943, 0.9180329442024231, 0.9313898086547852, 0.895280122756958, 0.9241929054260254, 0.9381566047668457, 0.9243384599685669, 0.9283952713012695, 0.9202297925949097, 0.9268770217895508, 0.9208382368087769, 0.876675009727478, 0.9404499530792236, 0.86555016040802, 0.9304574131965637, 0.9268158078193665, 0.9321712255477905, 0.9293045997619629, 0.9223030209541321, 0.9242615699768066, 0.9309574961662292, 0.9343479871749878, 0.9320640563964844, 0.9152313470840454, 0.9249094724655151, 0.9226486086845398, 0.9122583866119385, 0.8884483575820923, 0.9002394676208496, 0.9366241097450256, 0.9289029240608215, 0.9015277028083801, 0.9307084083557129, 0.9375996589660645, 0.8444013595581055, 0.9134469628334045, 0.937804102897644, 0.9345377087593079, 0.9292160272598267, 0.9224122166633606, 0.8899877667427063, 0.9300597906112671, 0.8913798332214355, 0.9341551065444946, 0.9086312055587769, 0.9237802028656006, 0.9356609582901001, 0.8980525135993958, 0.9169630408287048, 0.9007960557937622, 0.8524624109268188, 0.9264423847198486, 0.9103100895881653, 0.9338284134864807, 0.9219342470169067, 0.9268749356269836, 0.9164168238639832, 0.9163342118263245, 0.9219369292259216, 0.9295627474784851, 0.9103951454162598, 0.9146227240562439]\n",
      "Prev CNN: [0.9353537559509277, 0.914840817451477, 0.8454702496528625, 0.9159557819366455, 0.9329037070274353, 0.906509518623352, 0.9171421527862549, 0.9317882061004639, 0.9188157320022583, 0.8417632579803467, 0.9268618226051331, 0.90179443359375, 0.8520732522010803, 0.8711838126182556, 0.9382227063179016, 0.8911409974098206, 0.9131408333778381, 0.9147798418998718, 0.7242360711097717, 0.9154129028320312, 0.9276938438415527, 0.9309700131416321, 0.9218360781669617, 0.9260939359664917, 0.9030925631523132, 0.930931806564331, 0.9287123680114746, 0.8971997499465942, 0.895168125629425, 0.9290034770965576, 0.9082790017127991, 0.9327922463417053, 0.9213262796401978, 0.9110371470451355, 0.9019433856010437, 0.9285368919372559, 0.871587872505188, 0.9054267406463623, 0.9167895317077637, 0.924095869064331, 0.9258857369422913, 0.9291863441467285, 0.9387912750244141, 0.9158887267112732, 0.9272055625915527, 0.914932131767273, 0.926865816116333, 0.8927543759346008, 0.8829840421676636, 0.9193151593208313, 0.9451107978820801, 0.9288133382797241, 0.9310590028762817, 0.9105456471443176, 0.9122366905212402, 0.9187444448471069, 0.885603129863739, 0.9287058115005493, 0.9108738899230957, 0.9301175475120544, 0.9293227791786194, 0.9271514415740967, 0.9181264638900757, 0.9032393097877502, 0.9320969581604004, 0.8758970499038696, 0.9282366037368774, 0.9181221127510071, 0.9157271385192871, 0.9201944470405579, 0.9156397581100464, 0.9187686443328857, 0.9199671745300293, 0.9248127341270447, 0.889700710773468, 0.8943924307823181, 0.914503812789917, 0.8683533668518066, 0.9059141278266907, 0.8456946015357971, 0.9061341285705566, 0.9263679385185242, 0.8906506896018982, 0.8830864429473877, 0.8910396695137024, 0.8912994265556335, 0.9096360206604004, 0.9329741597175598, 0.9252737760543823, 0.9155104756355286, 0.8795786499977112, 0.9217866659164429, 0.8811948895454407, 0.9023239612579346, 0.9173622131347656]\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_48 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " average_pooling2d_24 (Avera  (None, 13, 13, 32)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 13, 13, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d_25 (Avera  (None, 5, 5, 64)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1600)              2561600   \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 3202      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,630,754\n",
      "Trainable params: 2,630,562\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history_cnn = best_model.fit(x=X_train ,y=y_labels ,epochs=epochs ,batch_size=batch_size ,validation_data=(X_val,y_val_labels) ,verbose=1,\n",
    "                           callbacks=[keras.callbacks.EarlyStopping(monitor='val_balanced_accuracy', patience=50, restore_best_weights=True),\n",
    "                                      keras.callbacks.ModelCheckpoint('cnn_model.h5', verbose=1, monitor= \"val_balanced_accuracy\", save_best_only=True)])\n",
    "if first_time:\n",
    "    prev_history = history_cnn\n",
    "    prev_model = model_cnn\n",
    "    first_time = False\n",
    "display_model_data(history_cnn, prev_history)\n",
    "print(f'This CNN: {history_cnn.history[\"val_balanced_accuracy\"][::-1]}')\n",
    "print(f'Prev CNN: {prev_history.history[\"val_balanced_accuracy\"][::-1]}')\n",
    "prev_model.summary()\n",
    "prev_history = history_cnn\n",
    "prev_model = model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9296037554740906, 0.9253382682800293, 0.9279530048370361, 0.9294486045837402, 0.8947063088417053, 0.924633800983429, 0.9290404915809631, 0.9192749857902527, 0.9263961315155029, 0.9235795736312866, 0.9221094250679016, 0.9222288727760315, 0.9211083650588989, 0.933263897895813, 0.9220494627952576, 0.930840253829956, 0.9348143339157104, 0.9352971911430359, 0.9305440187454224, 0.9293144345283508, 0.9332985877990723, 0.9243150949478149, 0.9242256283760071, 0.9133195281028748, 0.923386812210083, 0.927563488483429, 0.9235178232192993, 0.9366384744644165, 0.9205454587936401, 0.9167258739471436, 0.9267645478248596, 0.9297756552696228, 0.9169709086418152, 0.9204679727554321, 0.9257184863090515, 0.9170079231262207, 0.9292119741439819, 0.9311229586601257, 0.9058955311775208, 0.9304153323173523, 0.9194833636283875, 0.9241447448730469, 0.9368268251419067, 0.9133480191230774, 0.9184601306915283, 0.9227909445762634, 0.9325416684150696, 0.9330137968063354, 0.9243262410163879, 0.9131224751472473, 0.9404218792915344, 0.9323935508728027, 0.9257358908653259, 0.9282618165016174, 0.9146056771278381, 0.9262246489524841, 0.9339590668678284, 0.9237744212150574, 0.9278793334960938, 0.9122136831283569, 0.9168592691421509, 0.9198398590087891, 0.9231526255607605, 0.9234848022460938, 0.9161805510520935, 0.909988284111023, 0.9347530007362366, 0.9267249703407288, 0.9180582165718079, 0.921921968460083, 0.9324698448181152, 0.926333487033844, 0.9217413663864136, 0.9219833016395569, 0.9317154884338379, 0.9261490702629089, 0.9317285418510437, 0.9224717020988464, 0.930046796798706, 0.9008586406707764, 0.9273565411567688, 0.913404643535614, 0.9128400087356567, 0.9177922606468201, 0.9209571480751038, 0.9196086525917053, 0.9267776608467102, 0.9274654388427734, 0.9245889782905579, 0.9278127551078796, 0.9256993532180786, 0.9256024360656738, 0.9125587940216064, 0.9203039407730103, 0.9221653938293457, 0.9185462594032288, 0.926513671875, 0.927177906036377, 0.9307368397712708, 0.932792067527771, 0.9262464642524719, 0.9267804026603699, 0.9221593141555786, 0.9239490628242493, 0.9253378510475159, 0.9237625598907471, 0.9199220538139343, 0.9325178861618042, 0.9152350425720215, 0.9269171357154846, 0.9239776134490967, 0.9205408692359924, 0.9187464714050293, 0.923342227935791, 0.9322691559791565, 0.9190280437469482, 0.9132789969444275, 0.9257727265357971, 0.9179705381393433, 0.9256356954574585, 0.9320946931838989, 0.9233197569847107, 0.9164858460426331, 0.9223808646202087, 0.9129327535629272, 0.9137740135192871, 0.9208108186721802, 0.9148455262184143]\n"
     ]
    }
   ],
   "source": [
    "best_history = history_cnn #100 batch_size\n",
    "best_model = model_cnn\n",
    "print(best_history.history['val_balanced_accuracy'][::-1])\n",
    "keras.models.save_model(best_model, 'best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 1ms/step\n",
      "Percentage of Melanoma predictions is 20.63%\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load('Xtest_Classification1.npy')\n",
    "X_test = np.reshape((X_test).astype('float32')/255.0,(len(X_test),28,28,3))\n",
    "y_test = best_model.predict(X_test)\n",
    "# best_model.summary()\n",
    "y_test = y_test.round()\n",
    "print(f\"Percentage of Melanoma predictions is {np.count_nonzero(y_test[:,1] == 1)/len(y_test)*100:2.2f}%\")\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test = np.reshape(y_test,(len(y_test),1))\n",
    "np.save('ytest_Classification1.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 49 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display training images\n",
    "n = 49*3\n",
    "images = X_train[n:49+n]\n",
    "labels = y_train[n:49+n]\n",
    "rows, cols = 7, 7\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        ax = axes[i, j]\n",
    "        image = images[i*rows + j]\n",
    "        ax.imshow(image, interpolation='nearest')\n",
    "        ax.set_title(f\"Label {labels[i*cols + j]:1.0f}\")\n",
    "        ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.5450 - tp: 18341.0000 - fp: 5270.0000 - tn: 18341.0000 - fn: 5270.0000 - accuracy: 0.7768 train_balacc 0.7767989496421159\n",
      " val_balacc 0.8036591563611722\n",
      "\n",
      "Epoch 1: val_balacc improved from -inf to 0.80366, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 0.5450 - tp: 18341.0000 - fp: 5270.0000 - tn: 18341.0000 - fn: 5270.0000 - accuracy: 0.7768 - val_loss: 0.4091 - val_tp: 4744.0000 - val_fp: 1159.0000 - val_tn: 4744.0000 - val_fn: 1159.0000 - val_accuracy: 0.8037 - train_sensitivity: 0.7768 - train_specificity: 0.7768 - train_balacc: 0.7768 - val_sensitivity: 0.8037 - val_specificity: 0.8037 - val_balacc: 0.8037\n",
      "Epoch 2/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.3987 - tp: 18706.0000 - fp: 4594.0000 - tn: 18706.0000 - fn: 4594.0000 - accuracy: 0.8028 train_balacc 0.8033967218669265\n",
      " val_balacc 0.7829916991360325\n",
      "\n",
      "Epoch 2: val_balacc did not improve from 0.80366\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.3980 - tp: 18969.0000 - fp: 4642.0000 - tn: 18969.0000 - fn: 4642.0000 - accuracy: 0.8034 - val_loss: 0.4647 - val_tp: 4622.0000 - val_fp: 1281.0000 - val_tn: 4622.0000 - val_fn: 1281.0000 - val_accuracy: 0.7830 - train_sensitivity: 0.8034 - train_specificity: 0.8034 - train_balacc: 0.8034 - val_sensitivity: 0.7830 - val_specificity: 0.7830 - val_balacc: 0.7830\n",
      "Epoch 3/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.3789 - tp: 18700.0000 - fp: 4300.0000 - tn: 18700.0000 - fn: 4300.0000 - accuracy: 0.8130 train_balacc 0.8127991190546779\n",
      " val_balacc 0.8234795866508555\n",
      "\n",
      "Epoch 3: val_balacc improved from 0.80366 to 0.82348, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.3791 - tp: 19191.0000 - fp: 4420.0000 - tn: 19191.0000 - fn: 4420.0000 - accuracy: 0.8128 - val_loss: 0.3905 - val_tp: 4861.0000 - val_fp: 1042.0000 - val_tn: 4861.0000 - val_fn: 1042.0000 - val_accuracy: 0.8235 - train_sensitivity: 0.8128 - train_specificity: 0.8128 - train_balacc: 0.8128 - val_sensitivity: 0.8235 - val_specificity: 0.8235 - val_balacc: 0.8235\n",
      "Epoch 4/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.3748 - tp: 18637.0000 - fp: 4163.0000 - tn: 18637.0000 - fn: 4163.0000 - accuracy: 0.8174 train_balacc 0.8175850239295244\n",
      " val_balacc 0.8087413179739116\n",
      "\n",
      "Epoch 4: val_balacc did not improve from 0.82348\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.3750 - tp: 19304.0000 - fp: 4307.0000 - tn: 19304.0000 - fn: 4307.0000 - accuracy: 0.8176 - val_loss: 0.3905 - val_tp: 4774.0000 - val_fp: 1129.0000 - val_tn: 4774.0000 - val_fn: 1129.0000 - val_accuracy: 0.8087 - train_sensitivity: 0.8176 - train_specificity: 0.8176 - train_balacc: 0.8176 - val_sensitivity: 0.8087 - val_specificity: 0.8087 - val_balacc: 0.8087\n",
      "Epoch 5/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.3655 - tp: 18771.0000 - fp: 4029.0000 - tn: 18771.0000 - fn: 4029.0000 - accuracy: 0.8233 train_balacc 0.8234721104569904\n",
      " val_balacc 0.7518211079112316\n",
      "\n",
      "Epoch 5: val_balacc did not improve from 0.82348\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.3656 - tp: 19443.0000 - fp: 4168.0000 - tn: 19443.0000 - fn: 4168.0000 - accuracy: 0.8235 - val_loss: 0.4813 - val_tp: 4438.0000 - val_fp: 1465.0000 - val_tn: 4438.0000 - val_fn: 1465.0000 - val_accuracy: 0.7518 - train_sensitivity: 0.8235 - train_specificity: 0.8235 - train_balacc: 0.8235 - val_sensitivity: 0.7518 - val_specificity: 0.7518 - val_balacc: 0.7518\n",
      "Epoch 6/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.3551 - tp: 18986.0000 - fp: 3914.0000 - tn: 18986.0000 - fn: 3914.0000 - accuracy: 0.8291 train_balacc 0.8296980221083393\n",
      " val_balacc 0.8295781805861426\n",
      "\n",
      "Epoch 6: val_balacc improved from 0.82348 to 0.82958, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.3552 - tp: 19590.0000 - fp: 4021.0000 - tn: 19590.0000 - fn: 4021.0000 - accuracy: 0.8297 - val_loss: 0.3723 - val_tp: 4897.0000 - val_fp: 1006.0000 - val_tn: 4897.0000 - val_fn: 1006.0000 - val_accuracy: 0.8296 - train_sensitivity: 0.8297 - train_specificity: 0.8297 - train_balacc: 0.8297 - val_sensitivity: 0.8296 - val_specificity: 0.8296 - val_balacc: 0.8296\n",
      "Epoch 7/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.3456 - tp: 19657.0000 - fp: 3943.0000 - tn: 19657.0000 - fn: 3943.0000 - accuracy: 0.8329 train_balacc 0.8328321545042565\n",
      " val_balacc 0.8187362358122988\n",
      "\n",
      "Epoch 7: val_balacc did not improve from 0.82958\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.3458 - tp: 19664.0000 - fp: 3947.0000 - tn: 19664.0000 - fn: 3947.0000 - accuracy: 0.8328 - val_loss: 0.3941 - val_tp: 4833.0000 - val_fp: 1070.0000 - val_tn: 4833.0000 - val_fn: 1070.0000 - val_accuracy: 0.8187 - train_sensitivity: 0.8328 - train_specificity: 0.8328 - train_balacc: 0.8328 - val_sensitivity: 0.8187 - val_specificity: 0.8187 - val_balacc: 0.8187\n",
      "Epoch 8/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.3430 - tp: 19656.0000 - fp: 3844.0000 - tn: 19656.0000 - fn: 3844.0000 - accuracy: 0.8364 train_balacc 0.836474524585998\n",
      " val_balacc 0.8295781805861426\n",
      "\n",
      "Epoch 8: val_balacc did not improve from 0.82958\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.3430 - tp: 19750.0000 - fp: 3861.0000 - tn: 19750.0000 - fn: 3861.0000 - accuracy: 0.8365 - val_loss: 0.3890 - val_tp: 4897.0000 - val_fp: 1006.0000 - val_tn: 4897.0000 - val_fn: 1006.0000 - val_accuracy: 0.8296 - train_sensitivity: 0.8365 - train_specificity: 0.8365 - train_balacc: 0.8365 - val_sensitivity: 0.8296 - val_specificity: 0.8296 - val_balacc: 0.8296\n",
      "Epoch 9/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.3354 - tp: 19861.0000 - fp: 3739.0000 - tn: 19861.0000 - fn: 3739.0000 - accuracy: 0.8416 train_balacc 0.8416416077252128\n",
      " val_balacc 0.7953582923936982\n",
      "\n",
      "Epoch 9: val_balacc did not improve from 0.82958\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.3353 - tp: 19872.0000 - fp: 3739.0000 - tn: 19872.0000 - fn: 3739.0000 - accuracy: 0.8416 - val_loss: 0.4121 - val_tp: 4695.0000 - val_fp: 1208.0000 - val_tn: 4695.0000 - val_fn: 1208.0000 - val_accuracy: 0.7954 - train_sensitivity: 0.8416 - train_specificity: 0.8416 - train_balacc: 0.8416 - val_sensitivity: 0.7954 - val_specificity: 0.7954 - val_balacc: 0.7954\n",
      "Epoch 10/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.3307 - tp: 19899.0000 - fp: 3712.0000 - tn: 19899.0000 - fn: 3712.0000 - accuracy: 0.8428 train_balacc 0.8427851425183177\n",
      " val_balacc 0.8287311536506861\n",
      "\n",
      "Epoch 10: val_balacc did not improve from 0.82958\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.3307 - tp: 19899.0000 - fp: 3712.0000 - tn: 19899.0000 - fn: 3712.0000 - accuracy: 0.8428 - val_loss: 0.3683 - val_tp: 4892.0000 - val_fp: 1011.0000 - val_tn: 4892.0000 - val_fn: 1011.0000 - val_accuracy: 0.8287 - train_sensitivity: 0.8428 - train_specificity: 0.8428 - train_balacc: 0.8428 - val_sensitivity: 0.8287 - val_specificity: 0.8287 - val_balacc: 0.8287\n",
      "Epoch 11/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.3238 - tp: 19974.0000 - fp: 3626.0000 - tn: 19974.0000 - fn: 3626.0000 - accuracy: 0.8464 train_balacc 0.8463004531786031\n",
      " val_balacc 0.7792647806200237\n",
      "\n",
      "Epoch 11: val_balacc did not improve from 0.82958\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.3239 - tp: 19982.0000 - fp: 3629.0000 - tn: 19982.0000 - fn: 3629.0000 - accuracy: 0.8463 - val_loss: 0.4323 - val_tp: 4600.0000 - val_fp: 1303.0000 - val_tn: 4600.0000 - val_fn: 1303.0000 - val_accuracy: 0.7793 - train_sensitivity: 0.8463 - train_specificity: 0.8463 - train_balacc: 0.8463 - val_sensitivity: 0.7793 - val_specificity: 0.7793 - val_balacc: 0.7793\n",
      "Epoch 12/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.3179 - tp: 20157.0000 - fp: 3443.0000 - tn: 20157.0000 - fn: 3443.0000 - accuracy: 0.8541 train_balacc 0.8540934310279107\n",
      " val_balacc 0.8141622903608334\n",
      "\n",
      "Epoch 12: val_balacc did not improve from 0.82958\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.3179 - tp: 20166.0000 - fp: 3445.0000 - tn: 20166.0000 - fn: 3445.0000 - accuracy: 0.8541 - val_loss: 0.3898 - val_tp: 4806.0000 - val_fp: 1097.0000 - val_tn: 4806.0000 - val_fn: 1097.0000 - val_accuracy: 0.8142 - train_sensitivity: 0.8541 - train_specificity: 0.8541 - train_balacc: 0.8541 - val_sensitivity: 0.8142 - val_specificity: 0.8142 - val_balacc: 0.8142\n",
      "Epoch 13/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.3118 - tp: 19767.0000 - fp: 3333.0000 - tn: 19767.0000 - fn: 3333.0000 - accuracy: 0.8557 train_balacc 0.8554487315234425\n",
      " val_balacc 0.7934948331356937\n",
      "\n",
      "Epoch 13: val_balacc did not improve from 0.82958\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.3127 - tp: 20198.0000 - fp: 3413.0000 - tn: 20198.0000 - fn: 3413.0000 - accuracy: 0.8554 - val_loss: 0.4384 - val_tp: 4684.0000 - val_fp: 1219.0000 - val_tn: 4684.0000 - val_fn: 1219.0000 - val_accuracy: 0.7935 - train_sensitivity: 0.8554 - train_specificity: 0.8554 - train_balacc: 0.8554 - val_sensitivity: 0.7935 - val_specificity: 0.7935 - val_balacc: 0.7935\n",
      "Epoch 14/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.3063 - tp: 19631.0000 - fp: 3269.0000 - tn: 19631.0000 - fn: 3269.0000 - accuracy: 0.8572 train_balacc 0.8571428571428571\n",
      " val_balacc 0.8378790445536168\n",
      "\n",
      "Epoch 14: val_balacc improved from 0.82958 to 0.83788, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.3064 - tp: 20238.0000 - fp: 3373.0000 - tn: 20238.0000 - fn: 3373.0000 - accuracy: 0.8571 - val_loss: 0.3441 - val_tp: 4946.0000 - val_fp: 957.0000 - val_tn: 4946.0000 - val_fn: 957.0000 - val_accuracy: 0.8379 - train_sensitivity: 0.8571 - train_specificity: 0.8571 - train_balacc: 0.8571 - val_sensitivity: 0.8379 - val_specificity: 0.8379 - val_balacc: 0.8379\n",
      "Epoch 15/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.3057 - tp: 19646.0000 - fp: 3254.0000 - tn: 19646.0000 - fn: 3254.0000 - accuracy: 0.8579 train_balacc 0.8583287450764474\n",
      " val_balacc 0.8516008809080129\n",
      "\n",
      "Epoch 15: val_balacc improved from 0.83788 to 0.85160, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.3049 - tp: 20266.0000 - fp: 3345.0000 - tn: 20266.0000 - fn: 3345.0000 - accuracy: 0.8583 - val_loss: 0.3610 - val_tp: 5027.0000 - val_fp: 876.0000 - val_tn: 5027.0000 - val_fn: 876.0000 - val_accuracy: 0.8516 - train_sensitivity: 0.8583 - train_specificity: 0.8583 - train_balacc: 0.8583 - val_sensitivity: 0.8516 - val_specificity: 0.8516 - val_balacc: 0.8516\n",
      "Epoch 16/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2977 - tp: 19666.0000 - fp: 3134.0000 - tn: 19666.0000 - fn: 3134.0000 - accuracy: 0.8625 train_balacc 0.862436999703528\n",
      " val_balacc 0.8322886667796036\n",
      "\n",
      "Epoch 16: val_balacc did not improve from 0.85160\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2979 - tp: 20363.0000 - fp: 3248.0000 - tn: 20363.0000 - fn: 3248.0000 - accuracy: 0.8624 - val_loss: 0.3829 - val_tp: 4913.0000 - val_fp: 990.0000 - val_tn: 4913.0000 - val_fn: 990.0000 - val_accuracy: 0.8323 - train_sensitivity: 0.8624 - train_specificity: 0.8624 - train_balacc: 0.8624 - val_sensitivity: 0.8323 - val_specificity: 0.8323 - val_balacc: 0.8323\n",
      "Epoch 17/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2910 - tp: 19888.0000 - fp: 3112.0000 - tn: 19888.0000 - fn: 3112.0000 - accuracy: 0.8647 train_balacc 0.8644275973063402\n",
      " val_balacc 0.836354396069795\n",
      "\n",
      "Epoch 17: val_balacc did not improve from 0.85160\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2911 - tp: 20410.0000 - fp: 3201.0000 - tn: 20410.0000 - fn: 3201.0000 - accuracy: 0.8644 - val_loss: 0.3518 - val_tp: 4937.0000 - val_fp: 966.0000 - val_tn: 4937.0000 - val_fn: 966.0000 - val_accuracy: 0.8364 - train_sensitivity: 0.8644 - train_specificity: 0.8644 - train_balacc: 0.8644 - val_sensitivity: 0.8364 - val_specificity: 0.8364 - val_balacc: 0.8364\n",
      "Epoch 18/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2894 - tp: 20421.0000 - fp: 3179.0000 - tn: 20421.0000 - fn: 3179.0000 - accuracy: 0.8653 train_balacc 0.865317013256533\n",
      " val_balacc 0.8527867186176521\n",
      "\n",
      "Epoch 18: val_balacc improved from 0.85160 to 0.85279, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2894 - tp: 20431.0000 - fp: 3180.0000 - tn: 20431.0000 - fn: 3180.0000 - accuracy: 0.8653 - val_loss: 0.3448 - val_tp: 5034.0000 - val_fp: 869.0000 - val_tn: 5034.0000 - val_fn: 869.0000 - val_accuracy: 0.8528 - train_sensitivity: 0.8653 - train_specificity: 0.8653 - train_balacc: 0.8653 - val_sensitivity: 0.8528 - val_specificity: 0.8528 - val_balacc: 0.8528\n",
      "Epoch 19/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2895 - tp: 19817.0000 - fp: 3083.0000 - tn: 19817.0000 - fn: 3083.0000 - accuracy: 0.8654 train_balacc 0.866121722925755\n",
      " val_balacc 0.8121294257157378\n",
      "\n",
      "Epoch 19: val_balacc did not improve from 0.85279\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2883 - tp: 20450.0000 - fp: 3161.0000 - tn: 20450.0000 - fn: 3161.0000 - accuracy: 0.8661 - val_loss: 0.4133 - val_tp: 4794.0000 - val_fp: 1109.0000 - val_tn: 4794.0000 - val_fn: 1109.0000 - val_accuracy: 0.8121 - train_sensitivity: 0.8661 - train_specificity: 0.8661 - train_balacc: 0.8661 - val_sensitivity: 0.8121 - val_specificity: 0.8121 - val_balacc: 0.8121\n",
      "Epoch 20/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.2866 - tp: 20525.0000 - fp: 3086.0000 - tn: 20525.0000 - fn: 3086.0000 - accuracy: 0.8693 train_balacc 0.8692982084621574\n",
      " val_balacc 0.8698966627138743\n",
      "\n",
      "Epoch 20: val_balacc improved from 0.85279 to 0.86990, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2866 - tp: 20525.0000 - fp: 3086.0000 - tn: 20525.0000 - fn: 3086.0000 - accuracy: 0.8693 - val_loss: 0.3229 - val_tp: 5135.0000 - val_fp: 768.0000 - val_tn: 5135.0000 - val_fn: 768.0000 - val_accuracy: 0.8699 - train_sensitivity: 0.8693 - train_specificity: 0.8693 - train_balacc: 0.8693 - val_sensitivity: 0.8699 - val_specificity: 0.8699 - val_balacc: 0.8699\n",
      "Epoch 21/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2837 - tp: 20025.0000 - fp: 2975.0000 - tn: 20025.0000 - fn: 2975.0000 - accuracy: 0.8707 train_balacc 0.8698064461479819\n",
      " val_balacc 0.8607487718109436\n",
      "\n",
      "Epoch 21: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2844 - tp: 20537.0000 - fp: 3074.0000 - tn: 20537.0000 - fn: 3074.0000 - accuracy: 0.8698 - val_loss: 0.3338 - val_tp: 5081.0000 - val_fp: 822.0000 - val_tn: 5081.0000 - val_fn: 822.0000 - val_accuracy: 0.8607 - train_sensitivity: 0.8698 - train_specificity: 0.8698 - train_balacc: 0.8698 - val_sensitivity: 0.8607 - val_specificity: 0.8607 - val_balacc: 0.8607\n",
      "Epoch 22/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2789 - tp: 20170.0000 - fp: 2930.0000 - tn: 20170.0000 - fn: 2930.0000 - accuracy: 0.8732 train_balacc 0.8731523442463258\n",
      " val_balacc 0.8305946129086905\n",
      "\n",
      "Epoch 22: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2791 - tp: 20616.0000 - fp: 2995.0000 - tn: 20616.0000 - fn: 2995.0000 - accuracy: 0.8732 - val_loss: 0.3615 - val_tp: 4903.0000 - val_fp: 1000.0000 - val_tn: 4903.0000 - val_fn: 1000.0000 - val_accuracy: 0.8306 - train_sensitivity: 0.8732 - train_specificity: 0.8732 - train_balacc: 0.8732 - val_sensitivity: 0.8306 - val_specificity: 0.8306 - val_balacc: 0.8306\n",
      "Epoch 23/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2781 - tp: 20170.0000 - fp: 2930.0000 - tn: 20170.0000 - fn: 2930.0000 - accuracy: 0.8732 train_balacc 0.8734488162297235\n",
      " val_balacc 0.7807894291038455\n",
      "\n",
      "Epoch 23: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2776 - tp: 20623.0000 - fp: 2988.0000 - tn: 20623.0000 - fn: 2988.0000 - accuracy: 0.8734 - val_loss: 0.4629 - val_tp: 4609.0000 - val_fp: 1294.0000 - val_tn: 4609.0000 - val_fn: 1294.0000 - val_accuracy: 0.7808 - train_sensitivity: 0.8734 - train_specificity: 0.8734 - train_balacc: 0.8734 - val_sensitivity: 0.7808 - val_specificity: 0.7808 - val_balacc: 0.7808\n",
      "Epoch 24/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2737 - tp: 20195.0000 - fp: 2905.0000 - tn: 20195.0000 - fn: 2905.0000 - accuracy: 0.8742 train_balacc 0.8741264664774893\n",
      " val_balacc 0.7968829408775199\n",
      "\n",
      "Epoch 24: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2742 - tp: 20639.0000 - fp: 2972.0000 - tn: 20639.0000 - fn: 2972.0000 - accuracy: 0.8741 - val_loss: 0.4271 - val_tp: 4704.0000 - val_fp: 1199.0000 - val_tn: 4704.0000 - val_fn: 1199.0000 - val_accuracy: 0.7969 - train_sensitivity: 0.8741 - train_specificity: 0.8741 - train_balacc: 0.8741 - val_sensitivity: 0.7969 - val_specificity: 0.7969 - val_balacc: 0.7969\n",
      "Epoch 25/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2687 - tp: 20233.0000 - fp: 2867.0000 - tn: 20233.0000 - fn: 2867.0000 - accuracy: 0.8759 train_balacc 0.8761594172207869\n",
      " val_balacc 0.869727257326783\n",
      "\n",
      "Epoch 25: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2684 - tp: 20687.0000 - fp: 2924.0000 - tn: 20687.0000 - fn: 2924.0000 - accuracy: 0.8762 - val_loss: 0.3043 - val_tp: 5134.0000 - val_fp: 769.0000 - val_tn: 5134.0000 - val_fn: 769.0000 - val_accuracy: 0.8697 - train_sensitivity: 0.8762 - train_specificity: 0.8762 - train_balacc: 0.8762 - val_sensitivity: 0.8697 - val_specificity: 0.8697 - val_balacc: 0.8697\n",
      "Epoch 26/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2691 - tp: 20248.0000 - fp: 2852.0000 - tn: 20248.0000 - fn: 2852.0000 - accuracy: 0.8765 train_balacc 0.8761170640803015\n",
      " val_balacc 0.8326274775537862\n",
      "\n",
      "Epoch 26: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2700 - tp: 20686.0000 - fp: 2925.0000 - tn: 20686.0000 - fn: 2925.0000 - accuracy: 0.8761 - val_loss: 0.3850 - val_tp: 4915.0000 - val_fp: 988.0000 - val_tn: 4915.0000 - val_fn: 988.0000 - val_accuracy: 0.8326 - train_sensitivity: 0.8761 - train_specificity: 0.8761 - train_balacc: 0.8761 - val_sensitivity: 0.8326 - val_specificity: 0.8326 - val_balacc: 0.8326\n",
      "Epoch 27/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2659 - tp: 20108.0000 - fp: 2792.0000 - tn: 20108.0000 - fn: 2792.0000 - accuracy: 0.8781 train_balacc 0.8784888399474821\n",
      " val_balacc 0.8414365576825343\n",
      "\n",
      "Epoch 27: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2662 - tp: 20742.0000 - fp: 2869.0000 - tn: 20742.0000 - fn: 2869.0000 - accuracy: 0.8785 - val_loss: 0.3449 - val_tp: 4967.0000 - val_fp: 936.0000 - val_tn: 4967.0000 - val_fn: 936.0000 - val_accuracy: 0.8414 - train_sensitivity: 0.8785 - train_specificity: 0.8785 - train_balacc: 0.8785 - val_sensitivity: 0.8414 - val_specificity: 0.8414 - val_balacc: 0.8414\n",
      "Epoch 28/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2671 - tp: 20288.0000 - fp: 2812.0000 - tn: 20288.0000 - fn: 2812.0000 - accuracy: 0.8783 train_balacc 0.8787853119308797\n",
      " val_balacc 0.8593935287142132\n",
      "\n",
      "Epoch 28: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2664 - tp: 20749.0000 - fp: 2862.0000 - tn: 20749.0000 - fn: 2862.0000 - accuracy: 0.8788 - val_loss: 0.3311 - val_tp: 5073.0000 - val_fp: 830.0000 - val_tn: 5073.0000 - val_fn: 830.0000 - val_accuracy: 0.8594 - train_sensitivity: 0.8788 - train_specificity: 0.8788 - train_balacc: 0.8788 - val_sensitivity: 0.8594 - val_specificity: 0.8594 - val_balacc: 0.8594\n",
      "Epoch 29/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2636 - tp: 20080.0000 - fp: 2720.0000 - tn: 20080.0000 - fn: 2720.0000 - accuracy: 0.8807 train_balacc 0.880437084409809\n",
      " val_balacc 0.8500762324241911\n",
      "\n",
      "Epoch 29: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2637 - tp: 20788.0000 - fp: 2823.0000 - tn: 20788.0000 - fn: 2823.0000 - accuracy: 0.8804 - val_loss: 0.3224 - val_tp: 5018.0000 - val_fp: 885.0000 - val_tn: 5018.0000 - val_fn: 885.0000 - val_accuracy: 0.8501 - train_sensitivity: 0.8804 - train_specificity: 0.8804 - train_balacc: 0.8804 - val_sensitivity: 0.8501 - val_specificity: 0.8501 - val_balacc: 0.8501\n",
      "Epoch 30/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2610 - tp: 20290.0000 - fp: 2710.0000 - tn: 20290.0000 - fn: 2710.0000 - accuracy: 0.8822 train_balacc 0.8825547414340773\n",
      " val_balacc 0.8036591563611722\n",
      "\n",
      "Epoch 30: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2603 - tp: 20838.0000 - fp: 2773.0000 - tn: 20838.0000 - fn: 2773.0000 - accuracy: 0.8826 - val_loss: 0.4316 - val_tp: 4744.0000 - val_fp: 1159.0000 - val_tn: 4744.0000 - val_fn: 1159.0000 - val_accuracy: 0.8037 - train_sensitivity: 0.8826 - train_specificity: 0.8826 - train_balacc: 0.8826 - val_sensitivity: 0.8037 - val_specificity: 0.8037 - val_balacc: 0.8037\n",
      "Epoch 31/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2636 - tp: 20170.0000 - fp: 2730.0000 - tn: 20170.0000 - fn: 2730.0000 - accuracy: 0.8808 train_balacc 0.8806064969717504\n",
      " val_balacc 0.8243266135863121\n",
      "\n",
      "Epoch 31: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2631 - tp: 20792.0000 - fp: 2819.0000 - tn: 20792.0000 - fn: 2819.0000 - accuracy: 0.8806 - val_loss: 0.4136 - val_tp: 4866.0000 - val_fp: 1037.0000 - val_tn: 4866.0000 - val_fn: 1037.0000 - val_accuracy: 0.8243 - train_sensitivity: 0.8806 - train_specificity: 0.8806 - train_balacc: 0.8806 - val_sensitivity: 0.8243 - val_specificity: 0.8243 - val_balacc: 0.8243\n",
      "Epoch 32/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.2535 - tp: 20792.0000 - fp: 2708.0000 - tn: 20792.0000 - fn: 2708.0000 - accuracy: 0.8848 train_balacc 0.8846723984583457\n",
      " val_balacc 0.8290699644248687\n",
      "\n",
      "Epoch 32: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2538 - tp: 20888.0000 - fp: 2723.0000 - tn: 20888.0000 - fn: 2723.0000 - accuracy: 0.8847 - val_loss: 0.3972 - val_tp: 4894.0000 - val_fp: 1009.0000 - val_tn: 4894.0000 - val_fn: 1009.0000 - val_accuracy: 0.8291 - train_sensitivity: 0.8847 - train_specificity: 0.8847 - train_balacc: 0.8847 - val_sensitivity: 0.8291 - val_specificity: 0.8291 - val_balacc: 0.8291\n",
      "Epoch 33/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2543 - tp: 20160.0000 - fp: 2640.0000 - tn: 20160.0000 - fn: 2640.0000 - accuracy: 0.8842 train_balacc 0.8840794544915506\n",
      " val_balacc 0.8636286633914958\n",
      "\n",
      "Epoch 33: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2551 - tp: 20874.0000 - fp: 2737.0000 - tn: 20874.0000 - fn: 2737.0000 - accuracy: 0.8841 - val_loss: 0.3133 - val_tp: 5098.0000 - val_fp: 805.0000 - val_tn: 5098.0000 - val_fn: 805.0000 - val_accuracy: 0.8636 - train_sensitivity: 0.8841 - train_specificity: 0.8841 - train_balacc: 0.8841 - val_sensitivity: 0.8636 - val_specificity: 0.8636 - val_balacc: 0.8636\n",
      "Epoch 34/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.2509 - tp: 20885.0000 - fp: 2615.0000 - tn: 20885.0000 - fn: 2615.0000 - accuracy: 0.8887 train_balacc 0.8888230062259117\n",
      " val_balacc 0.8644756903269524\n",
      "\n",
      "Epoch 34: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2508 - tp: 20986.0000 - fp: 2625.0000 - tn: 20986.0000 - fn: 2625.0000 - accuracy: 0.8888 - val_loss: 0.3093 - val_tp: 5103.0000 - val_fp: 800.0000 - val_tn: 5103.0000 - val_fn: 800.0000 - val_accuracy: 0.8645 - train_sensitivity: 0.8888 - train_specificity: 0.8888 - train_balacc: 0.8888 - val_sensitivity: 0.8645 - val_specificity: 0.8645 - val_balacc: 0.8645\n",
      "Epoch 35/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2531 - tp: 20222.0000 - fp: 2578.0000 - tn: 20222.0000 - fn: 2578.0000 - accuracy: 0.8869 train_balacc 0.8864935834992165\n",
      " val_balacc 0.7873962392004066\n",
      "\n",
      "Epoch 35: val_balacc did not improve from 0.86990\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2535 - tp: 20931.0000 - fp: 2680.0000 - tn: 20931.0000 - fn: 2680.0000 - accuracy: 0.8865 - val_loss: 0.4896 - val_tp: 4648.0000 - val_fp: 1255.0000 - val_tn: 4648.0000 - val_fn: 1255.0000 - val_accuracy: 0.7874 - train_sensitivity: 0.8865 - train_specificity: 0.8865 - train_balacc: 0.8865 - val_sensitivity: 0.7874 - val_specificity: 0.7874 - val_balacc: 0.7874\n",
      "Epoch 36/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2523 - tp: 20338.0000 - fp: 2562.0000 - tn: 20338.0000 - fn: 2562.0000 - accuracy: 0.8881 train_balacc 0.8882724153996019\n",
      " val_balacc 0.876842283584618\n",
      "\n",
      "Epoch 36: val_balacc improved from 0.86990 to 0.87684, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2512 - tp: 20973.0000 - fp: 2638.0000 - tn: 20973.0000 - fn: 2638.0000 - accuracy: 0.8883 - val_loss: 0.3022 - val_tp: 5176.0000 - val_fp: 727.0000 - val_tn: 5176.0000 - val_fn: 727.0000 - val_accuracy: 0.8768 - train_sensitivity: 0.8883 - train_specificity: 0.8883 - train_balacc: 0.8883 - val_sensitivity: 0.8768 - val_specificity: 0.8768 - val_balacc: 0.8768\n",
      "Epoch 37/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2492 - tp: 20545.0000 - fp: 2555.0000 - tn: 20545.0000 - fn: 2555.0000 - accuracy: 0.8894 train_balacc 0.8896277158951337\n",
      " val_balacc 0.8473657462307301\n",
      "\n",
      "Epoch 37: val_balacc did not improve from 0.87684\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2488 - tp: 21005.0000 - fp: 2606.0000 - tn: 21005.0000 - fn: 2606.0000 - accuracy: 0.8896 - val_loss: 0.3894 - val_tp: 5002.0000 - val_fp: 901.0000 - val_tn: 5002.0000 - val_fn: 901.0000 - val_accuracy: 0.8474 - train_sensitivity: 0.8896 - train_specificity: 0.8896 - train_balacc: 0.8896 - val_sensitivity: 0.8474 - val_specificity: 0.8474 - val_balacc: 0.8474\n",
      "Epoch 38/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2494 - tp: 20238.0000 - fp: 2562.0000 - tn: 20238.0000 - fn: 2562.0000 - accuracy: 0.8876 train_balacc 0.8881453559781458\n",
      " val_balacc 0.8541419617143825\n",
      "\n",
      "Epoch 38: val_balacc did not improve from 0.87684\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2487 - tp: 20970.0000 - fp: 2641.0000 - tn: 20970.0000 - fn: 2641.0000 - accuracy: 0.8881 - val_loss: 0.3326 - val_tp: 5042.0000 - val_fp: 861.0000 - val_tn: 5042.0000 - val_fn: 861.0000 - val_accuracy: 0.8541 - train_sensitivity: 0.8881 - train_specificity: 0.8881 - train_balacc: 0.8881 - val_sensitivity: 0.8541 - val_specificity: 0.8541 - val_balacc: 0.8541\n",
      "Epoch 39/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2425 - tp: 20489.0000 - fp: 2511.0000 - tn: 20489.0000 - fn: 2511.0000 - accuracy: 0.8908 train_balacc 0.8906865444072678\n",
      " val_balacc 0.8641368795527697\n",
      "\n",
      "Epoch 39: val_balacc did not improve from 0.87684\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2428 - tp: 21030.0000 - fp: 2581.0000 - tn: 21030.0000 - fn: 2581.0000 - accuracy: 0.8907 - val_loss: 0.3127 - val_tp: 5101.0000 - val_fp: 802.0000 - val_tn: 5101.0000 - val_fn: 802.0000 - val_accuracy: 0.8641 - train_sensitivity: 0.8907 - train_specificity: 0.8907 - train_balacc: 0.8907 - val_sensitivity: 0.8641 - val_specificity: 0.8641 - val_balacc: 0.8641\n",
      "Epoch 40/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2446 - tp: 20493.0000 - fp: 2507.0000 - tn: 20493.0000 - fn: 2507.0000 - accuracy: 0.8910 train_balacc 0.8907712506882385\n",
      " val_balacc 0.7109944096222259\n",
      "\n",
      "Epoch 40: val_balacc did not improve from 0.87684\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2448 - tp: 21032.0000 - fp: 2579.0000 - tn: 21032.0000 - fn: 2579.0000 - accuracy: 0.8908 - val_loss: 1.1195 - val_tp: 4197.0000 - val_fp: 1706.0000 - val_tn: 4197.0000 - val_fn: 1706.0000 - val_accuracy: 0.7110 - train_sensitivity: 0.8908 - train_specificity: 0.8908 - train_balacc: 0.8908 - val_sensitivity: 0.7110 - val_specificity: 0.7110 - val_balacc: 0.7110\n",
      "Epoch 41/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2417 - tp: 20587.0000 - fp: 2413.0000 - tn: 20587.0000 - fn: 2413.0000 - accuracy: 0.8951 train_balacc 0.8952606835796875\n",
      " val_balacc 0.8422835846179908\n",
      "\n",
      "Epoch 41: val_balacc did not improve from 0.87684\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2409 - tp: 21138.0000 - fp: 2473.0000 - tn: 21138.0000 - fn: 2473.0000 - accuracy: 0.8953 - val_loss: 0.3351 - val_tp: 4972.0000 - val_fp: 931.0000 - val_tn: 4972.0000 - val_fn: 931.0000 - val_accuracy: 0.8423 - train_sensitivity: 0.8953 - train_specificity: 0.8953 - train_balacc: 0.8953 - val_sensitivity: 0.8423 - val_specificity: 0.8423 - val_balacc: 0.8423\n",
      "Epoch 42/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.2374 - tp: 20890.0000 - fp: 2410.0000 - tn: 20890.0000 - fn: 2410.0000 - accuracy: 0.8966 train_balacc 0.8966159840752191\n",
      " val_balacc 0.8541419617143825\n",
      "\n",
      "Epoch 42: val_balacc did not improve from 0.87684\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2371 - tp: 21170.0000 - fp: 2441.0000 - tn: 21170.0000 - fn: 2441.0000 - accuracy: 0.8966 - val_loss: 0.3264 - val_tp: 5042.0000 - val_fp: 861.0000 - val_tn: 5042.0000 - val_fn: 861.0000 - val_accuracy: 0.8541 - train_sensitivity: 0.8966 - train_specificity: 0.8966 - train_balacc: 0.8966 - val_sensitivity: 0.8541 - val_specificity: 0.8541 - val_balacc: 0.8541\n",
      "Epoch 43/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2351 - tp: 20485.0000 - fp: 2415.0000 - tn: 20485.0000 - fn: 2415.0000 - accuracy: 0.8945 train_balacc 0.8949218584558045\n",
      " val_balacc 0.8588853125529392\n",
      "\n",
      "Epoch 43: val_balacc did not improve from 0.87684\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2346 - tp: 21130.0000 - fp: 2481.0000 - tn: 21130.0000 - fn: 2481.0000 - accuracy: 0.8949 - val_loss: 0.3051 - val_tp: 5070.0000 - val_fp: 833.0000 - val_tn: 5070.0000 - val_fn: 833.0000 - val_accuracy: 0.8589 - train_sensitivity: 0.8949 - train_specificity: 0.8949 - train_balacc: 0.8949 - val_sensitivity: 0.8589 - val_specificity: 0.8589 - val_balacc: 0.8589\n",
      "Epoch 44/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2359 - tp: 20385.0000 - fp: 2415.0000 - tn: 20385.0000 - fn: 2415.0000 - accuracy: 0.8941 train_balacc 0.8940747956460972\n",
      " val_balacc 0.8778587159071658\n",
      "\n",
      "Epoch 44: val_balacc improved from 0.87684 to 0.87786, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2364 - tp: 21110.0000 - fp: 2501.0000 - tn: 21110.0000 - fn: 2501.0000 - accuracy: 0.8941 - val_loss: 0.2997 - val_tp: 5182.0000 - val_fp: 721.0000 - val_tn: 5182.0000 - val_fn: 721.0000 - val_accuracy: 0.8779 - train_sensitivity: 0.8941 - train_specificity: 0.8941 - train_balacc: 0.8941 - val_sensitivity: 0.8779 - val_specificity: 0.8779 - val_balacc: 0.8779\n",
      "Epoch 45/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.2340 - tp: 21165.0000 - fp: 2446.0000 - tn: 21165.0000 - fn: 2446.0000 - accuracy: 0.8964 train_balacc 0.8964042183727924\n",
      " val_balacc 0.8632898526173133\n",
      "\n",
      "Epoch 45: val_balacc did not improve from 0.87786\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2340 - tp: 21165.0000 - fp: 2446.0000 - tn: 21165.0000 - fn: 2446.0000 - accuracy: 0.8964 - val_loss: 0.3006 - val_tp: 5096.0000 - val_fp: 807.0000 - val_tn: 5096.0000 - val_fn: 807.0000 - val_accuracy: 0.8633 - train_sensitivity: 0.8964 - train_specificity: 0.8964 - train_balacc: 0.8964 - val_sensitivity: 0.8633 - val_specificity: 0.8633 - val_balacc: 0.8633\n",
      "Epoch 46/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2315 - tp: 20541.0000 - fp: 2359.0000 - tn: 20541.0000 - fn: 2359.0000 - accuracy: 0.8970 train_balacc 0.8970818686205582\n",
      " val_balacc 0.7757072674911062\n",
      "\n",
      "Epoch 46: val_balacc did not improve from 0.87786\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2319 - tp: 21181.0000 - fp: 2430.0000 - tn: 21181.0000 - fn: 2430.0000 - accuracy: 0.8971 - val_loss: 0.8251 - val_tp: 4579.0000 - val_fp: 1324.0000 - val_tn: 4579.0000 - val_fn: 1324.0000 - val_accuracy: 0.7757 - train_sensitivity: 0.8971 - train_specificity: 0.8971 - train_balacc: 0.8971 - val_sensitivity: 0.7757 - val_specificity: 0.7757 - val_balacc: 0.7757\n",
      "Epoch 47/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2372 - tp: 20493.0000 - fp: 2407.0000 - tn: 20493.0000 - fn: 2407.0000 - accuracy: 0.8949 train_balacc 0.8951336241582313\n",
      " val_balacc 0.8099271556835508\n",
      "\n",
      "Epoch 47: val_balacc did not improve from 0.87786\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2365 - tp: 21135.0000 - fp: 2476.0000 - tn: 21135.0000 - fn: 2476.0000 - accuracy: 0.8951 - val_loss: 0.4496 - val_tp: 4781.0000 - val_fp: 1122.0000 - val_tn: 4781.0000 - val_fn: 1122.0000 - val_accuracy: 0.8099 - train_sensitivity: 0.8951 - train_specificity: 0.8951 - train_balacc: 0.8951 - val_sensitivity: 0.8099 - val_specificity: 0.8099 - val_balacc: 0.8099\n",
      "Epoch 48/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2316 - tp: 20673.0000 - fp: 2327.0000 - tn: 20673.0000 - fn: 2327.0000 - accuracy: 0.8988 train_balacc 0.89843716911609\n",
      " val_balacc 0.8809080128748095\n",
      "\n",
      "Epoch 48: val_balacc improved from 0.87786 to 0.88091, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2325 - tp: 21213.0000 - fp: 2398.0000 - tn: 21213.0000 - fn: 2398.0000 - accuracy: 0.8984 - val_loss: 0.2745 - val_tp: 5200.0000 - val_fp: 703.0000 - val_tn: 5200.0000 - val_fn: 703.0000 - val_accuracy: 0.8809 - train_sensitivity: 0.8984 - train_specificity: 0.8984 - train_balacc: 0.8984 - val_sensitivity: 0.8809 - val_specificity: 0.8809 - val_balacc: 0.8809\n",
      "Epoch 49/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2310 - tp: 20785.0000 - fp: 2315.0000 - tn: 20785.0000 - fn: 2315.0000 - accuracy: 0.8998 train_balacc 0.8991148193638558\n",
      " val_balacc 0.865322717262409\n",
      "\n",
      "Epoch 49: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2322 - tp: 21229.0000 - fp: 2382.0000 - tn: 21229.0000 - fn: 2382.0000 - accuracy: 0.8991 - val_loss: 0.3128 - val_tp: 5108.0000 - val_fp: 795.0000 - val_tn: 5108.0000 - val_fn: 795.0000 - val_accuracy: 0.8653 - train_sensitivity: 0.8991 - train_specificity: 0.8991 - train_balacc: 0.8991 - val_sensitivity: 0.8653 - val_specificity: 0.8653 - val_balacc: 0.8653\n",
      "Epoch 50/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2294 - tp: 20638.0000 - fp: 2262.0000 - tn: 20638.0000 - fn: 2262.0000 - accuracy: 0.9012 train_balacc 0.9008936512642413\n",
      " val_balacc 0.8683720142300525\n",
      "\n",
      "Epoch 50: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2290 - tp: 21271.0000 - fp: 2340.0000 - tn: 21271.0000 - fn: 2340.0000 - accuracy: 0.9009 - val_loss: 0.3136 - val_tp: 5126.0000 - val_fp: 777.0000 - val_tn: 5126.0000 - val_fn: 777.0000 - val_accuracy: 0.8684 - train_sensitivity: 0.9009 - train_specificity: 0.9009 - train_balacc: 0.9009 - val_sensitivity: 0.8684 - val_specificity: 0.8684 - val_balacc: 0.8684\n",
      "Epoch 51/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.2263 - tp: 20950.0000 - fp: 2350.0000 - tn: 20950.0000 - fn: 2350.0000 - accuracy: 0.8991 train_balacc 0.8991995256448265\n",
      " val_balacc 0.8273759105539557\n",
      "\n",
      "Epoch 51: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2270 - tp: 21231.0000 - fp: 2380.0000 - tn: 21231.0000 - fn: 2380.0000 - accuracy: 0.8992 - val_loss: 0.4263 - val_tp: 4884.0000 - val_fp: 1019.0000 - val_tn: 4884.0000 - val_fn: 1019.0000 - val_accuracy: 0.8274 - train_sensitivity: 0.8992 - train_specificity: 0.8992 - train_balacc: 0.8992 - val_sensitivity: 0.8274 - val_specificity: 0.8274 - val_balacc: 0.8274\n",
      "Epoch 52/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2301 - tp: 20705.0000 - fp: 2295.0000 - tn: 20705.0000 - fn: 2295.0000 - accuracy: 0.9002 train_balacc 0.9002583541569608\n",
      " val_balacc 0.8161951550059292\n",
      "\n",
      "Epoch 52: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2297 - tp: 21256.0000 - fp: 2355.0000 - tn: 21256.0000 - fn: 2355.0000 - accuracy: 0.9003 - val_loss: 0.3895 - val_tp: 4818.0000 - val_fp: 1085.0000 - val_tn: 4818.0000 - val_fn: 1085.0000 - val_accuracy: 0.8162 - train_sensitivity: 0.9003 - train_specificity: 0.9003 - train_balacc: 0.9003 - val_sensitivity: 0.8162 - val_specificity: 0.8162 - val_balacc: 0.8162\n",
      "Epoch 53/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2260 - tp: 20817.0000 - fp: 2283.0000 - tn: 20817.0000 - fn: 2283.0000 - accuracy: 0.9012 train_balacc 0.9014018889500657\n",
      " val_balacc 0.851092664746739\n",
      "\n",
      "Epoch 53: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2258 - tp: 21283.0000 - fp: 2328.0000 - tn: 21283.0000 - fn: 2328.0000 - accuracy: 0.9014 - val_loss: 0.3493 - val_tp: 5024.0000 - val_fp: 879.0000 - val_tn: 5024.0000 - val_fn: 879.0000 - val_accuracy: 0.8511 - train_sensitivity: 0.9014 - train_specificity: 0.9014 - train_balacc: 0.9014 - val_sensitivity: 0.8511 - val_specificity: 0.8511 - val_balacc: 0.8511\n",
      "Epoch 54/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.2258 - tp: 20906.0000 - fp: 2294.0000 - tn: 20906.0000 - fn: 2294.0000 - accuracy: 0.9011 train_balacc 0.9012748295286096\n",
      " val_balacc 0.8046755886837201\n",
      "\n",
      "Epoch 54: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2251 - tp: 21280.0000 - fp: 2331.0000 - tn: 21280.0000 - fn: 2331.0000 - accuracy: 0.9013 - val_loss: 0.6117 - val_tp: 4750.0000 - val_fp: 1153.0000 - val_tn: 4750.0000 - val_fn: 1153.0000 - val_accuracy: 0.8047 - train_sensitivity: 0.9013 - train_specificity: 0.9013 - train_balacc: 0.9013 - val_sensitivity: 0.8047 - val_specificity: 0.8047 - val_balacc: 0.8047\n",
      "Epoch 55/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2241 - tp: 20574.0000 - fp: 2226.0000 - tn: 20574.0000 - fn: 2226.0000 - accuracy: 0.9024 train_balacc 0.9025454237431706\n",
      " val_balacc 0.8793833643909876\n",
      "\n",
      "Epoch 55: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2233 - tp: 21310.0000 - fp: 2301.0000 - tn: 21310.0000 - fn: 2301.0000 - accuracy: 0.9025 - val_loss: 0.2745 - val_tp: 5191.0000 - val_fp: 712.0000 - val_tn: 5191.0000 - val_fn: 712.0000 - val_accuracy: 0.8794 - train_sensitivity: 0.9025 - train_specificity: 0.9025 - train_balacc: 0.9025 - val_sensitivity: 0.8794 - val_specificity: 0.8794 - val_balacc: 0.8794\n",
      "Epoch 56/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.2177 - tp: 20985.0000 - fp: 2215.0000 - tn: 20985.0000 - fn: 2215.0000 - accuracy: 0.9045 train_balacc 0.9044513150650121\n",
      " val_balacc 0.8727765542944266\n",
      "\n",
      "Epoch 56: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2176 - tp: 21355.0000 - fp: 2256.0000 - tn: 21355.0000 - fn: 2256.0000 - accuracy: 0.9045 - val_loss: 0.2980 - val_tp: 5152.0000 - val_fp: 751.0000 - val_tn: 5152.0000 - val_fn: 751.0000 - val_accuracy: 0.8728 - train_sensitivity: 0.9045 - train_specificity: 0.9045 - train_balacc: 0.9045 - val_sensitivity: 0.8728 - val_specificity: 0.8728 - val_balacc: 0.8728\n",
      "Epoch 57/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.2210 - tp: 20971.0000 - fp: 2229.0000 - tn: 20971.0000 - fn: 2229.0000 - accuracy: 0.9039 train_balacc 0.9037736648172462\n",
      " val_balacc 0.8485515839403693\n",
      "\n",
      "Epoch 57: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2213 - tp: 21339.0000 - fp: 2272.0000 - tn: 21339.0000 - fn: 2272.0000 - accuracy: 0.9038 - val_loss: 0.3331 - val_tp: 5009.0000 - val_fp: 894.0000 - val_tn: 5009.0000 - val_fn: 894.0000 - val_accuracy: 0.8486 - train_sensitivity: 0.9038 - train_specificity: 0.9038 - train_balacc: 0.9038 - val_sensitivity: 0.8486 - val_specificity: 0.8486 - val_balacc: 0.8486\n",
      "Epoch 58/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2191 - tp: 20819.0000 - fp: 2181.0000 - tn: 20819.0000 - fn: 2181.0000 - accuracy: 0.9052 train_balacc 0.9053830841556901\n",
      " val_balacc 0.8668473657462308\n",
      "\n",
      "Epoch 58: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2188 - tp: 21377.0000 - fp: 2234.0000 - tn: 21377.0000 - fn: 2234.0000 - accuracy: 0.9054 - val_loss: 0.3218 - val_tp: 5117.0000 - val_fp: 786.0000 - val_tn: 5117.0000 - val_fn: 786.0000 - val_accuracy: 0.8668 - train_sensitivity: 0.9054 - train_specificity: 0.9054 - train_balacc: 0.9054 - val_sensitivity: 0.8668 - val_specificity: 0.8668 - val_balacc: 0.8668\n",
      "Epoch 59/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2175 - tp: 20868.0000 - fp: 2232.0000 - tn: 20868.0000 - fn: 2232.0000 - accuracy: 0.9034 train_balacc 0.903053661428995\n",
      " val_balacc 0.8590547179400305\n",
      "\n",
      "Epoch 59: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2176 - tp: 21322.0000 - fp: 2289.0000 - tn: 21322.0000 - fn: 2289.0000 - accuracy: 0.9031 - val_loss: 0.3213 - val_tp: 5071.0000 - val_fp: 832.0000 - val_tn: 5071.0000 - val_fn: 832.0000 - val_accuracy: 0.8591 - train_sensitivity: 0.9031 - train_specificity: 0.9031 - train_balacc: 0.9031 - val_sensitivity: 0.8591 - val_specificity: 0.8591 - val_balacc: 0.8591\n",
      "Epoch 60/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2227 - tp: 20861.0000 - fp: 2239.0000 - tn: 20861.0000 - fn: 2239.0000 - accuracy: 0.9031 train_balacc 0.9033924865528778\n",
      " val_balacc 0.8548195832627478\n",
      "\n",
      "Epoch 60: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2222 - tp: 21330.0000 - fp: 2281.0000 - tn: 21330.0000 - fn: 2281.0000 - accuracy: 0.9034 - val_loss: 0.3259 - val_tp: 5046.0000 - val_fp: 857.0000 - val_tn: 5046.0000 - val_fn: 857.0000 - val_accuracy: 0.8548 - train_sensitivity: 0.9034 - train_specificity: 0.9034 - train_balacc: 0.9034 - val_sensitivity: 0.8548 - val_specificity: 0.8548 - val_balacc: 0.8548\n",
      "Epoch 61/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2199 - tp: 21359.0000 - fp: 2241.0000 - tn: 21359.0000 - fn: 2241.0000 - accuracy: 0.9050 train_balacc 0.9050442590318072\n",
      " val_balacc 0.8770116889717093\n",
      "\n",
      "Epoch 61: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2199 - tp: 21369.0000 - fp: 2242.0000 - tn: 21369.0000 - fn: 2242.0000 - accuracy: 0.9050 - val_loss: 0.2793 - val_tp: 5177.0000 - val_fp: 726.0000 - val_tn: 5177.0000 - val_fn: 726.0000 - val_accuracy: 0.8770 - train_sensitivity: 0.9050 - train_specificity: 0.9050 - train_balacc: 0.9050 - val_sensitivity: 0.8770 - val_specificity: 0.8770 - val_balacc: 0.8770\n",
      "Epoch 62/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2172 - tp: 21421.0000 - fp: 2179.0000 - tn: 21421.0000 - fn: 2179.0000 - accuracy: 0.9077 train_balacc 0.9076701537419\n",
      " val_balacc 0.8660003388107742\n",
      "\n",
      "Epoch 62: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2171 - tp: 21431.0000 - fp: 2180.0000 - tn: 21431.0000 - fn: 2180.0000 - accuracy: 0.9077 - val_loss: 0.3339 - val_tp: 5112.0000 - val_fp: 791.0000 - val_tn: 5112.0000 - val_fn: 791.0000 - val_accuracy: 0.8660 - train_sensitivity: 0.9077 - train_specificity: 0.9077 - train_balacc: 0.9077 - val_sensitivity: 0.8660 - val_specificity: 0.8660 - val_balacc: 0.8660\n",
      "Epoch 63/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2183 - tp: 20802.0000 - fp: 2198.0000 - tn: 20802.0000 - fn: 2198.0000 - accuracy: 0.9044 train_balacc 0.9047054339079242\n",
      " val_balacc 0.822124343554125\n",
      "\n",
      "Epoch 63: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2178 - tp: 21361.0000 - fp: 2250.0000 - tn: 21361.0000 - fn: 2250.0000 - accuracy: 0.9047 - val_loss: 0.4070 - val_tp: 4853.0000 - val_fp: 1050.0000 - val_tn: 4853.0000 - val_fn: 1050.0000 - val_accuracy: 0.8221 - train_sensitivity: 0.9047 - train_specificity: 0.9047 - train_balacc: 0.9047 - val_sensitivity: 0.8221 - val_specificity: 0.8221 - val_balacc: 0.8221\n",
      "Epoch 64/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2177 - tp: 20819.0000 - fp: 2181.0000 - tn: 20819.0000 - fn: 2181.0000 - accuracy: 0.9052 train_balacc 0.9047054339079242\n",
      " val_balacc 0.8671861765204133\n",
      "\n",
      "Epoch 64: val_balacc did not improve from 0.88091\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2192 - tp: 21361.0000 - fp: 2250.0000 - tn: 21361.0000 - fn: 2250.0000 - accuracy: 0.9047 - val_loss: 0.2982 - val_tp: 5119.0000 - val_fp: 784.0000 - val_tn: 5119.0000 - val_fn: 784.0000 - val_accuracy: 0.8672 - train_sensitivity: 0.9047 - train_specificity: 0.9047 - train_balacc: 0.9047 - val_sensitivity: 0.8672 - val_specificity: 0.8672 - val_balacc: 0.8672\n",
      "Epoch 65/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2148 - tp: 21368.0000 - fp: 2232.0000 - tn: 21368.0000 - fn: 2232.0000 - accuracy: 0.9054 train_balacc 0.9054677904366609\n",
      " val_balacc 0.8817550398102659\n",
      "\n",
      "Epoch 65: val_balacc improved from 0.88091 to 0.88176, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2148 - tp: 21379.0000 - fp: 2232.0000 - tn: 21379.0000 - fn: 2232.0000 - accuracy: 0.9055 - val_loss: 0.2842 - val_tp: 5205.0000 - val_fp: 698.0000 - val_tn: 5205.0000 - val_fn: 698.0000 - val_accuracy: 0.8818 - train_sensitivity: 0.9055 - train_specificity: 0.9055 - train_balacc: 0.9055 - val_sensitivity: 0.8818 - val_specificity: 0.8818 - val_balacc: 0.8818\n",
      "Epoch 66/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2136 - tp: 20777.0000 - fp: 2123.0000 - tn: 20777.0000 - fn: 2123.0000 - accuracy: 0.9073 train_balacc 0.9071619160560755\n",
      " val_balacc 0.8531255293918346\n",
      "\n",
      "Epoch 66: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2136 - tp: 21419.0000 - fp: 2192.0000 - tn: 21419.0000 - fn: 2192.0000 - accuracy: 0.9072 - val_loss: 0.4212 - val_tp: 5036.0000 - val_fp: 867.0000 - val_tn: 5036.0000 - val_fn: 867.0000 - val_accuracy: 0.8531 - train_sensitivity: 0.9072 - train_specificity: 0.9072 - train_balacc: 0.9072 - val_sensitivity: 0.8531 - val_specificity: 0.8531 - val_balacc: 0.8531\n",
      "Epoch 67/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2145 - tp: 20777.0000 - fp: 2123.0000 - tn: 20777.0000 - fn: 2123.0000 - accuracy: 0.9073 train_balacc 0.9078819194443268\n",
      " val_balacc 0.8609181771980349\n",
      "\n",
      "Epoch 67: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2139 - tp: 21436.0000 - fp: 2175.0000 - tn: 21436.0000 - fn: 2175.0000 - accuracy: 0.9079 - val_loss: 0.3139 - val_tp: 5082.0000 - val_fp: 821.0000 - val_tn: 5082.0000 - val_fn: 821.0000 - val_accuracy: 0.8609 - train_sensitivity: 0.9079 - train_specificity: 0.9079 - train_balacc: 0.9079 - val_sensitivity: 0.8609 - val_specificity: 0.8609 - val_balacc: 0.8609\n",
      "Epoch 68/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2066 - tp: 21011.0000 - fp: 2089.0000 - tn: 21011.0000 - fn: 2089.0000 - accuracy: 0.9096 train_balacc 0.9094066325018\n",
      " val_balacc 0.8580382856174826\n",
      "\n",
      "Epoch 68: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2075 - tp: 21472.0000 - fp: 2139.0000 - tn: 21472.0000 - fn: 2139.0000 - accuracy: 0.9094 - val_loss: 0.3256 - val_tp: 5065.0000 - val_fp: 838.0000 - val_tn: 5065.0000 - val_fn: 838.0000 - val_accuracy: 0.8580 - train_sensitivity: 0.9094 - train_specificity: 0.9094 - train_balacc: 0.9094 - val_sensitivity: 0.8580 - val_specificity: 0.8580 - val_balacc: 0.8580\n",
      "Epoch 69/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2080 - tp: 21012.0000 - fp: 2088.0000 - tn: 21012.0000 - fn: 2088.0000 - accuracy: 0.9096 train_balacc 0.9094913387827708\n",
      " val_balacc 0.8614263933593088\n",
      "\n",
      "Epoch 69: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2078 - tp: 21474.0000 - fp: 2137.0000 - tn: 21474.0000 - fn: 2137.0000 - accuracy: 0.9095 - val_loss: 0.3063 - val_tp: 5085.0000 - val_fp: 818.0000 - val_tn: 5085.0000 - val_fn: 818.0000 - val_accuracy: 0.8614 - train_sensitivity: 0.9095 - train_specificity: 0.9095 - train_balacc: 0.9095 - val_sensitivity: 0.8614 - val_specificity: 0.8614 - val_balacc: 0.8614\n",
      "Epoch 70/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.2138 - tp: 21257.0000 - fp: 2143.0000 - tn: 21257.0000 - fn: 2143.0000 - accuracy: 0.9084 train_balacc 0.908601922832578\n",
      " val_balacc 0.8573606640691174\n",
      "\n",
      "Epoch 70: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2136 - tp: 21453.0000 - fp: 2158.0000 - tn: 21453.0000 - fn: 2158.0000 - accuracy: 0.9086 - val_loss: 0.3103 - val_tp: 5061.0000 - val_fp: 842.0000 - val_tn: 5061.0000 - val_fn: 842.0000 - val_accuracy: 0.8574 - train_sensitivity: 0.9086 - train_specificity: 0.9086 - train_balacc: 0.9086 - val_sensitivity: 0.8574 - val_specificity: 0.8574 - val_balacc: 0.8574\n",
      "Epoch 71/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2173 - tp: 20683.0000 - fp: 2117.0000 - tn: 20683.0000 - fn: 2117.0000 - accuracy: 0.9071 train_balacc 0.907331328618017\n",
      " val_balacc 0.7951888870066068\n",
      "\n",
      "Epoch 71: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2169 - tp: 21423.0000 - fp: 2188.0000 - tn: 21423.0000 - fn: 2188.0000 - accuracy: 0.9073 - val_loss: 0.4882 - val_tp: 4694.0000 - val_fp: 1209.0000 - val_tn: 4694.0000 - val_fn: 1209.0000 - val_accuracy: 0.7952 - train_sensitivity: 0.9073 - train_specificity: 0.9073 - train_balacc: 0.9073 - val_sensitivity: 0.7952 - val_specificity: 0.7952 - val_balacc: 0.7952\n",
      "Epoch 72/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.2070 - tp: 21410.0000 - fp: 2090.0000 - tn: 21410.0000 - fn: 2090.0000 - accuracy: 0.9111 train_balacc 0.9109736986997586\n",
      " val_balacc 0.8568524479078434\n",
      "\n",
      "Epoch 72: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2070 - tp: 21509.0000 - fp: 2102.0000 - tn: 21509.0000 - fn: 2102.0000 - accuracy: 0.9110 - val_loss: 0.3304 - val_tp: 5058.0000 - val_fp: 845.0000 - val_tn: 5058.0000 - val_fn: 845.0000 - val_accuracy: 0.8569 - train_sensitivity: 0.9110 - train_specificity: 0.9110 - train_balacc: 0.9110 - val_sensitivity: 0.8569 - val_specificity: 0.8569 - val_balacc: 0.8569\n",
      "Epoch 73/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2106 - tp: 20782.0000 - fp: 2118.0000 - tn: 20782.0000 - fn: 2118.0000 - accuracy: 0.9075 train_balacc 0.9068230909321926\n",
      " val_balacc 0.6498390648822633\n",
      "\n",
      "Epoch 73: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2122 - tp: 21411.0000 - fp: 2200.0000 - tn: 21411.0000 - fn: 2200.0000 - accuracy: 0.9068 - val_loss: 1.9343 - val_tp: 3836.0000 - val_fp: 2067.0000 - val_tn: 3836.0000 - val_fn: 2067.0000 - val_accuracy: 0.6498 - train_sensitivity: 0.9068 - train_specificity: 0.9068 - train_balacc: 0.9068 - val_sensitivity: 0.6498 - val_specificity: 0.6498 - val_balacc: 0.6498\n",
      "Epoch 74/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2061 - tp: 20947.0000 - fp: 2053.0000 - tn: 20947.0000 - fn: 2053.0000 - accuracy: 0.9107 train_balacc 0.910677226716361\n",
      " val_balacc 0.879552769778079\n",
      "\n",
      "Epoch 74: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2063 - tp: 21502.0000 - fp: 2109.0000 - tn: 21502.0000 - fn: 2109.0000 - accuracy: 0.9107 - val_loss: 0.2763 - val_tp: 5192.0000 - val_fp: 711.0000 - val_tn: 5192.0000 - val_fn: 711.0000 - val_accuracy: 0.8796 - train_sensitivity: 0.9107 - train_specificity: 0.9107 - train_balacc: 0.9107 - val_sensitivity: 0.8796 - val_specificity: 0.8796 - val_balacc: 0.8796\n",
      "Epoch 75/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2075 - tp: 20731.0000 - fp: 2069.0000 - tn: 20731.0000 - fn: 2069.0000 - accuracy: 0.9093 train_balacc 0.9095336919232561\n",
      " val_balacc 0.8563442317465696\n",
      "\n",
      "Epoch 75: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2068 - tp: 21475.0000 - fp: 2136.0000 - tn: 21475.0000 - fn: 2136.0000 - accuracy: 0.9095 - val_loss: 0.3244 - val_tp: 5055.0000 - val_fp: 848.0000 - val_tn: 5055.0000 - val_fn: 848.0000 - val_accuracy: 0.8563 - train_sensitivity: 0.9095 - train_specificity: 0.9095 - train_balacc: 0.9095 - val_sensitivity: 0.8563 - val_specificity: 0.8563 - val_balacc: 0.8563\n",
      "Epoch 76/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.2006 - tp: 21165.0000 - fp: 2035.0000 - tn: 21165.0000 - fn: 2035.0000 - accuracy: 0.9123 train_balacc 0.9120325272118928\n",
      " val_balacc 0.8771810943588007\n",
      "\n",
      "Epoch 76: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2007 - tp: 21534.0000 - fp: 2077.0000 - tn: 21534.0000 - fn: 2077.0000 - accuracy: 0.9120 - val_loss: 0.2930 - val_tp: 5178.0000 - val_fp: 725.0000 - val_tn: 5178.0000 - val_fn: 725.0000 - val_accuracy: 0.8772 - train_sensitivity: 0.9120 - train_specificity: 0.9120 - train_balacc: 0.9120 - val_sensitivity: 0.8772 - val_specificity: 0.8772 - val_balacc: 0.8772\n",
      "Epoch 77/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.2106 - tp: 21404.0000 - fp: 2096.0000 - tn: 21404.0000 - fn: 2096.0000 - accuracy: 0.9108 train_balacc 0.9109313455592732\n",
      " val_balacc 0.8566830425207521\n",
      "\n",
      "Epoch 77: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2105 - tp: 21508.0000 - fp: 2103.0000 - tn: 21508.0000 - fn: 2103.0000 - accuracy: 0.9109 - val_loss: 0.3462 - val_tp: 5057.0000 - val_fp: 846.0000 - val_tn: 5057.0000 - val_fn: 846.0000 - val_accuracy: 0.8567 - train_sensitivity: 0.9109 - train_specificity: 0.9109 - train_balacc: 0.9109 - val_sensitivity: 0.8567 - val_specificity: 0.8567 - val_balacc: 0.8567\n",
      "Epoch 78/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2049 - tp: 21474.0000 - fp: 2126.0000 - tn: 21474.0000 - fn: 2126.0000 - accuracy: 0.9099 train_balacc 0.9098301639066537\n",
      " val_balacc 0.8385566661019821\n",
      "\n",
      "Epoch 78: val_balacc did not improve from 0.88176\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2056 - tp: 21482.0000 - fp: 2129.0000 - tn: 21482.0000 - fn: 2129.0000 - accuracy: 0.9098 - val_loss: 0.3525 - val_tp: 4950.0000 - val_fp: 953.0000 - val_tn: 4950.0000 - val_fn: 953.0000 - val_accuracy: 0.8386 - train_sensitivity: 0.9098 - train_specificity: 0.9098 - train_balacc: 0.9098 - val_sensitivity: 0.8386 - val_specificity: 0.8386 - val_balacc: 0.8386\n",
      "Epoch 79/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2063 - tp: 21126.0000 - fp: 1974.0000 - tn: 21126.0000 - fn: 1974.0000 - accuracy: 0.9145 train_balacc 0.9146584219219855\n",
      " val_balacc 0.8829408775199051\n",
      "\n",
      "Epoch 79: val_balacc improved from 0.88176 to 0.88294, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2056 - tp: 21596.0000 - fp: 2015.0000 - tn: 21596.0000 - fn: 2015.0000 - accuracy: 0.9147 - val_loss: 0.2765 - val_tp: 5212.0000 - val_fp: 691.0000 - val_tn: 5212.0000 - val_fn: 691.0000 - val_accuracy: 0.8829 - train_sensitivity: 0.9147 - train_specificity: 0.9147 - train_balacc: 0.9147 - val_sensitivity: 0.8829 - val_specificity: 0.8829 - val_balacc: 0.8829\n",
      "Epoch 80/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2066 - tp: 20872.0000 - fp: 2028.0000 - tn: 20872.0000 - fn: 2028.0000 - accuracy: 0.9114 train_balacc 0.9115242895260683\n",
      " val_balacc 0.8792139590038963\n",
      "\n",
      "Epoch 80: val_balacc did not improve from 0.88294\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2065 - tp: 21522.0000 - fp: 2089.0000 - tn: 21522.0000 - fn: 2089.0000 - accuracy: 0.9115 - val_loss: 0.2889 - val_tp: 5190.0000 - val_fp: 713.0000 - val_tn: 5190.0000 - val_fn: 713.0000 - val_accuracy: 0.8792 - train_sensitivity: 0.9115 - train_specificity: 0.9115 - train_balacc: 0.9115 - val_sensitivity: 0.8792 - val_specificity: 0.8792 - val_balacc: 0.8792\n",
      "Epoch 81/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2031 - tp: 21038.0000 - fp: 1962.0000 - tn: 21038.0000 - fn: 1962.0000 - accuracy: 0.9147 train_balacc 0.9146584219219855\n",
      " val_balacc 0.8720989327460613\n",
      "\n",
      "Epoch 81: val_balacc did not improve from 0.88294\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2030 - tp: 21596.0000 - fp: 2015.0000 - tn: 21596.0000 - fn: 2015.0000 - accuracy: 0.9147 - val_loss: 0.2816 - val_tp: 5148.0000 - val_fp: 755.0000 - val_tn: 5148.0000 - val_fn: 755.0000 - val_accuracy: 0.8721 - train_sensitivity: 0.9147 - train_specificity: 0.9147 - train_balacc: 0.9147 - val_sensitivity: 0.8721 - val_specificity: 0.8721 - val_balacc: 0.8721\n",
      "Epoch 82/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2045 - tp: 21001.0000 - fp: 1999.0000 - tn: 21001.0000 - fn: 1999.0000 - accuracy: 0.9131 train_balacc 0.9128372368811147\n",
      " val_balacc 0.8549889886498391\n",
      "\n",
      "Epoch 82: val_balacc did not improve from 0.88294\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2049 - tp: 21553.0000 - fp: 2058.0000 - tn: 21553.0000 - fn: 2058.0000 - accuracy: 0.9128 - val_loss: 0.3104 - val_tp: 5047.0000 - val_fp: 856.0000 - val_tn: 5047.0000 - val_fn: 856.0000 - val_accuracy: 0.8550 - train_sensitivity: 0.9128 - train_specificity: 0.9128 - train_balacc: 0.9128 - val_sensitivity: 0.8550 - val_specificity: 0.8550 - val_balacc: 0.8550\n",
      "Epoch 83/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2012 - tp: 21063.0000 - fp: 2037.0000 - tn: 21063.0000 - fn: 2037.0000 - accuracy: 0.9118 train_balacc 0.9120325272118928\n",
      " val_balacc 0.8878536337455532\n",
      "\n",
      "Epoch 83: val_balacc improved from 0.88294 to 0.88785, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2003 - tp: 21534.0000 - fp: 2077.0000 - tn: 21534.0000 - fn: 2077.0000 - accuracy: 0.9120 - val_loss: 0.2607 - val_tp: 5241.0000 - val_fp: 662.0000 - val_tn: 5241.0000 - val_fn: 662.0000 - val_accuracy: 0.8879 - train_sensitivity: 0.9120 - train_specificity: 0.9120 - train_balacc: 0.9120 - val_sensitivity: 0.8879 - val_specificity: 0.8879 - val_balacc: 0.8879\n",
      "Epoch 84/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2015 - tp: 20973.0000 - fp: 1927.0000 - tn: 20973.0000 - fn: 1927.0000 - accuracy: 0.9159 train_balacc 0.9153360721697514\n",
      " val_balacc 0.8290699644248687\n",
      "\n",
      "Epoch 84: val_balacc did not improve from 0.88785\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2023 - tp: 21612.0000 - fp: 1999.0000 - tn: 21612.0000 - fn: 1999.0000 - accuracy: 0.9153 - val_loss: 0.4503 - val_tp: 4894.0000 - val_fp: 1009.0000 - val_tn: 4894.0000 - val_fn: 1009.0000 - val_accuracy: 0.8291 - train_sensitivity: 0.9153 - train_specificity: 0.9153 - train_balacc: 0.9153 - val_sensitivity: 0.8291 - val_specificity: 0.8291 - val_balacc: 0.8291\n",
      "Epoch 85/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1976 - tp: 20998.0000 - fp: 1902.0000 - tn: 20998.0000 - fn: 1902.0000 - accuracy: 0.9169 train_balacc 0.9170725509296515\n",
      " val_balacc 0.8563442317465696\n",
      "\n",
      "Epoch 85: val_balacc did not improve from 0.88785\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1975 - tp: 21653.0000 - fp: 1958.0000 - tn: 21653.0000 - fn: 1958.0000 - accuracy: 0.9171 - val_loss: 0.3585 - val_tp: 5055.0000 - val_fp: 848.0000 - val_tn: 5055.0000 - val_fn: 848.0000 - val_accuracy: 0.8563 - train_sensitivity: 0.9171 - train_specificity: 0.9171 - train_balacc: 0.9171 - val_sensitivity: 0.8563 - val_specificity: 0.8563 - val_balacc: 0.8563\n",
      "Epoch 86/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.2029 - tp: 21213.0000 - fp: 1987.0000 - tn: 21213.0000 - fn: 1987.0000 - accuracy: 0.9144 train_balacc 0.9141925373766465\n",
      " val_balacc 0.8815856344231746\n",
      "\n",
      "Epoch 86: val_balacc did not improve from 0.88785\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2031 - tp: 21585.0000 - fp: 2026.0000 - tn: 21585.0000 - fn: 2026.0000 - accuracy: 0.9142 - val_loss: 0.2775 - val_tp: 5204.0000 - val_fp: 699.0000 - val_tn: 5204.0000 - val_fn: 699.0000 - val_accuracy: 0.8816 - train_sensitivity: 0.9142 - train_specificity: 0.9142 - train_balacc: 0.9142 - val_sensitivity: 0.8816 - val_specificity: 0.8816 - val_balacc: 0.8816\n",
      "Epoch 87/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2018 - tp: 20947.0000 - fp: 1953.0000 - tn: 20947.0000 - fn: 1953.0000 - accuracy: 0.9147 train_balacc 0.9148701876244123\n",
      " val_balacc 0.8521090970692868\n",
      "\n",
      "Epoch 87: val_balacc did not improve from 0.88785\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2020 - tp: 21601.0000 - fp: 2010.0000 - tn: 21601.0000 - fn: 2010.0000 - accuracy: 0.9149 - val_loss: 0.3377 - val_tp: 5030.0000 - val_fp: 873.0000 - val_tn: 5030.0000 - val_fn: 873.0000 - val_accuracy: 0.8521 - train_sensitivity: 0.9149 - train_specificity: 0.9149 - train_balacc: 0.9149 - val_sensitivity: 0.8521 - val_specificity: 0.8521 - val_balacc: 0.8521\n",
      "Epoch 88/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1958 - tp: 20949.0000 - fp: 1951.0000 - tn: 20949.0000 - fn: 1951.0000 - accuracy: 0.9148 train_balacc 0.9147854813434416\n",
      " val_balacc 0.8815856344231746\n",
      "\n",
      "Epoch 88: val_balacc did not improve from 0.88785\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1961 - tp: 21599.0000 - fp: 2012.0000 - tn: 21599.0000 - fn: 2012.0000 - accuracy: 0.9148 - val_loss: 0.2888 - val_tp: 5204.0000 - val_fp: 699.0000 - val_tn: 5204.0000 - val_fn: 699.0000 - val_accuracy: 0.8816 - train_sensitivity: 0.9148 - train_specificity: 0.9148 - train_balacc: 0.9148 - val_sensitivity: 0.8816 - val_specificity: 0.8816 - val_balacc: 0.8816\n",
      "Epoch 89/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2027 - tp: 21569.0000 - fp: 2031.0000 - tn: 21569.0000 - fn: 2031.0000 - accuracy: 0.9139 train_balacc 0.9138960653932489\n",
      " val_balacc 0.8712519058106047\n",
      "\n",
      "Epoch 89: val_balacc did not improve from 0.88785\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2027 - tp: 21578.0000 - fp: 2033.0000 - tn: 21578.0000 - fn: 2033.0000 - accuracy: 0.9139 - val_loss: 0.2981 - val_tp: 5143.0000 - val_fp: 760.0000 - val_tn: 5143.0000 - val_fn: 760.0000 - val_accuracy: 0.8713 - train_sensitivity: 0.9139 - train_specificity: 0.9139 - train_balacc: 0.9139 - val_sensitivity: 0.8713 - val_specificity: 0.8713 - val_balacc: 0.8713\n",
      "Epoch 90/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1985 - tp: 21280.0000 - fp: 1920.0000 - tn: 21280.0000 - fn: 1920.0000 - accuracy: 0.9172 train_balacc 0.9174537291940197\n",
      " val_balacc 0.8690496357784178\n",
      "\n",
      "Epoch 90: val_balacc did not improve from 0.88785\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1984 - tp: 21662.0000 - fp: 1949.0000 - tn: 21662.0000 - fn: 1949.0000 - accuracy: 0.9175 - val_loss: 0.3344 - val_tp: 5130.0000 - val_fp: 773.0000 - val_tn: 5130.0000 - val_fn: 773.0000 - val_accuracy: 0.8690 - train_sensitivity: 0.9175 - train_specificity: 0.9175 - train_balacc: 0.9175 - val_sensitivity: 0.8690 - val_specificity: 0.8690 - val_balacc: 0.8690\n",
      "Epoch 91/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1959 - tp: 21072.0000 - fp: 1928.0000 - tn: 21072.0000 - fn: 1928.0000 - accuracy: 0.9162 train_balacc 0.9161831349794587\n",
      " val_balacc 0.8890394714551922\n",
      "\n",
      "Epoch 91: val_balacc improved from 0.88785 to 0.88904, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1960 - tp: 21632.0000 - fp: 1979.0000 - tn: 21632.0000 - fn: 1979.0000 - accuracy: 0.9162 - val_loss: 0.2610 - val_tp: 5248.0000 - val_fp: 655.0000 - val_tn: 5248.0000 - val_fn: 655.0000 - val_accuracy: 0.8890 - train_sensitivity: 0.9162 - train_specificity: 0.9162 - train_balacc: 0.9162 - val_sensitivity: 0.8890 - val_specificity: 0.8890 - val_balacc: 0.8890\n",
      "Epoch 92/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1986 - tp: 21076.0000 - fp: 1924.0000 - tn: 21076.0000 - fn: 1924.0000 - accuracy: 0.9163 train_balacc 0.9164796069628562\n",
      " val_balacc 0.8793833643909876\n",
      "\n",
      "Epoch 92: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1983 - tp: 21639.0000 - fp: 1972.0000 - tn: 21639.0000 - fn: 1972.0000 - accuracy: 0.9165 - val_loss: 0.2853 - val_tp: 5191.0000 - val_fp: 712.0000 - val_tn: 5191.0000 - val_fn: 712.0000 - val_accuracy: 0.8794 - train_sensitivity: 0.9165 - train_specificity: 0.9165 - train_balacc: 0.9165 - val_sensitivity: 0.8794 - val_specificity: 0.8794 - val_balacc: 0.8794\n",
      "Epoch 93/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1955 - tp: 21457.0000 - fp: 1943.0000 - tn: 21457.0000 - fn: 1943.0000 - accuracy: 0.9170 train_balacc 0.9169878446486807\n",
      " val_balacc 0.8761646620362528\n",
      "\n",
      "Epoch 93: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1953 - tp: 21651.0000 - fp: 1960.0000 - tn: 21651.0000 - fn: 1960.0000 - accuracy: 0.9170 - val_loss: 0.2872 - val_tp: 5172.0000 - val_fp: 731.0000 - val_tn: 5172.0000 - val_fn: 731.0000 - val_accuracy: 0.8762 - train_sensitivity: 0.9170 - train_specificity: 0.9170 - train_balacc: 0.9170 - val_sensitivity: 0.8762 - val_specificity: 0.8762 - val_balacc: 0.8762\n",
      "Epoch 94/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1931 - tp: 21181.0000 - fp: 1919.0000 - tn: 21181.0000 - fn: 1919.0000 - accuracy: 0.9169 train_balacc 0.916564313243827\n",
      " val_balacc 0.8446552600372692\n",
      "\n",
      "Epoch 94: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1934 - tp: 21641.0000 - fp: 1970.0000 - tn: 21641.0000 - fn: 1970.0000 - accuracy: 0.9166 - val_loss: 0.3902 - val_tp: 4986.0000 - val_fp: 917.0000 - val_tn: 4986.0000 - val_fn: 917.0000 - val_accuracy: 0.8447 - train_sensitivity: 0.9166 - train_specificity: 0.9166 - train_balacc: 0.9166 - val_sensitivity: 0.8447 - val_specificity: 0.8447 - val_balacc: 0.8447\n",
      "Epoch 95/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1951 - tp: 21039.0000 - fp: 1861.0000 - tn: 21039.0000 - fn: 1861.0000 - accuracy: 0.9187 train_balacc 0.9187666765490661\n",
      " val_balacc 0.8685414196171438\n",
      "\n",
      "Epoch 95: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1948 - tp: 21693.0000 - fp: 1918.0000 - tn: 21693.0000 - fn: 1918.0000 - accuracy: 0.9188 - val_loss: 0.3127 - val_tp: 5127.0000 - val_fp: 776.0000 - val_tn: 5127.0000 - val_fn: 776.0000 - val_accuracy: 0.8685 - train_sensitivity: 0.9188 - train_specificity: 0.9188 - train_balacc: 0.9188 - val_sensitivity: 0.8685 - val_specificity: 0.8685 - val_balacc: 0.8685\n",
      "Epoch 96/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1991 - tp: 21621.0000 - fp: 1979.0000 - tn: 21621.0000 - fn: 1979.0000 - accuracy: 0.9161 train_balacc 0.9161407818389734\n",
      " val_balacc 0.8477045570049128\n",
      "\n",
      "Epoch 96: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1991 - tp: 21631.0000 - fp: 1980.0000 - tn: 21631.0000 - fn: 1980.0000 - accuracy: 0.9161 - val_loss: 0.3376 - val_tp: 5004.0000 - val_fp: 899.0000 - val_tn: 5004.0000 - val_fn: 899.0000 - val_accuracy: 0.8477 - train_sensitivity: 0.9161 - train_specificity: 0.9161 - train_balacc: 0.9161 - val_sensitivity: 0.8477 - val_specificity: 0.8477 - val_balacc: 0.8477\n",
      "Epoch 97/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1954 - tp: 21035.0000 - fp: 1865.0000 - tn: 21035.0000 - fn: 1865.0000 - accuracy: 0.9186 train_balacc 0.9185972639871246\n",
      " val_balacc 0.877350499745892\n",
      "\n",
      "Epoch 97: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1955 - tp: 21689.0000 - fp: 1922.0000 - tn: 21689.0000 - fn: 1922.0000 - accuracy: 0.9186 - val_loss: 0.2994 - val_tp: 5179.0000 - val_fp: 724.0000 - val_tn: 5179.0000 - val_fn: 724.0000 - val_accuracy: 0.8774 - train_sensitivity: 0.9186 - train_specificity: 0.9186 - train_balacc: 0.9186 - val_sensitivity: 0.8774 - val_specificity: 0.8774 - val_balacc: 0.8774\n",
      "Epoch 98/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2013 - tp: 21656.0000 - fp: 1944.0000 - tn: 21656.0000 - fn: 1944.0000 - accuracy: 0.9176 train_balacc 0.9176654948964466\n",
      " val_balacc 0.883957309842453\n",
      "\n",
      "Epoch 98: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2013 - tp: 21667.0000 - fp: 1944.0000 - tn: 21667.0000 - fn: 1944.0000 - accuracy: 0.9177 - val_loss: 0.2658 - val_tp: 5218.0000 - val_fp: 685.0000 - val_tn: 5218.0000 - val_fn: 685.0000 - val_accuracy: 0.8840 - train_sensitivity: 0.9177 - train_specificity: 0.9177 - train_balacc: 0.9177 - val_sensitivity: 0.8840 - val_specificity: 0.8840 - val_balacc: 0.8840\n",
      "Epoch 99/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1933 - tp: 21193.0000 - fp: 1907.0000 - tn: 21193.0000 - fn: 1907.0000 - accuracy: 0.9174 train_balacc 0.9173266697725636\n",
      " val_balacc 0.8781975266813484\n",
      "\n",
      "Epoch 99: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1935 - tp: 21659.0000 - fp: 1952.0000 - tn: 21659.0000 - fn: 1952.0000 - accuracy: 0.9173 - val_loss: 0.2815 - val_tp: 5184.0000 - val_fp: 719.0000 - val_tn: 5184.0000 - val_fn: 719.0000 - val_accuracy: 0.8782 - train_sensitivity: 0.9173 - train_specificity: 0.9173 - train_balacc: 0.9173 - val_sensitivity: 0.8782 - val_specificity: 0.8782 - val_balacc: 0.8782\n",
      "Epoch 100/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1933 - tp: 21200.0000 - fp: 1900.0000 - tn: 21200.0000 - fn: 1900.0000 - accuracy: 0.9177 train_balacc 0.917707848036932\n",
      " val_balacc 0.863120447230222\n",
      "\n",
      "Epoch 100: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1922 - tp: 21668.0000 - fp: 1943.0000 - tn: 21668.0000 - fn: 1943.0000 - accuracy: 0.9177 - val_loss: 0.3102 - val_tp: 5095.0000 - val_fp: 808.0000 - val_tn: 5095.0000 - val_fn: 808.0000 - val_accuracy: 0.8631 - train_sensitivity: 0.9177 - train_specificity: 0.9177 - train_balacc: 0.9177 - val_sensitivity: 0.8631 - val_specificity: 0.8631 - val_balacc: 0.8631\n",
      "Epoch 101/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1946 - tp: 20980.0000 - fp: 1920.0000 - tn: 20980.0000 - fn: 1920.0000 - accuracy: 0.9162 train_balacc 0.9158866629960611\n",
      " val_balacc 0.8792139590038963\n",
      "\n",
      "Epoch 101: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1949 - tp: 21625.0000 - fp: 1986.0000 - tn: 21625.0000 - fn: 1986.0000 - accuracy: 0.9159 - val_loss: 0.2817 - val_tp: 5190.0000 - val_fp: 713.0000 - val_tn: 5190.0000 - val_fn: 713.0000 - val_accuracy: 0.8792 - train_sensitivity: 0.9159 - train_specificity: 0.9159 - train_balacc: 0.9159 - val_sensitivity: 0.8792 - val_specificity: 0.8792 - val_balacc: 0.8792\n",
      "Epoch 102/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1947 - tp: 21724.0000 - fp: 1876.0000 - tn: 21724.0000 - fn: 1876.0000 - accuracy: 0.9205 train_balacc 0.9204608021684808\n",
      " val_balacc 0.856005420972387\n",
      "\n",
      "Epoch 102: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1948 - tp: 21733.0000 - fp: 1878.0000 - tn: 21733.0000 - fn: 1878.0000 - accuracy: 0.9205 - val_loss: 0.3431 - val_tp: 5053.0000 - val_fp: 850.0000 - val_tn: 5053.0000 - val_fn: 850.0000 - val_accuracy: 0.8560 - train_sensitivity: 0.9205 - train_specificity: 0.9205 - train_balacc: 0.9205 - val_sensitivity: 0.8560 - val_specificity: 0.8560 - val_balacc: 0.8560\n",
      "Epoch 103/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1913 - tp: 21198.0000 - fp: 1802.0000 - tn: 21198.0000 - fn: 1802.0000 - accuracy: 0.9217 train_balacc 0.9214772775401296\n",
      " val_balacc 0.848382178553278\n",
      "\n",
      "Epoch 103: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1918 - tp: 21757.0000 - fp: 1854.0000 - tn: 21757.0000 - fn: 1854.0000 - accuracy: 0.9215 - val_loss: 0.3479 - val_tp: 5008.0000 - val_fp: 895.0000 - val_tn: 5008.0000 - val_fn: 895.0000 - val_accuracy: 0.8484 - train_sensitivity: 0.9215 - train_specificity: 0.9215 - train_balacc: 0.9215 - val_sensitivity: 0.8484 - val_specificity: 0.8484 - val_balacc: 0.8484\n",
      "Epoch 104/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1957 - tp: 20922.0000 - fp: 1878.0000 - tn: 20922.0000 - fn: 1878.0000 - accuracy: 0.9176 train_balacc 0.917834907458388\n",
      " val_balacc 0.8668473657462308\n",
      "\n",
      "Epoch 104: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1953 - tp: 21671.0000 - fp: 1940.0000 - tn: 21671.0000 - fn: 1940.0000 - accuracy: 0.9178 - val_loss: 0.3454 - val_tp: 5117.0000 - val_fp: 786.0000 - val_tn: 5117.0000 - val_fn: 786.0000 - val_accuracy: 0.8668 - train_sensitivity: 0.9178 - train_specificity: 0.9178 - train_balacc: 0.9178 - val_sensitivity: 0.8668 - val_specificity: 0.8668 - val_balacc: 0.8668\n",
      "Epoch 105/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1962 - tp: 20862.0000 - fp: 1938.0000 - tn: 20862.0000 - fn: 1938.0000 - accuracy: 0.9150 train_balacc 0.9149125407648977\n",
      " val_balacc 0.8832796882940878\n",
      "\n",
      "Epoch 105: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1968 - tp: 21602.0000 - fp: 2009.0000 - tn: 21602.0000 - fn: 2009.0000 - accuracy: 0.9149 - val_loss: 0.2955 - val_tp: 5214.0000 - val_fp: 689.0000 - val_tn: 5214.0000 - val_fn: 689.0000 - val_accuracy: 0.8833 - train_sensitivity: 0.9149 - train_specificity: 0.9149 - train_balacc: 0.9149 - val_sensitivity: 0.8833 - val_specificity: 0.8833 - val_balacc: 0.8833\n",
      "Epoch 106/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1970 - tp: 20924.0000 - fp: 1876.0000 - tn: 20924.0000 - fn: 1876.0000 - accuracy: 0.9177 train_balacc 0.9182584388632417\n",
      " val_balacc 0.8629510418431307\n",
      "\n",
      "Epoch 106: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1954 - tp: 21681.0000 - fp: 1930.0000 - tn: 21681.0000 - fn: 1930.0000 - accuracy: 0.9183 - val_loss: 0.3313 - val_tp: 5094.0000 - val_fp: 809.0000 - val_tn: 5094.0000 - val_fn: 809.0000 - val_accuracy: 0.8630 - train_sensitivity: 0.9183 - train_specificity: 0.9183 - train_balacc: 0.9183 - val_sensitivity: 0.8630 - val_specificity: 0.8630 - val_balacc: 0.8630\n",
      "Epoch 107/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1916 - tp: 21049.0000 - fp: 1851.0000 - tn: 21049.0000 - fn: 1851.0000 - accuracy: 0.9192 train_balacc 0.9191478548134344\n",
      " val_balacc 0.8854819583262747\n",
      "\n",
      "Epoch 107: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1915 - tp: 21702.0000 - fp: 1909.0000 - tn: 21702.0000 - fn: 1909.0000 - accuracy: 0.9191 - val_loss: 0.2719 - val_tp: 5227.0000 - val_fp: 676.0000 - val_tn: 5227.0000 - val_fn: 676.0000 - val_accuracy: 0.8855 - train_sensitivity: 0.9191 - train_specificity: 0.9191 - train_balacc: 0.9191 - val_sensitivity: 0.8855 - val_specificity: 0.8855 - val_balacc: 0.8855\n",
      "Epoch 108/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1939 - tp: 21359.0000 - fp: 1841.0000 - tn: 21359.0000 - fn: 1841.0000 - accuracy: 0.9206 train_balacc 0.9202490364660539\n",
      " val_balacc 0.8761646620362528\n",
      "\n",
      "Epoch 108: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1946 - tp: 21728.0000 - fp: 1883.0000 - tn: 21728.0000 - fn: 1883.0000 - accuracy: 0.9202 - val_loss: 0.2969 - val_tp: 5172.0000 - val_fp: 731.0000 - val_tn: 5172.0000 - val_fn: 731.0000 - val_accuracy: 0.8762 - train_sensitivity: 0.9202 - train_specificity: 0.9202 - train_balacc: 0.9202 - val_sensitivity: 0.8762 - val_specificity: 0.8762 - val_balacc: 0.8762\n",
      "Epoch 109/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1890 - tp: 21740.0000 - fp: 1860.0000 - tn: 21740.0000 - fn: 1860.0000 - accuracy: 0.9212 train_balacc 0.9212231586972174\n",
      " val_balacc 0.8836184990682704\n",
      "\n",
      "Epoch 109: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1889 - tp: 21751.0000 - fp: 1860.0000 - tn: 21751.0000 - fn: 1860.0000 - accuracy: 0.9212 - val_loss: 0.2771 - val_tp: 5216.0000 - val_fp: 687.0000 - val_tn: 5216.0000 - val_fn: 687.0000 - val_accuracy: 0.8836 - train_sensitivity: 0.9212 - train_specificity: 0.9212 - train_balacc: 0.9212 - val_sensitivity: 0.8836 - val_specificity: 0.8836 - val_balacc: 0.8836\n",
      "Epoch 110/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1887 - tp: 21028.0000 - fp: 1772.0000 - tn: 21028.0000 - fn: 1772.0000 - accuracy: 0.9223 train_balacc 0.9218161026640125\n",
      " val_balacc 0.8803997967135355\n",
      "\n",
      "Epoch 110: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1891 - tp: 21765.0000 - fp: 1846.0000 - tn: 21765.0000 - fn: 1846.0000 - accuracy: 0.9218 - val_loss: 0.2818 - val_tp: 5197.0000 - val_fp: 706.0000 - val_tn: 5197.0000 - val_fn: 706.0000 - val_accuracy: 0.8804 - train_sensitivity: 0.9218 - train_specificity: 0.9218 - train_balacc: 0.9218 - val_sensitivity: 0.8804 - val_specificity: 0.8804 - val_balacc: 0.8804\n",
      "Epoch 111/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1902 - tp: 21731.0000 - fp: 1869.0000 - tn: 21731.0000 - fn: 1869.0000 - accuracy: 0.9208 train_balacc 0.9207572741518784\n",
      " val_balacc 0.8654921226495003\n",
      "\n",
      "Epoch 111: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1903 - tp: 21740.0000 - fp: 1871.0000 - tn: 21740.0000 - fn: 1871.0000 - accuracy: 0.9208 - val_loss: 0.3121 - val_tp: 5109.0000 - val_fp: 794.0000 - val_tn: 5109.0000 - val_fn: 794.0000 - val_accuracy: 0.8655 - train_sensitivity: 0.9208 - train_specificity: 0.9208 - train_balacc: 0.9208 - val_sensitivity: 0.8655 - val_specificity: 0.8655 - val_balacc: 0.8655\n",
      "Epoch 112/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1884 - tp: 20984.0000 - fp: 1816.0000 - tn: 20984.0000 - fn: 1816.0000 - accuracy: 0.9204 train_balacc 0.92037609588751\n",
      " val_balacc 0.8682026088429612\n",
      "\n",
      "Epoch 112: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1881 - tp: 21731.0000 - fp: 1880.0000 - tn: 21731.0000 - fn: 1880.0000 - accuracy: 0.9204 - val_loss: 0.3002 - val_tp: 5125.0000 - val_fp: 778.0000 - val_tn: 5125.0000 - val_fn: 778.0000 - val_accuracy: 0.8682 - train_sensitivity: 0.9204 - train_specificity: 0.9204 - train_balacc: 0.9204 - val_sensitivity: 0.8682 - val_specificity: 0.8682 - val_balacc: 0.8682\n",
      "Epoch 113/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1947 - tp: 20969.0000 - fp: 1831.0000 - tn: 20969.0000 - fn: 1831.0000 - accuracy: 0.9197 train_balacc 0.9199525644826564\n",
      " val_balacc 0.829747585973234\n",
      "\n",
      "Epoch 113: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1941 - tp: 21721.0000 - fp: 1890.0000 - tn: 21721.0000 - fn: 1890.0000 - accuracy: 0.9200 - val_loss: 0.3616 - val_tp: 4898.0000 - val_fp: 1005.0000 - val_tn: 4898.0000 - val_fn: 1005.0000 - val_accuracy: 0.8297 - train_sensitivity: 0.9200 - train_specificity: 0.9200 - train_balacc: 0.9200 - val_sensitivity: 0.8297 - val_specificity: 0.8297 - val_balacc: 0.8297\n",
      "Epoch 114/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1927 - tp: 21679.0000 - fp: 1921.0000 - tn: 21679.0000 - fn: 1921.0000 - accuracy: 0.9186 train_balacc 0.9185125577061539\n",
      " val_balacc 0.8614263933593088\n",
      "\n",
      "Epoch 114: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1932 - tp: 21687.0000 - fp: 1924.0000 - tn: 21687.0000 - fn: 1924.0000 - accuracy: 0.9185 - val_loss: 0.3432 - val_tp: 5085.0000 - val_fp: 818.0000 - val_tn: 5085.0000 - val_fn: 818.0000 - val_accuracy: 0.8614 - train_sensitivity: 0.9185 - train_specificity: 0.9185 - train_balacc: 0.9185 - val_sensitivity: 0.8614 - val_specificity: 0.8614 - val_balacc: 0.8614\n",
      "Epoch 115/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1916 - tp: 21083.0000 - fp: 1817.0000 - tn: 21083.0000 - fn: 1817.0000 - accuracy: 0.9207 train_balacc 0.920714921011393\n",
      " val_balacc 0.8282229374894121\n",
      "\n",
      "Epoch 115: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1918 - tp: 21739.0000 - fp: 1872.0000 - tn: 21739.0000 - fn: 1872.0000 - accuracy: 0.9207 - val_loss: 0.3753 - val_tp: 4889.0000 - val_fp: 1014.0000 - val_tn: 4889.0000 - val_fn: 1014.0000 - val_accuracy: 0.8282 - train_sensitivity: 0.9207 - train_specificity: 0.9207 - train_balacc: 0.9207 - val_sensitivity: 0.8282 - val_specificity: 0.8282 - val_balacc: 0.8282\n",
      "Epoch 116/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1952 - tp: 20952.0000 - fp: 1848.0000 - tn: 20952.0000 - fn: 1848.0000 - accuracy: 0.9189 train_balacc 0.9192325610944051\n",
      " val_balacc 0.8781975266813484\n",
      "\n",
      "Epoch 116: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1943 - tp: 21704.0000 - fp: 1907.0000 - tn: 21704.0000 - fn: 1907.0000 - accuracy: 0.9192 - val_loss: 0.2858 - val_tp: 5184.0000 - val_fp: 719.0000 - val_tn: 5184.0000 - val_fn: 719.0000 - val_accuracy: 0.8782 - train_sensitivity: 0.9192 - train_specificity: 0.9192 - train_balacc: 0.9192 - val_sensitivity: 0.8782 - val_specificity: 0.8782 - val_balacc: 0.8782\n",
      "Epoch 117/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1927 - tp: 21646.0000 - fp: 1854.0000 - tn: 21646.0000 - fn: 1854.0000 - accuracy: 0.9211 train_balacc 0.921180805556732\n",
      " val_balacc 0.8629510418431307\n",
      "\n",
      "Epoch 117: val_balacc did not improve from 0.88904\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1925 - tp: 21750.0000 - fp: 1861.0000 - tn: 21750.0000 - fn: 1861.0000 - accuracy: 0.9212 - val_loss: 0.3027 - val_tp: 5094.0000 - val_fp: 809.0000 - val_tn: 5094.0000 - val_fn: 809.0000 - val_accuracy: 0.8630 - train_sensitivity: 0.9212 - train_specificity: 0.9212 - train_balacc: 0.9212 - val_sensitivity: 0.8630 - val_specificity: 0.8630 - val_balacc: 0.8630\n",
      "Epoch 118/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1946 - tp: 21738.0000 - fp: 1873.0000 - tn: 21738.0000 - fn: 1873.0000 - accuracy: 0.9207 train_balacc 0.9206725678709077\n",
      " val_balacc 0.8892088768422836\n",
      "\n",
      "Epoch 118: val_balacc improved from 0.88904 to 0.88921, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1946 - tp: 21738.0000 - fp: 1873.0000 - tn: 21738.0000 - fn: 1873.0000 - accuracy: 0.9207 - val_loss: 0.2641 - val_tp: 5249.0000 - val_fp: 654.0000 - val_tn: 5249.0000 - val_fn: 654.0000 - val_accuracy: 0.8892 - train_sensitivity: 0.9207 - train_specificity: 0.9207 - train_balacc: 0.9207 - val_sensitivity: 0.8892 - val_specificity: 0.8892 - val_balacc: 0.8892\n",
      "Epoch 119/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1948 - tp: 21076.0000 - fp: 1824.0000 - tn: 21076.0000 - fn: 1824.0000 - accuracy: 0.9203 train_balacc 0.9204608021684808\n",
      " val_balacc 0.8751482297137049\n",
      "\n",
      "Epoch 119: val_balacc did not improve from 0.88921\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1944 - tp: 21733.0000 - fp: 1878.0000 - tn: 21733.0000 - fn: 1878.0000 - accuracy: 0.9205 - val_loss: 0.3018 - val_tp: 5166.0000 - val_fp: 737.0000 - val_tn: 5166.0000 - val_fn: 737.0000 - val_accuracy: 0.8751 - train_sensitivity: 0.9205 - train_specificity: 0.9205 - train_balacc: 0.9205 - val_sensitivity: 0.8751 - val_specificity: 0.8751 - val_balacc: 0.8751\n",
      "Epoch 120/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1882 - tp: 21033.0000 - fp: 1767.0000 - tn: 21033.0000 - fn: 1767.0000 - accuracy: 0.9225 train_balacc 0.9227478717546906\n",
      " val_balacc 0.8661697441978655\n",
      "\n",
      "Epoch 120: val_balacc did not improve from 0.88921\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1884 - tp: 21787.0000 - fp: 1824.0000 - tn: 21787.0000 - fn: 1824.0000 - accuracy: 0.9227 - val_loss: 0.3389 - val_tp: 5113.0000 - val_fp: 790.0000 - val_tn: 5113.0000 - val_fn: 790.0000 - val_accuracy: 0.8662 - train_sensitivity: 0.9227 - train_specificity: 0.9227 - train_balacc: 0.9227 - val_sensitivity: 0.8662 - val_specificity: 0.8662 - val_balacc: 0.8662\n",
      "Epoch 121/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1883 - tp: 20993.0000 - fp: 1807.0000 - tn: 20993.0000 - fn: 1807.0000 - accuracy: 0.9207 train_balacc 0.9208419804328491\n",
      " val_balacc 0.8597323394883958\n",
      "\n",
      "Epoch 121: val_balacc did not improve from 0.88921\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1881 - tp: 21742.0000 - fp: 1869.0000 - tn: 21742.0000 - fn: 1869.0000 - accuracy: 0.9208 - val_loss: 0.3428 - val_tp: 5075.0000 - val_fp: 828.0000 - val_tn: 5075.0000 - val_fn: 828.0000 - val_accuracy: 0.8597 - train_sensitivity: 0.9208 - train_specificity: 0.9208 - train_balacc: 0.9208 - val_sensitivity: 0.8597 - val_specificity: 0.8597 - val_balacc: 0.8597\n",
      "Epoch 122/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1852 - tp: 21196.0000 - fp: 1804.0000 - tn: 21196.0000 - fn: 1804.0000 - accuracy: 0.9216 train_balacc 0.9222819872093516\n",
      " val_balacc 0.8897170930035575\n",
      "\n",
      "Epoch 122: val_balacc improved from 0.88921 to 0.88972, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1842 - tp: 21776.0000 - fp: 1835.0000 - tn: 21776.0000 - fn: 1835.0000 - accuracy: 0.9223 - val_loss: 0.2700 - val_tp: 5252.0000 - val_fp: 651.0000 - val_tn: 5252.0000 - val_fn: 651.0000 - val_accuracy: 0.8897 - train_sensitivity: 0.9223 - train_specificity: 0.9223 - train_balacc: 0.9223 - val_sensitivity: 0.8897 - val_specificity: 0.8897 - val_balacc: 0.8897\n",
      "Epoch 123/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1875 - tp: 21223.0000 - fp: 1777.0000 - tn: 21223.0000 - fn: 1777.0000 - accuracy: 0.9227 train_balacc 0.9227902248951759\n",
      " val_balacc 0.8136540741995596\n",
      "\n",
      "Epoch 123: val_balacc did not improve from 0.88972\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1881 - tp: 21788.0000 - fp: 1823.0000 - tn: 21788.0000 - fn: 1823.0000 - accuracy: 0.9228 - val_loss: 0.3995 - val_tp: 4803.0000 - val_fp: 1100.0000 - val_tn: 4803.0000 - val_fn: 1100.0000 - val_accuracy: 0.8137 - train_sensitivity: 0.9228 - train_specificity: 0.9228 - train_balacc: 0.9228 - val_sensitivity: 0.8137 - val_specificity: 0.8137 - val_balacc: 0.8137\n",
      "Epoch 124/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1843 - tp: 21067.0000 - fp: 1733.0000 - tn: 21067.0000 - fn: 1733.0000 - accuracy: 0.9240 train_balacc 0.9239761128287662\n",
      " val_balacc 0.8565136371336608\n",
      "\n",
      "Epoch 124: val_balacc did not improve from 0.88972\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1841 - tp: 21816.0000 - fp: 1795.0000 - tn: 21816.0000 - fn: 1795.0000 - accuracy: 0.9240 - val_loss: 0.3652 - val_tp: 5056.0000 - val_fp: 847.0000 - val_tn: 5056.0000 - val_fn: 847.0000 - val_accuracy: 0.8565 - train_sensitivity: 0.9240 - train_specificity: 0.9240 - train_balacc: 0.9240 - val_sensitivity: 0.8565 - val_specificity: 0.8565 - val_balacc: 0.8565\n",
      "Epoch 125/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1867 - tp: 21011.0000 - fp: 1789.0000 - tn: 21011.0000 - fn: 1789.0000 - accuracy: 0.9215 train_balacc 0.9217313963830418\n",
      " val_balacc 0.8136540741995596\n",
      "\n",
      "Epoch 125: val_balacc did not improve from 0.88972\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1859 - tp: 21763.0000 - fp: 1848.0000 - tn: 21763.0000 - fn: 1848.0000 - accuracy: 0.9217 - val_loss: 0.4631 - val_tp: 4803.0000 - val_fp: 1100.0000 - val_tn: 4803.0000 - val_fn: 1100.0000 - val_accuracy: 0.8137 - train_sensitivity: 0.9217 - train_specificity: 0.9217 - train_balacc: 0.9217 - val_sensitivity: 0.8137 - val_specificity: 0.8137 - val_balacc: 0.8137\n",
      "Epoch 126/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1897 - tp: 21776.0000 - fp: 1824.0000 - tn: 21776.0000 - fn: 1824.0000 - accuracy: 0.9227 train_balacc 0.9227478717546906\n",
      " val_balacc 0.88615957987464\n",
      "\n",
      "Epoch 126: val_balacc did not improve from 0.88972\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1897 - tp: 21787.0000 - fp: 1824.0000 - tn: 21787.0000 - fn: 1824.0000 - accuracy: 0.9227 - val_loss: 0.2702 - val_tp: 5231.0000 - val_fp: 672.0000 - val_tn: 5231.0000 - val_fn: 672.0000 - val_accuracy: 0.8862 - train_sensitivity: 0.9227 - train_specificity: 0.9227 - train_balacc: 0.9227 - val_sensitivity: 0.8862 - val_specificity: 0.8862 - val_balacc: 0.8862\n",
      "Epoch 127/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1797 - tp: 21185.0000 - fp: 1715.0000 - tn: 21185.0000 - fn: 1715.0000 - accuracy: 0.9251 train_balacc 0.9249925882004151\n",
      " val_balacc 0.8800609859393529\n",
      "\n",
      "Epoch 127: val_balacc did not improve from 0.88972\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1801 - tp: 21840.0000 - fp: 1771.0000 - tn: 21840.0000 - fn: 1771.0000 - accuracy: 0.9250 - val_loss: 0.2877 - val_tp: 5195.0000 - val_fp: 708.0000 - val_tn: 5195.0000 - val_fn: 708.0000 - val_accuracy: 0.8801 - train_sensitivity: 0.9250 - train_specificity: 0.9250 - train_balacc: 0.9250 - val_sensitivity: 0.8801 - val_specificity: 0.8801 - val_balacc: 0.8801\n",
      "Epoch 128/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1801 - tp: 21833.0000 - fp: 1767.0000 - tn: 21833.0000 - fn: 1767.0000 - accuracy: 0.9251 train_balacc 0.9251196476218712\n",
      " val_balacc 0.8763340674233441\n",
      "\n",
      "Epoch 128: val_balacc did not improve from 0.88972\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1801 - tp: 21843.0000 - fp: 1768.0000 - tn: 21843.0000 - fn: 1768.0000 - accuracy: 0.9251 - val_loss: 0.2893 - val_tp: 5173.0000 - val_fp: 730.0000 - val_tn: 5173.0000 - val_fn: 730.0000 - val_accuracy: 0.8763 - train_sensitivity: 0.9251 - train_specificity: 0.9251 - train_balacc: 0.9251 - val_sensitivity: 0.8763 - val_specificity: 0.8763 - val_balacc: 0.8763\n",
      "Epoch 129/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1842 - tp: 21072.0000 - fp: 1728.0000 - tn: 21072.0000 - fn: 1728.0000 - accuracy: 0.9242 train_balacc 0.9238914065477956\n",
      " val_balacc 0.8663391495849568\n",
      "\n",
      "Epoch 129: val_balacc did not improve from 0.88972\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1842 - tp: 21814.0000 - fp: 1797.0000 - tn: 21814.0000 - fn: 1797.0000 - accuracy: 0.9239 - val_loss: 0.3041 - val_tp: 5114.0000 - val_fp: 789.0000 - val_tn: 5114.0000 - val_fn: 789.0000 - val_accuracy: 0.8663 - train_sensitivity: 0.9239 - train_specificity: 0.9239 - train_balacc: 0.9239 - val_sensitivity: 0.8663 - val_specificity: 0.8663 - val_balacc: 0.8663\n",
      "Epoch 130/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1873 - tp: 21760.0000 - fp: 1840.0000 - tn: 21760.0000 - fn: 1840.0000 - accuracy: 0.9220 train_balacc 0.9220702215069247\n",
      " val_balacc 0.856005420972387\n",
      "\n",
      "Epoch 130: val_balacc did not improve from 0.88972\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1873 - tp: 21771.0000 - fp: 1840.0000 - tn: 21771.0000 - fn: 1840.0000 - accuracy: 0.9221 - val_loss: 0.3507 - val_tp: 5053.0000 - val_fp: 850.0000 - val_tn: 5053.0000 - val_fn: 850.0000 - val_accuracy: 0.8560 - train_sensitivity: 0.9221 - train_specificity: 0.9221 - train_balacc: 0.9221 - val_sensitivity: 0.8560 - val_specificity: 0.8560 - val_balacc: 0.8560\n",
      "Epoch 131/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1893 - tp: 21057.0000 - fp: 1743.0000 - tn: 21057.0000 - fn: 1743.0000 - accuracy: 0.9236 train_balacc 0.9235949345643979\n",
      " val_balacc 0.891580552261562\n",
      "\n",
      "Epoch 131: val_balacc improved from 0.88972 to 0.89158, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1885 - tp: 21807.0000 - fp: 1804.0000 - tn: 21807.0000 - fn: 1804.0000 - accuracy: 0.9236 - val_loss: 0.2645 - val_tp: 5263.0000 - val_fp: 640.0000 - val_tn: 5263.0000 - val_fn: 640.0000 - val_accuracy: 0.8916 - train_sensitivity: 0.9236 - train_specificity: 0.9236 - train_balacc: 0.9236 - val_sensitivity: 0.8916 - val_specificity: 0.8916 - val_balacc: 0.8916\n",
      "Epoch 132/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1882 - tp: 21334.0000 - fp: 1766.0000 - tn: 21334.0000 - fn: 1766.0000 - accuracy: 0.9235 train_balacc 0.9236372877048833\n",
      " val_balacc 0.8919193630357445\n",
      "\n",
      "Epoch 132: val_balacc improved from 0.89158 to 0.89192, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1879 - tp: 21808.0000 - fp: 1803.0000 - tn: 21808.0000 - fn: 1803.0000 - accuracy: 0.9236 - val_loss: 0.2587 - val_tp: 5265.0000 - val_fp: 638.0000 - val_tn: 5265.0000 - val_fn: 638.0000 - val_accuracy: 0.8919 - train_sensitivity: 0.9236 - train_specificity: 0.9236 - train_balacc: 0.9236 - val_sensitivity: 0.8919 - val_specificity: 0.8919 - val_balacc: 0.8919\n",
      "Epoch 133/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1841 - tp: 21151.0000 - fp: 1749.0000 - tn: 21151.0000 - fn: 1749.0000 - accuracy: 0.9236 train_balacc 0.9237219939858541\n",
      " val_balacc 0.8771810943588007\n",
      "\n",
      "Epoch 133: val_balacc did not improve from 0.89192\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1837 - tp: 21810.0000 - fp: 1801.0000 - tn: 21810.0000 - fn: 1801.0000 - accuracy: 0.9237 - val_loss: 0.2853 - val_tp: 5178.0000 - val_fp: 725.0000 - val_tn: 5178.0000 - val_fn: 725.0000 - val_accuracy: 0.8772 - train_sensitivity: 0.9237 - train_specificity: 0.9237 - train_balacc: 0.9237 - val_sensitivity: 0.8772 - val_specificity: 0.8772 - val_balacc: 0.8772\n",
      "Epoch 134/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1848 - tp: 21820.0000 - fp: 1780.0000 - tn: 21820.0000 - fn: 1780.0000 - accuracy: 0.9246 train_balacc 0.9245690567955613\n",
      " val_balacc 0.8682026088429612\n",
      "\n",
      "Epoch 134: val_balacc did not improve from 0.89192\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1847 - tp: 21830.0000 - fp: 1781.0000 - tn: 21830.0000 - fn: 1781.0000 - accuracy: 0.9246 - val_loss: 0.3086 - val_tp: 5125.0000 - val_fp: 778.0000 - val_tn: 5125.0000 - val_fn: 778.0000 - val_accuracy: 0.8682 - train_sensitivity: 0.9246 - train_specificity: 0.9246 - train_balacc: 0.9246 - val_sensitivity: 0.8682 - val_specificity: 0.8682 - val_balacc: 0.8682\n",
      "Epoch 135/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1863 - tp: 21794.0000 - fp: 1806.0000 - tn: 21794.0000 - fn: 1806.0000 - accuracy: 0.9235 train_balacc 0.9234255220024565\n",
      " val_balacc 0.8644756903269524\n",
      "\n",
      "Epoch 135: val_balacc did not improve from 0.89192\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1863 - tp: 21803.0000 - fp: 1808.0000 - tn: 21803.0000 - fn: 1808.0000 - accuracy: 0.9234 - val_loss: 0.3127 - val_tp: 5103.0000 - val_fp: 800.0000 - val_tn: 5103.0000 - val_fn: 800.0000 - val_accuracy: 0.8645 - train_sensitivity: 0.9234 - train_specificity: 0.9234 - train_balacc: 0.9234 - val_sensitivity: 0.8645 - val_specificity: 0.8645 - val_balacc: 0.8645\n",
      "Epoch 136/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1940 - tp: 21069.0000 - fp: 1831.0000 - tn: 21069.0000 - fn: 1831.0000 - accuracy: 0.9200 train_balacc 0.9205031553089662\n",
      " val_balacc 0.8593935287142132\n",
      "\n",
      "Epoch 136: val_balacc did not improve from 0.89192\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1933 - tp: 21734.0000 - fp: 1877.0000 - tn: 21734.0000 - fn: 1877.0000 - accuracy: 0.9205 - val_loss: 0.3349 - val_tp: 5073.0000 - val_fp: 830.0000 - val_tn: 5073.0000 - val_fn: 830.0000 - val_accuracy: 0.8594 - train_sensitivity: 0.9205 - train_specificity: 0.9205 - train_balacc: 0.9205 - val_sensitivity: 0.8594 - val_specificity: 0.8594 - val_balacc: 0.8594\n",
      "Epoch 137/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1846 - tp: 21844.0000 - fp: 1767.0000 - tn: 21844.0000 - fn: 1767.0000 - accuracy: 0.9252 train_balacc 0.9251620007623566\n",
      " val_balacc 0.893274606132475\n",
      "\n",
      "Epoch 137: val_balacc improved from 0.89192 to 0.89327, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1846 - tp: 21844.0000 - fp: 1767.0000 - tn: 21844.0000 - fn: 1767.0000 - accuracy: 0.9252 - val_loss: 0.2665 - val_tp: 5273.0000 - val_fp: 630.0000 - val_tn: 5273.0000 - val_fn: 630.0000 - val_accuracy: 0.8933 - train_sensitivity: 0.9252 - train_specificity: 0.9252 - train_balacc: 0.9252 - val_sensitivity: 0.8933 - val_specificity: 0.8933 - val_balacc: 0.8933\n",
      "Epoch 138/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1859 - tp: 21553.0000 - fp: 1747.0000 - tn: 21553.0000 - fn: 1747.0000 - accuracy: 0.9250 train_balacc 0.9250772944813858\n",
      " val_balacc 0.8571912586820261\n",
      "\n",
      "Epoch 138: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1859 - tp: 21842.0000 - fp: 1769.0000 - tn: 21842.0000 - fn: 1769.0000 - accuracy: 0.9251 - val_loss: 0.3358 - val_tp: 5060.0000 - val_fp: 843.0000 - val_tn: 5060.0000 - val_fn: 843.0000 - val_accuracy: 0.8572 - train_sensitivity: 0.9251 - train_specificity: 0.9251 - train_balacc: 0.9251 - val_sensitivity: 0.8572 - val_specificity: 0.8572 - val_balacc: 0.8572\n",
      "Epoch 139/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1815 - tp: 21328.0000 - fp: 1672.0000 - tn: 21328.0000 - fn: 1672.0000 - accuracy: 0.9273 train_balacc 0.9277455423319639\n",
      " val_balacc 0.8680332034558699\n",
      "\n",
      "Epoch 139: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1804 - tp: 21905.0000 - fp: 1706.0000 - tn: 21905.0000 - fn: 1706.0000 - accuracy: 0.9277 - val_loss: 0.3029 - val_tp: 5124.0000 - val_fp: 779.0000 - val_tn: 5124.0000 - val_fn: 779.0000 - val_accuracy: 0.8680 - train_sensitivity: 0.9277 - train_specificity: 0.9277 - train_balacc: 0.9277 - val_sensitivity: 0.8680 - val_specificity: 0.8680 - val_balacc: 0.8680\n",
      "Epoch 140/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1817 - tp: 21109.0000 - fp: 1691.0000 - tn: 21109.0000 - fn: 1691.0000 - accuracy: 0.9258 train_balacc 0.9263055355554615\n",
      " val_balacc 0.8009486701677113\n",
      "\n",
      "Epoch 140: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1812 - tp: 21871.0000 - fp: 1740.0000 - tn: 21871.0000 - fn: 1740.0000 - accuracy: 0.9263 - val_loss: 0.4028 - val_tp: 4728.0000 - val_fp: 1175.0000 - val_tn: 4728.0000 - val_fn: 1175.0000 - val_accuracy: 0.8009 - train_sensitivity: 0.9263 - train_specificity: 0.9263 - train_balacc: 0.9263 - val_sensitivity: 0.8009 - val_specificity: 0.8009 - val_balacc: 0.8009\n",
      "Epoch 141/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1802 - tp: 21737.0000 - fp: 1763.0000 - tn: 21737.0000 - fn: 1763.0000 - accuracy: 0.9250 train_balacc 0.9249078819194443\n",
      " val_balacc 0.8744706081653396\n",
      "\n",
      "Epoch 141: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1804 - tp: 21838.0000 - fp: 1773.0000 - tn: 21838.0000 - fn: 1773.0000 - accuracy: 0.9249 - val_loss: 0.3013 - val_tp: 5162.0000 - val_fp: 741.0000 - val_tn: 5162.0000 - val_fn: 741.0000 - val_accuracy: 0.8745 - train_sensitivity: 0.9249 - train_specificity: 0.9249 - train_balacc: 0.9249 - val_sensitivity: 0.8745 - val_specificity: 0.8745 - val_balacc: 0.8745\n",
      "Epoch 142/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1753 - tp: 21123.0000 - fp: 1677.0000 - tn: 21123.0000 - fn: 1677.0000 - accuracy: 0.9264 train_balacc 0.9263478886959468\n",
      " val_balacc 0.850584448585465\n",
      "\n",
      "Epoch 142: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1763 - tp: 21872.0000 - fp: 1739.0000 - tn: 21872.0000 - fn: 1739.0000 - accuracy: 0.9263 - val_loss: 0.3370 - val_tp: 5021.0000 - val_fp: 882.0000 - val_tn: 5021.0000 - val_fn: 882.0000 - val_accuracy: 0.8506 - train_sensitivity: 0.9263 - train_specificity: 0.9263 - train_balacc: 0.9263 - val_sensitivity: 0.8506 - val_specificity: 0.8506 - val_balacc: 0.8506\n",
      "Epoch 143/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1862 - tp: 21274.0000 - fp: 1726.0000 - tn: 21274.0000 - fn: 1726.0000 - accuracy: 0.9250 train_balacc 0.9253737664647833\n",
      " val_balacc 0.8519396916821955\n",
      "\n",
      "Epoch 143: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1859 - tp: 21849.0000 - fp: 1762.0000 - tn: 21849.0000 - fn: 1762.0000 - accuracy: 0.9254 - val_loss: 0.3535 - val_tp: 5029.0000 - val_fp: 874.0000 - val_tn: 5029.0000 - val_fn: 874.0000 - val_accuracy: 0.8519 - train_sensitivity: 0.9254 - train_specificity: 0.9254 - train_balacc: 0.9254 - val_sensitivity: 0.8519 - val_specificity: 0.8519 - val_balacc: 0.8519\n",
      "Epoch 144/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1811 - tp: 21839.0000 - fp: 1772.0000 - tn: 21839.0000 - fn: 1772.0000 - accuracy: 0.9250 train_balacc 0.9249502350599297\n",
      " val_balacc 0.8878536337455532\n",
      "\n",
      "Epoch 144: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1811 - tp: 21839.0000 - fp: 1772.0000 - tn: 21839.0000 - fn: 1772.0000 - accuracy: 0.9250 - val_loss: 0.2757 - val_tp: 5241.0000 - val_fp: 662.0000 - val_tn: 5241.0000 - val_fn: 662.0000 - val_accuracy: 0.8879 - train_sensitivity: 0.9250 - train_specificity: 0.9250 - train_balacc: 0.9250 - val_sensitivity: 0.8879 - val_specificity: 0.8879 - val_balacc: 0.8879\n",
      "Epoch 145/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1821 - tp: 21212.0000 - fp: 1688.0000 - tn: 21212.0000 - fn: 1688.0000 - accuracy: 0.9263 train_balacc 0.9257549447291517\n",
      " val_balacc 0.8846349313908183\n",
      "\n",
      "Epoch 145: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1824 - tp: 21858.0000 - fp: 1753.0000 - tn: 21858.0000 - fn: 1753.0000 - accuracy: 0.9258 - val_loss: 0.2731 - val_tp: 5222.0000 - val_fp: 681.0000 - val_tn: 5222.0000 - val_fn: 681.0000 - val_accuracy: 0.8846 - train_sensitivity: 0.9258 - train_specificity: 0.9258 - train_balacc: 0.9258 - val_sensitivity: 0.8846 - val_specificity: 0.8846 - val_balacc: 0.8846\n",
      "Epoch 146/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1812 - tp: 21836.0000 - fp: 1764.0000 - tn: 21836.0000 - fn: 1764.0000 - accuracy: 0.9253 train_balacc 0.925204353902842\n",
      " val_balacc 0.8765034728104354\n",
      "\n",
      "Epoch 146: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1813 - tp: 21845.0000 - fp: 1766.0000 - tn: 21845.0000 - fn: 1766.0000 - accuracy: 0.9252 - val_loss: 0.2845 - val_tp: 5174.0000 - val_fp: 729.0000 - val_tn: 5174.0000 - val_fn: 729.0000 - val_accuracy: 0.8765 - train_sensitivity: 0.9252 - train_specificity: 0.9252 - train_balacc: 0.9252 - val_sensitivity: 0.8765 - val_specificity: 0.8765 - val_balacc: 0.8765\n",
      "Epoch 147/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1822 - tp: 21349.0000 - fp: 1751.0000 - tn: 21349.0000 - fn: 1751.0000 - accuracy: 0.9242 train_balacc 0.9237219939858541\n",
      " val_balacc 0.8634592580044046\n",
      "\n",
      "Epoch 147: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1828 - tp: 21810.0000 - fp: 1801.0000 - tn: 21810.0000 - fn: 1801.0000 - accuracy: 0.9237 - val_loss: 0.3129 - val_tp: 5097.0000 - val_fp: 806.0000 - val_tn: 5097.0000 - val_fn: 806.0000 - val_accuracy: 0.8635 - train_sensitivity: 0.9237 - train_specificity: 0.9237 - train_balacc: 0.9237 - val_sensitivity: 0.8635 - val_specificity: 0.8635 - val_balacc: 0.8635\n",
      "Epoch 148/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1800 - tp: 21846.0000 - fp: 1754.0000 - tn: 21846.0000 - fn: 1754.0000 - accuracy: 0.9257 train_balacc 0.9256278853076956\n",
      " val_balacc 0.8522785024563782\n",
      "\n",
      "Epoch 148: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1801 - tp: 21855.0000 - fp: 1756.0000 - tn: 21855.0000 - fn: 1756.0000 - accuracy: 0.9256 - val_loss: 0.3823 - val_tp: 5031.0000 - val_fp: 872.0000 - val_tn: 5031.0000 - val_fn: 872.0000 - val_accuracy: 0.8523 - train_sensitivity: 0.9256 - train_specificity: 0.9256 - train_balacc: 0.9256 - val_sensitivity: 0.8523 - val_specificity: 0.8523 - val_balacc: 0.8523\n",
      "Epoch 149/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1818 - tp: 21300.0000 - fp: 1700.0000 - tn: 21300.0000 - fn: 1700.0000 - accuracy: 0.9261 train_balacc 0.9258820041506077\n",
      " val_balacc 0.8895476876164662\n",
      "\n",
      "Epoch 149: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1825 - tp: 21861.0000 - fp: 1750.0000 - tn: 21861.0000 - fn: 1750.0000 - accuracy: 0.9259 - val_loss: 0.2755 - val_tp: 5251.0000 - val_fp: 652.0000 - val_tn: 5251.0000 - val_fn: 652.0000 - val_accuracy: 0.8895 - train_sensitivity: 0.9259 - train_specificity: 0.9259 - train_balacc: 0.9259 - val_sensitivity: 0.8895 - val_specificity: 0.8895 - val_balacc: 0.8895\n",
      "Epoch 150/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1816 - tp: 21306.0000 - fp: 1694.0000 - tn: 21306.0000 - fn: 1694.0000 - accuracy: 0.9263 train_balacc 0.9260937698530346\n",
      " val_balacc 0.8780281212942571\n",
      "\n",
      "Epoch 150: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1814 - tp: 21866.0000 - fp: 1745.0000 - tn: 21866.0000 - fn: 1745.0000 - accuracy: 0.9261 - val_loss: 0.3043 - val_tp: 5183.0000 - val_fp: 720.0000 - val_tn: 5183.0000 - val_fn: 720.0000 - val_accuracy: 0.8780 - train_sensitivity: 0.9261 - train_specificity: 0.9261 - train_balacc: 0.9261 - val_sensitivity: 0.8780 - val_specificity: 0.8780 - val_balacc: 0.8780\n",
      "Epoch 151/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1807 - tp: 21088.0000 - fp: 1712.0000 - tn: 21088.0000 - fn: 1712.0000 - accuracy: 0.9249 train_balacc 0.9248231756384736\n",
      " val_balacc 0.8832796882940878\n",
      "\n",
      "Epoch 151: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1803 - tp: 21836.0000 - fp: 1775.0000 - tn: 21836.0000 - fn: 1775.0000 - accuracy: 0.9248 - val_loss: 0.2916 - val_tp: 5214.0000 - val_fp: 689.0000 - val_tn: 5214.0000 - val_fn: 689.0000 - val_accuracy: 0.8833 - train_sensitivity: 0.9248 - train_specificity: 0.9248 - train_balacc: 0.9248 - val_sensitivity: 0.8833 - val_specificity: 0.8833 - val_balacc: 0.8833\n",
      "Epoch 152/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1798 - tp: 21792.0000 - fp: 1708.0000 - tn: 21792.0000 - fn: 1708.0000 - accuracy: 0.9273 train_balacc 0.9271525983651687\n",
      " val_balacc 0.876842283584618\n",
      "\n",
      "Epoch 152: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1802 - tp: 21891.0000 - fp: 1720.0000 - tn: 21891.0000 - fn: 1720.0000 - accuracy: 0.9272 - val_loss: 0.2874 - val_tp: 5176.0000 - val_fp: 727.0000 - val_tn: 5176.0000 - val_fn: 727.0000 - val_accuracy: 0.8768 - train_sensitivity: 0.9272 - train_specificity: 0.9272 - train_balacc: 0.9272 - val_sensitivity: 0.8768 - val_specificity: 0.8768 - val_balacc: 0.8768\n",
      "Epoch 153/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1776 - tp: 21223.0000 - fp: 1677.0000 - tn: 21223.0000 - fn: 1677.0000 - accuracy: 0.9268 train_balacc 0.9263478886959468\n",
      " val_balacc 0.8898864983906488\n",
      "\n",
      "Epoch 153: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1781 - tp: 21872.0000 - fp: 1739.0000 - tn: 21872.0000 - fn: 1739.0000 - accuracy: 0.9263 - val_loss: 0.2672 - val_tp: 5253.0000 - val_fp: 650.0000 - val_tn: 5253.0000 - val_fn: 650.0000 - val_accuracy: 0.8899 - train_sensitivity: 0.9263 - train_specificity: 0.9263 - train_balacc: 0.9263 - val_sensitivity: 0.8899 - val_specificity: 0.8899 - val_balacc: 0.8899\n",
      "Epoch 154/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1771 - tp: 21148.0000 - fp: 1652.0000 - tn: 21148.0000 - fn: 1652.0000 - accuracy: 0.9275 train_balacc 0.9272796577866249\n",
      " val_balacc 0.8803997967135355\n",
      "\n",
      "Epoch 154: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1778 - tp: 21894.0000 - fp: 1717.0000 - tn: 21894.0000 - fn: 1717.0000 - accuracy: 0.9273 - val_loss: 0.2829 - val_tp: 5197.0000 - val_fp: 706.0000 - val_tn: 5197.0000 - val_fn: 706.0000 - val_accuracy: 0.8804 - train_sensitivity: 0.9273 - train_specificity: 0.9273 - train_balacc: 0.9273 - val_sensitivity: 0.8804 - val_specificity: 0.8804 - val_balacc: 0.8804\n",
      "Epoch 155/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1764 - tp: 21146.0000 - fp: 1654.0000 - tn: 21146.0000 - fn: 1654.0000 - accuracy: 0.9275 train_balacc 0.92787260175342\n",
      " val_balacc 0.8864983906488226\n",
      "\n",
      "Epoch 155: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1763 - tp: 21908.0000 - fp: 1703.0000 - tn: 21908.0000 - fn: 1703.0000 - accuracy: 0.9279 - val_loss: 0.2767 - val_tp: 5233.0000 - val_fp: 670.0000 - val_tn: 5233.0000 - val_fn: 670.0000 - val_accuracy: 0.8865 - train_sensitivity: 0.9279 - train_specificity: 0.9279 - train_balacc: 0.9279 - val_sensitivity: 0.8865 - val_specificity: 0.8865 - val_balacc: 0.8865\n",
      "Epoch 156/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1784 - tp: 21475.0000 - fp: 1725.0000 - tn: 21475.0000 - fn: 1725.0000 - accuracy: 0.9256 train_balacc 0.9254584727457541\n",
      " val_balacc 0.8695578519396917\n",
      "\n",
      "Epoch 156: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1796 - tp: 21851.0000 - fp: 1760.0000 - tn: 21851.0000 - fn: 1760.0000 - accuracy: 0.9255 - val_loss: 0.3068 - val_tp: 5133.0000 - val_fp: 770.0000 - val_tn: 5133.0000 - val_fn: 770.0000 - val_accuracy: 0.8696 - train_sensitivity: 0.9255 - train_specificity: 0.9255 - train_balacc: 0.9255 - val_sensitivity: 0.8696 - val_specificity: 0.8696 - val_balacc: 0.8696\n",
      "Epoch 157/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1851 - tp: 21861.0000 - fp: 1750.0000 - tn: 21861.0000 - fn: 1750.0000 - accuracy: 0.9259 train_balacc 0.9258820041506077\n",
      " val_balacc 0.8878536337455532\n",
      "\n",
      "Epoch 157: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1851 - tp: 21861.0000 - fp: 1750.0000 - tn: 21861.0000 - fn: 1750.0000 - accuracy: 0.9259 - val_loss: 0.2737 - val_tp: 5241.0000 - val_fp: 662.0000 - val_tn: 5241.0000 - val_fn: 662.0000 - val_accuracy: 0.8879 - train_sensitivity: 0.9259 - train_specificity: 0.9259 - train_balacc: 0.9259 - val_sensitivity: 0.8879 - val_specificity: 0.8879 - val_balacc: 0.8879\n",
      "Epoch 158/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1751 - tp: 21289.0000 - fp: 1611.0000 - tn: 21289.0000 - fn: 1611.0000 - accuracy: 0.9297 train_balacc 0.9294396679513786\n",
      " val_balacc 0.8859901744875487\n",
      "\n",
      "Epoch 158: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1753 - tp: 21945.0000 - fp: 1666.0000 - tn: 21945.0000 - fn: 1666.0000 - accuracy: 0.9294 - val_loss: 0.2785 - val_tp: 5230.0000 - val_fp: 673.0000 - val_tn: 5230.0000 - val_fn: 673.0000 - val_accuracy: 0.8860 - train_sensitivity: 0.9294 - train_specificity: 0.9294 - train_balacc: 0.9294 - val_sensitivity: 0.8860 - val_specificity: 0.8860 - val_balacc: 0.8860\n",
      "Epoch 159/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1820 - tp: 21845.0000 - fp: 1755.0000 - tn: 21845.0000 - fn: 1755.0000 - accuracy: 0.9256 train_balacc 0.925670238448181\n",
      " val_balacc 0.8875148229713705\n",
      "\n",
      "Epoch 159: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1819 - tp: 21856.0000 - fp: 1755.0000 - tn: 21856.0000 - fn: 1755.0000 - accuracy: 0.9257 - val_loss: 0.2676 - val_tp: 5239.0000 - val_fp: 664.0000 - val_tn: 5239.0000 - val_fn: 664.0000 - val_accuracy: 0.8875 - train_sensitivity: 0.9257 - train_specificity: 0.9257 - train_balacc: 0.9257 - val_sensitivity: 0.8875 - val_specificity: 0.8875 - val_balacc: 0.8875\n",
      "Epoch 160/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1832 - tp: 21864.0000 - fp: 1736.0000 - tn: 21864.0000 - fn: 1736.0000 - accuracy: 0.9264 train_balacc 0.9263902418364321\n",
      " val_balacc 0.8787057428426224\n",
      "\n",
      "Epoch 160: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1832 - tp: 21873.0000 - fp: 1738.0000 - tn: 21873.0000 - fn: 1738.0000 - accuracy: 0.9264 - val_loss: 0.2852 - val_tp: 5187.0000 - val_fp: 716.0000 - val_tn: 5187.0000 - val_fn: 716.0000 - val_accuracy: 0.8787 - train_sensitivity: 0.9264 - train_specificity: 0.9264 - train_balacc: 0.9264 - val_sensitivity: 0.8787 - val_specificity: 0.8787 - val_balacc: 0.8787\n",
      "Epoch 161/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1815 - tp: 21222.0000 - fp: 1678.0000 - tn: 21222.0000 - fn: 1678.0000 - accuracy: 0.9267 train_balacc 0.9273220109271102\n",
      " val_balacc 0.8048449940708114\n",
      "\n",
      "Epoch 161: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1800 - tp: 21895.0000 - fp: 1716.0000 - tn: 21895.0000 - fn: 1716.0000 - accuracy: 0.9273 - val_loss: 0.4653 - val_tp: 4751.0000 - val_fp: 1152.0000 - val_tn: 4751.0000 - val_fn: 1152.0000 - val_accuracy: 0.8048 - train_sensitivity: 0.9273 - train_specificity: 0.9273 - train_balacc: 0.9273 - val_sensitivity: 0.8048 - val_specificity: 0.8048 - val_balacc: 0.8048\n",
      "Epoch 162/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1790 - tp: 21157.0000 - fp: 1643.0000 - tn: 21157.0000 - fn: 1643.0000 - accuracy: 0.9279 train_balacc 0.9280420143153615\n",
      " val_balacc 0.8876842283584618\n",
      "\n",
      "Epoch 162: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1785 - tp: 21912.0000 - fp: 1699.0000 - tn: 21912.0000 - fn: 1699.0000 - accuracy: 0.9280 - val_loss: 0.2596 - val_tp: 5240.0000 - val_fp: 663.0000 - val_tn: 5240.0000 - val_fn: 663.0000 - val_accuracy: 0.8877 - train_sensitivity: 0.9280 - train_specificity: 0.9280 - train_balacc: 0.9280 - val_sensitivity: 0.8877 - val_specificity: 0.8877 - val_balacc: 0.8877\n",
      "Epoch 163/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1828 - tp: 21085.0000 - fp: 1715.0000 - tn: 21085.0000 - fn: 1715.0000 - accuracy: 0.9248 train_balacc 0.9247808224979882\n",
      " val_balacc 0.8859901744875487\n",
      "\n",
      "Epoch 163: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1830 - tp: 21835.0000 - fp: 1776.0000 - tn: 21835.0000 - fn: 1776.0000 - accuracy: 0.9248 - val_loss: 0.2793 - val_tp: 5230.0000 - val_fp: 673.0000 - val_tn: 5230.0000 - val_fn: 673.0000 - val_accuracy: 0.8860 - train_sensitivity: 0.9248 - train_specificity: 0.9248 - train_balacc: 0.9248 - val_sensitivity: 0.8860 - val_specificity: 0.8860 - val_balacc: 0.8860\n",
      "Epoch 164/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1706 - tp: 21922.0000 - fp: 1689.0000 - tn: 21922.0000 - fn: 1689.0000 - accuracy: 0.9285 train_balacc 0.9284655457202151\n",
      " val_balacc 0.8881924445197358\n",
      "\n",
      "Epoch 164: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1706 - tp: 21922.0000 - fp: 1689.0000 - tn: 21922.0000 - fn: 1689.0000 - accuracy: 0.9285 - val_loss: 0.2728 - val_tp: 5243.0000 - val_fp: 660.0000 - val_tn: 5243.0000 - val_fn: 660.0000 - val_accuracy: 0.8882 - train_sensitivity: 0.9285 - train_specificity: 0.9285 - train_balacc: 0.9285 - val_sensitivity: 0.8882 - val_specificity: 0.8882 - val_balacc: 0.8882\n",
      "Epoch 165/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1747 - tp: 21824.0000 - fp: 1676.0000 - tn: 21824.0000 - fn: 1676.0000 - accuracy: 0.9287 train_balacc 0.928677311422642\n",
      " val_balacc 0.8917499576486533\n",
      "\n",
      "Epoch 165: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1746 - tp: 21927.0000 - fp: 1684.0000 - tn: 21927.0000 - fn: 1684.0000 - accuracy: 0.9287 - val_loss: 0.2524 - val_tp: 5264.0000 - val_fp: 639.0000 - val_tn: 5264.0000 - val_fn: 639.0000 - val_accuracy: 0.8917 - train_sensitivity: 0.9287 - train_specificity: 0.9287 - train_balacc: 0.9287 - val_sensitivity: 0.8917 - val_specificity: 0.8917 - val_balacc: 0.8917\n",
      "Epoch 166/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1786 - tp: 21783.0000 - fp: 1717.0000 - tn: 21783.0000 - fn: 1717.0000 - accuracy: 0.9269 train_balacc 0.9269831858032274\n",
      " val_balacc 0.8649839064882263\n",
      "\n",
      "Epoch 166: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1789 - tp: 21887.0000 - fp: 1724.0000 - tn: 21887.0000 - fn: 1724.0000 - accuracy: 0.9270 - val_loss: 0.3423 - val_tp: 5106.0000 - val_fp: 797.0000 - val_tn: 5106.0000 - val_fn: 797.0000 - val_accuracy: 0.8650 - train_sensitivity: 0.9270 - train_specificity: 0.9270 - train_balacc: 0.9270 - val_sensitivity: 0.8650 - val_specificity: 0.8650 - val_balacc: 0.8650\n",
      "Epoch 167/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1826 - tp: 21899.0000 - fp: 1701.0000 - tn: 21899.0000 - fn: 1701.0000 - accuracy: 0.9279 train_balacc 0.9279149548939054\n",
      " val_balacc 0.8817550398102659\n",
      "\n",
      "Epoch 167: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1827 - tp: 21909.0000 - fp: 1702.0000 - tn: 21909.0000 - fn: 1702.0000 - accuracy: 0.9279 - val_loss: 0.2936 - val_tp: 5205.0000 - val_fp: 698.0000 - val_tn: 5205.0000 - val_fn: 698.0000 - val_accuracy: 0.8818 - train_sensitivity: 0.9279 - train_specificity: 0.9279 - train_balacc: 0.9279 - val_sensitivity: 0.8818 - val_specificity: 0.8818 - val_balacc: 0.8818\n",
      "Epoch 168/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1813 - tp: 21132.0000 - fp: 1668.0000 - tn: 21132.0000 - fn: 1668.0000 - accuracy: 0.9268 train_balacc 0.9262631824149761\n",
      " val_balacc 0.8893782822293749\n",
      "\n",
      "Epoch 168: val_balacc did not improve from 0.89327\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1829 - tp: 21870.0000 - fp: 1741.0000 - tn: 21870.0000 - fn: 1741.0000 - accuracy: 0.9263 - val_loss: 0.2666 - val_tp: 5250.0000 - val_fp: 653.0000 - val_tn: 5250.0000 - val_fn: 653.0000 - val_accuracy: 0.8894 - train_sensitivity: 0.9263 - train_specificity: 0.9263 - train_balacc: 0.9263 - val_sensitivity: 0.8894 - val_specificity: 0.8894 - val_balacc: 0.8894\n",
      "Epoch 169/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1803 - tp: 21900.0000 - fp: 1700.0000 - tn: 21900.0000 - fn: 1700.0000 - accuracy: 0.9280 train_balacc 0.9279996611748761\n",
      " val_balacc 0.8970015246484838\n",
      "\n",
      "Epoch 169: val_balacc improved from 0.89327 to 0.89700, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1802 - tp: 21911.0000 - fp: 1700.0000 - tn: 21911.0000 - fn: 1700.0000 - accuracy: 0.9280 - val_loss: 0.2570 - val_tp: 5295.0000 - val_fp: 608.0000 - val_tn: 5295.0000 - val_fn: 608.0000 - val_accuracy: 0.8970 - train_sensitivity: 0.9280 - train_specificity: 0.9280 - train_balacc: 0.9280 - val_sensitivity: 0.8970 - val_specificity: 0.8970 - val_balacc: 0.8970\n",
      "Epoch 170/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1723 - tp: 21223.0000 - fp: 1577.0000 - tn: 21223.0000 - fn: 1577.0000 - accuracy: 0.9308 train_balacc 0.9302867307610859\n",
      " val_balacc 0.8527867186176521\n",
      "\n",
      "Epoch 170: val_balacc did not improve from 0.89700\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1725 - tp: 21965.0000 - fp: 1646.0000 - tn: 21965.0000 - fn: 1646.0000 - accuracy: 0.9303 - val_loss: 0.3698 - val_tp: 5034.0000 - val_fp: 869.0000 - val_tn: 5034.0000 - val_fn: 869.0000 - val_accuracy: 0.8528 - train_sensitivity: 0.9303 - train_specificity: 0.9303 - train_balacc: 0.9303 - val_sensitivity: 0.8528 - val_specificity: 0.8528 - val_balacc: 0.8528\n",
      "Epoch 171/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1806 - tp: 21870.0000 - fp: 1730.0000 - tn: 21870.0000 - fn: 1730.0000 - accuracy: 0.9267 train_balacc 0.9266867138198297\n",
      " val_balacc 0.8715907165847874\n",
      "\n",
      "Epoch 171: val_balacc did not improve from 0.89700\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1807 - tp: 21880.0000 - fp: 1731.0000 - tn: 21880.0000 - fn: 1731.0000 - accuracy: 0.9267 - val_loss: 0.2870 - val_tp: 5145.0000 - val_fp: 758.0000 - val_tn: 5145.0000 - val_fn: 758.0000 - val_accuracy: 0.8716 - train_sensitivity: 0.9267 - train_specificity: 0.9267 - train_balacc: 0.9267 - val_sensitivity: 0.8716 - val_specificity: 0.8716 - val_balacc: 0.8716\n",
      "Epoch 172/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1775 - tp: 21192.0000 - fp: 1608.0000 - tn: 21192.0000 - fn: 1608.0000 - accuracy: 0.9295 train_balacc 0.9297361399347762\n",
      " val_balacc 0.8929357953582924\n",
      "\n",
      "Epoch 172: val_balacc did not improve from 0.89700\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1769 - tp: 21952.0000 - fp: 1659.0000 - tn: 21952.0000 - fn: 1659.0000 - accuracy: 0.9297 - val_loss: 0.2593 - val_tp: 5271.0000 - val_fp: 632.0000 - val_tn: 5271.0000 - val_fn: 632.0000 - val_accuracy: 0.8929 - train_sensitivity: 0.9297 - train_specificity: 0.9297 - train_balacc: 0.9297 - val_sensitivity: 0.8929 - val_specificity: 0.8929 - val_balacc: 0.8929\n",
      "Epoch 173/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1776 - tp: 21319.0000 - fp: 1681.0000 - tn: 21319.0000 - fn: 1681.0000 - accuracy: 0.9269 train_balacc 0.9266867138198297\n",
      " val_balacc 0.8597323394883958\n",
      "\n",
      "Epoch 173: val_balacc did not improve from 0.89700\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1772 - tp: 21880.0000 - fp: 1731.0000 - tn: 21880.0000 - fn: 1731.0000 - accuracy: 0.9267 - val_loss: 0.2999 - val_tp: 5075.0000 - val_fp: 828.0000 - val_tn: 5075.0000 - val_fn: 828.0000 - val_accuracy: 0.8597 - train_sensitivity: 0.9267 - train_specificity: 0.9267 - train_balacc: 0.9267 - val_sensitivity: 0.8597 - val_specificity: 0.8597 - val_balacc: 0.8597\n",
      "Epoch 174/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1760 - tp: 21515.0000 - fp: 1685.0000 - tn: 21515.0000 - fn: 1685.0000 - accuracy: 0.9274 train_balacc 0.926940832662742\n",
      " val_balacc 0.8365238014568863\n",
      "\n",
      "Epoch 174: val_balacc did not improve from 0.89700\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1781 - tp: 21886.0000 - fp: 1725.0000 - tn: 21886.0000 - fn: 1725.0000 - accuracy: 0.9269 - val_loss: 0.3604 - val_tp: 4938.0000 - val_fp: 965.0000 - val_tn: 4938.0000 - val_fn: 965.0000 - val_accuracy: 0.8365 - train_sensitivity: 0.9269 - train_specificity: 0.9269 - train_balacc: 0.9269 - val_sensitivity: 0.8365 - val_specificity: 0.8365 - val_balacc: 0.8365\n",
      "Epoch 175/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1844 - tp: 21803.0000 - fp: 1808.0000 - tn: 21803.0000 - fn: 1808.0000 - accuracy: 0.9234 train_balacc 0.9234255220024565\n",
      " val_balacc 0.7787565644587497\n",
      "\n",
      "Epoch 175: val_balacc did not improve from 0.89700\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1844 - tp: 21803.0000 - fp: 1808.0000 - tn: 21803.0000 - fn: 1808.0000 - accuracy: 0.9234 - val_loss: 0.7893 - val_tp: 4597.0000 - val_fp: 1306.0000 - val_tn: 4597.0000 - val_fn: 1306.0000 - val_accuracy: 0.7788 - train_sensitivity: 0.9234 - train_specificity: 0.9234 - train_balacc: 0.9234 - val_sensitivity: 0.7788 - val_specificity: 0.7788 - val_balacc: 0.7788\n",
      "Epoch 176/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1821 - tp: 21888.0000 - fp: 1723.0000 - tn: 21888.0000 - fn: 1723.0000 - accuracy: 0.9270 train_balacc 0.9270255389437126\n",
      " val_balacc 0.8553277994240217\n",
      "\n",
      "Epoch 176: val_balacc did not improve from 0.89700\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1821 - tp: 21888.0000 - fp: 1723.0000 - tn: 21888.0000 - fn: 1723.0000 - accuracy: 0.9270 - val_loss: 0.3166 - val_tp: 5049.0000 - val_fp: 854.0000 - val_tn: 5049.0000 - val_fn: 854.0000 - val_accuracy: 0.8553 - train_sensitivity: 0.9270 - train_specificity: 0.9270 - train_balacc: 0.9270 - val_sensitivity: 0.8553 - val_specificity: 0.8553 - val_balacc: 0.8553\n",
      "Epoch 177/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1795 - tp: 21222.0000 - fp: 1678.0000 - tn: 21222.0000 - fn: 1678.0000 - accuracy: 0.9267 train_balacc 0.9267714201008005\n",
      " val_balacc 0.8383872607148908\n",
      "\n",
      "Epoch 177: val_balacc did not improve from 0.89700\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1786 - tp: 21882.0000 - fp: 1729.0000 - tn: 21882.0000 - fn: 1729.0000 - accuracy: 0.9268 - val_loss: 0.3671 - val_tp: 4949.0000 - val_fp: 954.0000 - val_tn: 4949.0000 - val_fn: 954.0000 - val_accuracy: 0.8384 - train_sensitivity: 0.9268 - train_specificity: 0.9268 - train_balacc: 0.9268 - val_sensitivity: 0.8384 - val_specificity: 0.8384 - val_balacc: 0.8384\n",
      "Epoch 178/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1788 - tp: 21522.0000 - fp: 1678.0000 - tn: 21522.0000 - fn: 1678.0000 - accuracy: 0.9277 train_balacc 0.9274914234890517\n",
      " val_balacc 0.8985261731323056\n",
      "\n",
      "Epoch 178: val_balacc improved from 0.89700 to 0.89853, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1800 - tp: 21899.0000 - fp: 1712.0000 - tn: 21899.0000 - fn: 1712.0000 - accuracy: 0.9275 - val_loss: 0.2509 - val_tp: 5304.0000 - val_fp: 599.0000 - val_tn: 5304.0000 - val_fn: 599.0000 - val_accuracy: 0.8985 - train_sensitivity: 0.9275 - train_specificity: 0.9275 - train_balacc: 0.9275 - val_sensitivity: 0.8985 - val_specificity: 0.8985 - val_balacc: 0.8985\n",
      "Epoch 179/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1784 - tp: 21155.0000 - fp: 1645.0000 - tn: 21155.0000 - fn: 1645.0000 - accuracy: 0.9279 train_balacc 0.9275761297700225\n",
      " val_balacc 0.8880230391326445\n",
      "\n",
      "Epoch 179: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1780 - tp: 21901.0000 - fp: 1710.0000 - tn: 21901.0000 - fn: 1710.0000 - accuracy: 0.9276 - val_loss: 0.2714 - val_tp: 5242.0000 - val_fp: 661.0000 - val_tn: 5242.0000 - val_fn: 661.0000 - val_accuracy: 0.8880 - train_sensitivity: 0.9276 - train_specificity: 0.9276 - train_balacc: 0.9276 - val_sensitivity: 0.8880 - val_specificity: 0.8880 - val_balacc: 0.8880\n",
      "Epoch 180/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1778 - tp: 21323.0000 - fp: 1677.0000 - tn: 21323.0000 - fn: 1677.0000 - accuracy: 0.9271 train_balacc 0.9275337766295371\n",
      " val_balacc 0.8763340674233441\n",
      "\n",
      "Epoch 180: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1770 - tp: 21900.0000 - fp: 1711.0000 - tn: 21900.0000 - fn: 1711.0000 - accuracy: 0.9275 - val_loss: 0.2739 - val_tp: 5173.0000 - val_fp: 730.0000 - val_tn: 5173.0000 - val_fn: 730.0000 - val_accuracy: 0.8763 - train_sensitivity: 0.9275 - train_specificity: 0.9275 - train_balacc: 0.9275 - val_sensitivity: 0.8763 - val_specificity: 0.8763 - val_balacc: 0.8763\n",
      "Epoch 181/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1776 - tp: 21806.0000 - fp: 1694.0000 - tn: 21806.0000 - fn: 1694.0000 - accuracy: 0.9279 train_balacc 0.9277878954724493\n",
      " val_balacc 0.8658309334236829\n",
      "\n",
      "Epoch 181: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1778 - tp: 21906.0000 - fp: 1705.0000 - tn: 21906.0000 - fn: 1705.0000 - accuracy: 0.9278 - val_loss: 0.3135 - val_tp: 5111.0000 - val_fp: 792.0000 - val_tn: 5111.0000 - val_fn: 792.0000 - val_accuracy: 0.8658 - train_sensitivity: 0.9278 - train_specificity: 0.9278 - train_balacc: 0.9278 - val_sensitivity: 0.8658 - val_specificity: 0.8658 - val_balacc: 0.8658\n",
      "Epoch 182/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1775 - tp: 21249.0000 - fp: 1651.0000 - tn: 21249.0000 - fn: 1651.0000 - accuracy: 0.9279 train_balacc 0.9272373046461395\n",
      " val_balacc 0.8673555819075046\n",
      "\n",
      "Epoch 182: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1785 - tp: 21893.0000 - fp: 1718.0000 - tn: 21893.0000 - fn: 1718.0000 - accuracy: 0.9272 - val_loss: 0.3128 - val_tp: 5120.0000 - val_fp: 783.0000 - val_tn: 5120.0000 - val_fn: 783.0000 - val_accuracy: 0.8674 - train_sensitivity: 0.9272 - train_specificity: 0.9272 - train_balacc: 0.9272 - val_sensitivity: 0.8674 - val_specificity: 0.8674 - val_balacc: 0.8674\n",
      "Epoch 183/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1721 - tp: 21857.0000 - fp: 1643.0000 - tn: 21857.0000 - fn: 1643.0000 - accuracy: 0.9301 train_balacc 0.929947905637203\n",
      " val_balacc 0.893274606132475\n",
      "\n",
      "Epoch 183: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1724 - tp: 21957.0000 - fp: 1654.0000 - tn: 21957.0000 - fn: 1654.0000 - accuracy: 0.9299 - val_loss: 0.2640 - val_tp: 5273.0000 - val_fp: 630.0000 - val_tn: 5273.0000 - val_fn: 630.0000 - val_accuracy: 0.8933 - train_sensitivity: 0.9299 - train_specificity: 0.9299 - train_balacc: 0.9299 - val_sensitivity: 0.8933 - val_specificity: 0.8933 - val_balacc: 0.8933\n",
      "Epoch 184/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1782 - tp: 21329.0000 - fp: 1671.0000 - tn: 21329.0000 - fn: 1671.0000 - accuracy: 0.9273 train_balacc 0.9272373046461395\n",
      " val_balacc 0.8881924445197358\n",
      "\n",
      "Epoch 184: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1784 - tp: 21893.0000 - fp: 1718.0000 - tn: 21893.0000 - fn: 1718.0000 - accuracy: 0.9272 - val_loss: 0.2667 - val_tp: 5243.0000 - val_fp: 660.0000 - val_tn: 5243.0000 - val_fn: 660.0000 - val_accuracy: 0.8882 - train_sensitivity: 0.9272 - train_specificity: 0.9272 - train_balacc: 0.9272 - val_sensitivity: 0.8882 - val_specificity: 0.8882 - val_balacc: 0.8882\n",
      "Epoch 185/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1818 - tp: 21406.0000 - fp: 1694.0000 - tn: 21406.0000 - fn: 1694.0000 - accuracy: 0.9267 train_balacc 0.9263902418364321\n",
      " val_balacc 0.8807386074877182\n",
      "\n",
      "Epoch 185: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1826 - tp: 21873.0000 - fp: 1738.0000 - tn: 21873.0000 - fn: 1738.0000 - accuracy: 0.9264 - val_loss: 0.2746 - val_tp: 5199.0000 - val_fp: 704.0000 - val_tn: 5199.0000 - val_fn: 704.0000 - val_accuracy: 0.8807 - train_sensitivity: 0.9264 - train_specificity: 0.9264 - train_balacc: 0.9264 - val_sensitivity: 0.8807 - val_specificity: 0.8807 - val_balacc: 0.8807\n",
      "Epoch 186/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1779 - tp: 21930.0000 - fp: 1670.0000 - tn: 21930.0000 - fn: 1670.0000 - accuracy: 0.9292 train_balacc 0.9292279022489518\n",
      " val_balacc 0.7602913772657971\n",
      "\n",
      "Epoch 186: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1779 - tp: 21940.0000 - fp: 1671.0000 - tn: 21940.0000 - fn: 1671.0000 - accuracy: 0.9292 - val_loss: 1.1583 - val_tp: 4488.0000 - val_fp: 1415.0000 - val_tn: 4488.0000 - val_fn: 1415.0000 - val_accuracy: 0.7603 - train_sensitivity: 0.9292 - train_specificity: 0.9292 - train_balacc: 0.9292 - val_sensitivity: 0.7603 - val_specificity: 0.7603 - val_balacc: 0.7603\n",
      "Epoch 187/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1732 - tp: 21939.0000 - fp: 1661.0000 - tn: 21939.0000 - fn: 1661.0000 - accuracy: 0.9296 train_balacc 0.9296514336538054\n",
      " val_balacc 0.8931052007453837\n",
      "\n",
      "Epoch 187: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1732 - tp: 21950.0000 - fp: 1661.0000 - tn: 21950.0000 - fn: 1661.0000 - accuracy: 0.9297 - val_loss: 0.2585 - val_tp: 5272.0000 - val_fp: 631.0000 - val_tn: 5272.0000 - val_fn: 631.0000 - val_accuracy: 0.8931 - train_sensitivity: 0.9297 - train_specificity: 0.9297 - train_balacc: 0.9297 - val_sensitivity: 0.8931 - val_specificity: 0.8931 - val_balacc: 0.8931\n",
      "Epoch 188/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1796 - tp: 21905.0000 - fp: 1695.0000 - tn: 21905.0000 - fn: 1695.0000 - accuracy: 0.9282 train_balacc 0.928211426877303\n",
      " val_balacc 0.8897170930035575\n",
      "\n",
      "Epoch 188: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1795 - tp: 21916.0000 - fp: 1695.0000 - tn: 21916.0000 - fn: 1695.0000 - accuracy: 0.9282 - val_loss: 0.2510 - val_tp: 5252.0000 - val_fp: 651.0000 - val_tn: 5252.0000 - val_fn: 651.0000 - val_accuracy: 0.8897 - train_sensitivity: 0.9282 - train_specificity: 0.9282 - train_balacc: 0.9282 - val_sensitivity: 0.8897 - val_specificity: 0.8897 - val_balacc: 0.8897\n",
      "Epoch 189/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1719 - tp: 21596.0000 - fp: 1604.0000 - tn: 21596.0000 - fn: 1604.0000 - accuracy: 0.9309 train_balacc 0.9310067341493372\n",
      " val_balacc 0.8939522276808403\n",
      "\n",
      "Epoch 189: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1715 - tp: 21982.0000 - fp: 1629.0000 - tn: 21982.0000 - fn: 1629.0000 - accuracy: 0.9310 - val_loss: 0.2633 - val_tp: 5277.0000 - val_fp: 626.0000 - val_tn: 5277.0000 - val_fn: 626.0000 - val_accuracy: 0.8940 - train_sensitivity: 0.9310 - train_specificity: 0.9310 - train_balacc: 0.9310 - val_sensitivity: 0.8940 - val_specificity: 0.8940 - val_balacc: 0.8940\n",
      "Epoch 190/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1797 - tp: 21744.0000 - fp: 1756.0000 - tn: 21744.0000 - fn: 1756.0000 - accuracy: 0.9253 train_balacc 0.9252890601838126\n",
      " val_balacc 0.8919193630357445\n",
      "\n",
      "Epoch 190: val_balacc did not improve from 0.89853\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1801 - tp: 21847.0000 - fp: 1764.0000 - tn: 21847.0000 - fn: 1764.0000 - accuracy: 0.9253 - val_loss: 0.2578 - val_tp: 5265.0000 - val_fp: 638.0000 - val_tn: 5265.0000 - val_fn: 638.0000 - val_accuracy: 0.8919 - train_sensitivity: 0.9253 - train_specificity: 0.9253 - train_balacc: 0.9253 - val_sensitivity: 0.8919 - val_specificity: 0.8919 - val_balacc: 0.8919\n",
      "Epoch 191/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1793 - tp: 21480.0000 - fp: 1620.0000 - tn: 21480.0000 - fn: 1620.0000 - accuracy: 0.9299 train_balacc 0.9297784930752615\n",
      " val_balacc 0.9027613078095883\n",
      "\n",
      "Epoch 191: val_balacc improved from 0.89853 to 0.90276, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1794 - tp: 21953.0000 - fp: 1658.0000 - tn: 21953.0000 - fn: 1658.0000 - accuracy: 0.9298 - val_loss: 0.2375 - val_tp: 5329.0000 - val_fp: 574.0000 - val_tn: 5329.0000 - val_fn: 574.0000 - val_accuracy: 0.9028 - train_sensitivity: 0.9298 - train_specificity: 0.9298 - train_balacc: 0.9298 - val_sensitivity: 0.9028 - val_specificity: 0.9028 - val_balacc: 0.9028\n",
      "Epoch 192/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1765 - tp: 21352.0000 - fp: 1648.0000 - tn: 21352.0000 - fn: 1648.0000 - accuracy: 0.9283 train_balacc 0.9281267205963322\n",
      " val_balacc 0.8854819583262747\n",
      "\n",
      "Epoch 192: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1767 - tp: 21914.0000 - fp: 1697.0000 - tn: 21914.0000 - fn: 1697.0000 - accuracy: 0.9281 - val_loss: 0.2734 - val_tp: 5227.0000 - val_fp: 676.0000 - val_tn: 5227.0000 - val_fn: 676.0000 - val_accuracy: 0.8855 - train_sensitivity: 0.9281 - train_specificity: 0.9281 - train_balacc: 0.9281 - val_sensitivity: 0.8855 - val_specificity: 0.8855 - val_balacc: 0.8855\n",
      "Epoch 193/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1752 - tp: 21934.0000 - fp: 1666.0000 - tn: 21934.0000 - fn: 1666.0000 - accuracy: 0.9294 train_balacc 0.9294396679513786\n",
      " val_balacc 0.8970015246484838\n",
      "\n",
      "Epoch 193: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1752 - tp: 21945.0000 - fp: 1666.0000 - tn: 21945.0000 - fn: 1666.0000 - accuracy: 0.9294 - val_loss: 0.2557 - val_tp: 5295.0000 - val_fp: 608.0000 - val_tn: 5295.0000 - val_fn: 608.0000 - val_accuracy: 0.8970 - train_sensitivity: 0.9294 - train_specificity: 0.9294 - train_balacc: 0.9294 - val_sensitivity: 0.8970 - val_specificity: 0.8970 - val_balacc: 0.8970\n",
      "Epoch 194/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1770 - tp: 21156.0000 - fp: 1644.0000 - tn: 21156.0000 - fn: 1644.0000 - accuracy: 0.9279 train_balacc 0.9282537800177884\n",
      " val_balacc 0.8807386074877182\n",
      "\n",
      "Epoch 194: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1770 - tp: 21917.0000 - fp: 1694.0000 - tn: 21917.0000 - fn: 1694.0000 - accuracy: 0.9283 - val_loss: 0.2990 - val_tp: 5199.0000 - val_fp: 704.0000 - val_tn: 5199.0000 - val_fn: 704.0000 - val_accuracy: 0.8807 - train_sensitivity: 0.9283 - train_specificity: 0.9283 - train_balacc: 0.9283 - val_sensitivity: 0.8807 - val_specificity: 0.8807 - val_balacc: 0.8807\n",
      "Epoch 195/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1747 - tp: 21168.0000 - fp: 1632.0000 - tn: 21168.0000 - fn: 1632.0000 - accuracy: 0.9284 train_balacc 0.9285926051416713\n",
      " val_balacc 0.8819244451973572\n",
      "\n",
      "Epoch 195: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1741 - tp: 21925.0000 - fp: 1686.0000 - tn: 21925.0000 - fn: 1686.0000 - accuracy: 0.9286 - val_loss: 0.2807 - val_tp: 5206.0000 - val_fp: 697.0000 - val_tn: 5206.0000 - val_fn: 697.0000 - val_accuracy: 0.8819 - train_sensitivity: 0.9286 - train_specificity: 0.9286 - train_balacc: 0.9286 - val_sensitivity: 0.8819 - val_specificity: 0.8819 - val_balacc: 0.8819\n",
      "Epoch 196/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1766 - tp: 21355.0000 - fp: 1645.0000 - tn: 21355.0000 - fn: 1645.0000 - accuracy: 0.9285 train_balacc 0.929143195967981\n",
      " val_balacc 0.8919193630357445\n",
      "\n",
      "Epoch 196: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1754 - tp: 21938.0000 - fp: 1673.0000 - tn: 21938.0000 - fn: 1673.0000 - accuracy: 0.9291 - val_loss: 0.2719 - val_tp: 5265.0000 - val_fp: 638.0000 - val_tn: 5265.0000 - val_fn: 638.0000 - val_accuracy: 0.8919 - train_sensitivity: 0.9291 - train_specificity: 0.9291 - train_balacc: 0.9291 - val_sensitivity: 0.8919 - val_specificity: 0.8919 - val_balacc: 0.8919\n",
      "Epoch 197/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1740 - tp: 21896.0000 - fp: 1715.0000 - tn: 21896.0000 - fn: 1715.0000 - accuracy: 0.9274 train_balacc 0.9273643640675956\n",
      " val_balacc 0.8678637980687786\n",
      "\n",
      "Epoch 197: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1740 - tp: 21896.0000 - fp: 1715.0000 - tn: 21896.0000 - fn: 1715.0000 - accuracy: 0.9274 - val_loss: 0.3055 - val_tp: 5123.0000 - val_fp: 780.0000 - val_tn: 5123.0000 - val_fn: 780.0000 - val_accuracy: 0.8679 - train_sensitivity: 0.9274 - train_specificity: 0.9274 - train_balacc: 0.9274 - val_sensitivity: 0.8679 - val_specificity: 0.8679 - val_balacc: 0.8679\n",
      "Epoch 198/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1780 - tp: 21950.0000 - fp: 1650.0000 - tn: 21950.0000 - fn: 1650.0000 - accuracy: 0.9301 train_balacc 0.930074965058659\n",
      " val_balacc 0.8875148229713705\n",
      "\n",
      "Epoch 198: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1781 - tp: 21960.0000 - fp: 1651.0000 - tn: 21960.0000 - fn: 1651.0000 - accuracy: 0.9301 - val_loss: 0.2666 - val_tp: 5239.0000 - val_fp: 664.0000 - val_tn: 5239.0000 - val_fn: 664.0000 - val_accuracy: 0.8875 - train_sensitivity: 0.9301 - train_specificity: 0.9301 - train_balacc: 0.9301 - val_sensitivity: 0.8875 - val_specificity: 0.8875 - val_balacc: 0.8875\n",
      "Epoch 199/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1726 - tp: 21642.0000 - fp: 1558.0000 - tn: 21642.0000 - fn: 1558.0000 - accuracy: 0.9328 train_balacc 0.9325738003472958\n",
      " val_balacc 0.8117906149415551\n",
      "\n",
      "Epoch 199: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1731 - tp: 22019.0000 - fp: 1592.0000 - tn: 22019.0000 - fn: 1592.0000 - accuracy: 0.9326 - val_loss: 0.4589 - val_tp: 4792.0000 - val_fp: 1111.0000 - val_tn: 4792.0000 - val_fn: 1111.0000 - val_accuracy: 0.8118 - train_sensitivity: 0.9326 - train_specificity: 0.9326 - train_balacc: 0.9326 - val_sensitivity: 0.8118 - val_specificity: 0.8118 - val_balacc: 0.8118\n",
      "Epoch 200/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1706 - tp: 21255.0000 - fp: 1545.0000 - tn: 21255.0000 - fn: 1545.0000 - accuracy: 0.9322 train_balacc 0.9326585066282664\n",
      " val_balacc 0.8902253091648314\n",
      "\n",
      "Epoch 200: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1693 - tp: 22021.0000 - fp: 1590.0000 - tn: 22021.0000 - fn: 1590.0000 - accuracy: 0.9327 - val_loss: 0.2622 - val_tp: 5255.0000 - val_fp: 648.0000 - val_tn: 5255.0000 - val_fn: 648.0000 - val_accuracy: 0.8902 - train_sensitivity: 0.9327 - train_specificity: 0.9327 - train_balacc: 0.9327 - val_sensitivity: 0.8902 - val_specificity: 0.8902 - val_balacc: 0.8902\n",
      "Epoch 201/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1698 - tp: 21226.0000 - fp: 1574.0000 - tn: 21226.0000 - fn: 1574.0000 - accuracy: 0.9310 train_balacc 0.9311761467112787\n",
      " val_balacc 0.8617652041334914\n",
      "\n",
      "Epoch 201: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1693 - tp: 21986.0000 - fp: 1625.0000 - tn: 21986.0000 - fn: 1625.0000 - accuracy: 0.9312 - val_loss: 0.3712 - val_tp: 5087.0000 - val_fp: 816.0000 - val_tn: 5087.0000 - val_fn: 816.0000 - val_accuracy: 0.8618 - train_sensitivity: 0.9312 - train_specificity: 0.9312 - train_balacc: 0.9312 - val_sensitivity: 0.8618 - val_specificity: 0.8618 - val_balacc: 0.8618\n",
      "Epoch 202/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1726 - tp: 21189.0000 - fp: 1611.0000 - tn: 21189.0000 - fn: 1611.0000 - accuracy: 0.9293 train_balacc 0.929143195967981\n",
      " val_balacc 0.8473657462307301\n",
      "\n",
      "Epoch 202: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1727 - tp: 21938.0000 - fp: 1673.0000 - tn: 21938.0000 - fn: 1673.0000 - accuracy: 0.9291 - val_loss: 0.3465 - val_tp: 5002.0000 - val_fp: 901.0000 - val_tn: 5002.0000 - val_fn: 901.0000 - val_accuracy: 0.8474 - train_sensitivity: 0.9291 - train_specificity: 0.9291 - train_balacc: 0.9291 - val_sensitivity: 0.8474 - val_specificity: 0.8474 - val_balacc: 0.8474\n",
      "Epoch 203/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1685 - tp: 21261.0000 - fp: 1539.0000 - tn: 21261.0000 - fn: 1539.0000 - accuracy: 0.9325 train_balacc 0.9323620346448689\n",
      " val_balacc 0.8927663899712011\n",
      "\n",
      "Epoch 203: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1686 - tp: 22014.0000 - fp: 1597.0000 - tn: 22014.0000 - fn: 1597.0000 - accuracy: 0.9324 - val_loss: 0.2457 - val_tp: 5270.0000 - val_fp: 633.0000 - val_tn: 5270.0000 - val_fn: 633.0000 - val_accuracy: 0.8928 - train_sensitivity: 0.9324 - train_specificity: 0.9324 - train_balacc: 0.9324 - val_sensitivity: 0.8928 - val_specificity: 0.8928 - val_balacc: 0.8928\n",
      "Epoch 204/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1745 - tp: 21208.0000 - fp: 1592.0000 - tn: 21208.0000 - fn: 1592.0000 - accuracy: 0.9302 train_balacc 0.930074965058659\n",
      " val_balacc 0.8509232593596476\n",
      "\n",
      "Epoch 204: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1753 - tp: 21960.0000 - fp: 1651.0000 - tn: 21960.0000 - fn: 1651.0000 - accuracy: 0.9301 - val_loss: 0.4468 - val_tp: 5023.0000 - val_fp: 880.0000 - val_tn: 5023.0000 - val_fn: 880.0000 - val_accuracy: 0.8509 - train_sensitivity: 0.9301 - train_specificity: 0.9301 - train_balacc: 0.9301 - val_sensitivity: 0.8509 - val_specificity: 0.8509 - val_balacc: 0.8509\n",
      "Epoch 205/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1766 - tp: 21927.0000 - fp: 1673.0000 - tn: 21927.0000 - fn: 1673.0000 - accuracy: 0.9291 train_balacc 0.9291008428274956\n",
      " val_balacc 0.883957309842453\n",
      "\n",
      "Epoch 205: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1766 - tp: 21937.0000 - fp: 1674.0000 - tn: 21937.0000 - fn: 1674.0000 - accuracy: 0.9291 - val_loss: 0.2777 - val_tp: 5218.0000 - val_fp: 685.0000 - val_tn: 5218.0000 - val_fn: 685.0000 - val_accuracy: 0.8840 - train_sensitivity: 0.9291 - train_specificity: 0.9291 - train_balacc: 0.9291 - val_sensitivity: 0.8840 - val_specificity: 0.8840 - val_balacc: 0.8840\n",
      "Epoch 206/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1762 - tp: 21844.0000 - fp: 1656.0000 - tn: 21844.0000 - fn: 1656.0000 - accuracy: 0.9295 train_balacc 0.9294396679513786\n",
      " val_balacc 0.8670167711333221\n",
      "\n",
      "Epoch 206: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1765 - tp: 21945.0000 - fp: 1666.0000 - tn: 21945.0000 - fn: 1666.0000 - accuracy: 0.9294 - val_loss: 0.3203 - val_tp: 5118.0000 - val_fp: 785.0000 - val_tn: 5118.0000 - val_fn: 785.0000 - val_accuracy: 0.8670 - train_sensitivity: 0.9294 - train_specificity: 0.9294 - train_balacc: 0.9294 - val_sensitivity: 0.8670 - val_specificity: 0.8670 - val_balacc: 0.8670\n",
      "Epoch 207/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1743 - tp: 21172.0000 - fp: 1628.0000 - tn: 21172.0000 - fn: 1628.0000 - accuracy: 0.9286 train_balacc 0.92787260175342\n",
      " val_balacc 0.8868372014230053\n",
      "\n",
      "Epoch 207: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1755 - tp: 21908.0000 - fp: 1703.0000 - tn: 21908.0000 - fn: 1703.0000 - accuracy: 0.9279 - val_loss: 0.2647 - val_tp: 5235.0000 - val_fp: 668.0000 - val_tn: 5235.0000 - val_fn: 668.0000 - val_accuracy: 0.8868 - train_sensitivity: 0.9279 - train_specificity: 0.9279 - train_balacc: 0.9279 - val_sensitivity: 0.8868 - val_specificity: 0.8868 - val_balacc: 0.8868\n",
      "Epoch 208/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1761 - tp: 21156.0000 - fp: 1644.0000 - tn: 21156.0000 - fn: 1644.0000 - accuracy: 0.9279 train_balacc 0.9275337766295371\n",
      " val_balacc 0.8580382856174826\n",
      "\n",
      "Epoch 208: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1777 - tp: 21900.0000 - fp: 1711.0000 - tn: 21900.0000 - fn: 1711.0000 - accuracy: 0.9275 - val_loss: 0.3243 - val_tp: 5065.0000 - val_fp: 838.0000 - val_tn: 5065.0000 - val_fn: 838.0000 - val_accuracy: 0.8580 - train_sensitivity: 0.9275 - train_specificity: 0.9275 - train_balacc: 0.9275 - val_sensitivity: 0.8580 - val_specificity: 0.8580 - val_balacc: 0.8580\n",
      "Epoch 209/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1762 - tp: 21329.0000 - fp: 1571.0000 - tn: 21329.0000 - fn: 1571.0000 - accuracy: 0.9314 train_balacc 0.9315573249756469\n",
      " val_balacc 0.6789767914619685\n",
      "\n",
      "Epoch 209: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1757 - tp: 21995.0000 - fp: 1616.0000 - tn: 21995.0000 - fn: 1616.0000 - accuracy: 0.9316 - val_loss: 1.2433 - val_tp: 4008.0000 - val_fp: 1895.0000 - val_tn: 4008.0000 - val_fn: 1895.0000 - val_accuracy: 0.6790 - train_sensitivity: 0.9316 - train_specificity: 0.9316 - train_balacc: 0.9316 - val_sensitivity: 0.6790 - val_specificity: 0.6790 - val_balacc: 0.6790\n",
      "Epoch 210/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1700 - tp: 21453.0000 - fp: 1547.0000 - tn: 21453.0000 - fn: 1547.0000 - accuracy: 0.9327 train_balacc 0.9327432129092372\n",
      " val_balacc 0.8970015246484838\n",
      "\n",
      "Epoch 210: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1699 - tp: 22023.0000 - fp: 1588.0000 - tn: 22023.0000 - fn: 1588.0000 - accuracy: 0.9327 - val_loss: 0.2741 - val_tp: 5295.0000 - val_fp: 608.0000 - val_tn: 5295.0000 - val_fn: 608.0000 - val_accuracy: 0.8970 - train_sensitivity: 0.9327 - train_specificity: 0.9327 - train_balacc: 0.9327 - val_sensitivity: 0.8970 - val_specificity: 0.8970 - val_balacc: 0.8970\n",
      "Epoch 211/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1731 - tp: 21643.0000 - fp: 1557.0000 - tn: 21643.0000 - fn: 1557.0000 - accuracy: 0.9329 train_balacc 0.9330820380331202\n",
      " val_balacc 0.8587159071658479\n",
      "\n",
      "Epoch 211: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1725 - tp: 22031.0000 - fp: 1580.0000 - tn: 22031.0000 - fn: 1580.0000 - accuracy: 0.9331 - val_loss: 0.3348 - val_tp: 5069.0000 - val_fp: 834.0000 - val_tn: 5069.0000 - val_fn: 834.0000 - val_accuracy: 0.8587 - train_sensitivity: 0.9331 - train_specificity: 0.9331 - train_balacc: 0.9331 - val_sensitivity: 0.8587 - val_specificity: 0.8587 - val_balacc: 0.8587\n",
      "Epoch 212/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1729 - tp: 21952.0000 - fp: 1648.0000 - tn: 21952.0000 - fn: 1648.0000 - accuracy: 0.9302 train_balacc 0.9301173181991444\n",
      " val_balacc 0.8809080128748095\n",
      "\n",
      "Epoch 212: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1729 - tp: 21961.0000 - fp: 1650.0000 - tn: 21961.0000 - fn: 1650.0000 - accuracy: 0.9301 - val_loss: 0.2890 - val_tp: 5200.0000 - val_fp: 703.0000 - val_tn: 5200.0000 - val_fn: 703.0000 - val_accuracy: 0.8809 - train_sensitivity: 0.9301 - train_specificity: 0.9301 - train_balacc: 0.9301 - val_sensitivity: 0.8809 - val_specificity: 0.8809 - val_balacc: 0.8809\n",
      "Epoch 213/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1719 - tp: 21345.0000 - fp: 1555.0000 - tn: 21345.0000 - fn: 1555.0000 - accuracy: 0.9321 train_balacc 0.9324043877853543\n",
      " val_balacc 0.8856513637133661\n",
      "\n",
      "Epoch 213: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1711 - tp: 22015.0000 - fp: 1596.0000 - tn: 22015.0000 - fn: 1596.0000 - accuracy: 0.9324 - val_loss: 0.3099 - val_tp: 5228.0000 - val_fp: 675.0000 - val_tn: 5228.0000 - val_fn: 675.0000 - val_accuracy: 0.8857 - train_sensitivity: 0.9324 - train_specificity: 0.9324 - train_balacc: 0.9324 - val_sensitivity: 0.8857 - val_specificity: 0.8857 - val_balacc: 0.8857\n",
      "Epoch 214/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1762 - tp: 21373.0000 - fp: 1627.0000 - tn: 21373.0000 - fn: 1627.0000 - accuracy: 0.9293 train_balacc 0.9295243742323493\n",
      " val_balacc 0.8705742842622395\n",
      "\n",
      "Epoch 214: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1751 - tp: 21947.0000 - fp: 1664.0000 - tn: 21947.0000 - fn: 1664.0000 - accuracy: 0.9295 - val_loss: 0.3101 - val_tp: 5139.0000 - val_fp: 764.0000 - val_tn: 5139.0000 - val_fn: 764.0000 - val_accuracy: 0.8706 - train_sensitivity: 0.9295 - train_specificity: 0.9295 - train_balacc: 0.9295 - val_sensitivity: 0.8706 - val_specificity: 0.8706 - val_balacc: 0.8706\n",
      "Epoch 215/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1769 - tp: 21290.0000 - fp: 1610.0000 - tn: 21290.0000 - fn: 1610.0000 - accuracy: 0.9297 train_balacc 0.9299055524967176\n",
      " val_balacc 0.8280535321023208\n",
      "\n",
      "Epoch 215: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1764 - tp: 21956.0000 - fp: 1655.0000 - tn: 21956.0000 - fn: 1655.0000 - accuracy: 0.9299 - val_loss: 0.5087 - val_tp: 4888.0000 - val_fp: 1015.0000 - val_tn: 4888.0000 - val_fn: 1015.0000 - val_accuracy: 0.8281 - train_sensitivity: 0.9299 - train_specificity: 0.9299 - train_balacc: 0.9299 - val_sensitivity: 0.8281 - val_specificity: 0.8281 - val_balacc: 0.8281\n",
      "Epoch 216/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1717 - tp: 21980.0000 - fp: 1620.0000 - tn: 21980.0000 - fn: 1620.0000 - accuracy: 0.9314 train_balacc 0.9313879124137054\n",
      " val_balacc 0.8985261731323056\n",
      "\n",
      "Epoch 216: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1717 - tp: 21991.0000 - fp: 1620.0000 - tn: 21991.0000 - fn: 1620.0000 - accuracy: 0.9314 - val_loss: 0.2464 - val_tp: 5304.0000 - val_fp: 599.0000 - val_tn: 5304.0000 - val_fn: 599.0000 - val_accuracy: 0.8985 - train_sensitivity: 0.9314 - train_specificity: 0.9314 - train_balacc: 0.9314 - val_sensitivity: 0.8985 - val_specificity: 0.8985 - val_balacc: 0.8985\n",
      "Epoch 217/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1717 - tp: 21433.0000 - fp: 1567.0000 - tn: 21433.0000 - fn: 1567.0000 - accuracy: 0.9319 train_balacc 0.9323620346448689\n",
      " val_balacc 0.8959850923259359\n",
      "\n",
      "Epoch 217: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1704 - tp: 22014.0000 - fp: 1597.0000 - tn: 22014.0000 - fn: 1597.0000 - accuracy: 0.9324 - val_loss: 0.2644 - val_tp: 5289.0000 - val_fp: 614.0000 - val_tn: 5289.0000 - val_fn: 614.0000 - val_accuracy: 0.8960 - train_sensitivity: 0.9324 - train_specificity: 0.9324 - train_balacc: 0.9324 - val_sensitivity: 0.8960 - val_specificity: 0.8960 - val_balacc: 0.8960\n",
      "Epoch 218/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1744 - tp: 21491.0000 - fp: 1609.0000 - tn: 21491.0000 - fn: 1609.0000 - accuracy: 0.9303 train_balacc 0.9302867307610859\n",
      " val_balacc 0.8587159071658479\n",
      "\n",
      "Epoch 218: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1740 - tp: 21965.0000 - fp: 1646.0000 - tn: 21965.0000 - fn: 1646.0000 - accuracy: 0.9303 - val_loss: 0.3294 - val_tp: 5069.0000 - val_fp: 834.0000 - val_tn: 5069.0000 - val_fn: 834.0000 - val_accuracy: 0.8587 - train_sensitivity: 0.9303 - train_specificity: 0.9303 - train_balacc: 0.9303 - val_sensitivity: 0.8587 - val_specificity: 0.8587 - val_balacc: 0.8587\n",
      "Epoch 219/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1743 - tp: 21873.0000 - fp: 1627.0000 - tn: 21873.0000 - fn: 1627.0000 - accuracy: 0.9308 train_balacc 0.930752615306425\n",
      " val_balacc 0.8300863967474166\n",
      "\n",
      "Epoch 219: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1745 - tp: 21976.0000 - fp: 1635.0000 - tn: 21976.0000 - fn: 1635.0000 - accuracy: 0.9308 - val_loss: 0.3661 - val_tp: 4900.0000 - val_fp: 1003.0000 - val_tn: 4900.0000 - val_fn: 1003.0000 - val_accuracy: 0.8301 - train_sensitivity: 0.9308 - train_specificity: 0.9308 - train_balacc: 0.9308 - val_sensitivity: 0.8301 - val_specificity: 0.8301 - val_balacc: 0.8301\n",
      "Epoch 220/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1697 - tp: 21213.0000 - fp: 1587.0000 - tn: 21213.0000 - fn: 1587.0000 - accuracy: 0.9304 train_balacc 0.9307949684469103\n",
      " val_balacc 0.8009486701677113\n",
      "\n",
      "Epoch 220: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1698 - tp: 21977.0000 - fp: 1634.0000 - tn: 21977.0000 - fn: 1634.0000 - accuracy: 0.9308 - val_loss: 0.4788 - val_tp: 4728.0000 - val_fp: 1175.0000 - val_tn: 4728.0000 - val_fn: 1175.0000 - val_accuracy: 0.8009 - train_sensitivity: 0.9308 - train_specificity: 0.9308 - train_balacc: 0.9308 - val_sensitivity: 0.8009 - val_specificity: 0.8009 - val_balacc: 0.8009\n",
      "Epoch 221/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1725 - tp: 21221.0000 - fp: 1579.0000 - tn: 21221.0000 - fn: 1579.0000 - accuracy: 0.9307 train_balacc 0.930879674727881\n",
      " val_balacc 0.8714213111976961\n",
      "\n",
      "Epoch 221: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1722 - tp: 21979.0000 - fp: 1632.0000 - tn: 21979.0000 - fn: 1632.0000 - accuracy: 0.9309 - val_loss: 0.3097 - val_tp: 5144.0000 - val_fp: 759.0000 - val_tn: 5144.0000 - val_fn: 759.0000 - val_accuracy: 0.8714 - train_sensitivity: 0.9309 - train_specificity: 0.9309 - train_balacc: 0.9309 - val_sensitivity: 0.8714 - val_specificity: 0.8714 - val_balacc: 0.8714\n",
      "Epoch 222/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1704 - tp: 21412.0000 - fp: 1588.0000 - tn: 21412.0000 - fn: 1588.0000 - accuracy: 0.9310 train_balacc 0.9315573249756469\n",
      " val_balacc 0.8624428256818567\n",
      "\n",
      "Epoch 222: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1692 - tp: 21995.0000 - fp: 1616.0000 - tn: 21995.0000 - fn: 1616.0000 - accuracy: 0.9316 - val_loss: 0.3020 - val_tp: 5091.0000 - val_fp: 812.0000 - val_tn: 5091.0000 - val_fn: 812.0000 - val_accuracy: 0.8624 - train_sensitivity: 0.9316 - train_specificity: 0.9316 - train_balacc: 0.9316 - val_sensitivity: 0.8624 - val_specificity: 0.8624 - val_balacc: 0.8624\n",
      "Epoch 223/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1688 - tp: 21258.0000 - fp: 1542.0000 - tn: 21258.0000 - fn: 1542.0000 - accuracy: 0.9324 train_balacc 0.9321926220829274\n",
      " val_balacc 0.8864983906488226\n",
      "\n",
      "Epoch 223: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1695 - tp: 22010.0000 - fp: 1601.0000 - tn: 22010.0000 - fn: 1601.0000 - accuracy: 0.9322 - val_loss: 0.2702 - val_tp: 5233.0000 - val_fp: 670.0000 - val_tn: 5233.0000 - val_fn: 670.0000 - val_accuracy: 0.8865 - train_sensitivity: 0.9322 - train_specificity: 0.9322 - train_balacc: 0.9322 - val_sensitivity: 0.8865 - val_specificity: 0.8865 - val_balacc: 0.8865\n",
      "Epoch 224/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1664 - tp: 21555.0000 - fp: 1545.0000 - tn: 21555.0000 - fn: 1545.0000 - accuracy: 0.9331 train_balacc 0.9334208631570031\n",
      " val_balacc 0.879044553616805\n",
      "\n",
      "Epoch 224: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1661 - tp: 22039.0000 - fp: 1572.0000 - tn: 22039.0000 - fn: 1572.0000 - accuracy: 0.9334 - val_loss: 0.2715 - val_tp: 5189.0000 - val_fp: 714.0000 - val_tn: 5189.0000 - val_fn: 714.0000 - val_accuracy: 0.8790 - train_sensitivity: 0.9334 - train_specificity: 0.9334 - train_balacc: 0.9334 - val_sensitivity: 0.8790 - val_specificity: 0.8790 - val_balacc: 0.8790\n",
      "Epoch 225/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1719 - tp: 21726.0000 - fp: 1674.0000 - tn: 21726.0000 - fn: 1674.0000 - accuracy: 0.9285 train_balacc 0.928677311422642\n",
      " val_balacc 0.8873454175842792\n",
      "\n",
      "Epoch 225: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1714 - tp: 21927.0000 - fp: 1684.0000 - tn: 21927.0000 - fn: 1684.0000 - accuracy: 0.9287 - val_loss: 0.2792 - val_tp: 5238.0000 - val_fp: 665.0000 - val_tn: 5238.0000 - val_fn: 665.0000 - val_accuracy: 0.8873 - train_sensitivity: 0.9287 - train_specificity: 0.9287 - train_balacc: 0.9287 - val_sensitivity: 0.8873 - val_specificity: 0.8873 - val_balacc: 0.8873\n",
      "Epoch 226/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1712 - tp: 21381.0000 - fp: 1519.0000 - tn: 21381.0000 - fn: 1519.0000 - accuracy: 0.9337 train_balacc 0.933293803735547\n",
      " val_balacc 0.8892088768422836\n",
      "\n",
      "Epoch 226: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1711 - tp: 22036.0000 - fp: 1575.0000 - tn: 22036.0000 - fn: 1575.0000 - accuracy: 0.9333 - val_loss: 0.2560 - val_tp: 5249.0000 - val_fp: 654.0000 - val_tn: 5249.0000 - val_fn: 654.0000 - val_accuracy: 0.8892 - train_sensitivity: 0.9333 - train_specificity: 0.9333 - train_balacc: 0.9333 - val_sensitivity: 0.8892 - val_specificity: 0.8892 - val_balacc: 0.8892\n",
      "Epoch 227/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1744 - tp: 21972.0000 - fp: 1628.0000 - tn: 21972.0000 - fn: 1628.0000 - accuracy: 0.9310 train_balacc 0.9310490872898225\n",
      " val_balacc 0.8873454175842792\n",
      "\n",
      "Epoch 227: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1743 - tp: 21983.0000 - fp: 1628.0000 - tn: 21983.0000 - fn: 1628.0000 - accuracy: 0.9310 - val_loss: 0.2574 - val_tp: 5238.0000 - val_fp: 665.0000 - val_tn: 5238.0000 - val_fn: 665.0000 - val_accuracy: 0.8873 - train_sensitivity: 0.9310 - train_specificity: 0.9310 - train_balacc: 0.9310 - val_sensitivity: 0.8873 - val_specificity: 0.8873 - val_balacc: 0.8873\n",
      "Epoch 228/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1724 - tp: 21325.0000 - fp: 1575.0000 - tn: 21325.0000 - fn: 1575.0000 - accuracy: 0.9312 train_balacc 0.9311761467112787\n",
      " val_balacc 0.8802303913264442\n",
      "\n",
      "Epoch 228: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1735 - tp: 21986.0000 - fp: 1625.0000 - tn: 21986.0000 - fn: 1625.0000 - accuracy: 0.9312 - val_loss: 0.2918 - val_tp: 5196.0000 - val_fp: 707.0000 - val_tn: 5196.0000 - val_fn: 707.0000 - val_accuracy: 0.8802 - train_sensitivity: 0.9312 - train_specificity: 0.9312 - train_balacc: 0.9312 - val_sensitivity: 0.8802 - val_specificity: 0.8802 - val_balacc: 0.8802\n",
      "Epoch 229/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1751 - tp: 21279.0000 - fp: 1621.0000 - tn: 21279.0000 - fn: 1621.0000 - accuracy: 0.9292 train_balacc 0.9292702553894371\n",
      " val_balacc 0.8675249872945959\n",
      "\n",
      "Epoch 229: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1751 - tp: 21941.0000 - fp: 1670.0000 - tn: 21941.0000 - fn: 1670.0000 - accuracy: 0.9293 - val_loss: 0.3212 - val_tp: 5121.0000 - val_fp: 782.0000 - val_tn: 5121.0000 - val_fn: 782.0000 - val_accuracy: 0.8675 - train_sensitivity: 0.9293 - train_specificity: 0.9293 - train_balacc: 0.9293 - val_sensitivity: 0.8675 - val_specificity: 0.8675 - val_balacc: 0.8675\n",
      "Epoch 230/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1713 - tp: 21671.0000 - fp: 1629.0000 - tn: 21671.0000 - fn: 1629.0000 - accuracy: 0.9301 train_balacc 0.9302020244801152\n",
      " val_balacc 0.876842283584618\n",
      "\n",
      "Epoch 230: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1714 - tp: 21963.0000 - fp: 1648.0000 - tn: 21963.0000 - fn: 1648.0000 - accuracy: 0.9302 - val_loss: 0.2813 - val_tp: 5176.0000 - val_fp: 727.0000 - val_tn: 5176.0000 - val_fn: 727.0000 - val_accuracy: 0.8768 - train_sensitivity: 0.9302 - train_specificity: 0.9302 - train_balacc: 0.9302 - val_sensitivity: 0.8768 - val_specificity: 0.8768 - val_balacc: 0.8768\n",
      "Epoch 231/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1803 - tp: 21219.0000 - fp: 1581.0000 - tn: 21219.0000 - fn: 1581.0000 - accuracy: 0.9307 train_balacc 0.9311761467112787\n",
      " val_balacc 0.8802303913264442\n",
      "\n",
      "Epoch 231: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1796 - tp: 21986.0000 - fp: 1625.0000 - tn: 21986.0000 - fn: 1625.0000 - accuracy: 0.9312 - val_loss: 0.2915 - val_tp: 5196.0000 - val_fp: 707.0000 - val_tn: 5196.0000 - val_fn: 707.0000 - val_accuracy: 0.8802 - train_sensitivity: 0.9312 - train_specificity: 0.9312 - train_balacc: 0.9312 - val_sensitivity: 0.8802 - val_specificity: 0.8802 - val_balacc: 0.8802\n",
      "Epoch 232/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1673 - tp: 21377.0000 - fp: 1523.0000 - tn: 21377.0000 - fn: 1523.0000 - accuracy: 0.9335 train_balacc 0.9333361568760323\n",
      " val_balacc 0.8905641199390141\n",
      "\n",
      "Epoch 232: val_balacc did not improve from 0.90276\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1697 - tp: 22037.0000 - fp: 1574.0000 - tn: 22037.0000 - fn: 1574.0000 - accuracy: 0.9333 - val_loss: 0.2563 - val_tp: 5257.0000 - val_fp: 646.0000 - val_tn: 5257.0000 - val_fn: 646.0000 - val_accuracy: 0.8906 - train_sensitivity: 0.9333 - train_specificity: 0.9333 - train_balacc: 0.9333 - val_sensitivity: 0.8906 - val_specificity: 0.8906 - val_balacc: 0.8906\n",
      "Size of the training fold is 23611\n",
      "Size of the validation fold is 5903\n",
      "Class imbalance in Train is 0.46%\n",
      "Class imbalance in Validation is 0.46%\n",
      "Epoch 1/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2131 - tp: 21579.0000 - fp: 2021.0000 - tn: 21579.0000 - fn: 2021.0000 - accuracy: 0.9144 train_balacc 0.914361949938588\n",
      " val_balacc 0.8964933084872099\n",
      "\n",
      "Epoch 1: val_balacc improved from -inf to 0.89649, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2131 - tp: 21589.0000 - fp: 2022.0000 - tn: 21589.0000 - fn: 2022.0000 - accuracy: 0.9144 - val_loss: 0.2615 - val_tp: 5292.0000 - val_fp: 611.0000 - val_tn: 5292.0000 - val_fn: 611.0000 - val_accuracy: 0.8965 - train_sensitivity: 0.9144 - train_specificity: 0.9144 - train_balacc: 0.9144 - val_sensitivity: 0.8965 - val_specificity: 0.8965 - val_balacc: 0.8965\n",
      "Epoch 2/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2114 - tp: 21140.0000 - fp: 1960.0000 - tn: 21140.0000 - fn: 1960.0000 - accuracy: 0.9152 train_balacc 0.9147007750624708\n",
      " val_balacc 0.945282059969507\n",
      "\n",
      "Epoch 2: val_balacc improved from 0.89649 to 0.94528, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2116 - tp: 21597.0000 - fp: 2014.0000 - tn: 21597.0000 - fn: 2014.0000 - accuracy: 0.9147 - val_loss: 0.2016 - val_tp: 5580.0000 - val_fp: 323.0000 - val_tn: 5580.0000 - val_fn: 323.0000 - val_accuracy: 0.9453 - train_sensitivity: 0.9147 - train_specificity: 0.9147 - train_balacc: 0.9147 - val_sensitivity: 0.9453 - val_specificity: 0.9453 - val_balacc: 0.9453\n",
      "Epoch 3/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2150 - tp: 21111.0000 - fp: 1989.0000 - tn: 21111.0000 - fn: 1989.0000 - accuracy: 0.9139 train_balacc 0.9136419465503367\n",
      " val_balacc 0.9244451973572759\n",
      "\n",
      "Epoch 3: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2155 - tp: 21572.0000 - fp: 2039.0000 - tn: 21572.0000 - fn: 2039.0000 - accuracy: 0.9136 - val_loss: 0.2201 - val_tp: 5457.0000 - val_fp: 446.0000 - val_tn: 5457.0000 - val_fn: 446.0000 - val_accuracy: 0.9244 - train_sensitivity: 0.9136 - train_specificity: 0.9136 - train_balacc: 0.9136 - val_sensitivity: 0.9244 - val_specificity: 0.9244 - val_balacc: 0.9244\n",
      "Epoch 4/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.2027 - tp: 21421.0000 - fp: 1879.0000 - tn: 21421.0000 - fn: 1879.0000 - accuracy: 0.9194 train_balacc 0.9190631485324637\n",
      " val_balacc 0.9246146027443672\n",
      "\n",
      "Epoch 4: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2031 - tp: 21700.0000 - fp: 1911.0000 - tn: 21700.0000 - fn: 1911.0000 - accuracy: 0.9191 - val_loss: 0.2031 - val_tp: 5458.0000 - val_fp: 445.0000 - val_tn: 5458.0000 - val_fn: 445.0000 - val_accuracy: 0.9246 - train_sensitivity: 0.9191 - train_specificity: 0.9191 - train_balacc: 0.9191 - val_sensitivity: 0.9246 - val_specificity: 0.9246 - val_balacc: 0.9246\n",
      "Epoch 5/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2073 - tp: 21595.0000 - fp: 2005.0000 - tn: 21595.0000 - fn: 2005.0000 - accuracy: 0.9150 train_balacc 0.9150819533268392\n",
      " val_balacc 0.9188548195832628\n",
      "\n",
      "Epoch 5: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2073 - tp: 21606.0000 - fp: 2005.0000 - tn: 21606.0000 - fn: 2005.0000 - accuracy: 0.9151 - val_loss: 0.2020 - val_tp: 5424.0000 - val_fp: 479.0000 - val_tn: 5424.0000 - val_fn: 479.0000 - val_accuracy: 0.9189 - train_sensitivity: 0.9151 - train_specificity: 0.9151 - train_balacc: 0.9151 - val_sensitivity: 0.9189 - val_specificity: 0.9189 - val_balacc: 0.9189\n",
      "Epoch 6/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2099 - tp: 21610.0000 - fp: 1990.0000 - tn: 21610.0000 - fn: 1990.0000 - accuracy: 0.9157 train_balacc 0.9157172504341197\n",
      " val_balacc 0.9149584956801626\n",
      "\n",
      "Epoch 6: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2098 - tp: 21621.0000 - fp: 1990.0000 - tn: 21621.0000 - fn: 1990.0000 - accuracy: 0.9157 - val_loss: 0.2193 - val_tp: 5401.0000 - val_fp: 502.0000 - val_tn: 5401.0000 - val_fn: 502.0000 - val_accuracy: 0.9150 - train_sensitivity: 0.9157 - train_specificity: 0.9157 - train_balacc: 0.9157 - val_sensitivity: 0.9150 - val_specificity: 0.9150 - val_balacc: 0.9150\n",
      "Epoch 7/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.2011 - tp: 21518.0000 - fp: 1982.0000 - tn: 21518.0000 - fn: 1982.0000 - accuracy: 0.9157 train_balacc 0.9154207784507221\n",
      " val_balacc 0.895476876164662\n",
      "\n",
      "Epoch 7: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2014 - tp: 21614.0000 - fp: 1997.0000 - tn: 21614.0000 - fn: 1997.0000 - accuracy: 0.9154 - val_loss: 0.2275 - val_tp: 5286.0000 - val_fp: 617.0000 - val_tn: 5286.0000 - val_fn: 617.0000 - val_accuracy: 0.8955 - train_sensitivity: 0.9154 - train_specificity: 0.9154 - train_balacc: 0.9154 - val_sensitivity: 0.8955 - val_specificity: 0.8955 - val_balacc: 0.8955\n",
      "Epoch 8/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.2097 - tp: 21354.0000 - fp: 2046.0000 - tn: 21354.0000 - fn: 2046.0000 - accuracy: 0.9126 train_balacc 0.9124984117572318\n",
      " val_balacc 0.9373200067762155\n",
      "\n",
      "Epoch 8: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2100 - tp: 21545.0000 - fp: 2066.0000 - tn: 21545.0000 - fn: 2066.0000 - accuracy: 0.9125 - val_loss: 0.2132 - val_tp: 5533.0000 - val_fp: 370.0000 - val_tn: 5533.0000 - val_fn: 370.0000 - val_accuracy: 0.9373 - train_sensitivity: 0.9125 - train_specificity: 0.9125 - train_balacc: 0.9125 - val_sensitivity: 0.9373 - val_specificity: 0.9373 - val_balacc: 0.9373\n",
      "Epoch 9/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2014 - tp: 21125.0000 - fp: 1875.0000 - tn: 21125.0000 - fn: 1875.0000 - accuracy: 0.9185 train_balacc 0.9184702045656685\n",
      " val_balacc 0.9205488734541758\n",
      "\n",
      "Epoch 9: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2012 - tp: 21686.0000 - fp: 1925.0000 - tn: 21686.0000 - fn: 1925.0000 - accuracy: 0.9185 - val_loss: 0.1926 - val_tp: 5434.0000 - val_fp: 469.0000 - val_tn: 5434.0000 - val_fn: 469.0000 - val_accuracy: 0.9205 - train_sensitivity: 0.9185 - train_specificity: 0.9185 - train_balacc: 0.9185 - val_sensitivity: 0.9205 - val_specificity: 0.9205 - val_balacc: 0.9205\n",
      "Epoch 10/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2052 - tp: 21046.0000 - fp: 1954.0000 - tn: 21046.0000 - fn: 1954.0000 - accuracy: 0.9150 train_balacc 0.9147007750624708\n",
      " val_balacc 0.9022530916483145\n",
      "\n",
      "Epoch 10: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2059 - tp: 21597.0000 - fp: 2014.0000 - tn: 21597.0000 - fn: 2014.0000 - accuracy: 0.9147 - val_loss: 0.2126 - val_tp: 5326.0000 - val_fp: 577.0000 - val_tn: 5326.0000 - val_fn: 577.0000 - val_accuracy: 0.9023 - train_sensitivity: 0.9147 - train_specificity: 0.9147 - train_balacc: 0.9147 - val_sensitivity: 0.9023 - val_specificity: 0.9023 - val_balacc: 0.9023\n",
      "Epoch 11/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2043 - tp: 20979.0000 - fp: 1921.0000 - tn: 20979.0000 - fn: 1921.0000 - accuracy: 0.9161 train_balacc 0.9162678412604295\n",
      " val_balacc 0.8072166694900897\n",
      "\n",
      "Epoch 11: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2054 - tp: 21634.0000 - fp: 1977.0000 - tn: 21634.0000 - fn: 1977.0000 - accuracy: 0.9163 - val_loss: 0.4526 - val_tp: 4765.0000 - val_fp: 1138.0000 - val_tn: 4765.0000 - val_fn: 1138.0000 - val_accuracy: 0.8072 - train_sensitivity: 0.9163 - train_specificity: 0.9163 - train_balacc: 0.9163 - val_sensitivity: 0.8072 - val_specificity: 0.8072 - val_balacc: 0.8072\n",
      "Epoch 12/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.2013 - tp: 21280.0000 - fp: 1920.0000 - tn: 21280.0000 - fn: 1920.0000 - accuracy: 0.9172 train_balacc 0.9167760789462539\n",
      " val_balacc 0.9119091987125191\n",
      "\n",
      "Epoch 12: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2029 - tp: 21646.0000 - fp: 1965.0000 - tn: 21646.0000 - fn: 1965.0000 - accuracy: 0.9168 - val_loss: 0.2528 - val_tp: 5383.0000 - val_fp: 520.0000 - val_tn: 5383.0000 - val_fn: 520.0000 - val_accuracy: 0.9119 - train_sensitivity: 0.9168 - train_specificity: 0.9168 - train_balacc: 0.9168 - val_sensitivity: 0.9119 - val_specificity: 0.9119 - val_balacc: 0.9119\n",
      "Epoch 13/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.2008 - tp: 20946.0000 - fp: 1954.0000 - tn: 20946.0000 - fn: 1954.0000 - accuracy: 0.9147 train_balacc 0.9149972470458685\n",
      " val_balacc 0.8651533118753176\n",
      "\n",
      "Epoch 13: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2002 - tp: 21604.0000 - fp: 2007.0000 - tn: 21604.0000 - fn: 2007.0000 - accuracy: 0.9150 - val_loss: 0.3240 - val_tp: 5107.0000 - val_fp: 796.0000 - val_tn: 5107.0000 - val_fn: 796.0000 - val_accuracy: 0.8652 - train_sensitivity: 0.9150 - train_specificity: 0.9150 - train_balacc: 0.9150 - val_sensitivity: 0.8652 - val_specificity: 0.8652 - val_balacc: 0.8652\n",
      "Epoch 14/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1991 - tp: 20909.0000 - fp: 1891.0000 - tn: 20909.0000 - fn: 1891.0000 - accuracy: 0.9171 train_balacc 0.9170301977891661\n",
      " val_balacc 0.8480433677790954\n",
      "\n",
      "Epoch 14: val_balacc did not improve from 0.94528\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1986 - tp: 21652.0000 - fp: 1959.0000 - tn: 21652.0000 - fn: 1959.0000 - accuracy: 0.9170 - val_loss: 0.2994 - val_tp: 5006.0000 - val_fp: 897.0000 - val_tn: 5006.0000 - val_fn: 897.0000 - val_accuracy: 0.8480 - train_sensitivity: 0.9170 - train_specificity: 0.9170 - train_balacc: 0.9170 - val_sensitivity: 0.8480 - val_specificity: 0.8480 - val_balacc: 0.8480\n",
      "Epoch 15/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.2056 - tp: 21637.0000 - fp: 1963.0000 - tn: 21637.0000 - fn: 1963.0000 - accuracy: 0.9168 train_balacc 0.9168184320867392\n",
      " val_balacc 0.9500254108080637\n",
      "\n",
      "Epoch 15: val_balacc improved from 0.94528 to 0.95003, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.2055 - tp: 21647.0000 - fp: 1964.0000 - tn: 21647.0000 - fn: 1964.0000 - accuracy: 0.9168 - val_loss: 0.1530 - val_tp: 5608.0000 - val_fp: 295.0000 - val_tn: 5608.0000 - val_fn: 295.0000 - val_accuracy: 0.9500 - train_sensitivity: 0.9168 - train_specificity: 0.9168 - train_balacc: 0.9168 - val_sensitivity: 0.9500 - val_specificity: 0.9500 - val_balacc: 0.9500\n",
      "Epoch 16/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1993 - tp: 21641.0000 - fp: 1959.0000 - tn: 21641.0000 - fn: 1959.0000 - accuracy: 0.9170 train_balacc 0.9170301977891661\n",
      " val_balacc 0.9344401151956632\n",
      "\n",
      "Epoch 16: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1992 - tp: 21652.0000 - fp: 1959.0000 - tn: 21652.0000 - fn: 1959.0000 - accuracy: 0.9170 - val_loss: 0.1647 - val_tp: 5516.0000 - val_fp: 387.0000 - val_tn: 5516.0000 - val_fn: 387.0000 - val_accuracy: 0.9344 - train_sensitivity: 0.9170 - train_specificity: 0.9170 - train_balacc: 0.9170 - val_sensitivity: 0.9344 - val_specificity: 0.9344 - val_balacc: 0.9344\n",
      "Epoch 17/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1984 - tp: 21703.0000 - fp: 1897.0000 - tn: 21703.0000 - fn: 1897.0000 - accuracy: 0.9196 train_balacc 0.9196560924992588\n",
      " val_balacc 0.9324072505505675\n",
      "\n",
      "Epoch 17: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1983 - tp: 21714.0000 - fp: 1897.0000 - tn: 21714.0000 - fn: 1897.0000 - accuracy: 0.9197 - val_loss: 0.1798 - val_tp: 5504.0000 - val_fp: 399.0000 - val_tn: 5504.0000 - val_fn: 399.0000 - val_accuracy: 0.9324 - train_sensitivity: 0.9197 - train_specificity: 0.9197 - train_balacc: 0.9197 - val_sensitivity: 0.9324 - val_specificity: 0.9324 - val_balacc: 0.9324\n",
      "Epoch 18/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.2038 - tp: 21125.0000 - fp: 1975.0000 - tn: 21125.0000 - fn: 1975.0000 - accuracy: 0.9145 train_balacc 0.9146160687815001\n",
      " val_balacc 0.9357953582923937\n",
      "\n",
      "Epoch 18: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.2039 - tp: 21595.0000 - fp: 2016.0000 - tn: 21595.0000 - fn: 2016.0000 - accuracy: 0.9146 - val_loss: 0.1809 - val_tp: 5524.0000 - val_fp: 379.0000 - val_tn: 5524.0000 - val_fn: 379.0000 - val_accuracy: 0.9358 - train_sensitivity: 0.9146 - train_specificity: 0.9146 - train_balacc: 0.9146 - val_sensitivity: 0.9358 - val_specificity: 0.9358 - val_balacc: 0.9358\n",
      "Epoch 19/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1966 - tp: 21023.0000 - fp: 1877.0000 - tn: 21023.0000 - fn: 1877.0000 - accuracy: 0.9180 train_balacc 0.9175807886154759\n",
      " val_balacc 0.8737929866169745\n",
      "\n",
      "Epoch 19: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1972 - tp: 21665.0000 - fp: 1946.0000 - tn: 21665.0000 - fn: 1946.0000 - accuracy: 0.9176 - val_loss: 0.2382 - val_tp: 5158.0000 - val_fp: 745.0000 - val_tn: 5158.0000 - val_fn: 745.0000 - val_accuracy: 0.8738 - train_sensitivity: 0.9176 - train_specificity: 0.9176 - train_balacc: 0.9176 - val_sensitivity: 0.8738 - val_specificity: 0.8738 - val_balacc: 0.8738\n",
      "Epoch 20/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.2044 - tp: 20877.0000 - fp: 1923.0000 - tn: 20877.0000 - fn: 1923.0000 - accuracy: 0.9157 train_balacc 0.9156748972936343\n",
      " val_balacc 0.9068270370997797\n",
      "\n",
      "Epoch 20: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2043 - tp: 21620.0000 - fp: 1991.0000 - tn: 21620.0000 - fn: 1991.0000 - accuracy: 0.9157 - val_loss: 0.2075 - val_tp: 5353.0000 - val_fp: 550.0000 - val_tn: 5353.0000 - val_fn: 550.0000 - val_accuracy: 0.9068 - train_sensitivity: 0.9157 - train_specificity: 0.9157 - train_balacc: 0.9157 - val_sensitivity: 0.9068 - val_specificity: 0.9068 - val_balacc: 0.9068\n",
      "Epoch 21/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.2033 - tp: 21080.0000 - fp: 1920.0000 - tn: 21080.0000 - fn: 1920.0000 - accuracy: 0.9165 train_balacc 0.9163949006818856\n",
      " val_balacc 0.8820938505844486\n",
      "\n",
      "Epoch 21: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2034 - tp: 21637.0000 - fp: 1974.0000 - tn: 21637.0000 - fn: 1974.0000 - accuracy: 0.9164 - val_loss: 0.2317 - val_tp: 5207.0000 - val_fp: 696.0000 - val_tn: 5207.0000 - val_fn: 696.0000 - val_accuracy: 0.8821 - train_sensitivity: 0.9164 - train_specificity: 0.9164 - train_balacc: 0.9164 - val_sensitivity: 0.8821 - val_specificity: 0.8821 - val_balacc: 0.8821\n",
      "Epoch 22/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1975 - tp: 21057.0000 - fp: 1943.0000 - tn: 21057.0000 - fn: 1943.0000 - accuracy: 0.9155 train_balacc 0.9153784253102367\n",
      " val_balacc 0.945282059969507\n",
      "\n",
      "Epoch 22: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1972 - tp: 21613.0000 - fp: 1998.0000 - tn: 21613.0000 - fn: 1998.0000 - accuracy: 0.9154 - val_loss: 0.1578 - val_tp: 5580.0000 - val_fp: 323.0000 - val_tn: 5580.0000 - val_fn: 323.0000 - val_accuracy: 0.9453 - train_sensitivity: 0.9154 - train_specificity: 0.9154 - train_balacc: 0.9154 - val_sensitivity: 0.9453 - val_specificity: 0.9453 - val_balacc: 0.9453\n",
      "Epoch 23/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1994 - tp: 21519.0000 - fp: 1881.0000 - tn: 21519.0000 - fn: 1881.0000 - accuracy: 0.9196 train_balacc 0.919571386218288\n",
      " val_balacc 0.7447060816533966\n",
      "\n",
      "Epoch 23: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1991 - tp: 21712.0000 - fp: 1899.0000 - tn: 21712.0000 - fn: 1899.0000 - accuracy: 0.9196 - val_loss: 1.1337 - val_tp: 4396.0000 - val_fp: 1507.0000 - val_tn: 4396.0000 - val_fn: 1507.0000 - val_accuracy: 0.7447 - train_sensitivity: 0.9196 - train_specificity: 0.9196 - train_balacc: 0.9196 - val_sensitivity: 0.7447 - val_specificity: 0.7447 - val_balacc: 0.7447\n",
      "Epoch 24/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.2005 - tp: 21564.0000 - fp: 1936.0000 - tn: 21564.0000 - fn: 1936.0000 - accuracy: 0.9176 train_balacc 0.9174113760535344\n",
      " val_balacc 0.9368117906149416\n",
      "\n",
      "Epoch 24: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2007 - tp: 21661.0000 - fp: 1950.0000 - tn: 21661.0000 - fn: 1950.0000 - accuracy: 0.9174 - val_loss: 0.1675 - val_tp: 5530.0000 - val_fp: 373.0000 - val_tn: 5530.0000 - val_fn: 373.0000 - val_accuracy: 0.9368 - train_sensitivity: 0.9174 - train_specificity: 0.9174 - train_balacc: 0.9174 - val_sensitivity: 0.9368 - val_specificity: 0.9368 - val_balacc: 0.9368\n",
      "Epoch 25/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1959 - tp: 20916.0000 - fp: 1884.0000 - tn: 20916.0000 - fn: 1884.0000 - accuracy: 0.9174 train_balacc 0.9180043200203295\n",
      " val_balacc 0.9334236828731154\n",
      "\n",
      "Epoch 25: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1948 - tp: 21675.0000 - fp: 1936.0000 - tn: 21675.0000 - fn: 1936.0000 - accuracy: 0.9180 - val_loss: 0.2048 - val_tp: 5510.0000 - val_fp: 393.0000 - val_tn: 5510.0000 - val_fn: 393.0000 - val_accuracy: 0.9334 - train_sensitivity: 0.9180 - train_specificity: 0.9180 - train_balacc: 0.9180 - val_sensitivity: 0.9334 - val_specificity: 0.9334 - val_balacc: 0.9334\n",
      "Epoch 26/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1966 - tp: 21086.0000 - fp: 1914.0000 - tn: 21086.0000 - fn: 1914.0000 - accuracy: 0.9168 train_balacc 0.91690313836771\n",
      " val_balacc 0.922242927325089\n",
      "\n",
      "Epoch 26: val_balacc did not improve from 0.95003\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1964 - tp: 21649.0000 - fp: 1962.0000 - tn: 21649.0000 - fn: 1962.0000 - accuracy: 0.9169 - val_loss: 0.2167 - val_tp: 5444.0000 - val_fp: 459.0000 - val_tn: 5444.0000 - val_fn: 459.0000 - val_accuracy: 0.9222 - train_sensitivity: 0.9169 - train_specificity: 0.9169 - train_balacc: 0.9169 - val_sensitivity: 0.9222 - val_specificity: 0.9222 - val_balacc: 0.9222\n",
      "Epoch 27/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1960 - tp: 20980.0000 - fp: 1820.0000 - tn: 20980.0000 - fn: 1820.0000 - accuracy: 0.9202 train_balacc 0.9203337427470247\n",
      " val_balacc 0.9557851939691682\n",
      "\n",
      "Epoch 27: val_balacc improved from 0.95003 to 0.95579, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1953 - tp: 21730.0000 - fp: 1881.0000 - tn: 21730.0000 - fn: 1881.0000 - accuracy: 0.9203 - val_loss: 0.1487 - val_tp: 5642.0000 - val_fp: 261.0000 - val_tn: 5642.0000 - val_fn: 261.0000 - val_accuracy: 0.9558 - train_sensitivity: 0.9203 - train_specificity: 0.9203 - train_balacc: 0.9203 - val_sensitivity: 0.9558 - val_specificity: 0.9558 - val_balacc: 0.9558\n",
      "Epoch 28/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1975 - tp: 21731.0000 - fp: 1869.0000 - tn: 21731.0000 - fn: 1869.0000 - accuracy: 0.9208 train_balacc 0.9207996272923638\n",
      " val_balacc 0.9388446552600372\n",
      "\n",
      "Epoch 28: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1976 - tp: 21741.0000 - fp: 1870.0000 - tn: 21741.0000 - fn: 1870.0000 - accuracy: 0.9208 - val_loss: 0.2034 - val_tp: 5542.0000 - val_fp: 361.0000 - val_tn: 5542.0000 - val_fn: 361.0000 - val_accuracy: 0.9388 - train_sensitivity: 0.9208 - train_specificity: 0.9208 - train_balacc: 0.9208 - val_sensitivity: 0.9388 - val_specificity: 0.9388 - val_balacc: 0.9388\n",
      "Epoch 29/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.2001 - tp: 21651.0000 - fp: 1960.0000 - tn: 21651.0000 - fn: 1960.0000 - accuracy: 0.9170 train_balacc 0.9169878446486807\n",
      " val_balacc 0.8912417414873793\n",
      "\n",
      "Epoch 29: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.2001 - tp: 21651.0000 - fp: 1960.0000 - tn: 21651.0000 - fn: 1960.0000 - accuracy: 0.9170 - val_loss: 0.2337 - val_tp: 5261.0000 - val_fp: 642.0000 - val_tn: 5261.0000 - val_fn: 642.0000 - val_accuracy: 0.8912 - train_sensitivity: 0.9170 - train_specificity: 0.9170 - train_balacc: 0.9170 - val_sensitivity: 0.8912 - val_specificity: 0.8912 - val_balacc: 0.8912\n",
      "Epoch 30/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1919 - tp: 21229.0000 - fp: 1871.0000 - tn: 21229.0000 - fn: 1871.0000 - accuracy: 0.9190 train_balacc 0.9182160857227564\n",
      " val_balacc 0.8970015246484838\n",
      "\n",
      "Epoch 30: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1928 - tp: 21680.0000 - fp: 1931.0000 - tn: 21680.0000 - fn: 1931.0000 - accuracy: 0.9182 - val_loss: 0.2597 - val_tp: 5295.0000 - val_fp: 608.0000 - val_tn: 5295.0000 - val_fn: 608.0000 - val_accuracy: 0.8970 - train_sensitivity: 0.9182 - train_specificity: 0.9182 - train_balacc: 0.9182 - val_sensitivity: 0.8970 - val_specificity: 0.8970 - val_balacc: 0.8970\n",
      "Epoch 31/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1964 - tp: 20996.0000 - fp: 1804.0000 - tn: 20996.0000 - fn: 1804.0000 - accuracy: 0.9209 train_balacc 0.9209690398543052\n",
      " val_balacc 0.8231407758766729\n",
      "\n",
      "Epoch 31: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1960 - tp: 21745.0000 - fp: 1866.0000 - tn: 21745.0000 - fn: 1866.0000 - accuracy: 0.9210 - val_loss: 0.3183 - val_tp: 4859.0000 - val_fp: 1044.0000 - val_tn: 4859.0000 - val_fn: 1044.0000 - val_accuracy: 0.8231 - train_sensitivity: 0.9210 - train_specificity: 0.9210 - train_balacc: 0.9210 - val_sensitivity: 0.8231 - val_specificity: 0.8231 - val_balacc: 0.8231\n",
      "Epoch 32/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1951 - tp: 21708.0000 - fp: 1892.0000 - tn: 21708.0000 - fn: 1892.0000 - accuracy: 0.9198 train_balacc 0.9198678582016857\n",
      " val_balacc 0.9180077926478062\n",
      "\n",
      "Epoch 32: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1951 - tp: 21719.0000 - fp: 1892.0000 - tn: 21719.0000 - fn: 1892.0000 - accuracy: 0.9199 - val_loss: 0.2079 - val_tp: 5419.0000 - val_fp: 484.0000 - val_tn: 5419.0000 - val_fn: 484.0000 - val_accuracy: 0.9180 - train_sensitivity: 0.9199 - train_specificity: 0.9199 - train_balacc: 0.9199 - val_sensitivity: 0.9180 - val_specificity: 0.9180 - val_balacc: 0.9180\n",
      "Epoch 33/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1989 - tp: 21283.0000 - fp: 1917.0000 - tn: 21283.0000 - fn: 1917.0000 - accuracy: 0.9174 train_balacc 0.917707848036932\n",
      " val_balacc 0.9269862781636456\n",
      "\n",
      "Epoch 33: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1989 - tp: 21668.0000 - fp: 1943.0000 - tn: 21668.0000 - fn: 1943.0000 - accuracy: 0.9177 - val_loss: 0.1954 - val_tp: 5472.0000 - val_fp: 431.0000 - val_tn: 5472.0000 - val_fn: 431.0000 - val_accuracy: 0.9270 - train_sensitivity: 0.9177 - train_specificity: 0.9177 - train_balacc: 0.9177 - val_sensitivity: 0.9270 - val_specificity: 0.9270 - val_balacc: 0.9270\n",
      "Epoch 34/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1934 - tp: 21182.0000 - fp: 1818.0000 - tn: 21182.0000 - fn: 1818.0000 - accuracy: 0.9210 train_balacc 0.9208843335733344\n",
      " val_balacc 0.891580552261562\n",
      "\n",
      "Epoch 34: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1948 - tp: 21743.0000 - fp: 1868.0000 - tn: 21743.0000 - fn: 1868.0000 - accuracy: 0.9209 - val_loss: 0.2314 - val_tp: 5263.0000 - val_fp: 640.0000 - val_tn: 5263.0000 - val_fn: 640.0000 - val_accuracy: 0.8916 - train_sensitivity: 0.9209 - train_specificity: 0.9209 - train_balacc: 0.9209 - val_sensitivity: 0.8916 - val_specificity: 0.8916 - val_balacc: 0.8916\n",
      "Epoch 35/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1940 - tp: 21183.0000 - fp: 1817.0000 - tn: 21183.0000 - fn: 1817.0000 - accuracy: 0.9210 train_balacc 0.9214349243996443\n",
      " val_balacc 0.933762493647298\n",
      "\n",
      "Epoch 35: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1931 - tp: 21756.0000 - fp: 1855.0000 - tn: 21756.0000 - fn: 1855.0000 - accuracy: 0.9214 - val_loss: 0.1568 - val_tp: 5512.0000 - val_fp: 391.0000 - val_tn: 5512.0000 - val_fn: 391.0000 - val_accuracy: 0.9338 - train_sensitivity: 0.9214 - train_specificity: 0.9214 - train_balacc: 0.9214 - val_sensitivity: 0.9338 - val_specificity: 0.9338 - val_balacc: 0.9338\n",
      "Epoch 36/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1912 - tp: 21263.0000 - fp: 1837.0000 - tn: 21263.0000 - fn: 1837.0000 - accuracy: 0.9205 train_balacc 0.9200372707636271\n",
      " val_balacc 0.9268168727765543\n",
      "\n",
      "Epoch 36: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1920 - tp: 21723.0000 - fp: 1888.0000 - tn: 21723.0000 - fn: 1888.0000 - accuracy: 0.9200 - val_loss: 0.1824 - val_tp: 5471.0000 - val_fp: 432.0000 - val_tn: 5471.0000 - val_fn: 432.0000 - val_accuracy: 0.9268 - train_sensitivity: 0.9200 - train_specificity: 0.9200 - train_balacc: 0.9200 - val_sensitivity: 0.9268 - val_specificity: 0.9268 - val_balacc: 0.9268\n",
      "Epoch 37/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1954 - tp: 21055.0000 - fp: 1845.0000 - tn: 21055.0000 - fn: 1845.0000 - accuracy: 0.9194 train_balacc 0.9187666765490661\n",
      " val_balacc 0.8448246654243605\n",
      "\n",
      "Epoch 37: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1958 - tp: 21693.0000 - fp: 1918.0000 - tn: 21693.0000 - fn: 1918.0000 - accuracy: 0.9188 - val_loss: 0.3864 - val_tp: 4987.0000 - val_fp: 916.0000 - val_tn: 4987.0000 - val_fn: 916.0000 - val_accuracy: 0.8448 - train_sensitivity: 0.9188 - train_specificity: 0.9188 - train_balacc: 0.9188 - val_sensitivity: 0.8448 - val_specificity: 0.8448 - val_balacc: 0.8448\n",
      "Epoch 38/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1906 - tp: 21184.0000 - fp: 1816.0000 - tn: 21184.0000 - fn: 1816.0000 - accuracy: 0.9210 train_balacc 0.9213925712591589\n",
      " val_balacc 0.8805692021006268\n",
      "\n",
      "Epoch 38: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1906 - tp: 21755.0000 - fp: 1856.0000 - tn: 21755.0000 - fn: 1856.0000 - accuracy: 0.9214 - val_loss: 0.2584 - val_tp: 5198.0000 - val_fp: 705.0000 - val_tn: 5198.0000 - val_fn: 705.0000 - val_accuracy: 0.8806 - train_sensitivity: 0.9214 - train_specificity: 0.9214 - train_balacc: 0.9214 - val_sensitivity: 0.8806 - val_specificity: 0.8806 - val_balacc: 0.8806\n",
      "Epoch 39/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1892 - tp: 21183.0000 - fp: 1817.0000 - tn: 21183.0000 - fn: 1817.0000 - accuracy: 0.9210 train_balacc 0.9215619838211003\n",
      " val_balacc 0.8624428256818567\n",
      "\n",
      "Epoch 39: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1885 - tp: 21759.0000 - fp: 1852.0000 - tn: 21759.0000 - fn: 1852.0000 - accuracy: 0.9216 - val_loss: 0.3278 - val_tp: 5091.0000 - val_fp: 812.0000 - val_tn: 5091.0000 - val_fn: 812.0000 - val_accuracy: 0.8624 - train_sensitivity: 0.9216 - train_specificity: 0.9216 - train_balacc: 0.9216 - val_sensitivity: 0.8624 - val_specificity: 0.8624 - val_balacc: 0.8624\n",
      "Epoch 40/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1880 - tp: 21072.0000 - fp: 1828.0000 - tn: 21072.0000 - fn: 1828.0000 - accuracy: 0.9202 train_balacc 0.9196984456397442\n",
      " val_balacc 0.9383364390987633\n",
      "\n",
      "Epoch 40: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1890 - tp: 21715.0000 - fp: 1896.0000 - tn: 21715.0000 - fn: 1896.0000 - accuracy: 0.9197 - val_loss: 0.1762 - val_tp: 5539.0000 - val_fp: 364.0000 - val_tn: 5539.0000 - val_fn: 364.0000 - val_accuracy: 0.9383 - train_sensitivity: 0.9197 - train_specificity: 0.9197 - train_balacc: 0.9197 - val_sensitivity: 0.9383 - val_specificity: 0.9383 - val_balacc: 0.9383\n",
      "Epoch 41/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1933 - tp: 21015.0000 - fp: 1885.0000 - tn: 21015.0000 - fn: 1885.0000 - accuracy: 0.9177 train_balacc 0.9178772605988734\n",
      " val_balacc 0.9313908182280196\n",
      "\n",
      "Epoch 41: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1922 - tp: 21672.0000 - fp: 1939.0000 - tn: 21672.0000 - fn: 1939.0000 - accuracy: 0.9179 - val_loss: 0.1681 - val_tp: 5498.0000 - val_fp: 405.0000 - val_tn: 5498.0000 - val_fn: 405.0000 - val_accuracy: 0.9314 - train_sensitivity: 0.9179 - train_specificity: 0.9179 - train_balacc: 0.9179 - val_sensitivity: 0.9314 - val_specificity: 0.9314 - val_balacc: 0.9314\n",
      "Epoch 42/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1922 - tp: 21085.0000 - fp: 1815.0000 - tn: 21085.0000 - fn: 1815.0000 - accuracy: 0.9207 train_balacc 0.9205031553089662\n",
      " val_balacc 0.9259698458410978\n",
      "\n",
      "Epoch 42: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1922 - tp: 21734.0000 - fp: 1877.0000 - tn: 21734.0000 - fn: 1877.0000 - accuracy: 0.9205 - val_loss: 0.2120 - val_tp: 5466.0000 - val_fp: 437.0000 - val_tn: 5466.0000 - val_fn: 437.0000 - val_accuracy: 0.9260 - train_sensitivity: 0.9205 - train_specificity: 0.9205 - train_balacc: 0.9205 - val_sensitivity: 0.9260 - val_specificity: 0.9260 - val_balacc: 0.9260\n",
      "Epoch 43/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1940 - tp: 21149.0000 - fp: 1851.0000 - tn: 21149.0000 - fn: 1851.0000 - accuracy: 0.9195 train_balacc 0.9196560924992588\n",
      " val_balacc 0.9185160088090801\n",
      "\n",
      "Epoch 43: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1942 - tp: 21714.0000 - fp: 1897.0000 - tn: 21714.0000 - fn: 1897.0000 - accuracy: 0.9197 - val_loss: 0.1963 - val_tp: 5422.0000 - val_fp: 481.0000 - val_tn: 5422.0000 - val_fn: 481.0000 - val_accuracy: 0.9185 - train_sensitivity: 0.9197 - train_specificity: 0.9197 - train_balacc: 0.9197 - val_sensitivity: 0.9185 - val_specificity: 0.9185 - val_balacc: 0.9185\n",
      "Epoch 44/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1950 - tp: 21703.0000 - fp: 1908.0000 - tn: 21703.0000 - fn: 1908.0000 - accuracy: 0.9192 train_balacc 0.9191902079539198\n",
      " val_balacc 0.9093681179061495\n",
      "\n",
      "Epoch 44: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1950 - tp: 21703.0000 - fp: 1908.0000 - tn: 21703.0000 - fn: 1908.0000 - accuracy: 0.9192 - val_loss: 0.2421 - val_tp: 5368.0000 - val_fp: 535.0000 - val_tn: 5368.0000 - val_fn: 535.0000 - val_accuracy: 0.9094 - train_sensitivity: 0.9192 - train_specificity: 0.9192 - train_balacc: 0.9192 - val_sensitivity: 0.9094 - val_specificity: 0.9094 - val_balacc: 0.9094\n",
      "Epoch 45/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1869 - tp: 21312.0000 - fp: 1788.0000 - tn: 21312.0000 - fn: 1788.0000 - accuracy: 0.9226 train_balacc 0.9220702215069247\n",
      " val_balacc 0.9015754700999492\n",
      "\n",
      "Epoch 45: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1880 - tp: 21771.0000 - fp: 1840.0000 - tn: 21771.0000 - fn: 1840.0000 - accuracy: 0.9221 - val_loss: 0.2508 - val_tp: 5322.0000 - val_fp: 581.0000 - val_tn: 5322.0000 - val_fn: 581.0000 - val_accuracy: 0.9016 - train_sensitivity: 0.9221 - train_specificity: 0.9221 - train_balacc: 0.9221 - val_sensitivity: 0.9016 - val_specificity: 0.9016 - val_balacc: 0.9016\n",
      "Epoch 46/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1910 - tp: 20995.0000 - fp: 1805.0000 - tn: 20995.0000 - fn: 1805.0000 - accuracy: 0.9208 train_balacc 0.92037609588751\n",
      " val_balacc 0.9105539556157886\n",
      "\n",
      "Epoch 46: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1921 - tp: 21731.0000 - fp: 1880.0000 - tn: 21731.0000 - fn: 1880.0000 - accuracy: 0.9204 - val_loss: 0.2166 - val_tp: 5375.0000 - val_fp: 528.0000 - val_tn: 5375.0000 - val_fn: 528.0000 - val_accuracy: 0.9106 - train_sensitivity: 0.9204 - train_specificity: 0.9204 - train_balacc: 0.9204 - val_sensitivity: 0.9106 - val_specificity: 0.9106 - val_balacc: 0.9106\n",
      "Epoch 47/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1902 - tp: 21204.0000 - fp: 1796.0000 - tn: 21204.0000 - fn: 1796.0000 - accuracy: 0.9219 train_balacc 0.9216890432425564\n",
      " val_balacc 0.9130950364221583\n",
      "\n",
      "Epoch 47: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1906 - tp: 21762.0000 - fp: 1849.0000 - tn: 21762.0000 - fn: 1849.0000 - accuracy: 0.9217 - val_loss: 0.2093 - val_tp: 5390.0000 - val_fp: 513.0000 - val_tn: 5390.0000 - val_fn: 513.0000 - val_accuracy: 0.9131 - train_sensitivity: 0.9217 - train_specificity: 0.9217 - train_balacc: 0.9217 - val_sensitivity: 0.9131 - val_specificity: 0.9131 - val_balacc: 0.9131\n",
      "Epoch 48/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1865 - tp: 21228.0000 - fp: 1772.0000 - tn: 21228.0000 - fn: 1772.0000 - accuracy: 0.9230 train_balacc 0.9222819872093516\n",
      " val_balacc 0.9117397933254278\n",
      "\n",
      "Epoch 48: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1879 - tp: 21776.0000 - fp: 1835.0000 - tn: 21776.0000 - fn: 1835.0000 - accuracy: 0.9223 - val_loss: 0.2236 - val_tp: 5382.0000 - val_fp: 521.0000 - val_tn: 5382.0000 - val_fn: 521.0000 - val_accuracy: 0.9117 - train_sensitivity: 0.9223 - train_specificity: 0.9223 - train_balacc: 0.9223 - val_sensitivity: 0.9117 - val_specificity: 0.9117 - val_balacc: 0.9117\n",
      "Epoch 49/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1913 - tp: 21387.0000 - fp: 1813.0000 - tn: 21387.0000 - fn: 1813.0000 - accuracy: 0.9219 train_balacc 0.9213502181186735\n",
      " val_balacc 0.9247840081314586\n",
      "\n",
      "Epoch 49: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1925 - tp: 21754.0000 - fp: 1857.0000 - tn: 21754.0000 - fn: 1857.0000 - accuracy: 0.9214 - val_loss: 0.2117 - val_tp: 5459.0000 - val_fp: 444.0000 - val_tn: 5459.0000 - val_fn: 444.0000 - val_accuracy: 0.9248 - train_sensitivity: 0.9214 - train_specificity: 0.9214 - train_balacc: 0.9214 - val_sensitivity: 0.9248 - val_specificity: 0.9248 - val_balacc: 0.9248\n",
      "Epoch 50/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1885 - tp: 21368.0000 - fp: 1832.0000 - tn: 21368.0000 - fn: 1832.0000 - accuracy: 0.9210 train_balacc 0.9210537461352759\n",
      " val_balacc 0.893782822293749\n",
      "\n",
      "Epoch 50: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1885 - tp: 21747.0000 - fp: 1864.0000 - tn: 21747.0000 - fn: 1864.0000 - accuracy: 0.9211 - val_loss: 0.2171 - val_tp: 5276.0000 - val_fp: 627.0000 - val_tn: 5276.0000 - val_fn: 627.0000 - val_accuracy: 0.8938 - train_sensitivity: 0.9211 - train_specificity: 0.9211 - train_balacc: 0.9211 - val_sensitivity: 0.8938 - val_specificity: 0.8938 - val_balacc: 0.8938\n",
      "Epoch 51/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1896 - tp: 21004.0000 - fp: 1796.0000 - tn: 21004.0000 - fn: 1796.0000 - accuracy: 0.9212 train_balacc 0.9211384524162467\n",
      " val_balacc 0.8666779603591395\n",
      "\n",
      "Epoch 51: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1897 - tp: 21749.0000 - fp: 1862.0000 - tn: 21749.0000 - fn: 1862.0000 - accuracy: 0.9211 - val_loss: 0.2702 - val_tp: 5116.0000 - val_fp: 787.0000 - val_tn: 5116.0000 - val_fn: 787.0000 - val_accuracy: 0.8667 - train_sensitivity: 0.9211 - train_specificity: 0.9211 - train_balacc: 0.9211 - val_sensitivity: 0.8667 - val_specificity: 0.8667 - val_balacc: 0.8667\n",
      "Epoch 52/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1915 - tp: 21460.0000 - fp: 1840.0000 - tn: 21460.0000 - fn: 1840.0000 - accuracy: 0.9210 train_balacc 0.9204608021684808\n",
      " val_balacc 0.9174995764865322\n",
      "\n",
      "Epoch 52: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1920 - tp: 21733.0000 - fp: 1878.0000 - tn: 21733.0000 - fn: 1878.0000 - accuracy: 0.9205 - val_loss: 0.2308 - val_tp: 5416.0000 - val_fp: 487.0000 - val_tn: 5416.0000 - val_fn: 487.0000 - val_accuracy: 0.9175 - train_sensitivity: 0.9205 - train_specificity: 0.9205 - train_balacc: 0.9205 - val_sensitivity: 0.9175 - val_specificity: 0.9175 - val_balacc: 0.9175\n",
      "Epoch 53/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1855 - tp: 21281.0000 - fp: 1819.0000 - tn: 21281.0000 - fn: 1819.0000 - accuracy: 0.9213 train_balacc 0.9212231586972174\n",
      " val_balacc 0.9291885481958326\n",
      "\n",
      "Epoch 53: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1856 - tp: 21751.0000 - fp: 1860.0000 - tn: 21751.0000 - fn: 1860.0000 - accuracy: 0.9212 - val_loss: 0.1966 - val_tp: 5485.0000 - val_fp: 418.0000 - val_tn: 5485.0000 - val_fn: 418.0000 - val_accuracy: 0.9292 - train_sensitivity: 0.9212 - train_specificity: 0.9212 - train_balacc: 0.9212 - val_sensitivity: 0.9292 - val_specificity: 0.9292 - val_balacc: 0.9292\n",
      "Epoch 54/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1911 - tp: 21107.0000 - fp: 1793.0000 - tn: 21107.0000 - fn: 1793.0000 - accuracy: 0.9217 train_balacc 0.9217737495235272\n",
      " val_balacc 0.9354565475182111\n",
      "\n",
      "Epoch 54: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1905 - tp: 21764.0000 - fp: 1847.0000 - tn: 21764.0000 - fn: 1847.0000 - accuracy: 0.9218 - val_loss: 0.1897 - val_tp: 5522.0000 - val_fp: 381.0000 - val_tn: 5522.0000 - val_fn: 381.0000 - val_accuracy: 0.9355 - train_sensitivity: 0.9218 - train_specificity: 0.9218 - train_balacc: 0.9218 - val_sensitivity: 0.9355 - val_specificity: 0.9355 - val_balacc: 0.9355\n",
      "Epoch 55/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1818 - tp: 21063.0000 - fp: 1737.0000 - tn: 21063.0000 - fn: 1737.0000 - accuracy: 0.9238 train_balacc 0.9238067002668248\n",
      " val_balacc 0.9034389293579536\n",
      "\n",
      "Epoch 55: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1811 - tp: 21812.0000 - fp: 1799.0000 - tn: 21812.0000 - fn: 1799.0000 - accuracy: 0.9238 - val_loss: 0.2406 - val_tp: 5333.0000 - val_fp: 570.0000 - val_tn: 5333.0000 - val_fn: 570.0000 - val_accuracy: 0.9034 - train_sensitivity: 0.9238 - train_specificity: 0.9238 - train_balacc: 0.9238 - val_sensitivity: 0.9034 - val_specificity: 0.9034 - val_balacc: 0.9034\n",
      "Epoch 56/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1917 - tp: 21739.0000 - fp: 1861.0000 - tn: 21739.0000 - fn: 1861.0000 - accuracy: 0.9211 train_balacc 0.9211384524162467\n",
      " val_balacc 0.9298661697441979\n",
      "\n",
      "Epoch 56: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1917 - tp: 21749.0000 - fp: 1862.0000 - tn: 21749.0000 - fn: 1862.0000 - accuracy: 0.9211 - val_loss: 0.1869 - val_tp: 5489.0000 - val_fp: 414.0000 - val_tn: 5489.0000 - val_fn: 414.0000 - val_accuracy: 0.9299 - train_sensitivity: 0.9211 - train_specificity: 0.9211 - train_balacc: 0.9211 - val_sensitivity: 0.9299 - val_specificity: 0.9299 - val_balacc: 0.9299\n",
      "Epoch 57/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1909 - tp: 21063.0000 - fp: 1737.0000 - tn: 21063.0000 - fn: 1737.0000 - accuracy: 0.9238 train_balacc 0.924060819109737\n",
      " val_balacc 0.9286803320345587\n",
      "\n",
      "Epoch 57: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1899 - tp: 21818.0000 - fp: 1793.0000 - tn: 21818.0000 - fn: 1793.0000 - accuracy: 0.9241 - val_loss: 0.1824 - val_tp: 5482.0000 - val_fp: 421.0000 - val_tn: 5482.0000 - val_fn: 421.0000 - val_accuracy: 0.9287 - train_sensitivity: 0.9241 - train_specificity: 0.9241 - train_balacc: 0.9241 - val_sensitivity: 0.9287 - val_specificity: 0.9287 - val_balacc: 0.9287\n",
      "Epoch 58/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1940 - tp: 21040.0000 - fp: 1860.0000 - tn: 21040.0000 - fn: 1860.0000 - accuracy: 0.9188 train_balacc 0.9185549108466393\n",
      " val_balacc 0.8788751482297137\n",
      "\n",
      "Epoch 58: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1947 - tp: 21688.0000 - fp: 1923.0000 - tn: 21688.0000 - fn: 1923.0000 - accuracy: 0.9186 - val_loss: 0.2923 - val_tp: 5188.0000 - val_fp: 715.0000 - val_tn: 5188.0000 - val_fn: 715.0000 - val_accuracy: 0.8789 - train_sensitivity: 0.9186 - train_specificity: 0.9186 - train_balacc: 0.9186 - val_sensitivity: 0.8789 - val_specificity: 0.8789 - val_balacc: 0.8789\n",
      "Epoch 59/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1838 - tp: 21793.0000 - fp: 1807.0000 - tn: 21793.0000 - fn: 1807.0000 - accuracy: 0.9234 train_balacc 0.9233408157214857\n",
      " val_balacc 0.8629510418431307\n",
      "\n",
      "Epoch 59: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1839 - tp: 21801.0000 - fp: 1810.0000 - tn: 21801.0000 - fn: 1810.0000 - accuracy: 0.9233 - val_loss: 0.4109 - val_tp: 5094.0000 - val_fp: 809.0000 - val_tn: 5094.0000 - val_fn: 809.0000 - val_accuracy: 0.8630 - train_sensitivity: 0.9233 - train_specificity: 0.9233 - train_balacc: 0.9233 - val_sensitivity: 0.8630 - val_specificity: 0.8630 - val_balacc: 0.8630\n",
      "Epoch 60/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1826 - tp: 21279.0000 - fp: 1721.0000 - tn: 21279.0000 - fn: 1721.0000 - accuracy: 0.9252 train_balacc 0.9254161196052687\n",
      " val_balacc 0.919532441131628\n",
      "\n",
      "Epoch 60: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1824 - tp: 21850.0000 - fp: 1761.0000 - tn: 21850.0000 - fn: 1761.0000 - accuracy: 0.9254 - val_loss: 0.2374 - val_tp: 5428.0000 - val_fp: 475.0000 - val_tn: 5428.0000 - val_fn: 475.0000 - val_accuracy: 0.9195 - train_sensitivity: 0.9254 - train_specificity: 0.9254 - train_balacc: 0.9254 - val_sensitivity: 0.9195 - val_specificity: 0.9195 - val_balacc: 0.9195\n",
      "Epoch 61/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1874 - tp: 21810.0000 - fp: 1790.0000 - tn: 21810.0000 - fn: 1790.0000 - accuracy: 0.9242 train_balacc 0.9241878785311931\n",
      " val_balacc 0.8465187192952736\n",
      "\n",
      "Epoch 61: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1874 - tp: 21821.0000 - fp: 1790.0000 - tn: 21821.0000 - fn: 1790.0000 - accuracy: 0.9242 - val_loss: 0.3475 - val_tp: 4997.0000 - val_fp: 906.0000 - val_tn: 4997.0000 - val_fn: 906.0000 - val_accuracy: 0.8465 - train_sensitivity: 0.9242 - train_specificity: 0.9242 - train_balacc: 0.9242 - val_sensitivity: 0.8465 - val_specificity: 0.8465 - val_balacc: 0.8465\n",
      "Epoch 62/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1859 - tp: 21813.0000 - fp: 1787.0000 - tn: 21813.0000 - fn: 1787.0000 - accuracy: 0.9243 train_balacc 0.9242302316716785\n",
      " val_balacc 0.8856513637133661\n",
      "\n",
      "Epoch 62: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1860 - tp: 21822.0000 - fp: 1789.0000 - tn: 21822.0000 - fn: 1789.0000 - accuracy: 0.9242 - val_loss: 0.2595 - val_tp: 5228.0000 - val_fp: 675.0000 - val_tn: 5228.0000 - val_fn: 675.0000 - val_accuracy: 0.8857 - train_sensitivity: 0.9242 - train_specificity: 0.9242 - train_balacc: 0.9242 - val_sensitivity: 0.8857 - val_specificity: 0.8857 - val_balacc: 0.8857\n",
      "Epoch 63/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1841 - tp: 21461.0000 - fp: 1739.0000 - tn: 21461.0000 - fn: 1739.0000 - accuracy: 0.9250 train_balacc 0.9250772944813858\n",
      " val_balacc 0.8964933084872099\n",
      "\n",
      "Epoch 63: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1837 - tp: 21842.0000 - fp: 1769.0000 - tn: 21842.0000 - fn: 1769.0000 - accuracy: 0.9251 - val_loss: 0.2226 - val_tp: 5292.0000 - val_fp: 611.0000 - val_tn: 5292.0000 - val_fn: 611.0000 - val_accuracy: 0.8965 - train_sensitivity: 0.9251 - train_specificity: 0.9251 - train_balacc: 0.9251 - val_sensitivity: 0.8965 - val_specificity: 0.8965 - val_balacc: 0.8965\n",
      "Epoch 64/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1864 - tp: 21404.0000 - fp: 1796.0000 - tn: 21404.0000 - fn: 1796.0000 - accuracy: 0.9226 train_balacc 0.9227055186142052\n",
      " val_balacc 0.8497374216500084\n",
      "\n",
      "Epoch 64: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1867 - tp: 21786.0000 - fp: 1825.0000 - tn: 21786.0000 - fn: 1825.0000 - accuracy: 0.9227 - val_loss: 0.3558 - val_tp: 5016.0000 - val_fp: 887.0000 - val_tn: 5016.0000 - val_fn: 887.0000 - val_accuracy: 0.8497 - train_sensitivity: 0.9227 - train_specificity: 0.9227 - train_balacc: 0.9227 - val_sensitivity: 0.8497 - val_specificity: 0.8497 - val_balacc: 0.8497\n",
      "Epoch 65/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1916 - tp: 21108.0000 - fp: 1792.0000 - tn: 21108.0000 - fn: 1792.0000 - accuracy: 0.9217 train_balacc 0.9215196306806149\n",
      " val_balacc 0.8634592580044046\n",
      "\n",
      "Epoch 65: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1921 - tp: 21758.0000 - fp: 1853.0000 - tn: 21758.0000 - fn: 1853.0000 - accuracy: 0.9215 - val_loss: 0.3294 - val_tp: 5097.0000 - val_fp: 806.0000 - val_tn: 5097.0000 - val_fn: 806.0000 - val_accuracy: 0.8635 - train_sensitivity: 0.9215 - train_specificity: 0.9215 - train_balacc: 0.9215 - val_sensitivity: 0.8635 - val_specificity: 0.8635 - val_balacc: 0.8635\n",
      "Epoch 66/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1884 - tp: 21257.0000 - fp: 1743.0000 - tn: 21257.0000 - fn: 1743.0000 - accuracy: 0.9242 train_balacc 0.9246961162170175\n",
      " val_balacc 0.7318312722344571\n",
      "\n",
      "Epoch 66: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1894 - tp: 21833.0000 - fp: 1778.0000 - tn: 21833.0000 - fn: 1778.0000 - accuracy: 0.9247 - val_loss: 1.7057 - val_tp: 4320.0000 - val_fp: 1583.0000 - val_tn: 4320.0000 - val_fn: 1583.0000 - val_accuracy: 0.7318 - train_sensitivity: 0.9247 - train_specificity: 0.9247 - train_balacc: 0.9247 - val_sensitivity: 0.7318 - val_specificity: 0.7318 - val_balacc: 0.7318\n",
      "Epoch 67/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1821 - tp: 21851.0000 - fp: 1760.0000 - tn: 21851.0000 - fn: 1760.0000 - accuracy: 0.9255 train_balacc 0.9254584727457541\n",
      " val_balacc 0.7828222937489412\n",
      "\n",
      "Epoch 67: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1821 - tp: 21851.0000 - fp: 1760.0000 - tn: 21851.0000 - fn: 1760.0000 - accuracy: 0.9255 - val_loss: 0.4656 - val_tp: 4621.0000 - val_fp: 1282.0000 - val_tn: 4621.0000 - val_fn: 1282.0000 - val_accuracy: 0.7828 - train_sensitivity: 0.9255 - train_specificity: 0.9255 - train_balacc: 0.9255 - val_sensitivity: 0.7828 - val_specificity: 0.7828 - val_balacc: 0.7828\n",
      "Epoch 68/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1892 - tp: 21082.0000 - fp: 1718.0000 - tn: 21082.0000 - fn: 1718.0000 - accuracy: 0.9246 train_balacc 0.9246114099360467\n",
      " val_balacc 0.9020836862612231\n",
      "\n",
      "Epoch 68: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1893 - tp: 21831.0000 - fp: 1780.0000 - tn: 21831.0000 - fn: 1780.0000 - accuracy: 0.9246 - val_loss: 0.2402 - val_tp: 5325.0000 - val_fp: 578.0000 - val_tn: 5325.0000 - val_fn: 578.0000 - val_accuracy: 0.9021 - train_sensitivity: 0.9246 - train_specificity: 0.9246 - train_balacc: 0.9246 - val_sensitivity: 0.9021 - val_specificity: 0.9021 - val_balacc: 0.9021\n",
      "Epoch 69/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1854 - tp: 21429.0000 - fp: 1771.0000 - tn: 21429.0000 - fn: 1771.0000 - accuracy: 0.9237 train_balacc 0.9233831688619711\n",
      " val_balacc 0.9119091987125191\n",
      "\n",
      "Epoch 69: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1857 - tp: 21802.0000 - fp: 1809.0000 - tn: 21802.0000 - fn: 1809.0000 - accuracy: 0.9234 - val_loss: 0.2363 - val_tp: 5383.0000 - val_fp: 520.0000 - val_tn: 5383.0000 - val_fn: 520.0000 - val_accuracy: 0.9119 - train_sensitivity: 0.9234 - train_specificity: 0.9234 - train_balacc: 0.9234 - val_sensitivity: 0.9119 - val_specificity: 0.9119 - val_balacc: 0.9119\n",
      "Epoch 70/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1873 - tp: 21221.0000 - fp: 1779.0000 - tn: 21221.0000 - fn: 1779.0000 - accuracy: 0.9227 train_balacc 0.9224513997712931\n",
      " val_balacc 0.8959850923259359\n",
      "\n",
      "Epoch 70: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1884 - tp: 21780.0000 - fp: 1831.0000 - tn: 21780.0000 - fn: 1831.0000 - accuracy: 0.9225 - val_loss: 0.2496 - val_tp: 5289.0000 - val_fp: 614.0000 - val_tn: 5289.0000 - val_fn: 614.0000 - val_accuracy: 0.8960 - train_sensitivity: 0.9225 - train_specificity: 0.9225 - train_balacc: 0.9225 - val_sensitivity: 0.8960 - val_specificity: 0.8960 - val_balacc: 0.8960\n",
      "Epoch 71/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1853 - tp: 21135.0000 - fp: 1765.0000 - tn: 21135.0000 - fn: 1765.0000 - accuracy: 0.9229 train_balacc 0.9231714031595443\n",
      " val_balacc 0.905810604777232\n",
      "\n",
      "Epoch 71: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1849 - tp: 21797.0000 - fp: 1814.0000 - tn: 21797.0000 - fn: 1814.0000 - accuracy: 0.9232 - val_loss: 0.2135 - val_tp: 5347.0000 - val_fp: 556.0000 - val_tn: 5347.0000 - val_fn: 556.0000 - val_accuracy: 0.9058 - train_sensitivity: 0.9232 - train_specificity: 0.9232 - train_balacc: 0.9232 - val_sensitivity: 0.9058 - val_specificity: 0.9058 - val_balacc: 0.9058\n",
      "Epoch 72/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1800 - tp: 21261.0000 - fp: 1739.0000 - tn: 21261.0000 - fn: 1739.0000 - accuracy: 0.9244 train_balacc 0.9246114099360467\n",
      " val_balacc 0.8959850923259359\n",
      "\n",
      "Epoch 72: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1800 - tp: 21831.0000 - fp: 1780.0000 - tn: 21831.0000 - fn: 1780.0000 - accuracy: 0.9246 - val_loss: 0.2344 - val_tp: 5289.0000 - val_fp: 614.0000 - val_tn: 5289.0000 - val_fn: 614.0000 - val_accuracy: 0.8960 - train_sensitivity: 0.9246 - train_specificity: 0.9246 - train_balacc: 0.9246 - val_sensitivity: 0.8960 - val_specificity: 0.8960 - val_balacc: 0.8960\n",
      "Epoch 73/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1856 - tp: 21646.0000 - fp: 1754.0000 - tn: 21646.0000 - fn: 1754.0000 - accuracy: 0.9250 train_balacc 0.9251620007623566\n",
      " val_balacc 0.9064882263255971\n",
      "\n",
      "Epoch 73: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1854 - tp: 21844.0000 - fp: 1767.0000 - tn: 21844.0000 - fn: 1767.0000 - accuracy: 0.9252 - val_loss: 0.2076 - val_tp: 5351.0000 - val_fp: 552.0000 - val_tn: 5351.0000 - val_fn: 552.0000 - val_accuracy: 0.9065 - train_sensitivity: 0.9252 - train_specificity: 0.9252 - train_balacc: 0.9252 - val_sensitivity: 0.9065 - val_specificity: 0.9065 - val_balacc: 0.9065\n",
      "Epoch 74/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1844 - tp: 21032.0000 - fp: 1768.0000 - tn: 21032.0000 - fn: 1768.0000 - accuracy: 0.9225 train_balacc 0.9224090466308077\n",
      " val_balacc 0.923936981196002\n",
      "\n",
      "Epoch 74: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1843 - tp: 21779.0000 - fp: 1832.0000 - tn: 21779.0000 - fn: 1832.0000 - accuracy: 0.9224 - val_loss: 0.2056 - val_tp: 5454.0000 - val_fp: 449.0000 - val_tn: 5454.0000 - val_fn: 449.0000 - val_accuracy: 0.9239 - train_sensitivity: 0.9224 - train_specificity: 0.9224 - train_balacc: 0.9224 - val_sensitivity: 0.9239 - val_specificity: 0.9239 - val_balacc: 0.9239\n",
      "Epoch 75/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1775 - tp: 21333.0000 - fp: 1667.0000 - tn: 21333.0000 - fn: 1667.0000 - accuracy: 0.9275 train_balacc 0.9270255389437126\n",
      " val_balacc 0.8580382856174826\n",
      "\n",
      "Epoch 75: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1774 - tp: 21888.0000 - fp: 1723.0000 - tn: 21888.0000 - fn: 1723.0000 - accuracy: 0.9270 - val_loss: 0.3228 - val_tp: 5065.0000 - val_fp: 838.0000 - val_tn: 5065.0000 - val_fn: 838.0000 - val_accuracy: 0.8580 - train_sensitivity: 0.9270 - train_specificity: 0.9270 - train_balacc: 0.9270 - val_sensitivity: 0.8580 - val_specificity: 0.8580 - val_balacc: 0.8580\n",
      "Epoch 76/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1851 - tp: 21193.0000 - fp: 1707.0000 - tn: 21193.0000 - fn: 1707.0000 - accuracy: 0.9255 train_balacc 0.9258820041506077\n",
      " val_balacc 0.9274944943249195\n",
      "\n",
      "Epoch 76: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1840 - tp: 21861.0000 - fp: 1750.0000 - tn: 21861.0000 - fn: 1750.0000 - accuracy: 0.9259 - val_loss: 0.1703 - val_tp: 5475.0000 - val_fp: 428.0000 - val_tn: 5475.0000 - val_fn: 428.0000 - val_accuracy: 0.9275 - train_sensitivity: 0.9259 - train_specificity: 0.9259 - train_balacc: 0.9259 - val_sensitivity: 0.9275 - val_specificity: 0.9275 - val_balacc: 0.9275\n",
      "Epoch 77/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1798 - tp: 21168.0000 - fp: 1732.0000 - tn: 21168.0000 - fn: 1732.0000 - accuracy: 0.9244 train_balacc 0.9246537630765321\n",
      " val_balacc 0.8610875825851262\n",
      "\n",
      "Epoch 77: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1795 - tp: 21832.0000 - fp: 1779.0000 - tn: 21832.0000 - fn: 1779.0000 - accuracy: 0.9247 - val_loss: 0.2719 - val_tp: 5083.0000 - val_fp: 820.0000 - val_tn: 5083.0000 - val_fn: 820.0000 - val_accuracy: 0.8611 - train_sensitivity: 0.9247 - train_specificity: 0.9247 - train_balacc: 0.9247 - val_sensitivity: 0.8611 - val_specificity: 0.8611 - val_balacc: 0.8611\n",
      "Epoch 78/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1867 - tp: 21560.0000 - fp: 1740.0000 - tn: 21560.0000 - fn: 1740.0000 - accuracy: 0.9253 train_balacc 0.9250349413409005\n",
      " val_balacc 0.9398610875825851\n",
      "\n",
      "Epoch 78: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1872 - tp: 21841.0000 - fp: 1770.0000 - tn: 21841.0000 - fn: 1770.0000 - accuracy: 0.9250 - val_loss: 0.1758 - val_tp: 5548.0000 - val_fp: 355.0000 - val_tn: 5548.0000 - val_fn: 355.0000 - val_accuracy: 0.9399 - train_sensitivity: 0.9250 - train_specificity: 0.9250 - train_balacc: 0.9250 - val_sensitivity: 0.9399 - val_specificity: 0.9399 - val_balacc: 0.9399\n",
      "Epoch 79/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1834 - tp: 21776.0000 - fp: 1824.0000 - tn: 21776.0000 - fn: 1824.0000 - accuracy: 0.9227 train_balacc 0.9227055186142052\n",
      " val_balacc 0.9227511434863629\n",
      "\n",
      "Epoch 79: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1834 - tp: 21786.0000 - fp: 1825.0000 - tn: 21786.0000 - fn: 1825.0000 - accuracy: 0.9227 - val_loss: 0.1955 - val_tp: 5447.0000 - val_fp: 456.0000 - val_tn: 5447.0000 - val_fn: 456.0000 - val_accuracy: 0.9228 - train_sensitivity: 0.9227 - train_specificity: 0.9227 - train_balacc: 0.9227 - val_sensitivity: 0.9228 - val_specificity: 0.9228 - val_balacc: 0.9228\n",
      "Epoch 80/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1777 - tp: 21426.0000 - fp: 1674.0000 - tn: 21426.0000 - fn: 1674.0000 - accuracy: 0.9275 train_balacc 0.9280843674558469\n",
      " val_balacc 0.8561748263594783\n",
      "\n",
      "Epoch 80: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1765 - tp: 21913.0000 - fp: 1698.0000 - tn: 21913.0000 - fn: 1698.0000 - accuracy: 0.9281 - val_loss: 0.3379 - val_tp: 5054.0000 - val_fp: 849.0000 - val_tn: 5054.0000 - val_fn: 849.0000 - val_accuracy: 0.8562 - train_sensitivity: 0.9281 - train_specificity: 0.9281 - train_balacc: 0.9281 - val_sensitivity: 0.8562 - val_specificity: 0.8562 - val_balacc: 0.8562\n",
      "Epoch 81/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1815 - tp: 21404.0000 - fp: 1696.0000 - tn: 21404.0000 - fn: 1696.0000 - accuracy: 0.9266 train_balacc 0.9266867138198297\n",
      " val_balacc 0.9152973064543453\n",
      "\n",
      "Epoch 81: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1817 - tp: 21880.0000 - fp: 1731.0000 - tn: 21880.0000 - fn: 1731.0000 - accuracy: 0.9267 - val_loss: 0.2031 - val_tp: 5403.0000 - val_fp: 500.0000 - val_tn: 5403.0000 - val_fn: 500.0000 - val_accuracy: 0.9153 - train_sensitivity: 0.9267 - train_specificity: 0.9267 - train_balacc: 0.9267 - val_sensitivity: 0.9153 - val_specificity: 0.9153 - val_balacc: 0.9153\n",
      "Epoch 82/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1880 - tp: 21122.0000 - fp: 1778.0000 - tn: 21122.0000 - fn: 1778.0000 - accuracy: 0.9224 train_balacc 0.9225784591927492\n",
      " val_balacc 0.9102151448416059\n",
      "\n",
      "Epoch 82: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1879 - tp: 21783.0000 - fp: 1828.0000 - tn: 21783.0000 - fn: 1828.0000 - accuracy: 0.9226 - val_loss: 0.2006 - val_tp: 5373.0000 - val_fp: 530.0000 - val_tn: 5373.0000 - val_fn: 530.0000 - val_accuracy: 0.9102 - train_sensitivity: 0.9226 - train_specificity: 0.9226 - train_balacc: 0.9226 - val_sensitivity: 0.9102 - val_specificity: 0.9102 - val_balacc: 0.9102\n",
      "Epoch 83/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1792 - tp: 21117.0000 - fp: 1683.0000 - tn: 21117.0000 - fn: 1683.0000 - accuracy: 0.9262 train_balacc 0.9264325949769175\n",
      " val_balacc 0.9098763340674233\n",
      "\n",
      "Epoch 83: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1784 - tp: 21874.0000 - fp: 1737.0000 - tn: 21874.0000 - fn: 1737.0000 - accuracy: 0.9264 - val_loss: 0.2211 - val_tp: 5371.0000 - val_fp: 532.0000 - val_tn: 5371.0000 - val_fn: 532.0000 - val_accuracy: 0.9099 - train_sensitivity: 0.9264 - train_specificity: 0.9264 - train_balacc: 0.9264 - val_sensitivity: 0.9099 - val_specificity: 0.9099 - val_balacc: 0.9099\n",
      "Epoch 84/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1800 - tp: 21836.0000 - fp: 1764.0000 - tn: 21836.0000 - fn: 1764.0000 - accuracy: 0.9253 train_balacc 0.9252467070433272\n",
      " val_balacc 0.9139420633576147\n",
      "\n",
      "Epoch 84: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1801 - tp: 21846.0000 - fp: 1765.0000 - tn: 21846.0000 - fn: 1765.0000 - accuracy: 0.9252 - val_loss: 0.2062 - val_tp: 5395.0000 - val_fp: 508.0000 - val_tn: 5395.0000 - val_fn: 508.0000 - val_accuracy: 0.9139 - train_sensitivity: 0.9252 - train_specificity: 0.9252 - train_balacc: 0.9252 - val_sensitivity: 0.9139 - val_specificity: 0.9139 - val_balacc: 0.9139\n",
      "Epoch 85/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1785 - tp: 21948.0000 - fp: 1652.0000 - tn: 21948.0000 - fn: 1652.0000 - accuracy: 0.9300 train_balacc 0.9300326119181738\n",
      " val_balacc 0.9041165509063188\n",
      "\n",
      "Epoch 85: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1784 - tp: 21959.0000 - fp: 1652.0000 - tn: 21959.0000 - fn: 1652.0000 - accuracy: 0.9300 - val_loss: 0.2017 - val_tp: 5337.0000 - val_fp: 566.0000 - val_tn: 5337.0000 - val_fn: 566.0000 - val_accuracy: 0.9041 - train_sensitivity: 0.9300 - train_specificity: 0.9300 - train_balacc: 0.9300 - val_sensitivity: 0.9041 - val_specificity: 0.9041 - val_balacc: 0.9041\n",
      "Epoch 86/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1808 - tp: 21756.0000 - fp: 1744.0000 - tn: 21756.0000 - fn: 1744.0000 - accuracy: 0.9258 train_balacc 0.9257549447291517\n",
      " val_balacc 0.8661697441978655\n",
      "\n",
      "Epoch 86: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1810 - tp: 21858.0000 - fp: 1753.0000 - tn: 21858.0000 - fn: 1753.0000 - accuracy: 0.9258 - val_loss: 0.3064 - val_tp: 5113.0000 - val_fp: 790.0000 - val_tn: 5113.0000 - val_fn: 790.0000 - val_accuracy: 0.8662 - train_sensitivity: 0.9258 - train_specificity: 0.9258 - train_balacc: 0.9258 - val_sensitivity: 0.8662 - val_specificity: 0.8662 - val_balacc: 0.8662\n",
      "Epoch 87/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1795 - tp: 21746.0000 - fp: 1754.0000 - tn: 21746.0000 - fn: 1754.0000 - accuracy: 0.9254 train_balacc 0.9252890601838126\n",
      " val_balacc 0.9205488734541758\n",
      "\n",
      "Epoch 87: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1794 - tp: 21847.0000 - fp: 1764.0000 - tn: 21847.0000 - fn: 1764.0000 - accuracy: 0.9253 - val_loss: 0.2168 - val_tp: 5434.0000 - val_fp: 469.0000 - val_tn: 5434.0000 - val_fn: 469.0000 - val_accuracy: 0.9205 - train_sensitivity: 0.9253 - train_specificity: 0.9253 - train_balacc: 0.9253 - val_sensitivity: 0.9205 - val_specificity: 0.9205 - val_balacc: 0.9205\n",
      "Epoch 88/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1797 - tp: 21752.0000 - fp: 1748.0000 - tn: 21752.0000 - fn: 1748.0000 - accuracy: 0.9256 train_balacc 0.9255855321672102\n",
      " val_balacc 0.9105539556157886\n",
      "\n",
      "Epoch 88: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1797 - tp: 21854.0000 - fp: 1757.0000 - tn: 21854.0000 - fn: 1757.0000 - accuracy: 0.9256 - val_loss: 0.2579 - val_tp: 5375.0000 - val_fp: 528.0000 - val_tn: 5375.0000 - val_fn: 528.0000 - val_accuracy: 0.9106 - train_sensitivity: 0.9256 - train_specificity: 0.9256 - train_balacc: 0.9256 - val_sensitivity: 0.9106 - val_specificity: 0.9106 - val_balacc: 0.9106\n",
      "Epoch 89/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1811 - tp: 21192.0000 - fp: 1708.0000 - tn: 21192.0000 - fn: 1708.0000 - accuracy: 0.9254 train_balacc 0.9252467070433272\n",
      " val_balacc 0.9302049805183805\n",
      "\n",
      "Epoch 89: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1810 - tp: 21846.0000 - fp: 1765.0000 - tn: 21846.0000 - fn: 1765.0000 - accuracy: 0.9252 - val_loss: 0.1894 - val_tp: 5491.0000 - val_fp: 412.0000 - val_tn: 5491.0000 - val_fn: 412.0000 - val_accuracy: 0.9302 - train_sensitivity: 0.9252 - train_specificity: 0.9252 - train_balacc: 0.9252 - val_sensitivity: 0.9302 - val_specificity: 0.9302 - val_balacc: 0.9302\n",
      "Epoch 90/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1812 - tp: 21290.0000 - fp: 1710.0000 - tn: 21290.0000 - fn: 1710.0000 - accuracy: 0.9257 train_balacc 0.925670238448181\n",
      " val_balacc 0.9100457394545146\n",
      "\n",
      "Epoch 90: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1809 - tp: 21856.0000 - fp: 1755.0000 - tn: 21856.0000 - fn: 1755.0000 - accuracy: 0.9257 - val_loss: 0.2146 - val_tp: 5372.0000 - val_fp: 531.0000 - val_tn: 5372.0000 - val_fn: 531.0000 - val_accuracy: 0.9100 - train_sensitivity: 0.9257 - train_specificity: 0.9257 - train_balacc: 0.9257 - val_sensitivity: 0.9100 - val_specificity: 0.9100 - val_balacc: 0.9100\n",
      "Epoch 91/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1777 - tp: 21254.0000 - fp: 1646.0000 - tn: 21254.0000 - fn: 1646.0000 - accuracy: 0.9281 train_balacc 0.9281690737368176\n",
      " val_balacc 0.908012874809419\n",
      "\n",
      "Epoch 91: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1775 - tp: 21915.0000 - fp: 1696.0000 - tn: 21915.0000 - fn: 1696.0000 - accuracy: 0.9282 - val_loss: 0.2093 - val_tp: 5360.0000 - val_fp: 543.0000 - val_tn: 5360.0000 - val_fn: 543.0000 - val_accuracy: 0.9080 - train_sensitivity: 0.9282 - train_specificity: 0.9282 - train_balacc: 0.9282 - val_sensitivity: 0.9080 - val_specificity: 0.9080 - val_balacc: 0.9080\n",
      "Epoch 92/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1786 - tp: 21503.0000 - fp: 1697.0000 - tn: 21503.0000 - fn: 1697.0000 - accuracy: 0.9269 train_balacc 0.927067892084198\n",
      " val_balacc 0.9339318990343893\n",
      "\n",
      "Epoch 92: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1786 - tp: 21889.0000 - fp: 1722.0000 - tn: 21889.0000 - fn: 1722.0000 - accuracy: 0.9271 - val_loss: 0.1700 - val_tp: 5513.0000 - val_fp: 390.0000 - val_tn: 5513.0000 - val_fn: 390.0000 - val_accuracy: 0.9339 - train_sensitivity: 0.9271 - train_specificity: 0.9271 - train_balacc: 0.9271 - val_sensitivity: 0.9339 - val_specificity: 0.9339 - val_balacc: 0.9339\n",
      "Epoch 93/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1788 - tp: 21881.0000 - fp: 1730.0000 - tn: 21881.0000 - fn: 1730.0000 - accuracy: 0.9267 train_balacc 0.9267290669603151\n",
      " val_balacc 0.8924275791970184\n",
      "\n",
      "Epoch 93: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1788 - tp: 21881.0000 - fp: 1730.0000 - tn: 21881.0000 - fn: 1730.0000 - accuracy: 0.9267 - val_loss: 0.2766 - val_tp: 5268.0000 - val_fp: 635.0000 - val_tn: 5268.0000 - val_fn: 635.0000 - val_accuracy: 0.8924 - train_sensitivity: 0.9267 - train_specificity: 0.9267 - train_balacc: 0.9267 - val_sensitivity: 0.8924 - val_specificity: 0.8924 - val_balacc: 0.8924\n",
      "Epoch 94/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1810 - tp: 21124.0000 - fp: 1676.0000 - tn: 21124.0000 - fn: 1676.0000 - accuracy: 0.9265 train_balacc 0.9262631824149761\n",
      " val_balacc 0.895476876164662\n",
      "\n",
      "Epoch 94: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1804 - tp: 21870.0000 - fp: 1741.0000 - tn: 21870.0000 - fn: 1741.0000 - accuracy: 0.9263 - val_loss: 0.2554 - val_tp: 5286.0000 - val_fp: 617.0000 - val_tn: 5286.0000 - val_fn: 617.0000 - val_accuracy: 0.8955 - train_sensitivity: 0.9263 - train_specificity: 0.9263 - train_balacc: 0.9263 - val_sensitivity: 0.8955 - val_specificity: 0.8955 - val_balacc: 0.8955\n",
      "Epoch 95/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1742 - tp: 21562.0000 - fp: 1638.0000 - tn: 21562.0000 - fn: 1638.0000 - accuracy: 0.9294 train_balacc 0.9289314302655541\n",
      " val_balacc 0.8781975266813484\n",
      "\n",
      "Epoch 95: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1753 - tp: 21933.0000 - fp: 1678.0000 - tn: 21933.0000 - fn: 1678.0000 - accuracy: 0.9289 - val_loss: 0.2501 - val_tp: 5184.0000 - val_fp: 719.0000 - val_tn: 5184.0000 - val_fn: 719.0000 - val_accuracy: 0.8782 - train_sensitivity: 0.9289 - train_specificity: 0.9289 - train_balacc: 0.9289 - val_sensitivity: 0.8782 - val_specificity: 0.8782 - val_balacc: 0.8782\n",
      "Epoch 96/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1823 - tp: 21216.0000 - fp: 1684.0000 - tn: 21216.0000 - fn: 1684.0000 - accuracy: 0.9265 train_balacc 0.9264749481174029\n",
      " val_balacc 0.7906149415551414\n",
      "\n",
      "Epoch 96: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1824 - tp: 21875.0000 - fp: 1736.0000 - tn: 21875.0000 - fn: 1736.0000 - accuracy: 0.9265 - val_loss: 0.5834 - val_tp: 4667.0000 - val_fp: 1236.0000 - val_tn: 4667.0000 - val_fn: 1236.0000 - val_accuracy: 0.7906 - train_sensitivity: 0.9265 - train_specificity: 0.9265 - train_balacc: 0.9265 - val_sensitivity: 0.7906 - val_specificity: 0.7906 - val_balacc: 0.7906\n",
      "Epoch 97/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1748 - tp: 21333.0000 - fp: 1667.0000 - tn: 21333.0000 - fn: 1667.0000 - accuracy: 0.9275 train_balacc 0.9275337766295371\n",
      " val_balacc 0.8743012027782483\n",
      "\n",
      "Epoch 97: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1750 - tp: 21900.0000 - fp: 1711.0000 - tn: 21900.0000 - fn: 1711.0000 - accuracy: 0.9275 - val_loss: 0.3223 - val_tp: 5161.0000 - val_fp: 742.0000 - val_tn: 5161.0000 - val_fn: 742.0000 - val_accuracy: 0.8743 - train_sensitivity: 0.9275 - train_specificity: 0.9275 - train_balacc: 0.9275 - val_sensitivity: 0.8743 - val_specificity: 0.8743 - val_balacc: 0.8743\n",
      "Epoch 98/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1858 - tp: 21279.0000 - fp: 1721.0000 - tn: 21279.0000 - fn: 1721.0000 - accuracy: 0.9252 train_balacc 0.9257549447291517\n",
      " val_balacc 0.9351177367440284\n",
      "\n",
      "Epoch 98: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1854 - tp: 21858.0000 - fp: 1753.0000 - tn: 21858.0000 - fn: 1753.0000 - accuracy: 0.9258 - val_loss: 0.1769 - val_tp: 5520.0000 - val_fp: 383.0000 - val_tn: 5520.0000 - val_fn: 383.0000 - val_accuracy: 0.9351 - train_sensitivity: 0.9258 - train_specificity: 0.9258 - train_balacc: 0.9258 - val_sensitivity: 0.9351 - val_specificity: 0.9351 - val_balacc: 0.9351\n",
      "Epoch 99/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1799 - tp: 21205.0000 - fp: 1695.0000 - tn: 21205.0000 - fn: 1695.0000 - accuracy: 0.9260 train_balacc 0.9259243572910931\n",
      " val_balacc 0.9019142808741318\n",
      "\n",
      "Epoch 99: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1799 - tp: 21862.0000 - fp: 1749.0000 - tn: 21862.0000 - fn: 1749.0000 - accuracy: 0.9259 - val_loss: 0.2391 - val_tp: 5324.0000 - val_fp: 579.0000 - val_tn: 5324.0000 - val_fn: 579.0000 - val_accuracy: 0.9019 - train_sensitivity: 0.9259 - train_specificity: 0.9259 - train_balacc: 0.9259 - val_sensitivity: 0.9019 - val_specificity: 0.9019 - val_balacc: 0.9019\n",
      "Epoch 100/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1773 - tp: 21126.0000 - fp: 1674.0000 - tn: 21126.0000 - fn: 1674.0000 - accuracy: 0.9266 train_balacc 0.9259667104315785\n",
      " val_balacc 0.9066576317126884\n",
      "\n",
      "Epoch 100: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1777 - tp: 21863.0000 - fp: 1748.0000 - tn: 21863.0000 - fn: 1748.0000 - accuracy: 0.9260 - val_loss: 0.2391 - val_tp: 5352.0000 - val_fp: 551.0000 - val_tn: 5352.0000 - val_fn: 551.0000 - val_accuracy: 0.9067 - train_sensitivity: 0.9260 - train_specificity: 0.9260 - train_balacc: 0.9260 - val_sensitivity: 0.9067 - val_specificity: 0.9067 - val_balacc: 0.9067\n",
      "Epoch 101/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1792 - tp: 21110.0000 - fp: 1690.0000 - tn: 21110.0000 - fn: 1690.0000 - accuracy: 0.9259 train_balacc 0.9258820041506077\n",
      " val_balacc 0.8907335253261054\n",
      "\n",
      "Epoch 101: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1787 - tp: 21861.0000 - fp: 1750.0000 - tn: 21861.0000 - fn: 1750.0000 - accuracy: 0.9259 - val_loss: 0.2331 - val_tp: 5258.0000 - val_fp: 645.0000 - val_tn: 5258.0000 - val_fn: 645.0000 - val_accuracy: 0.8907 - train_sensitivity: 0.9259 - train_specificity: 0.9259 - train_balacc: 0.9259 - val_sensitivity: 0.8907 - val_specificity: 0.8907 - val_balacc: 0.8907\n",
      "Epoch 102/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1817 - tp: 21411.0000 - fp: 1689.0000 - tn: 21411.0000 - fn: 1689.0000 - accuracy: 0.9269 train_balacc 0.9269831858032274\n",
      " val_balacc 0.8803997967135355\n",
      "\n",
      "Epoch 102: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1814 - tp: 21887.0000 - fp: 1724.0000 - tn: 21887.0000 - fn: 1724.0000 - accuracy: 0.9270 - val_loss: 0.2726 - val_tp: 5197.0000 - val_fp: 706.0000 - val_tn: 5197.0000 - val_fn: 706.0000 - val_accuracy: 0.8804 - train_sensitivity: 0.9270 - train_specificity: 0.9270 - train_balacc: 0.9270 - val_sensitivity: 0.8804 - val_specificity: 0.8804 - val_balacc: 0.8804\n",
      "Epoch 103/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1833 - tp: 21323.0000 - fp: 1777.0000 - tn: 21323.0000 - fn: 1777.0000 - accuracy: 0.9231 train_balacc 0.9230866968785736\n",
      " val_balacc 0.8863289852617313\n",
      "\n",
      "Epoch 103: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1831 - tp: 21795.0000 - fp: 1816.0000 - tn: 21795.0000 - fn: 1816.0000 - accuracy: 0.9231 - val_loss: 0.2408 - val_tp: 5232.0000 - val_fp: 671.0000 - val_tn: 5232.0000 - val_fn: 671.0000 - val_accuracy: 0.8863 - train_sensitivity: 0.9231 - train_specificity: 0.9231 - train_balacc: 0.9231 - val_sensitivity: 0.8863 - val_specificity: 0.8863 - val_balacc: 0.8863\n",
      "Epoch 104/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1786 - tp: 21200.0000 - fp: 1700.0000 - tn: 21200.0000 - fn: 1700.0000 - accuracy: 0.9258 train_balacc 0.9256278853076956\n",
      " val_balacc 0.9235981704218195\n",
      "\n",
      "Epoch 104: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1809 - tp: 21855.0000 - fp: 1756.0000 - tn: 21855.0000 - fn: 1756.0000 - accuracy: 0.9256 - val_loss: 0.2079 - val_tp: 5452.0000 - val_fp: 451.0000 - val_tn: 5452.0000 - val_fn: 451.0000 - val_accuracy: 0.9236 - train_sensitivity: 0.9256 - train_specificity: 0.9256 - train_balacc: 0.9256 - val_sensitivity: 0.9236 - val_specificity: 0.9236 - val_balacc: 0.9236\n",
      "Epoch 105/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1778 - tp: 21884.0000 - fp: 1716.0000 - tn: 21884.0000 - fn: 1716.0000 - accuracy: 0.9273 train_balacc 0.9272373046461395\n",
      " val_balacc 0.8963239031001186\n",
      "\n",
      "Epoch 105: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1780 - tp: 21893.0000 - fp: 1718.0000 - tn: 21893.0000 - fn: 1718.0000 - accuracy: 0.9272 - val_loss: 0.2273 - val_tp: 5291.0000 - val_fp: 612.0000 - val_tn: 5291.0000 - val_fn: 612.0000 - val_accuracy: 0.8963 - train_sensitivity: 0.9272 - train_specificity: 0.9272 - train_balacc: 0.9272 - val_sensitivity: 0.8963 - val_specificity: 0.8963 - val_balacc: 0.8963\n",
      "Epoch 106/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1779 - tp: 21307.0000 - fp: 1693.0000 - tn: 21307.0000 - fn: 1693.0000 - accuracy: 0.9264 train_balacc 0.92613612299352\n",
      " val_balacc 0.9278333050991021\n",
      "\n",
      "Epoch 106: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1789 - tp: 21867.0000 - fp: 1744.0000 - tn: 21867.0000 - fn: 1744.0000 - accuracy: 0.9261 - val_loss: 0.1817 - val_tp: 5477.0000 - val_fp: 426.0000 - val_tn: 5477.0000 - val_fn: 426.0000 - val_accuracy: 0.9278 - train_sensitivity: 0.9261 - train_specificity: 0.9261 - train_balacc: 0.9261 - val_sensitivity: 0.9278 - val_specificity: 0.9278 - val_balacc: 0.9278\n",
      "Epoch 107/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1838 - tp: 21209.0000 - fp: 1691.0000 - tn: 21209.0000 - fn: 1691.0000 - accuracy: 0.9262 train_balacc 0.9261784761340054\n",
      " val_balacc 0.8500762324241911\n",
      "\n",
      "Epoch 107: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1835 - tp: 21868.0000 - fp: 1743.0000 - tn: 21868.0000 - fn: 1743.0000 - accuracy: 0.9262 - val_loss: 0.3499 - val_tp: 5018.0000 - val_fp: 885.0000 - val_tn: 5018.0000 - val_fn: 885.0000 - val_accuracy: 0.8501 - train_sensitivity: 0.9262 - train_specificity: 0.9262 - train_balacc: 0.9262 - val_sensitivity: 0.8501 - val_specificity: 0.8501 - val_balacc: 0.8501\n",
      "Epoch 108/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1747 - tp: 21901.0000 - fp: 1699.0000 - tn: 21901.0000 - fn: 1699.0000 - accuracy: 0.9280 train_balacc 0.9280420143153615\n",
      " val_balacc 0.9119091987125191\n",
      "\n",
      "Epoch 108: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1747 - tp: 21912.0000 - fp: 1699.0000 - tn: 21912.0000 - fn: 1699.0000 - accuracy: 0.9280 - val_loss: 0.2102 - val_tp: 5383.0000 - val_fp: 520.0000 - val_tn: 5383.0000 - val_fn: 520.0000 - val_accuracy: 0.9119 - train_sensitivity: 0.9280 - train_specificity: 0.9280 - train_balacc: 0.9280 - val_sensitivity: 0.9119 - val_specificity: 0.9119 - val_balacc: 0.9119\n",
      "Epoch 109/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1767 - tp: 21857.0000 - fp: 1743.0000 - tn: 21857.0000 - fn: 1743.0000 - accuracy: 0.9261 train_balacc 0.9260937698530346\n",
      " val_balacc 0.9264780620023717\n",
      "\n",
      "Epoch 109: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1768 - tp: 21866.0000 - fp: 1745.0000 - tn: 21866.0000 - fn: 1745.0000 - accuracy: 0.9261 - val_loss: 0.2151 - val_tp: 5469.0000 - val_fp: 434.0000 - val_tn: 5469.0000 - val_fn: 434.0000 - val_accuracy: 0.9265 - train_sensitivity: 0.9261 - train_specificity: 0.9261 - train_balacc: 0.9261 - val_sensitivity: 0.9265 - val_specificity: 0.9265 - val_balacc: 0.9265\n",
      "Epoch 110/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1781 - tp: 21879.0000 - fp: 1721.0000 - tn: 21879.0000 - fn: 1721.0000 - accuracy: 0.9271 train_balacc 0.9270255389437126\n",
      " val_balacc 0.8712519058106047\n",
      "\n",
      "Epoch 110: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1782 - tp: 21888.0000 - fp: 1723.0000 - tn: 21888.0000 - fn: 1723.0000 - accuracy: 0.9270 - val_loss: 0.2790 - val_tp: 5143.0000 - val_fp: 760.0000 - val_tn: 5143.0000 - val_fn: 760.0000 - val_accuracy: 0.8713 - train_sensitivity: 0.9270 - train_specificity: 0.9270 - train_balacc: 0.9270 - val_sensitivity: 0.8713 - val_specificity: 0.8713 - val_balacc: 0.8713\n",
      "Epoch 111/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1752 - tp: 21173.0000 - fp: 1627.0000 - tn: 21173.0000 - fn: 1627.0000 - accuracy: 0.9286 train_balacc 0.9288890771250689\n",
      " val_balacc 0.9174995764865322\n",
      "\n",
      "Epoch 111: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1743 - tp: 21932.0000 - fp: 1679.0000 - tn: 21932.0000 - fn: 1679.0000 - accuracy: 0.9289 - val_loss: 0.1839 - val_tp: 5416.0000 - val_fp: 487.0000 - val_tn: 5416.0000 - val_fn: 487.0000 - val_accuracy: 0.9175 - train_sensitivity: 0.9289 - train_specificity: 0.9289 - train_balacc: 0.9289 - val_sensitivity: 0.9175 - val_specificity: 0.9175 - val_balacc: 0.9175\n",
      "Epoch 112/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1797 - tp: 21310.0000 - fp: 1690.0000 - tn: 21310.0000 - fn: 1690.0000 - accuracy: 0.9265 train_balacc 0.9265173012578882\n",
      " val_balacc 0.9136032525834321\n",
      "\n",
      "Epoch 112: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1792 - tp: 21876.0000 - fp: 1735.0000 - tn: 21876.0000 - fn: 1735.0000 - accuracy: 0.9265 - val_loss: 0.2120 - val_tp: 5393.0000 - val_fp: 510.0000 - val_tn: 5393.0000 - val_fn: 510.0000 - val_accuracy: 0.9136 - train_sensitivity: 0.9265 - train_specificity: 0.9265 - train_balacc: 0.9265 - val_sensitivity: 0.9136 - val_specificity: 0.9136 - val_balacc: 0.9136\n",
      "Epoch 113/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1758 - tp: 21114.0000 - fp: 1686.0000 - tn: 21114.0000 - fn: 1686.0000 - accuracy: 0.9261 train_balacc 0.925797297869637\n",
      " val_balacc 0.9247840081314586\n",
      "\n",
      "Epoch 113: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1757 - tp: 21859.0000 - fp: 1752.0000 - tn: 21859.0000 - fn: 1752.0000 - accuracy: 0.9258 - val_loss: 0.1958 - val_tp: 5459.0000 - val_fp: 444.0000 - val_tn: 5459.0000 - val_fn: 444.0000 - val_accuracy: 0.9248 - train_sensitivity: 0.9258 - train_specificity: 0.9258 - train_balacc: 0.9258 - val_sensitivity: 0.9248 - val_specificity: 0.9248 - val_balacc: 0.9248\n",
      "Epoch 114/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1758 - tp: 21161.0000 - fp: 1639.0000 - tn: 21161.0000 - fn: 1639.0000 - accuracy: 0.9281 train_balacc 0.928338486298759\n",
      " val_balacc 0.8827714721328138\n",
      "\n",
      "Epoch 114: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1754 - tp: 21919.0000 - fp: 1692.0000 - tn: 21919.0000 - fn: 1692.0000 - accuracy: 0.9283 - val_loss: 0.2490 - val_tp: 5211.0000 - val_fp: 692.0000 - val_tn: 5211.0000 - val_fn: 692.0000 - val_accuracy: 0.8828 - train_sensitivity: 0.9283 - train_specificity: 0.9283 - train_balacc: 0.9283 - val_sensitivity: 0.8828 - val_specificity: 0.8828 - val_balacc: 0.8828\n",
      "Epoch 115/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1738 - tp: 21935.0000 - fp: 1665.0000 - tn: 21935.0000 - fn: 1665.0000 - accuracy: 0.9294 train_balacc 0.9293973148108933\n",
      " val_balacc 0.8941216330679316\n",
      "\n",
      "Epoch 115: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1738 - tp: 21944.0000 - fp: 1667.0000 - tn: 21944.0000 - fn: 1667.0000 - accuracy: 0.9294 - val_loss: 0.2349 - val_tp: 5278.0000 - val_fp: 625.0000 - val_tn: 5278.0000 - val_fn: 625.0000 - val_accuracy: 0.8941 - train_sensitivity: 0.9294 - train_specificity: 0.9294 - train_balacc: 0.9294 - val_sensitivity: 0.8941 - val_specificity: 0.8941 - val_balacc: 0.8941\n",
      "Epoch 116/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1743 - tp: 21821.0000 - fp: 1679.0000 - tn: 21821.0000 - fn: 1679.0000 - accuracy: 0.9286 train_balacc 0.9285078988607005\n",
      " val_balacc 0.9225817380992716\n",
      "\n",
      "Epoch 116: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1744 - tp: 21923.0000 - fp: 1688.0000 - tn: 21923.0000 - fn: 1688.0000 - accuracy: 0.9285 - val_loss: 0.2174 - val_tp: 5446.0000 - val_fp: 457.0000 - val_tn: 5446.0000 - val_fn: 457.0000 - val_accuracy: 0.9226 - train_sensitivity: 0.9285 - train_specificity: 0.9285 - train_balacc: 0.9285 - val_sensitivity: 0.9226 - val_specificity: 0.9226 - val_balacc: 0.9226\n",
      "Epoch 117/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1730 - tp: 21768.0000 - fp: 1632.0000 - tn: 21768.0000 - fn: 1632.0000 - accuracy: 0.9303 train_balacc 0.9304561433230274\n",
      " val_balacc 0.9347789259698458\n",
      "\n",
      "Epoch 117: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1727 - tp: 21969.0000 - fp: 1642.0000 - tn: 21969.0000 - fn: 1642.0000 - accuracy: 0.9305 - val_loss: 0.1679 - val_tp: 5518.0000 - val_fp: 385.0000 - val_tn: 5518.0000 - val_fn: 385.0000 - val_accuracy: 0.9348 - train_sensitivity: 0.9305 - train_specificity: 0.9305 - train_balacc: 0.9305 - val_sensitivity: 0.9348 - val_specificity: 0.9348 - val_balacc: 0.9348\n",
      "Epoch 118/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1716 - tp: 21347.0000 - fp: 1653.0000 - tn: 21347.0000 - fn: 1653.0000 - accuracy: 0.9281 train_balacc 0.9281690737368176\n",
      " val_balacc 0.8802303913264442\n",
      "\n",
      "Epoch 118: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1713 - tp: 21915.0000 - fp: 1696.0000 - tn: 21915.0000 - fn: 1696.0000 - accuracy: 0.9282 - val_loss: 0.2597 - val_tp: 5196.0000 - val_fp: 707.0000 - val_tn: 5196.0000 - val_fn: 707.0000 - val_accuracy: 0.8802 - train_sensitivity: 0.9282 - train_specificity: 0.9282 - train_balacc: 0.9282 - val_sensitivity: 0.8802 - val_specificity: 0.8802 - val_balacc: 0.8802\n",
      "Epoch 119/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1794 - tp: 21471.0000 - fp: 1629.0000 - tn: 21471.0000 - fn: 1629.0000 - accuracy: 0.9295 train_balacc 0.9291008428274956\n",
      " val_balacc 0.7851939691682196\n",
      "\n",
      "Epoch 119: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1802 - tp: 21937.0000 - fp: 1674.0000 - tn: 21937.0000 - fn: 1674.0000 - accuracy: 0.9291 - val_loss: 0.5543 - val_tp: 4635.0000 - val_fp: 1268.0000 - val_tn: 4635.0000 - val_fn: 1268.0000 - val_accuracy: 0.7852 - train_sensitivity: 0.9291 - train_specificity: 0.9291 - train_balacc: 0.9291 - val_sensitivity: 0.7852 - val_specificity: 0.7852 - val_balacc: 0.7852\n",
      "Epoch 120/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1815 - tp: 21407.0000 - fp: 1693.0000 - tn: 21407.0000 - fn: 1693.0000 - accuracy: 0.9267 train_balacc 0.9267714201008005\n",
      " val_balacc 0.8654921226495003\n",
      "\n",
      "Epoch 120: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1810 - tp: 21882.0000 - fp: 1729.0000 - tn: 21882.0000 - fn: 1729.0000 - accuracy: 0.9268 - val_loss: 0.2732 - val_tp: 5109.0000 - val_fp: 794.0000 - val_tn: 5109.0000 - val_fn: 794.0000 - val_accuracy: 0.8655 - train_sensitivity: 0.9268 - train_specificity: 0.9268 - train_balacc: 0.9268 - val_sensitivity: 0.8655 - val_specificity: 0.8655 - val_balacc: 0.8655\n",
      "Epoch 121/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1780 - tp: 21090.0000 - fp: 1710.0000 - tn: 21090.0000 - fn: 1710.0000 - accuracy: 0.9250 train_balacc 0.9250772944813858\n",
      " val_balacc 0.8841267152295443\n",
      "\n",
      "Epoch 121: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1778 - tp: 21842.0000 - fp: 1769.0000 - tn: 21842.0000 - fn: 1769.0000 - accuracy: 0.9251 - val_loss: 0.2570 - val_tp: 5219.0000 - val_fp: 684.0000 - val_tn: 5219.0000 - val_fn: 684.0000 - val_accuracy: 0.8841 - train_sensitivity: 0.9251 - train_specificity: 0.9251 - train_balacc: 0.9251 - val_sensitivity: 0.8841 - val_specificity: 0.8841 - val_balacc: 0.8841\n",
      "Epoch 122/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1729 - tp: 21280.0000 - fp: 1620.0000 - tn: 21280.0000 - fn: 1620.0000 - accuracy: 0.9293 train_balacc 0.9292279022489518\n",
      " val_balacc 0.9169913603252583\n",
      "\n",
      "Epoch 122: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1722 - tp: 21940.0000 - fp: 1671.0000 - tn: 21940.0000 - fn: 1671.0000 - accuracy: 0.9292 - val_loss: 0.2089 - val_tp: 5413.0000 - val_fp: 490.0000 - val_tn: 5413.0000 - val_fn: 490.0000 - val_accuracy: 0.9170 - train_sensitivity: 0.9292 - train_specificity: 0.9292 - train_balacc: 0.9292 - val_sensitivity: 0.9170 - val_specificity: 0.9170 - val_balacc: 0.9170\n",
      "Epoch 123/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1725 - tp: 21675.0000 - fp: 1625.0000 - tn: 21675.0000 - fn: 1625.0000 - accuracy: 0.9303 train_balacc 0.930413790182542\n",
      " val_balacc 0.9076740640352363\n",
      "\n",
      "Epoch 123: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1720 - tp: 21968.0000 - fp: 1643.0000 - tn: 21968.0000 - fn: 1643.0000 - accuracy: 0.9304 - val_loss: 0.1996 - val_tp: 5358.0000 - val_fp: 545.0000 - val_tn: 5358.0000 - val_fn: 545.0000 - val_accuracy: 0.9077 - train_sensitivity: 0.9304 - train_specificity: 0.9304 - train_balacc: 0.9304 - val_sensitivity: 0.9077 - val_specificity: 0.9077 - val_balacc: 0.9077\n",
      "Epoch 124/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1667 - tp: 21471.0000 - fp: 1529.0000 - tn: 21471.0000 - fn: 1529.0000 - accuracy: 0.9335 train_balacc 0.9327432129092372\n",
      " val_balacc 0.9152973064543453\n",
      "\n",
      "Epoch 124: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1690 - tp: 22023.0000 - fp: 1588.0000 - tn: 22023.0000 - fn: 1588.0000 - accuracy: 0.9327 - val_loss: 0.2167 - val_tp: 5403.0000 - val_fp: 500.0000 - val_tn: 5403.0000 - val_fn: 500.0000 - val_accuracy: 0.9153 - train_sensitivity: 0.9327 - train_specificity: 0.9327 - train_balacc: 0.9327 - val_sensitivity: 0.9153 - val_specificity: 0.9153 - val_balacc: 0.9153\n",
      "Epoch 125/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1719 - tp: 21572.0000 - fp: 1628.0000 - tn: 21572.0000 - fn: 1628.0000 - accuracy: 0.9298 train_balacc 0.9298631993562323\n",
      " val_balacc 0.9327460613247501\n",
      "\n",
      "Epoch 125: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1714 - tp: 21955.0000 - fp: 1656.0000 - tn: 21955.0000 - fn: 1656.0000 - accuracy: 0.9299 - val_loss: 0.1867 - val_tp: 5506.0000 - val_fp: 397.0000 - val_tn: 5506.0000 - val_fn: 397.0000 - val_accuracy: 0.9327 - train_sensitivity: 0.9299 - train_specificity: 0.9299 - train_balacc: 0.9299 - val_sensitivity: 0.9327 - val_specificity: 0.9327 - val_balacc: 0.9327\n",
      "Epoch 126/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1705 - tp: 21265.0000 - fp: 1635.0000 - tn: 21265.0000 - fn: 1635.0000 - accuracy: 0.9286 train_balacc 0.9291855491084664\n",
      " val_balacc 0.8726071489073353\n",
      "\n",
      "Epoch 126: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1690 - tp: 21939.0000 - fp: 1672.0000 - tn: 21939.0000 - fn: 1672.0000 - accuracy: 0.9292 - val_loss: 0.3105 - val_tp: 5151.0000 - val_fp: 752.0000 - val_tn: 5151.0000 - val_fn: 752.0000 - val_accuracy: 0.8726 - train_sensitivity: 0.9292 - train_specificity: 0.9292 - train_balacc: 0.9292 - val_sensitivity: 0.8726 - val_specificity: 0.8726 - val_balacc: 0.8726\n",
      "Epoch 127/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1687 - tp: 21432.0000 - fp: 1568.0000 - tn: 21432.0000 - fn: 1568.0000 - accuracy: 0.9318 train_balacc 0.9318537969590445\n",
      " val_balacc 0.9012366593257666\n",
      "\n",
      "Epoch 127: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1694 - tp: 22002.0000 - fp: 1609.0000 - tn: 22002.0000 - fn: 1609.0000 - accuracy: 0.9319 - val_loss: 0.2152 - val_tp: 5320.0000 - val_fp: 583.0000 - val_tn: 5320.0000 - val_fn: 583.0000 - val_accuracy: 0.9012 - train_sensitivity: 0.9319 - train_specificity: 0.9319 - train_balacc: 0.9319 - val_sensitivity: 0.9012 - val_specificity: 0.9012 - val_balacc: 0.9012\n",
      "Epoch 128/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1744 - tp: 21184.0000 - fp: 1616.0000 - tn: 21184.0000 - fn: 1616.0000 - accuracy: 0.9291 train_balacc 0.929143195967981\n",
      " val_balacc 0.8243266135863121\n",
      "\n",
      "Epoch 128: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1748 - tp: 21938.0000 - fp: 1673.0000 - tn: 21938.0000 - fn: 1673.0000 - accuracy: 0.9291 - val_loss: 0.3313 - val_tp: 4866.0000 - val_fp: 1037.0000 - val_tn: 4866.0000 - val_fn: 1037.0000 - val_accuracy: 0.8243 - train_sensitivity: 0.9291 - train_specificity: 0.9291 - train_balacc: 0.9291 - val_sensitivity: 0.8243 - val_specificity: 0.8243 - val_balacc: 0.8243\n",
      "Epoch 129/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1701 - tp: 21922.0000 - fp: 1689.0000 - tn: 21922.0000 - fn: 1689.0000 - accuracy: 0.9285 train_balacc 0.9284655457202151\n",
      " val_balacc 0.9037777401321362\n",
      "\n",
      "Epoch 129: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1701 - tp: 21922.0000 - fp: 1689.0000 - tn: 21922.0000 - fn: 1689.0000 - accuracy: 0.9285 - val_loss: 0.2258 - val_tp: 5335.0000 - val_fp: 568.0000 - val_tn: 5335.0000 - val_fn: 568.0000 - val_accuracy: 0.9038 - train_sensitivity: 0.9285 - train_specificity: 0.9285 - train_balacc: 0.9285 - val_sensitivity: 0.9038 - val_specificity: 0.9038 - val_balacc: 0.9038\n",
      "Epoch 130/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1753 - tp: 21317.0000 - fp: 1583.0000 - tn: 21317.0000 - fn: 1583.0000 - accuracy: 0.9309 train_balacc 0.9306255558849689\n",
      " val_balacc 0.7694392681687278\n",
      "\n",
      "Epoch 130: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1756 - tp: 21973.0000 - fp: 1638.0000 - tn: 21973.0000 - fn: 1638.0000 - accuracy: 0.9306 - val_loss: 1.0744 - val_tp: 4542.0000 - val_fp: 1361.0000 - val_tn: 4542.0000 - val_fn: 1361.0000 - val_accuracy: 0.7694 - train_sensitivity: 0.9306 - train_specificity: 0.9306 - train_balacc: 0.9306 - val_sensitivity: 0.7694 - val_specificity: 0.7694 - val_balacc: 0.7694\n",
      "Epoch 131/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1692 - tp: 21420.0000 - fp: 1580.0000 - tn: 21420.0000 - fn: 1580.0000 - accuracy: 0.9313 train_balacc 0.9313032061327348\n",
      " val_balacc 0.9036083347450449\n",
      "\n",
      "Epoch 131: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1691 - tp: 21989.0000 - fp: 1622.0000 - tn: 21989.0000 - fn: 1622.0000 - accuracy: 0.9313 - val_loss: 0.2103 - val_tp: 5334.0000 - val_fp: 569.0000 - val_tn: 5334.0000 - val_fn: 569.0000 - val_accuracy: 0.9036 - train_sensitivity: 0.9313 - train_specificity: 0.9313 - train_balacc: 0.9313 - val_sensitivity: 0.9036 - val_specificity: 0.9036 - val_balacc: 0.9036\n",
      "Epoch 132/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1731 - tp: 21169.0000 - fp: 1631.0000 - tn: 21169.0000 - fn: 1631.0000 - accuracy: 0.9285 train_balacc 0.928211426877303\n",
      " val_balacc 0.8680332034558699\n",
      "\n",
      "Epoch 132: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1751 - tp: 21916.0000 - fp: 1695.0000 - tn: 21916.0000 - fn: 1695.0000 - accuracy: 0.9282 - val_loss: 0.2621 - val_tp: 5124.0000 - val_fp: 779.0000 - val_tn: 5124.0000 - val_fn: 779.0000 - val_accuracy: 0.8680 - train_sensitivity: 0.9282 - train_specificity: 0.9282 - train_balacc: 0.9282 - val_sensitivity: 0.8680 - val_specificity: 0.8680 - val_balacc: 0.8680\n",
      "Epoch 133/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1733 - tp: 21384.0000 - fp: 1616.0000 - tn: 21384.0000 - fn: 1616.0000 - accuracy: 0.9297 train_balacc 0.9298208462157469\n",
      " val_balacc 0.9212264950025411\n",
      "\n",
      "Epoch 133: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1733 - tp: 21954.0000 - fp: 1657.0000 - tn: 21954.0000 - fn: 1657.0000 - accuracy: 0.9298 - val_loss: 0.1836 - val_tp: 5438.0000 - val_fp: 465.0000 - val_tn: 5438.0000 - val_fn: 465.0000 - val_accuracy: 0.9212 - train_sensitivity: 0.9298 - train_specificity: 0.9298 - train_balacc: 0.9298 - val_sensitivity: 0.9212 - val_specificity: 0.9212 - val_balacc: 0.9212\n",
      "Epoch 134/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1728 - tp: 21427.0000 - fp: 1573.0000 - tn: 21427.0000 - fn: 1573.0000 - accuracy: 0.9316 train_balacc 0.9313455592732202\n",
      " val_balacc 0.9154667118414366\n",
      "\n",
      "Epoch 134: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1738 - tp: 21990.0000 - fp: 1621.0000 - tn: 21990.0000 - fn: 1621.0000 - accuracy: 0.9313 - val_loss: 0.2131 - val_tp: 5404.0000 - val_fp: 499.0000 - val_tn: 5404.0000 - val_fn: 499.0000 - val_accuracy: 0.9155 - train_sensitivity: 0.9313 - train_specificity: 0.9313 - train_balacc: 0.9313 - val_sensitivity: 0.9155 - val_specificity: 0.9155 - val_balacc: 0.9155\n",
      "Epoch 135/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1735 - tp: 21252.0000 - fp: 1648.0000 - tn: 21252.0000 - fn: 1648.0000 - accuracy: 0.9280 train_balacc 0.92787260175342\n",
      " val_balacc 0.8671861765204133\n",
      "\n",
      "Epoch 135: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1728 - tp: 21908.0000 - fp: 1703.0000 - tn: 21908.0000 - fn: 1703.0000 - accuracy: 0.9279 - val_loss: 0.3412 - val_tp: 5119.0000 - val_fp: 784.0000 - val_tn: 5119.0000 - val_fn: 784.0000 - val_accuracy: 0.8672 - train_sensitivity: 0.9279 - train_specificity: 0.9279 - train_balacc: 0.9279 - val_sensitivity: 0.8672 - val_specificity: 0.8672 - val_balacc: 0.8672\n",
      "Epoch 136/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1763 - tp: 21453.0000 - fp: 1647.0000 - tn: 21453.0000 - fn: 1647.0000 - accuracy: 0.9287 train_balacc 0.9277878954724493\n",
      " val_balacc 0.8707436896493308\n",
      "\n",
      "Epoch 136: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1774 - tp: 21906.0000 - fp: 1705.0000 - tn: 21906.0000 - fn: 1705.0000 - accuracy: 0.9278 - val_loss: 0.2601 - val_tp: 5140.0000 - val_fp: 763.0000 - val_tn: 5140.0000 - val_fn: 763.0000 - val_accuracy: 0.8707 - train_sensitivity: 0.9278 - train_specificity: 0.9278 - train_balacc: 0.9278 - val_sensitivity: 0.8707 - val_specificity: 0.8707 - val_balacc: 0.8707\n",
      "Epoch 137/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1710 - tp: 21837.0000 - fp: 1663.0000 - tn: 21837.0000 - fn: 1663.0000 - accuracy: 0.9292 train_balacc 0.9291855491084664\n",
      " val_balacc 0.8895476876164662\n",
      "\n",
      "Epoch 137: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1713 - tp: 21939.0000 - fp: 1672.0000 - tn: 21939.0000 - fn: 1672.0000 - accuracy: 0.9292 - val_loss: 0.2741 - val_tp: 5251.0000 - val_fp: 652.0000 - val_tn: 5251.0000 - val_fn: 652.0000 - val_accuracy: 0.8895 - train_sensitivity: 0.9292 - train_specificity: 0.9292 - train_balacc: 0.9292 - val_sensitivity: 0.8895 - val_specificity: 0.8895 - val_balacc: 0.8895\n",
      "Epoch 138/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1757 - tp: 21165.0000 - fp: 1735.0000 - tn: 21165.0000 - fn: 1735.0000 - accuracy: 0.9242 train_balacc 0.9241455253907077\n",
      " val_balacc 0.8693884465526004\n",
      "\n",
      "Epoch 138: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1753 - tp: 21820.0000 - fp: 1791.0000 - tn: 21820.0000 - fn: 1791.0000 - accuracy: 0.9241 - val_loss: 0.2860 - val_tp: 5132.0000 - val_fp: 771.0000 - val_tn: 5132.0000 - val_fn: 771.0000 - val_accuracy: 0.8694 - train_sensitivity: 0.9241 - train_specificity: 0.9241 - train_balacc: 0.9241 - val_sensitivity: 0.8694 - val_specificity: 0.8694 - val_balacc: 0.8694\n",
      "Epoch 139/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1708 - tp: 21291.0000 - fp: 1609.0000 - tn: 21291.0000 - fn: 1609.0000 - accuracy: 0.9297 train_balacc 0.9299055524967176\n",
      " val_balacc 0.8783669320684397\n",
      "\n",
      "Epoch 139: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1710 - tp: 21956.0000 - fp: 1655.0000 - tn: 21956.0000 - fn: 1655.0000 - accuracy: 0.9299 - val_loss: 0.2647 - val_tp: 5185.0000 - val_fp: 718.0000 - val_tn: 5185.0000 - val_fn: 718.0000 - val_accuracy: 0.8784 - train_sensitivity: 0.9299 - train_specificity: 0.9299 - train_balacc: 0.9299 - val_sensitivity: 0.8784 - val_specificity: 0.8784 - val_balacc: 0.8784\n",
      "Epoch 140/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1719 - tp: 21766.0000 - fp: 1634.0000 - tn: 21766.0000 - fn: 1634.0000 - accuracy: 0.9302 train_balacc 0.9302020244801152\n",
      " val_balacc 0.9213959003896324\n",
      "\n",
      "Epoch 140: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1718 - tp: 21963.0000 - fp: 1648.0000 - tn: 21963.0000 - fn: 1648.0000 - accuracy: 0.9302 - val_loss: 0.1847 - val_tp: 5439.0000 - val_fp: 464.0000 - val_tn: 5439.0000 - val_fn: 464.0000 - val_accuracy: 0.9214 - train_sensitivity: 0.9302 - train_specificity: 0.9302 - train_balacc: 0.9302 - val_sensitivity: 0.9214 - val_specificity: 0.9214 - val_balacc: 0.9214\n",
      "Epoch 141/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1717 - tp: 21474.0000 - fp: 1626.0000 - tn: 21474.0000 - fn: 1626.0000 - accuracy: 0.9296 train_balacc 0.9301173181991444\n",
      " val_balacc 0.8798915805522616\n",
      "\n",
      "Epoch 141: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1704 - tp: 21961.0000 - fp: 1650.0000 - tn: 21961.0000 - fn: 1650.0000 - accuracy: 0.9301 - val_loss: 0.2598 - val_tp: 5194.0000 - val_fp: 709.0000 - val_tn: 5194.0000 - val_fn: 709.0000 - val_accuracy: 0.8799 - train_sensitivity: 0.9301 - train_specificity: 0.9301 - train_balacc: 0.9301 - val_sensitivity: 0.8799 - val_specificity: 0.8799 - val_balacc: 0.8799\n",
      "Epoch 142/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1760 - tp: 21201.0000 - fp: 1599.0000 - tn: 21201.0000 - fn: 1599.0000 - accuracy: 0.9299 train_balacc 0.9297361399347762\n",
      " val_balacc 0.9054717940030493\n",
      "\n",
      "Epoch 142: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1758 - tp: 21952.0000 - fp: 1659.0000 - tn: 21952.0000 - fn: 1659.0000 - accuracy: 0.9297 - val_loss: 0.2198 - val_tp: 5345.0000 - val_fp: 558.0000 - val_tn: 5345.0000 - val_fn: 558.0000 - val_accuracy: 0.9055 - train_sensitivity: 0.9297 - train_specificity: 0.9297 - train_balacc: 0.9297 - val_sensitivity: 0.9055 - val_specificity: 0.9055 - val_balacc: 0.9055\n",
      "Epoch 143/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1608 - tp: 21332.0000 - fp: 1468.0000 - tn: 21332.0000 - fn: 1468.0000 - accuracy: 0.9356 train_balacc 0.9350302824954471\n",
      " val_balacc 0.9258004404540064\n",
      "\n",
      "Epoch 143: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1619 - tp: 22077.0000 - fp: 1534.0000 - tn: 22077.0000 - fn: 1534.0000 - accuracy: 0.9350 - val_loss: 0.1882 - val_tp: 5465.0000 - val_fp: 438.0000 - val_tn: 5465.0000 - val_fn: 438.0000 - val_accuracy: 0.9258 - train_sensitivity: 0.9350 - train_specificity: 0.9350 - train_balacc: 0.9350 - val_sensitivity: 0.9258 - val_specificity: 0.9258 - val_balacc: 0.9258\n",
      "Epoch 144/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1728 - tp: 21399.0000 - fp: 1601.0000 - tn: 21399.0000 - fn: 1601.0000 - accuracy: 0.9304 train_balacc 0.9304561433230274\n",
      " val_balacc 0.8739623920040658\n",
      "\n",
      "Epoch 144: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1717 - tp: 21969.0000 - fp: 1642.0000 - tn: 21969.0000 - fn: 1642.0000 - accuracy: 0.9305 - val_loss: 0.2597 - val_tp: 5159.0000 - val_fp: 744.0000 - val_tn: 5159.0000 - val_fn: 744.0000 - val_accuracy: 0.8740 - train_sensitivity: 0.9305 - train_specificity: 0.9305 - train_balacc: 0.9305 - val_sensitivity: 0.8740 - val_specificity: 0.8740 - val_balacc: 0.8740\n",
      "Epoch 145/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1676 - tp: 21404.0000 - fp: 1596.0000 - tn: 21404.0000 - fn: 1596.0000 - accuracy: 0.9306 train_balacc 0.929947905637203\n",
      " val_balacc 0.9141114687447061\n",
      "\n",
      "Epoch 145: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1690 - tp: 21957.0000 - fp: 1654.0000 - tn: 21957.0000 - fn: 1654.0000 - accuracy: 0.9299 - val_loss: 0.2013 - val_tp: 5396.0000 - val_fp: 507.0000 - val_tn: 5396.0000 - val_fn: 507.0000 - val_accuracy: 0.9141 - train_sensitivity: 0.9299 - train_specificity: 0.9299 - train_balacc: 0.9299 - val_sensitivity: 0.9141 - val_specificity: 0.9141 - val_balacc: 0.9141\n",
      "Epoch 146/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1705 - tp: 21343.0000 - fp: 1557.0000 - tn: 21343.0000 - fn: 1557.0000 - accuracy: 0.9320 train_balacc 0.931684384397103\n",
      " val_balacc 0.8990343892935795\n",
      "\n",
      "Epoch 146: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1723 - tp: 21998.0000 - fp: 1613.0000 - tn: 21998.0000 - fn: 1613.0000 - accuracy: 0.9317 - val_loss: 0.2201 - val_tp: 5307.0000 - val_fp: 596.0000 - val_tn: 5307.0000 - val_fn: 596.0000 - val_accuracy: 0.8990 - train_sensitivity: 0.9317 - train_specificity: 0.9317 - train_balacc: 0.9317 - val_sensitivity: 0.8990 - val_specificity: 0.8990 - val_balacc: 0.8990\n",
      "Epoch 147/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1688 - tp: 21340.0000 - fp: 1560.0000 - tn: 21340.0000 - fn: 1560.0000 - accuracy: 0.9319 train_balacc 0.9315996781161323\n",
      " val_balacc 0.8580382856174826\n",
      "\n",
      "Epoch 147: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1692 - tp: 21996.0000 - fp: 1615.0000 - tn: 21996.0000 - fn: 1615.0000 - accuracy: 0.9316 - val_loss: 0.3451 - val_tp: 5065.0000 - val_fp: 838.0000 - val_tn: 5065.0000 - val_fn: 838.0000 - val_accuracy: 0.8580 - train_sensitivity: 0.9316 - train_specificity: 0.9316 - train_balacc: 0.9316 - val_sensitivity: 0.8580 - val_specificity: 0.8580 - val_balacc: 0.8580\n",
      "Epoch 148/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1674 - tp: 21250.0000 - fp: 1550.0000 - tn: 21250.0000 - fn: 1550.0000 - accuracy: 0.9320 train_balacc 0.9314726186946762\n",
      " val_balacc 0.9237675758089107\n",
      "\n",
      "Epoch 148: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1688 - tp: 21993.0000 - fp: 1618.0000 - tn: 21993.0000 - fn: 1618.0000 - accuracy: 0.9315 - val_loss: 0.1695 - val_tp: 5453.0000 - val_fp: 450.0000 - val_tn: 5453.0000 - val_fn: 450.0000 - val_accuracy: 0.9238 - train_sensitivity: 0.9315 - train_specificity: 0.9315 - train_balacc: 0.9315 - val_sensitivity: 0.9238 - val_specificity: 0.9238 - val_balacc: 0.9238\n",
      "Epoch 149/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1749 - tp: 21446.0000 - fp: 1654.0000 - tn: 21446.0000 - fn: 1654.0000 - accuracy: 0.9284 train_balacc 0.9284655457202151\n",
      " val_balacc 0.9213959003896324\n",
      "\n",
      "Epoch 149: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1751 - tp: 21922.0000 - fp: 1689.0000 - tn: 21922.0000 - fn: 1689.0000 - accuracy: 0.9285 - val_loss: 0.2081 - val_tp: 5439.0000 - val_fp: 464.0000 - val_tn: 5439.0000 - val_fn: 464.0000 - val_accuracy: 0.9214 - train_sensitivity: 0.9285 - train_specificity: 0.9285 - train_balacc: 0.9285 - val_sensitivity: 0.9214 - val_specificity: 0.9214 - val_balacc: 0.9214\n",
      "Epoch 150/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1713 - tp: 21335.0000 - fp: 1565.0000 - tn: 21335.0000 - fn: 1565.0000 - accuracy: 0.9317 train_balacc 0.9315573249756469\n",
      " val_balacc 0.8820938505844486\n",
      "\n",
      "Epoch 150: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1719 - tp: 21995.0000 - fp: 1616.0000 - tn: 21995.0000 - fn: 1616.0000 - accuracy: 0.9316 - val_loss: 0.2453 - val_tp: 5207.0000 - val_fp: 696.0000 - val_tn: 5207.0000 - val_fn: 696.0000 - val_accuracy: 0.8821 - train_sensitivity: 0.9316 - train_specificity: 0.9316 - train_balacc: 0.9316 - val_sensitivity: 0.8821 - val_specificity: 0.8821 - val_balacc: 0.8821\n",
      "Epoch 151/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1693 - tp: 21918.0000 - fp: 1582.0000 - tn: 21918.0000 - fn: 1582.0000 - accuracy: 0.9327 train_balacc 0.9323620346448689\n",
      " val_balacc 0.9315602236151109\n",
      "\n",
      "Epoch 151: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1696 - tp: 22014.0000 - fp: 1597.0000 - tn: 22014.0000 - fn: 1597.0000 - accuracy: 0.9324 - val_loss: 0.1817 - val_tp: 5499.0000 - val_fp: 404.0000 - val_tn: 5499.0000 - val_fn: 404.0000 - val_accuracy: 0.9316 - train_sensitivity: 0.9324 - train_specificity: 0.9324 - train_balacc: 0.9324 - val_sensitivity: 0.9316 - val_specificity: 0.9316 - val_balacc: 0.9316\n",
      "Epoch 152/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1707 - tp: 21876.0000 - fp: 1624.0000 - tn: 21876.0000 - fn: 1624.0000 - accuracy: 0.9309 train_balacc 0.9309220278683664\n",
      " val_balacc 0.8570218532949347\n",
      "\n",
      "Epoch 152: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1705 - tp: 21980.0000 - fp: 1631.0000 - tn: 21980.0000 - fn: 1631.0000 - accuracy: 0.9309 - val_loss: 0.3927 - val_tp: 5059.0000 - val_fp: 844.0000 - val_tn: 5059.0000 - val_fn: 844.0000 - val_accuracy: 0.8570 - train_sensitivity: 0.9309 - train_specificity: 0.9309 - train_balacc: 0.9309 - val_sensitivity: 0.8570 - val_specificity: 0.8570 - val_balacc: 0.8570\n",
      "Epoch 153/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1750 - tp: 21584.0000 - fp: 1616.0000 - tn: 21584.0000 - fn: 1616.0000 - accuracy: 0.9303 train_balacc 0.9306255558849689\n",
      " val_balacc 0.9208876842283584\n",
      "\n",
      "Epoch 153: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1742 - tp: 21973.0000 - fp: 1638.0000 - tn: 21973.0000 - fn: 1638.0000 - accuracy: 0.9306 - val_loss: 0.2018 - val_tp: 5436.0000 - val_fp: 467.0000 - val_tn: 5436.0000 - val_fn: 467.0000 - val_accuracy: 0.9209 - train_sensitivity: 0.9306 - train_specificity: 0.9306 - train_balacc: 0.9306 - val_sensitivity: 0.9209 - val_specificity: 0.9209 - val_balacc: 0.9209\n",
      "Epoch 154/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1699 - tp: 21324.0000 - fp: 1576.0000 - tn: 21324.0000 - fn: 1576.0000 - accuracy: 0.9312 train_balacc 0.9314726186946762\n",
      " val_balacc 0.8482127731661867\n",
      "\n",
      "Epoch 154: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1692 - tp: 21993.0000 - fp: 1618.0000 - tn: 21993.0000 - fn: 1618.0000 - accuracy: 0.9315 - val_loss: 0.3387 - val_tp: 5007.0000 - val_fp: 896.0000 - val_tn: 5007.0000 - val_fn: 896.0000 - val_accuracy: 0.8482 - train_sensitivity: 0.9315 - train_specificity: 0.9315 - train_balacc: 0.9315 - val_sensitivity: 0.8482 - val_specificity: 0.8482 - val_balacc: 0.8482\n",
      "Epoch 155/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1664 - tp: 21463.0000 - fp: 1537.0000 - tn: 21463.0000 - fn: 1537.0000 - accuracy: 0.9332 train_balacc 0.9331243911736056\n",
      " val_balacc 0.8864983906488226\n",
      "\n",
      "Epoch 155: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1675 - tp: 22032.0000 - fp: 1579.0000 - tn: 22032.0000 - fn: 1579.0000 - accuracy: 0.9331 - val_loss: 0.2465 - val_tp: 5233.0000 - val_fp: 670.0000 - val_tn: 5233.0000 - val_fn: 670.0000 - val_accuracy: 0.8865 - train_sensitivity: 0.9331 - train_specificity: 0.9331 - train_balacc: 0.9331 - val_sensitivity: 0.8865 - val_specificity: 0.8865 - val_balacc: 0.8865\n",
      "Epoch 156/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1654 - tp: 21598.0000 - fp: 1602.0000 - tn: 21598.0000 - fn: 1602.0000 - accuracy: 0.9309 train_balacc 0.9310914404303079\n",
      " val_balacc 0.9088599017448755\n",
      "\n",
      "Epoch 156: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1649 - tp: 21984.0000 - fp: 1627.0000 - tn: 21984.0000 - fn: 1627.0000 - accuracy: 0.9311 - val_loss: 0.2278 - val_tp: 5365.0000 - val_fp: 538.0000 - val_tn: 5365.0000 - val_fn: 538.0000 - val_accuracy: 0.9089 - train_sensitivity: 0.9311 - train_specificity: 0.9311 - train_balacc: 0.9311 - val_sensitivity: 0.9089 - val_specificity: 0.9089 - val_balacc: 0.9089\n",
      "Epoch 157/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1670 - tp: 21367.0000 - fp: 1533.0000 - tn: 21367.0000 - fn: 1533.0000 - accuracy: 0.9331 train_balacc 0.9332090974545763\n",
      " val_balacc 0.9095375232932408\n",
      "\n",
      "Epoch 157: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1666 - tp: 22034.0000 - fp: 1577.0000 - tn: 22034.0000 - fn: 1577.0000 - accuracy: 0.9332 - val_loss: 0.2239 - val_tp: 5369.0000 - val_fp: 534.0000 - val_tn: 5369.0000 - val_fn: 534.0000 - val_accuracy: 0.9095 - train_sensitivity: 0.9332 - train_specificity: 0.9332 - train_balacc: 0.9332 - val_sensitivity: 0.9095 - val_specificity: 0.9095 - val_balacc: 0.9095\n",
      "Epoch 158/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1731 - tp: 21715.0000 - fp: 1585.0000 - tn: 21715.0000 - fn: 1585.0000 - accuracy: 0.9320 train_balacc 0.9321926220829274\n",
      " val_balacc 0.929357953582924\n",
      "\n",
      "Epoch 158: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1725 - tp: 22010.0000 - fp: 1601.0000 - tn: 22010.0000 - fn: 1601.0000 - accuracy: 0.9322 - val_loss: 0.1751 - val_tp: 5486.0000 - val_fp: 417.0000 - val_tn: 5486.0000 - val_fn: 417.0000 - val_accuracy: 0.9294 - train_sensitivity: 0.9322 - train_specificity: 0.9322 - train_balacc: 0.9322 - val_sensitivity: 0.9294 - val_specificity: 0.9294 - val_balacc: 0.9294\n",
      "Epoch 159/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1679 - tp: 21862.0000 - fp: 1638.0000 - tn: 21862.0000 - fn: 1638.0000 - accuracy: 0.9303 train_balacc 0.9302020244801152\n",
      " val_balacc 0.9114009825512451\n",
      "\n",
      "Epoch 159: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1680 - tp: 21963.0000 - fp: 1648.0000 - tn: 21963.0000 - fn: 1648.0000 - accuracy: 0.9302 - val_loss: 0.2072 - val_tp: 5380.0000 - val_fp: 523.0000 - val_tn: 5380.0000 - val_fn: 523.0000 - val_accuracy: 0.9114 - train_sensitivity: 0.9302 - train_specificity: 0.9302 - train_balacc: 0.9302 - val_sensitivity: 0.9114 - val_specificity: 0.9114 - val_balacc: 0.9114\n",
      "Epoch 160/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1652 - tp: 21539.0000 - fp: 1561.0000 - tn: 21539.0000 - fn: 1561.0000 - accuracy: 0.9324 train_balacc 0.9321926220829274\n",
      " val_balacc 0.9122480094867017\n",
      "\n",
      "Epoch 160: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1661 - tp: 22010.0000 - fp: 1601.0000 - tn: 22010.0000 - fn: 1601.0000 - accuracy: 0.9322 - val_loss: 0.2115 - val_tp: 5385.0000 - val_fp: 518.0000 - val_tn: 5385.0000 - val_fn: 518.0000 - val_accuracy: 0.9122 - train_sensitivity: 0.9322 - train_specificity: 0.9322 - train_balacc: 0.9322 - val_sensitivity: 0.9122 - val_specificity: 0.9122 - val_balacc: 0.9122\n",
      "Epoch 161/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1645 - tp: 21543.0000 - fp: 1557.0000 - tn: 21543.0000 - fn: 1557.0000 - accuracy: 0.9326 train_balacc 0.9323196815043836\n",
      " val_balacc 0.9242757919701846\n",
      "\n",
      "Epoch 161: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1649 - tp: 22013.0000 - fp: 1598.0000 - tn: 22013.0000 - fn: 1598.0000 - accuracy: 0.9323 - val_loss: 0.1723 - val_tp: 5456.0000 - val_fp: 447.0000 - val_tn: 5456.0000 - val_fn: 447.0000 - val_accuracy: 0.9243 - train_sensitivity: 0.9323 - train_specificity: 0.9323 - train_balacc: 0.9323 - val_sensitivity: 0.9243 - val_specificity: 0.9243 - val_balacc: 0.9243\n",
      "Epoch 162/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1643 - tp: 21304.0000 - fp: 1496.0000 - tn: 21304.0000 - fn: 1496.0000 - accuracy: 0.9344 train_balacc 0.934098513404769\n",
      " val_balacc 0.8775199051329833\n",
      "\n",
      "Epoch 162: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1647 - tp: 22055.0000 - fp: 1556.0000 - tn: 22055.0000 - fn: 1556.0000 - accuracy: 0.9341 - val_loss: 0.2519 - val_tp: 5180.0000 - val_fp: 723.0000 - val_tn: 5180.0000 - val_fn: 723.0000 - val_accuracy: 0.8775 - train_sensitivity: 0.9341 - train_specificity: 0.9341 - train_balacc: 0.9341 - val_sensitivity: 0.8775 - val_specificity: 0.8775 - val_balacc: 0.8775\n",
      "Epoch 163/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1662 - tp: 21537.0000 - fp: 1563.0000 - tn: 21537.0000 - fn: 1563.0000 - accuracy: 0.9323 train_balacc 0.9324043877853543\n",
      " val_balacc 0.9285109266474674\n",
      "\n",
      "Epoch 163: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1657 - tp: 22015.0000 - fp: 1596.0000 - tn: 22015.0000 - fn: 1596.0000 - accuracy: 0.9324 - val_loss: 0.1880 - val_tp: 5481.0000 - val_fp: 422.0000 - val_tn: 5481.0000 - val_fn: 422.0000 - val_accuracy: 0.9285 - train_sensitivity: 0.9324 - train_specificity: 0.9324 - train_balacc: 0.9324 - val_sensitivity: 0.9285 - val_specificity: 0.9285 - val_balacc: 0.9285\n",
      "Epoch 164/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1682 - tp: 21351.0000 - fp: 1549.0000 - tn: 21351.0000 - fn: 1549.0000 - accuracy: 0.9324 train_balacc 0.9324043877853543\n",
      " val_balacc 0.870235473488057\n",
      "\n",
      "Epoch 164: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1680 - tp: 22015.0000 - fp: 1596.0000 - tn: 22015.0000 - fn: 1596.0000 - accuracy: 0.9324 - val_loss: 0.3523 - val_tp: 5137.0000 - val_fp: 766.0000 - val_tn: 5137.0000 - val_fn: 766.0000 - val_accuracy: 0.8702 - train_sensitivity: 0.9324 - train_specificity: 0.9324 - train_balacc: 0.9324 - val_sensitivity: 0.8702 - val_specificity: 0.8702 - val_balacc: 0.8702\n",
      "Epoch 165/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1709 - tp: 21615.0000 - fp: 1585.0000 - tn: 21615.0000 - fn: 1585.0000 - accuracy: 0.9317 train_balacc 0.9317267375375884\n",
      " val_balacc 0.8781975266813484\n",
      "\n",
      "Epoch 165: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1705 - tp: 21999.0000 - fp: 1612.0000 - tn: 21999.0000 - fn: 1612.0000 - accuracy: 0.9317 - val_loss: 0.2833 - val_tp: 5184.0000 - val_fp: 719.0000 - val_tn: 5184.0000 - val_fn: 719.0000 - val_accuracy: 0.8782 - train_sensitivity: 0.9317 - train_specificity: 0.9317 - train_balacc: 0.9317 - val_sensitivity: 0.8782 - val_specificity: 0.8782 - val_balacc: 0.8782\n",
      "Epoch 166/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1641 - tp: 21662.0000 - fp: 1538.0000 - tn: 21662.0000 - fn: 1538.0000 - accuracy: 0.9337 train_balacc 0.9336749819999153\n",
      " val_balacc 0.9059800101643233\n",
      "\n",
      "Epoch 166: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1644 - tp: 22045.0000 - fp: 1566.0000 - tn: 22045.0000 - fn: 1566.0000 - accuracy: 0.9337 - val_loss: 0.2214 - val_tp: 5348.0000 - val_fp: 555.0000 - val_tn: 5348.0000 - val_fn: 555.0000 - val_accuracy: 0.9060 - train_sensitivity: 0.9337 - train_specificity: 0.9337 - train_balacc: 0.9337 - val_sensitivity: 0.9060 - val_specificity: 0.9060 - val_balacc: 0.9060\n",
      "Epoch 167/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1658 - tp: 21346.0000 - fp: 1554.0000 - tn: 21346.0000 - fn: 1554.0000 - accuracy: 0.9321 train_balacc 0.9315996781161323\n",
      " val_balacc 0.9357953582923937\n",
      "\n",
      "Epoch 167: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1691 - tp: 21996.0000 - fp: 1615.0000 - tn: 21996.0000 - fn: 1615.0000 - accuracy: 0.9316 - val_loss: 0.1802 - val_tp: 5524.0000 - val_fp: 379.0000 - val_tn: 5524.0000 - val_fn: 379.0000 - val_accuracy: 0.9358 - train_sensitivity: 0.9316 - train_specificity: 0.9316 - train_balacc: 0.9316 - val_sensitivity: 0.9358 - val_specificity: 0.9358 - val_balacc: 0.9358\n",
      "Epoch 168/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1738 - tp: 21261.0000 - fp: 1639.0000 - tn: 21261.0000 - fn: 1639.0000 - accuracy: 0.9284 train_balacc 0.9283808394392444\n",
      " val_balacc 0.9107233610028799\n",
      "\n",
      "Epoch 168: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1743 - tp: 21920.0000 - fp: 1691.0000 - tn: 21920.0000 - fn: 1691.0000 - accuracy: 0.9284 - val_loss: 0.2196 - val_tp: 5376.0000 - val_fp: 527.0000 - val_tn: 5376.0000 - val_fn: 527.0000 - val_accuracy: 0.9107 - train_sensitivity: 0.9284 - train_specificity: 0.9284 - train_balacc: 0.9284 - val_sensitivity: 0.9107 - val_specificity: 0.9107 - val_balacc: 0.9107\n",
      "Epoch 169/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1732 - tp: 21418.0000 - fp: 1582.0000 - tn: 21418.0000 - fn: 1582.0000 - accuracy: 0.9312 train_balacc 0.9317690906780738\n",
      " val_balacc 0.8892088768422836\n",
      "\n",
      "Epoch 169: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1714 - tp: 22000.0000 - fp: 1611.0000 - tn: 22000.0000 - fn: 1611.0000 - accuracy: 0.9318 - val_loss: 0.2409 - val_tp: 5249.0000 - val_fp: 654.0000 - val_tn: 5249.0000 - val_fn: 654.0000 - val_accuracy: 0.8892 - train_sensitivity: 0.9318 - train_specificity: 0.9318 - train_balacc: 0.9318 - val_sensitivity: 0.8892 - val_specificity: 0.8892 - val_balacc: 0.8892\n",
      "Epoch 170/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1727 - tp: 21294.0000 - fp: 1606.0000 - tn: 21294.0000 - fn: 1606.0000 - accuracy: 0.9299 train_balacc 0.929947905637203\n",
      " val_balacc 0.9036083347450449\n",
      "\n",
      "Epoch 170: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1725 - tp: 21957.0000 - fp: 1654.0000 - tn: 21957.0000 - fn: 1654.0000 - accuracy: 0.9299 - val_loss: 0.2269 - val_tp: 5334.0000 - val_fp: 569.0000 - val_tn: 5334.0000 - val_fn: 569.0000 - val_accuracy: 0.9036 - train_sensitivity: 0.9299 - train_specificity: 0.9299 - train_balacc: 0.9299 - val_sensitivity: 0.9036 - val_specificity: 0.9036 - val_balacc: 0.9036\n",
      "Epoch 171/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1633 - tp: 22040.0000 - fp: 1560.0000 - tn: 22040.0000 - fn: 1560.0000 - accuracy: 0.9339 train_balacc 0.9338020414213714\n",
      " val_balacc 0.886667796035914\n",
      "\n",
      "Epoch 171: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1637 - tp: 22048.0000 - fp: 1563.0000 - tn: 22048.0000 - fn: 1563.0000 - accuracy: 0.9338 - val_loss: 0.2356 - val_tp: 5234.0000 - val_fp: 669.0000 - val_tn: 5234.0000 - val_fn: 669.0000 - val_accuracy: 0.8867 - train_sensitivity: 0.9338 - train_specificity: 0.9338 - train_balacc: 0.9338 - val_sensitivity: 0.8867 - val_specificity: 0.8867 - val_balacc: 0.8867\n",
      "Epoch 172/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1612 - tp: 21493.0000 - fp: 1507.0000 - tn: 21493.0000 - fn: 1507.0000 - accuracy: 0.9345 train_balacc 0.9343526322476812\n",
      " val_balacc 0.9112315771641538\n",
      "\n",
      "Epoch 172: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1608 - tp: 22061.0000 - fp: 1550.0000 - tn: 22061.0000 - fn: 1550.0000 - accuracy: 0.9344 - val_loss: 0.2276 - val_tp: 5379.0000 - val_fp: 524.0000 - val_tn: 5379.0000 - val_fn: 524.0000 - val_accuracy: 0.9112 - train_sensitivity: 0.9344 - train_specificity: 0.9344 - train_balacc: 0.9344 - val_sensitivity: 0.9112 - val_specificity: 0.9112 - val_balacc: 0.9112\n",
      "Epoch 173/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1720 - tp: 21993.0000 - fp: 1618.0000 - tn: 21993.0000 - fn: 1618.0000 - accuracy: 0.9315 train_balacc 0.9314726186946762\n",
      " val_balacc 0.9130950364221583\n",
      "\n",
      "Epoch 173: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1720 - tp: 21993.0000 - fp: 1618.0000 - tn: 21993.0000 - fn: 1618.0000 - accuracy: 0.9315 - val_loss: 0.1993 - val_tp: 5390.0000 - val_fp: 513.0000 - val_tn: 5390.0000 - val_fn: 513.0000 - val_accuracy: 0.9131 - train_sensitivity: 0.9315 - train_specificity: 0.9315 - train_balacc: 0.9315 - val_sensitivity: 0.9131 - val_specificity: 0.9131 - val_balacc: 0.9131\n",
      "Epoch 174/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1690 - tp: 21674.0000 - fp: 1626.0000 - tn: 21674.0000 - fn: 1626.0000 - accuracy: 0.9302 train_balacc 0.929947905637203\n",
      " val_balacc 0.8561748263594783\n",
      "\n",
      "Epoch 174: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1689 - tp: 21957.0000 - fp: 1654.0000 - tn: 21957.0000 - fn: 1654.0000 - accuracy: 0.9299 - val_loss: 0.3041 - val_tp: 5054.0000 - val_fp: 849.0000 - val_tn: 5054.0000 - val_fn: 849.0000 - val_accuracy: 0.8562 - train_sensitivity: 0.9299 - train_specificity: 0.9299 - train_balacc: 0.9299 - val_sensitivity: 0.8562 - val_specificity: 0.8562 - val_balacc: 0.8562\n",
      "Epoch 175/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1710 - tp: 21249.0000 - fp: 1551.0000 - tn: 21249.0000 - fn: 1551.0000 - accuracy: 0.9320 train_balacc 0.9318114438185592\n",
      " val_balacc 0.8639674741656784\n",
      "\n",
      "Epoch 175: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1701 - tp: 22001.0000 - fp: 1610.0000 - tn: 22001.0000 - fn: 1610.0000 - accuracy: 0.9318 - val_loss: 0.3255 - val_tp: 5100.0000 - val_fp: 803.0000 - val_tn: 5100.0000 - val_fn: 803.0000 - val_accuracy: 0.8640 - train_sensitivity: 0.9318 - train_specificity: 0.9318 - train_balacc: 0.9318 - val_sensitivity: 0.8640 - val_specificity: 0.8640 - val_balacc: 0.8640\n",
      "Epoch 176/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1669 - tp: 21791.0000 - fp: 1609.0000 - tn: 21791.0000 - fn: 1609.0000 - accuracy: 0.9312 train_balacc 0.9310914404303079\n",
      " val_balacc 0.8992037946806708\n",
      "\n",
      "Epoch 176: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1667 - tp: 21984.0000 - fp: 1627.0000 - tn: 21984.0000 - fn: 1627.0000 - accuracy: 0.9311 - val_loss: 0.2131 - val_tp: 5308.0000 - val_fp: 595.0000 - val_tn: 5308.0000 - val_fn: 595.0000 - val_accuracy: 0.8992 - train_sensitivity: 0.9311 - train_specificity: 0.9311 - train_balacc: 0.9311 - val_sensitivity: 0.8992 - val_specificity: 0.8992 - val_balacc: 0.8992\n",
      "Epoch 177/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1638 - tp: 21676.0000 - fp: 1524.0000 - tn: 21676.0000 - fn: 1524.0000 - accuracy: 0.9343 train_balacc 0.9344796916691372\n",
      " val_balacc 0.8178892088768422\n",
      "\n",
      "Epoch 177: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1632 - tp: 22064.0000 - fp: 1547.0000 - tn: 22064.0000 - fn: 1547.0000 - accuracy: 0.9345 - val_loss: 0.4098 - val_tp: 4828.0000 - val_fp: 1075.0000 - val_tn: 4828.0000 - val_fn: 1075.0000 - val_accuracy: 0.8179 - train_sensitivity: 0.9345 - train_specificity: 0.9345 - train_balacc: 0.9345 - val_sensitivity: 0.8179 - val_specificity: 0.8179 - val_balacc: 0.8179\n",
      "Epoch 178/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1662 - tp: 21642.0000 - fp: 1558.0000 - tn: 21642.0000 - fn: 1558.0000 - accuracy: 0.9328 train_balacc 0.9325314472068104\n",
      " val_balacc 0.915127901067254\n",
      "\n",
      "Epoch 178: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1671 - tp: 22018.0000 - fp: 1593.0000 - tn: 22018.0000 - fn: 1593.0000 - accuracy: 0.9325 - val_loss: 0.1906 - val_tp: 5402.0000 - val_fp: 501.0000 - val_tn: 5402.0000 - val_fn: 501.0000 - val_accuracy: 0.9151 - train_sensitivity: 0.9325 - train_specificity: 0.9325 - train_balacc: 0.9325 - val_sensitivity: 0.9151 - val_specificity: 0.9151 - val_balacc: 0.9151\n",
      "Epoch 179/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1669 - tp: 21995.0000 - fp: 1605.0000 - tn: 21995.0000 - fn: 1605.0000 - accuracy: 0.9320 train_balacc 0.9319385032400153\n",
      " val_balacc 0.8859901744875487\n",
      "\n",
      "Epoch 179: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1675 - tp: 22004.0000 - fp: 1607.0000 - tn: 22004.0000 - fn: 1607.0000 - accuracy: 0.9319 - val_loss: 0.2550 - val_tp: 5230.0000 - val_fp: 673.0000 - val_tn: 5230.0000 - val_fn: 673.0000 - val_accuracy: 0.8860 - train_sensitivity: 0.9319 - train_specificity: 0.9319 - train_balacc: 0.9319 - val_sensitivity: 0.8860 - val_specificity: 0.8860 - val_balacc: 0.8860\n",
      "Epoch 180/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1670 - tp: 21622.0000 - fp: 1578.0000 - tn: 21622.0000 - fn: 1578.0000 - accuracy: 0.9320 train_balacc 0.9321926220829274\n",
      " val_balacc 0.9112315771641538\n",
      "\n",
      "Epoch 180: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1663 - tp: 22010.0000 - fp: 1601.0000 - tn: 22010.0000 - fn: 1601.0000 - accuracy: 0.9322 - val_loss: 0.2046 - val_tp: 5379.0000 - val_fp: 524.0000 - val_tn: 5379.0000 - val_fn: 524.0000 - val_accuracy: 0.9112 - train_sensitivity: 0.9322 - train_specificity: 0.9322 - train_balacc: 0.9322 - val_sensitivity: 0.9112 - val_specificity: 0.9112 - val_balacc: 0.9112\n",
      "Epoch 181/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1640 - tp: 21478.0000 - fp: 1522.0000 - tn: 21478.0000 - fn: 1522.0000 - accuracy: 0.9338 train_balacc 0.9333785100165177\n",
      " val_balacc 0.9142808741317974\n",
      "\n",
      "Epoch 181: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1643 - tp: 22038.0000 - fp: 1573.0000 - tn: 22038.0000 - fn: 1573.0000 - accuracy: 0.9334 - val_loss: 0.2160 - val_tp: 5397.0000 - val_fp: 506.0000 - val_tn: 5397.0000 - val_fn: 506.0000 - val_accuracy: 0.9143 - train_sensitivity: 0.9334 - train_specificity: 0.9334 - train_balacc: 0.9334 - val_sensitivity: 0.9143 - val_specificity: 0.9143 - val_balacc: 0.9143\n",
      "Epoch 182/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1600 - tp: 21688.0000 - fp: 1512.0000 - tn: 21688.0000 - fn: 1512.0000 - accuracy: 0.9348 train_balacc 0.9347761636525348\n",
      " val_balacc 0.9130950364221583\n",
      "\n",
      "Epoch 182: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1602 - tp: 22071.0000 - fp: 1540.0000 - tn: 22071.0000 - fn: 1540.0000 - accuracy: 0.9348 - val_loss: 0.2244 - val_tp: 5390.0000 - val_fp: 513.0000 - val_tn: 5390.0000 - val_fn: 513.0000 - val_accuracy: 0.9131 - train_sensitivity: 0.9348 - train_specificity: 0.9348 - train_balacc: 0.9348 - val_sensitivity: 0.9131 - val_specificity: 0.9131 - val_balacc: 0.9131\n",
      "Epoch 183/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1657 - tp: 21939.0000 - fp: 1561.0000 - tn: 21939.0000 - fn: 1561.0000 - accuracy: 0.9336 train_balacc 0.9337596882808861\n",
      " val_balacc 0.8680332034558699\n",
      "\n",
      "Epoch 183: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1653 - tp: 22047.0000 - fp: 1564.0000 - tn: 22047.0000 - fn: 1564.0000 - accuracy: 0.9338 - val_loss: 0.2822 - val_tp: 5124.0000 - val_fp: 779.0000 - val_tn: 5124.0000 - val_fn: 779.0000 - val_accuracy: 0.8680 - train_sensitivity: 0.9338 - train_specificity: 0.9338 - train_balacc: 0.9338 - val_sensitivity: 0.8680 - val_specificity: 0.8680 - val_balacc: 0.8680\n",
      "Epoch 184/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1649 - tp: 21747.0000 - fp: 1553.0000 - tn: 21747.0000 - fn: 1553.0000 - accuracy: 0.9333 train_balacc 0.9333361568760323\n",
      " val_balacc 0.9171607657123496\n",
      "\n",
      "Epoch 184: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1647 - tp: 22037.0000 - fp: 1574.0000 - tn: 22037.0000 - fn: 1574.0000 - accuracy: 0.9333 - val_loss: 0.1902 - val_tp: 5414.0000 - val_fp: 489.0000 - val_tn: 5414.0000 - val_fn: 489.0000 - val_accuracy: 0.9172 - train_sensitivity: 0.9333 - train_specificity: 0.9333 - train_balacc: 0.9333 - val_sensitivity: 0.9172 - val_specificity: 0.9172 - val_balacc: 0.9172\n",
      "Epoch 185/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1629 - tp: 21254.0000 - fp: 1546.0000 - tn: 21254.0000 - fn: 1546.0000 - accuracy: 0.9322 train_balacc 0.9319385032400153\n",
      " val_balacc 0.9244451973572759\n",
      "\n",
      "Epoch 185: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1637 - tp: 22004.0000 - fp: 1607.0000 - tn: 22004.0000 - fn: 1607.0000 - accuracy: 0.9319 - val_loss: 0.1822 - val_tp: 5457.0000 - val_fp: 446.0000 - val_tn: 5457.0000 - val_fn: 446.0000 - val_accuracy: 0.9244 - train_sensitivity: 0.9319 - train_specificity: 0.9319 - train_balacc: 0.9319 - val_sensitivity: 0.9244 - val_specificity: 0.9244 - val_balacc: 0.9244\n",
      "Epoch 186/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1640 - tp: 21776.0000 - fp: 1524.0000 - tn: 21776.0000 - fn: 1524.0000 - accuracy: 0.9346 train_balacc 0.9347338105120495\n",
      " val_balacc 0.8929357953582924\n",
      "\n",
      "Epoch 186: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1636 - tp: 22070.0000 - fp: 1541.0000 - tn: 22070.0000 - fn: 1541.0000 - accuracy: 0.9347 - val_loss: 0.2693 - val_tp: 5271.0000 - val_fp: 632.0000 - val_tn: 5271.0000 - val_fn: 632.0000 - val_accuracy: 0.8929 - train_sensitivity: 0.9347 - train_specificity: 0.9347 - train_balacc: 0.9347 - val_sensitivity: 0.8929 - val_specificity: 0.8929 - val_balacc: 0.8929\n",
      "Epoch 187/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1667 - tp: 21242.0000 - fp: 1558.0000 - tn: 21242.0000 - fn: 1558.0000 - accuracy: 0.9317 train_balacc 0.9320232095209859\n",
      " val_balacc 0.8792139590038963\n",
      "\n",
      "Epoch 187: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1656 - tp: 22006.0000 - fp: 1605.0000 - tn: 22006.0000 - fn: 1605.0000 - accuracy: 0.9320 - val_loss: 0.2821 - val_tp: 5190.0000 - val_fp: 713.0000 - val_tn: 5190.0000 - val_fn: 713.0000 - val_accuracy: 0.8792 - train_sensitivity: 0.9320 - train_specificity: 0.9320 - train_balacc: 0.9320 - val_sensitivity: 0.8792 - val_specificity: 0.8792 - val_balacc: 0.8792\n",
      "Epoch 188/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1662 - tp: 21588.0000 - fp: 1512.0000 - tn: 21588.0000 - fn: 1512.0000 - accuracy: 0.9345 train_balacc 0.9341408665452543\n",
      " val_balacc 0.8649839064882263\n",
      "\n",
      "Epoch 188: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1670 - tp: 22056.0000 - fp: 1555.0000 - tn: 22056.0000 - fn: 1555.0000 - accuracy: 0.9341 - val_loss: 0.2909 - val_tp: 5106.0000 - val_fp: 797.0000 - val_tn: 5106.0000 - val_fn: 797.0000 - val_accuracy: 0.8650 - train_sensitivity: 0.9341 - train_specificity: 0.9341 - train_balacc: 0.9341 - val_sensitivity: 0.8650 - val_specificity: 0.8650 - val_balacc: 0.8650\n",
      "Epoch 189/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1618 - tp: 21875.0000 - fp: 1525.0000 - tn: 21875.0000 - fn: 1525.0000 - accuracy: 0.9348 train_balacc 0.934903223073991\n",
      " val_balacc 0.9213959003896324\n",
      "\n",
      "Epoch 189: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1615 - tp: 22074.0000 - fp: 1537.0000 - tn: 22074.0000 - fn: 1537.0000 - accuracy: 0.9349 - val_loss: 0.1852 - val_tp: 5439.0000 - val_fp: 464.0000 - val_tn: 5439.0000 - val_fn: 464.0000 - val_accuracy: 0.9214 - train_sensitivity: 0.9349 - train_specificity: 0.9349 - train_balacc: 0.9349 - val_sensitivity: 0.9214 - val_specificity: 0.9214 - val_balacc: 0.9214\n",
      "Epoch 190/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1656 - tp: 21962.0000 - fp: 1538.0000 - tn: 21962.0000 - fn: 1538.0000 - accuracy: 0.9346 train_balacc 0.934564397950108\n",
      " val_balacc 0.863120447230222\n",
      "\n",
      "Epoch 190: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1655 - tp: 22066.0000 - fp: 1545.0000 - tn: 22066.0000 - fn: 1545.0000 - accuracy: 0.9346 - val_loss: 0.2789 - val_tp: 5095.0000 - val_fp: 808.0000 - val_tn: 5095.0000 - val_fn: 808.0000 - val_accuracy: 0.8631 - train_sensitivity: 0.9346 - train_specificity: 0.9346 - train_balacc: 0.9346 - val_sensitivity: 0.8631 - val_specificity: 0.8631 - val_balacc: 0.8631\n",
      "Epoch 191/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1612 - tp: 21490.0000 - fp: 1510.0000 - tn: 21490.0000 - fn: 1510.0000 - accuracy: 0.9343 train_balacc 0.9346491042310787\n",
      " val_balacc 0.8993732000677621\n",
      "\n",
      "Epoch 191: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1602 - tp: 22068.0000 - fp: 1543.0000 - tn: 22068.0000 - fn: 1543.0000 - accuracy: 0.9346 - val_loss: 0.2546 - val_tp: 5309.0000 - val_fp: 594.0000 - val_tn: 5309.0000 - val_fn: 594.0000 - val_accuracy: 0.8994 - train_sensitivity: 0.9346 - train_specificity: 0.9346 - train_balacc: 0.9346 - val_sensitivity: 0.8994 - val_specificity: 0.8994 - val_balacc: 0.8994\n",
      "Epoch 192/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1604 - tp: 21431.0000 - fp: 1469.0000 - tn: 21431.0000 - fn: 1469.0000 - accuracy: 0.9359 train_balacc 0.9356232264622422\n",
      " val_balacc 0.8876842283584618\n",
      "\n",
      "Epoch 192: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1623 - tp: 22091.0000 - fp: 1520.0000 - tn: 22091.0000 - fn: 1520.0000 - accuracy: 0.9356 - val_loss: 0.2597 - val_tp: 5240.0000 - val_fp: 663.0000 - val_tn: 5240.0000 - val_fn: 663.0000 - val_accuracy: 0.8877 - train_sensitivity: 0.9356 - train_specificity: 0.9356 - train_balacc: 0.9356 - val_sensitivity: 0.8877 - val_specificity: 0.8877 - val_balacc: 0.8877\n",
      "Epoch 193/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1572 - tp: 21432.0000 - fp: 1468.0000 - tn: 21432.0000 - fn: 1468.0000 - accuracy: 0.9359 train_balacc 0.9362585235695227\n",
      " val_balacc 0.9095375232932408\n",
      "\n",
      "Epoch 193: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1567 - tp: 22106.0000 - fp: 1505.0000 - tn: 22106.0000 - fn: 1505.0000 - accuracy: 0.9363 - val_loss: 0.2115 - val_tp: 5369.0000 - val_fp: 534.0000 - val_tn: 5369.0000 - val_fn: 534.0000 - val_accuracy: 0.9095 - train_sensitivity: 0.9363 - train_specificity: 0.9363 - train_balacc: 0.9363 - val_sensitivity: 0.9095 - val_specificity: 0.9095 - val_balacc: 0.9095\n",
      "Epoch 194/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1595 - tp: 21506.0000 - fp: 1494.0000 - tn: 21506.0000 - fn: 1494.0000 - accuracy: 0.9350 train_balacc 0.9355808733217568\n",
      " val_balacc 0.9112315771641538\n",
      "\n",
      "Epoch 194: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1586 - tp: 22090.0000 - fp: 1521.0000 - tn: 22090.0000 - fn: 1521.0000 - accuracy: 0.9356 - val_loss: 0.2059 - val_tp: 5379.0000 - val_fp: 524.0000 - val_tn: 5379.0000 - val_fn: 524.0000 - val_accuracy: 0.9112 - train_sensitivity: 0.9356 - train_specificity: 0.9356 - train_balacc: 0.9356 - val_sensitivity: 0.9112 - val_specificity: 0.9112 - val_balacc: 0.9112\n",
      "Epoch 195/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1599 - tp: 21485.0000 - fp: 1515.0000 - tn: 21485.0000 - fn: 1515.0000 - accuracy: 0.9341 train_balacc 0.9342255728262251\n",
      " val_balacc 0.8583770963916653\n",
      "\n",
      "Epoch 195: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1595 - tp: 22058.0000 - fp: 1553.0000 - tn: 22058.0000 - fn: 1553.0000 - accuracy: 0.9342 - val_loss: 0.3273 - val_tp: 5067.0000 - val_fp: 836.0000 - val_tn: 5067.0000 - val_fn: 836.0000 - val_accuracy: 0.8584 - train_sensitivity: 0.9342 - train_specificity: 0.9342 - train_balacc: 0.9342 - val_sensitivity: 0.8584 - val_specificity: 0.8584 - val_balacc: 0.8584\n",
      "Epoch 196/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1601 - tp: 21342.0000 - fp: 1458.0000 - tn: 21342.0000 - fn: 1458.0000 - accuracy: 0.9361 train_balacc 0.9362585235695227\n",
      " val_balacc 0.9156361172285279\n",
      "\n",
      "Epoch 196: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1600 - tp: 22106.0000 - fp: 1505.0000 - tn: 22106.0000 - fn: 1505.0000 - accuracy: 0.9363 - val_loss: 0.1858 - val_tp: 5405.0000 - val_fp: 498.0000 - val_tn: 5405.0000 - val_fn: 498.0000 - val_accuracy: 0.9156 - train_sensitivity: 0.9363 - train_specificity: 0.9363 - train_balacc: 0.9363 - val_sensitivity: 0.9156 - val_specificity: 0.9156 - val_balacc: 0.9156\n",
      "Epoch 197/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1574 - tp: 21611.0000 - fp: 1489.0000 - tn: 21611.0000 - fn: 1489.0000 - accuracy: 0.9355 train_balacc 0.9352420481978738\n",
      " val_balacc 0.9159749280027105\n",
      "\n",
      "Epoch 197: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1579 - tp: 22082.0000 - fp: 1529.0000 - tn: 22082.0000 - fn: 1529.0000 - accuracy: 0.9352 - val_loss: 0.1929 - val_tp: 5407.0000 - val_fp: 496.0000 - val_tn: 5407.0000 - val_fn: 496.0000 - val_accuracy: 0.9160 - train_sensitivity: 0.9352 - train_specificity: 0.9352 - train_balacc: 0.9352 - val_sensitivity: 0.9160 - val_specificity: 0.9160 - val_balacc: 0.9160\n",
      "Epoch 198/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1562 - tp: 21543.0000 - fp: 1457.0000 - tn: 21543.0000 - fn: 1457.0000 - accuracy: 0.9367 train_balacc 0.9363008767100081\n",
      " val_balacc 0.9000508216161274\n",
      "\n",
      "Epoch 198: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1573 - tp: 22107.0000 - fp: 1504.0000 - tn: 22107.0000 - fn: 1504.0000 - accuracy: 0.9363 - val_loss: 0.2056 - val_tp: 5313.0000 - val_fp: 590.0000 - val_tn: 5313.0000 - val_fn: 590.0000 - val_accuracy: 0.9001 - train_sensitivity: 0.9363 - train_specificity: 0.9363 - train_balacc: 0.9363 - val_sensitivity: 0.9001 - val_specificity: 0.9001 - val_balacc: 0.9001\n",
      "Epoch 199/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1694 - tp: 21459.0000 - fp: 1541.0000 - tn: 21459.0000 - fn: 1541.0000 - accuracy: 0.9330 train_balacc 0.9327432129092372\n",
      " val_balacc 0.9020836862612231\n",
      "\n",
      "Epoch 199: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1708 - tp: 22023.0000 - fp: 1588.0000 - tn: 22023.0000 - fn: 1588.0000 - accuracy: 0.9327 - val_loss: 0.2409 - val_tp: 5325.0000 - val_fp: 578.0000 - val_tn: 5325.0000 - val_fn: 578.0000 - val_accuracy: 0.9021 - train_sensitivity: 0.9327 - train_specificity: 0.9327 - train_balacc: 0.9327 - val_sensitivity: 0.9021 - val_specificity: 0.9021 - val_balacc: 0.9021\n",
      "Epoch 200/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1661 - tp: 21750.0000 - fp: 1550.0000 - tn: 21750.0000 - fn: 1550.0000 - accuracy: 0.9335 train_balacc 0.9335055694379738\n",
      " val_balacc 0.9069964424868711\n",
      "\n",
      "Epoch 200: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1659 - tp: 22041.0000 - fp: 1570.0000 - tn: 22041.0000 - fn: 1570.0000 - accuracy: 0.9335 - val_loss: 0.2070 - val_tp: 5354.0000 - val_fp: 549.0000 - val_tn: 5354.0000 - val_fn: 549.0000 - val_accuracy: 0.9070 - train_sensitivity: 0.9335 - train_specificity: 0.9335 - train_balacc: 0.9335 - val_sensitivity: 0.9070 - val_specificity: 0.9070 - val_balacc: 0.9070\n",
      "Epoch 201/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1610 - tp: 21399.0000 - fp: 1501.0000 - tn: 21399.0000 - fn: 1501.0000 - accuracy: 0.9345 train_balacc 0.9340138071237982\n",
      " val_balacc 0.9181771980348975\n",
      "\n",
      "Epoch 201: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1605 - tp: 22053.0000 - fp: 1558.0000 - tn: 22053.0000 - fn: 1558.0000 - accuracy: 0.9340 - val_loss: 0.1915 - val_tp: 5420.0000 - val_fp: 483.0000 - val_tn: 5420.0000 - val_fn: 483.0000 - val_accuracy: 0.9182 - train_sensitivity: 0.9340 - train_specificity: 0.9340 - train_balacc: 0.9340 - val_sensitivity: 0.9182 - val_specificity: 0.9182 - val_balacc: 0.9182\n",
      "Epoch 202/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1567 - tp: 21554.0000 - fp: 1446.0000 - tn: 21554.0000 - fn: 1446.0000 - accuracy: 0.9371 train_balacc 0.9374867646435984\n",
      " val_balacc 0.8478739623920041\n",
      "\n",
      "Epoch 202: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1567 - tp: 22135.0000 - fp: 1476.0000 - tn: 22135.0000 - fn: 1476.0000 - accuracy: 0.9375 - val_loss: 0.3660 - val_tp: 5005.0000 - val_fp: 898.0000 - val_tn: 5005.0000 - val_fn: 898.0000 - val_accuracy: 0.8479 - train_sensitivity: 0.9375 - train_specificity: 0.9375 - train_balacc: 0.9375 - val_sensitivity: 0.8479 - val_specificity: 0.8479 - val_balacc: 0.8479\n",
      "Epoch 203/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1629 - tp: 21813.0000 - fp: 1587.0000 - tn: 21813.0000 - fn: 1587.0000 - accuracy: 0.9322 train_balacc 0.9319808563805007\n",
      " val_balacc 0.8907335253261054\n",
      "\n",
      "Epoch 203: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1640 - tp: 22005.0000 - fp: 1606.0000 - tn: 22005.0000 - fn: 1606.0000 - accuracy: 0.9320 - val_loss: 0.2646 - val_tp: 5258.0000 - val_fp: 645.0000 - val_tn: 5258.0000 - val_fn: 645.0000 - val_accuracy: 0.8907 - train_sensitivity: 0.9320 - train_specificity: 0.9320 - train_balacc: 0.9320 - val_sensitivity: 0.8907 - val_specificity: 0.8907 - val_balacc: 0.8907\n",
      "Epoch 204/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1626 - tp: 22081.0000 - fp: 1519.0000 - tn: 22081.0000 - fn: 1519.0000 - accuracy: 0.9356 train_balacc 0.9355808733217568\n",
      " val_balacc 0.8729459596815179\n",
      "\n",
      "Epoch 204: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1627 - tp: 22090.0000 - fp: 1521.0000 - tn: 22090.0000 - fn: 1521.0000 - accuracy: 0.9356 - val_loss: 0.2833 - val_tp: 5153.0000 - val_fp: 750.0000 - val_tn: 5153.0000 - val_fn: 750.0000 - val_accuracy: 0.8729 - train_sensitivity: 0.9356 - train_specificity: 0.9356 - train_balacc: 0.9356 - val_sensitivity: 0.8729 - val_specificity: 0.8729 - val_balacc: 0.8729\n",
      "Epoch 205/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1610 - tp: 21985.0000 - fp: 1515.0000 - tn: 21985.0000 - fn: 1515.0000 - accuracy: 0.9355 train_balacc 0.935707932743213\n",
      " val_balacc 0.9198712519058106\n",
      "\n",
      "Epoch 205: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1606 - tp: 22093.0000 - fp: 1518.0000 - tn: 22093.0000 - fn: 1518.0000 - accuracy: 0.9357 - val_loss: 0.1963 - val_tp: 5430.0000 - val_fp: 473.0000 - val_tn: 5430.0000 - val_fn: 473.0000 - val_accuracy: 0.9199 - train_sensitivity: 0.9357 - train_specificity: 0.9357 - train_balacc: 0.9357 - val_sensitivity: 0.9199 - val_specificity: 0.9199 - val_balacc: 0.9199\n",
      "Epoch 206/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1605 - tp: 21914.0000 - fp: 1486.0000 - tn: 21914.0000 - fn: 1486.0000 - accuracy: 0.9365 train_balacc 0.9362585235695227\n",
      " val_balacc 0.908012874809419\n",
      "\n",
      "Epoch 206: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1612 - tp: 22106.0000 - fp: 1505.0000 - tn: 22106.0000 - fn: 1505.0000 - accuracy: 0.9363 - val_loss: 0.2064 - val_tp: 5360.0000 - val_fp: 543.0000 - val_tn: 5360.0000 - val_fn: 543.0000 - val_accuracy: 0.9080 - train_sensitivity: 0.9363 - train_specificity: 0.9363 - train_balacc: 0.9363 - val_sensitivity: 0.9080 - val_specificity: 0.9080 - val_balacc: 0.9080\n",
      "Epoch 207/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1618 - tp: 21283.0000 - fp: 1517.0000 - tn: 21283.0000 - fn: 1517.0000 - accuracy: 0.9335 train_balacc 0.9329126254711787\n",
      " val_balacc 0.8902253091648314\n",
      "\n",
      "Epoch 207: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1633 - tp: 22027.0000 - fp: 1584.0000 - tn: 22027.0000 - fn: 1584.0000 - accuracy: 0.9329 - val_loss: 0.2475 - val_tp: 5255.0000 - val_fp: 648.0000 - val_tn: 5255.0000 - val_fn: 648.0000 - val_accuracy: 0.8902 - train_sensitivity: 0.9329 - train_specificity: 0.9329 - train_balacc: 0.9329 - val_sensitivity: 0.8902 - val_specificity: 0.8902 - val_balacc: 0.8902\n",
      "Epoch 208/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1566 - tp: 22112.0000 - fp: 1499.0000 - tn: 22112.0000 - fn: 1499.0000 - accuracy: 0.9365 train_balacc 0.9365126424124349\n",
      " val_balacc 0.8851431475520921\n",
      "\n",
      "Epoch 208: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1566 - tp: 22112.0000 - fp: 1499.0000 - tn: 22112.0000 - fn: 1499.0000 - accuracy: 0.9365 - val_loss: 0.2324 - val_tp: 5225.0000 - val_fp: 678.0000 - val_tn: 5225.0000 - val_fn: 678.0000 - val_accuracy: 0.8851 - train_sensitivity: 0.9365 - train_specificity: 0.9365 - train_balacc: 0.9365 - val_sensitivity: 0.8851 - val_specificity: 0.8851 - val_balacc: 0.8851\n",
      "Epoch 209/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1633 - tp: 21289.0000 - fp: 1511.0000 - tn: 21289.0000 - fn: 1511.0000 - accuracy: 0.9337 train_balacc 0.9343102791071958\n",
      " val_balacc 0.9061494155514145\n",
      "\n",
      "Epoch 209: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1619 - tp: 22060.0000 - fp: 1551.0000 - tn: 22060.0000 - fn: 1551.0000 - accuracy: 0.9343 - val_loss: 0.2246 - val_tp: 5349.0000 - val_fp: 554.0000 - val_tn: 5349.0000 - val_fn: 554.0000 - val_accuracy: 0.9061 - train_sensitivity: 0.9343 - train_specificity: 0.9343 - train_balacc: 0.9343 - val_sensitivity: 0.9061 - val_specificity: 0.9061 - val_balacc: 0.9061\n",
      "Epoch 210/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1605 - tp: 21479.0000 - fp: 1521.0000 - tn: 21479.0000 - fn: 1521.0000 - accuracy: 0.9339 train_balacc 0.9335902757189446\n",
      " val_balacc 0.9230899542605455\n",
      "\n",
      "Epoch 210: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1635 - tp: 22043.0000 - fp: 1568.0000 - tn: 22043.0000 - fn: 1568.0000 - accuracy: 0.9336 - val_loss: 0.1880 - val_tp: 5449.0000 - val_fp: 454.0000 - val_tn: 5449.0000 - val_fn: 454.0000 - val_accuracy: 0.9231 - train_sensitivity: 0.9336 - train_specificity: 0.9336 - train_balacc: 0.9336 - val_sensitivity: 0.9231 - val_specificity: 0.9231 - val_balacc: 0.9231\n",
      "Epoch 211/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1603 - tp: 21429.0000 - fp: 1471.0000 - tn: 21429.0000 - fn: 1471.0000 - accuracy: 0.9358 train_balacc 0.9355385201812715\n",
      " val_balacc 0.8526173132305608\n",
      "\n",
      "Epoch 211: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1606 - tp: 22089.0000 - fp: 1522.0000 - tn: 22089.0000 - fn: 1522.0000 - accuracy: 0.9355 - val_loss: 0.3147 - val_tp: 5033.0000 - val_fp: 870.0000 - val_tn: 5033.0000 - val_fn: 870.0000 - val_accuracy: 0.8526 - train_sensitivity: 0.9355 - train_specificity: 0.9355 - train_balacc: 0.9355 - val_sensitivity: 0.8526 - val_specificity: 0.8526 - val_balacc: 0.8526\n",
      "Epoch 212/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1607 - tp: 21722.0000 - fp: 1478.0000 - tn: 21722.0000 - fn: 1478.0000 - accuracy: 0.9363 train_balacc 0.9360467578670958\n",
      " val_balacc 0.8959850923259359\n",
      "\n",
      "Epoch 212: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1636 - tp: 22101.0000 - fp: 1510.0000 - tn: 22101.0000 - fn: 1510.0000 - accuracy: 0.9360 - val_loss: 0.2236 - val_tp: 5289.0000 - val_fp: 614.0000 - val_tn: 5289.0000 - val_fn: 614.0000 - val_accuracy: 0.8960 - train_sensitivity: 0.9360 - train_specificity: 0.9360 - train_balacc: 0.9360 - val_sensitivity: 0.8960 - val_specificity: 0.8960 - val_balacc: 0.8960\n",
      "Epoch 213/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1601 - tp: 21435.0000 - fp: 1465.0000 - tn: 21435.0000 - fn: 1465.0000 - accuracy: 0.9360 train_balacc 0.9357502858836982\n",
      " val_balacc 0.9012366593257666\n",
      "\n",
      "Epoch 213: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1617 - tp: 22094.0000 - fp: 1517.0000 - tn: 22094.0000 - fn: 1517.0000 - accuracy: 0.9358 - val_loss: 0.2218 - val_tp: 5320.0000 - val_fp: 583.0000 - val_tn: 5320.0000 - val_fn: 583.0000 - val_accuracy: 0.9012 - train_sensitivity: 0.9358 - train_specificity: 0.9358 - train_balacc: 0.9358 - val_sensitivity: 0.9012 - val_specificity: 0.9012 - val_balacc: 0.9012\n",
      "Epoch 214/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1629 - tp: 21634.0000 - fp: 1466.0000 - tn: 21634.0000 - fn: 1466.0000 - accuracy: 0.9365 train_balacc 0.936639701833891\n",
      " val_balacc 0.9273250889378282\n",
      "\n",
      "Epoch 214: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1622 - tp: 22115.0000 - fp: 1496.0000 - tn: 22115.0000 - fn: 1496.0000 - accuracy: 0.9366 - val_loss: 0.1696 - val_tp: 5474.0000 - val_fp: 429.0000 - val_tn: 5474.0000 - val_fn: 429.0000 - val_accuracy: 0.9273 - train_sensitivity: 0.9366 - train_specificity: 0.9366 - train_balacc: 0.9366 - val_sensitivity: 0.9273 - val_specificity: 0.9273 - val_balacc: 0.9273\n",
      "Epoch 215/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1578 - tp: 21477.0000 - fp: 1523.0000 - tn: 21477.0000 - fn: 1523.0000 - accuracy: 0.9338 train_balacc 0.9337173351404007\n",
      " val_balacc 0.8751482297137049\n",
      "\n",
      "Epoch 215: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1590 - tp: 22046.0000 - fp: 1565.0000 - tn: 22046.0000 - fn: 1565.0000 - accuracy: 0.9337 - val_loss: 0.2578 - val_tp: 5166.0000 - val_fp: 737.0000 - val_tn: 5166.0000 - val_fn: 737.0000 - val_accuracy: 0.8751 - train_sensitivity: 0.9337 - train_specificity: 0.9337 - train_balacc: 0.9337 - val_sensitivity: 0.8751 - val_specificity: 0.8751 - val_balacc: 0.8751\n",
      "Epoch 216/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1605 - tp: 21586.0000 - fp: 1514.0000 - tn: 21586.0000 - fn: 1514.0000 - accuracy: 0.9345 train_balacc 0.9347338105120495\n",
      " val_balacc 0.9066576317126884\n",
      "\n",
      "Epoch 216: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1601 - tp: 22070.0000 - fp: 1541.0000 - tn: 22070.0000 - fn: 1541.0000 - accuracy: 0.9347 - val_loss: 0.2041 - val_tp: 5352.0000 - val_fp: 551.0000 - val_tn: 5352.0000 - val_fn: 551.0000 - val_accuracy: 0.9067 - train_sensitivity: 0.9347 - train_specificity: 0.9347 - train_balacc: 0.9347 - val_sensitivity: 0.9067 - val_specificity: 0.9067 - val_balacc: 0.9067\n",
      "Epoch 217/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1567 - tp: 22121.0000 - fp: 1479.0000 - tn: 22121.0000 - fn: 1479.0000 - accuracy: 0.9373 train_balacc 0.9373173520816569\n",
      " val_balacc 0.841267152295443\n",
      "\n",
      "Epoch 217: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1567 - tp: 22131.0000 - fp: 1480.0000 - tn: 22131.0000 - fn: 1480.0000 - accuracy: 0.9373 - val_loss: 0.6101 - val_tp: 4966.0000 - val_fp: 937.0000 - val_tn: 4966.0000 - val_fn: 937.0000 - val_accuracy: 0.8413 - train_sensitivity: 0.9373 - train_specificity: 0.9373 - train_balacc: 0.9373 - val_sensitivity: 0.8413 - val_specificity: 0.8413 - val_balacc: 0.8413\n",
      "Epoch 218/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1670 - tp: 21622.0000 - fp: 1478.0000 - tn: 21622.0000 - fn: 1478.0000 - accuracy: 0.9360 train_balacc 0.9366820549743764\n",
      " val_balacc 0.8485515839403693\n",
      "\n",
      "Epoch 218: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1653 - tp: 22116.0000 - fp: 1495.0000 - tn: 22116.0000 - fn: 1495.0000 - accuracy: 0.9367 - val_loss: 0.3782 - val_tp: 5009.0000 - val_fp: 894.0000 - val_tn: 5009.0000 - val_fn: 894.0000 - val_accuracy: 0.8486 - train_sensitivity: 0.9367 - train_specificity: 0.9367 - train_balacc: 0.9367 - val_sensitivity: 0.8486 - val_specificity: 0.8486 - val_balacc: 0.8486\n",
      "Epoch 219/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1574 - tp: 21561.0000 - fp: 1439.0000 - tn: 21561.0000 - fn: 1439.0000 - accuracy: 0.9374 train_balacc 0.9374867646435984\n",
      " val_balacc 0.9137726579705234\n",
      "\n",
      "Epoch 219: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1581 - tp: 22135.0000 - fp: 1476.0000 - tn: 22135.0000 - fn: 1476.0000 - accuracy: 0.9375 - val_loss: 0.2084 - val_tp: 5394.0000 - val_fp: 509.0000 - val_tn: 5394.0000 - val_fn: 509.0000 - val_accuracy: 0.9138 - train_sensitivity: 0.9375 - train_specificity: 0.9375 - train_balacc: 0.9375 - val_sensitivity: 0.9138 - val_specificity: 0.9138 - val_balacc: 0.9138\n",
      "Epoch 220/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1576 - tp: 21362.0000 - fp: 1438.0000 - tn: 21362.0000 - fn: 1438.0000 - accuracy: 0.9369 train_balacc 0.9369361738172886\n",
      " val_balacc 0.8892088768422836\n",
      "\n",
      "Epoch 220: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1574 - tp: 22122.0000 - fp: 1489.0000 - tn: 22122.0000 - fn: 1489.0000 - accuracy: 0.9369 - val_loss: 0.2815 - val_tp: 5249.0000 - val_fp: 654.0000 - val_tn: 5249.0000 - val_fn: 654.0000 - val_accuracy: 0.8892 - train_sensitivity: 0.9369 - train_specificity: 0.9369 - train_balacc: 0.9369 - val_sensitivity: 0.8892 - val_specificity: 0.8892 - val_balacc: 0.8892\n",
      "Epoch 221/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1592 - tp: 21695.0000 - fp: 1505.0000 - tn: 21695.0000 - fn: 1505.0000 - accuracy: 0.9351 train_balacc 0.93536910761933\n",
      " val_balacc 0.8692190411655091\n",
      "\n",
      "Epoch 221: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1587 - tp: 22085.0000 - fp: 1526.0000 - tn: 22085.0000 - fn: 1526.0000 - accuracy: 0.9354 - val_loss: 0.2721 - val_tp: 5131.0000 - val_fp: 772.0000 - val_tn: 5131.0000 - val_fn: 772.0000 - val_accuracy: 0.8692 - train_sensitivity: 0.9354 - train_specificity: 0.9354 - train_balacc: 0.9354 - val_sensitivity: 0.8692 - val_specificity: 0.8692 - val_balacc: 0.8692\n",
      "Epoch 222/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1544 - tp: 21700.0000 - fp: 1500.0000 - tn: 21700.0000 - fn: 1500.0000 - accuracy: 0.9353 train_balacc 0.9352844013383592\n",
      " val_balacc 0.9141114687447061\n",
      "\n",
      "Epoch 222: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1549 - tp: 22083.0000 - fp: 1528.0000 - tn: 22083.0000 - fn: 1528.0000 - accuracy: 0.9353 - val_loss: 0.2165 - val_tp: 5396.0000 - val_fp: 507.0000 - val_tn: 5396.0000 - val_fn: 507.0000 - val_accuracy: 0.9141 - train_sensitivity: 0.9353 - train_specificity: 0.9353 - train_balacc: 0.9353 - val_sensitivity: 0.9141 - val_specificity: 0.9141 - val_balacc: 0.9141\n",
      "Epoch 223/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1554 - tp: 22038.0000 - fp: 1462.0000 - tn: 22038.0000 - fn: 1462.0000 - accuracy: 0.9378 train_balacc 0.937910296048452\n",
      " val_balacc 0.8881924445197358\n",
      "\n",
      "Epoch 223: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1553 - tp: 22145.0000 - fp: 1466.0000 - tn: 22145.0000 - fn: 1466.0000 - accuracy: 0.9379 - val_loss: 0.2619 - val_tp: 5243.0000 - val_fp: 660.0000 - val_tn: 5243.0000 - val_fn: 660.0000 - val_accuracy: 0.8882 - train_sensitivity: 0.9379 - train_specificity: 0.9379 - train_balacc: 0.9379 - val_sensitivity: 0.8882 - val_specificity: 0.8882 - val_balacc: 0.8882\n",
      "Epoch 224/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1593 - tp: 21504.0000 - fp: 1496.0000 - tn: 21504.0000 - fn: 1496.0000 - accuracy: 0.9350 train_balacc 0.9346914573715641\n",
      " val_balacc 0.6386583093342368\n",
      "\n",
      "Epoch 224: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1600 - tp: 22069.0000 - fp: 1542.0000 - tn: 22069.0000 - fn: 1542.0000 - accuracy: 0.9347 - val_loss: 1.0371 - val_tp: 3770.0000 - val_fp: 2133.0000 - val_tn: 3770.0000 - val_fn: 2133.0000 - val_accuracy: 0.6387 - train_sensitivity: 0.9347 - train_specificity: 0.9347 - train_balacc: 0.9347 - val_sensitivity: 0.6387 - val_specificity: 0.6387 - val_balacc: 0.6387\n",
      "Epoch 225/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1573 - tp: 21660.0000 - fp: 1440.0000 - tn: 21660.0000 - fn: 1440.0000 - accuracy: 0.9377 train_balacc 0.9379526491889374\n",
      " val_balacc 0.8680332034558699\n",
      "\n",
      "Epoch 225: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1564 - tp: 22146.0000 - fp: 1465.0000 - tn: 22146.0000 - fn: 1465.0000 - accuracy: 0.9380 - val_loss: 0.2954 - val_tp: 5124.0000 - val_fp: 779.0000 - val_tn: 5124.0000 - val_fn: 779.0000 - val_accuracy: 0.8680 - train_sensitivity: 0.9380 - train_specificity: 0.9380 - train_balacc: 0.9380 - val_sensitivity: 0.8680 - val_specificity: 0.8680 - val_balacc: 0.8680\n",
      "Epoch 226/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1549 - tp: 22053.0000 - fp: 1447.0000 - tn: 22053.0000 - fn: 1447.0000 - accuracy: 0.9384 train_balacc 0.9384185337342764\n",
      " val_balacc 0.8698966627138743\n",
      "\n",
      "Epoch 226: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1549 - tp: 22157.0000 - fp: 1454.0000 - tn: 22157.0000 - fn: 1454.0000 - accuracy: 0.9384 - val_loss: 0.3114 - val_tp: 5135.0000 - val_fp: 768.0000 - val_tn: 5135.0000 - val_fn: 768.0000 - val_accuracy: 0.8699 - train_sensitivity: 0.9384 - train_specificity: 0.9384 - train_balacc: 0.9384 - val_sensitivity: 0.8699 - val_specificity: 0.8699 - val_balacc: 0.8699\n",
      "Epoch 227/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1615 - tp: 22064.0000 - fp: 1536.0000 - tn: 22064.0000 - fn: 1536.0000 - accuracy: 0.9349 train_balacc 0.934903223073991\n",
      " val_balacc 0.8309334236828732\n",
      "\n",
      "Epoch 227: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1615 - tp: 22074.0000 - fp: 1537.0000 - tn: 22074.0000 - fn: 1537.0000 - accuracy: 0.9349 - val_loss: 0.4066 - val_tp: 4905.0000 - val_fp: 998.0000 - val_tn: 4905.0000 - val_fn: 998.0000 - val_accuracy: 0.8309 - train_sensitivity: 0.9349 - train_specificity: 0.9349 - train_balacc: 0.9349 - val_sensitivity: 0.8309 - val_specificity: 0.8309 - val_balacc: 0.8309\n",
      "Epoch 228/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1523 - tp: 22004.0000 - fp: 1496.0000 - tn: 22004.0000 - fn: 1496.0000 - accuracy: 0.9363 train_balacc 0.9363008767100081\n",
      " val_balacc 0.8885312552939183\n",
      "\n",
      "Epoch 228: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1525 - tp: 22107.0000 - fp: 1504.0000 - tn: 22107.0000 - fn: 1504.0000 - accuracy: 0.9363 - val_loss: 0.2721 - val_tp: 5245.0000 - val_fp: 658.0000 - val_tn: 5245.0000 - val_fn: 658.0000 - val_accuracy: 0.8885 - train_sensitivity: 0.9363 - train_specificity: 0.9363 - train_balacc: 0.9363 - val_sensitivity: 0.8885 - val_specificity: 0.8885 - val_balacc: 0.8885\n",
      "Epoch 229/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1516 - tp: 21767.0000 - fp: 1433.0000 - tn: 21767.0000 - fn: 1433.0000 - accuracy: 0.9382 train_balacc 0.9380797086103935\n",
      " val_balacc 0.8443164492630866\n",
      "\n",
      "Epoch 229: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1525 - tp: 22149.0000 - fp: 1462.0000 - tn: 22149.0000 - fn: 1462.0000 - accuracy: 0.9381 - val_loss: 0.3573 - val_tp: 4984.0000 - val_fp: 919.0000 - val_tn: 4984.0000 - val_fn: 919.0000 - val_accuracy: 0.8443 - train_sensitivity: 0.9381 - train_specificity: 0.9381 - train_balacc: 0.9381 - val_sensitivity: 0.8443 - val_specificity: 0.8443 - val_balacc: 0.8443\n",
      "Epoch 230/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1533 - tp: 22105.0000 - fp: 1495.0000 - tn: 22105.0000 - fn: 1495.0000 - accuracy: 0.9367 train_balacc 0.936639701833891\n",
      " val_balacc 0.9249534135185499\n",
      "\n",
      "Epoch 230: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1533 - tp: 22115.0000 - fp: 1496.0000 - tn: 22115.0000 - fn: 1496.0000 - accuracy: 0.9366 - val_loss: 0.1784 - val_tp: 5460.0000 - val_fp: 443.0000 - val_tn: 5460.0000 - val_fn: 443.0000 - val_accuracy: 0.9250 - train_sensitivity: 0.9366 - train_specificity: 0.9366 - train_balacc: 0.9366 - val_sensitivity: 0.9250 - val_specificity: 0.9250 - val_balacc: 0.9250\n",
      "Epoch 231/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1570 - tp: 21630.0000 - fp: 1470.0000 - tn: 21630.0000 - fn: 1470.0000 - accuracy: 0.9364 train_balacc 0.9363432298504935\n",
      " val_balacc 0.8966627138743012\n",
      "\n",
      "Epoch 231: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1575 - tp: 22108.0000 - fp: 1503.0000 - tn: 22108.0000 - fn: 1503.0000 - accuracy: 0.9363 - val_loss: 0.2189 - val_tp: 5293.0000 - val_fp: 610.0000 - val_tn: 5293.0000 - val_fn: 610.0000 - val_accuracy: 0.8967 - train_sensitivity: 0.9363 - train_specificity: 0.9363 - train_balacc: 0.9363 - val_sensitivity: 0.8967 - val_specificity: 0.8967 - val_balacc: 0.8967\n",
      "Epoch 232/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1564 - tp: 21540.0000 - fp: 1460.0000 - tn: 21540.0000 - fn: 1460.0000 - accuracy: 0.9365 train_balacc 0.9364279361314641\n",
      " val_balacc 0.900897848551584\n",
      "\n",
      "Epoch 232: val_balacc did not improve from 0.95579\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1563 - tp: 22110.0000 - fp: 1501.0000 - tn: 22110.0000 - fn: 1501.0000 - accuracy: 0.9364 - val_loss: 0.2438 - val_tp: 5318.0000 - val_fp: 585.0000 - val_tn: 5318.0000 - val_fn: 585.0000 - val_accuracy: 0.9009 - train_sensitivity: 0.9364 - train_specificity: 0.9364 - train_balacc: 0.9364 - val_sensitivity: 0.9009 - val_specificity: 0.9009 - val_balacc: 0.9009\n",
      "Size of the training fold is 23611\n",
      "Size of the validation fold is 5903\n",
      "Class imbalance in Train is 0.46%\n",
      "Class imbalance in Validation is 0.46%\n",
      "Epoch 1/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1850 - tp: 21481.0000 - fp: 1719.0000 - tn: 21481.0000 - fn: 1719.0000 - accuracy: 0.9259 train_balacc 0.9253737664647833\n",
      " val_balacc 0.9539217347111638\n",
      "\n",
      "Epoch 1: val_balacc improved from -inf to 0.95392, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1860 - tp: 21849.0000 - fp: 1762.0000 - tn: 21849.0000 - fn: 1762.0000 - accuracy: 0.9254 - val_loss: 0.1453 - val_tp: 5631.0000 - val_fp: 272.0000 - val_tn: 5631.0000 - val_fn: 272.0000 - val_accuracy: 0.9539 - train_sensitivity: 0.9254 - train_specificity: 0.9254 - train_balacc: 0.9254 - val_sensitivity: 0.9539 - val_specificity: 0.9539 - val_balacc: 0.9539\n",
      "Epoch 2/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1849 - tp: 21329.0000 - fp: 1671.0000 - tn: 21329.0000 - fn: 1671.0000 - accuracy: 0.9273 train_balacc 0.9274914234890517\n",
      " val_balacc 0.9351177367440284\n",
      "\n",
      "Epoch 2: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1841 - tp: 21899.0000 - fp: 1712.0000 - tn: 21899.0000 - fn: 1712.0000 - accuracy: 0.9275 - val_loss: 0.1629 - val_tp: 5520.0000 - val_fp: 383.0000 - val_tn: 5520.0000 - val_fn: 383.0000 - val_accuracy: 0.9351 - train_sensitivity: 0.9275 - train_specificity: 0.9275 - train_balacc: 0.9275 - val_sensitivity: 0.9351 - val_specificity: 0.9351 - val_balacc: 0.9351\n",
      "Epoch 3/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1795 - tp: 21433.0000 - fp: 1667.0000 - tn: 21433.0000 - fn: 1667.0000 - accuracy: 0.9278 train_balacc 0.928211426877303\n",
      " val_balacc 0.9400304929696764\n",
      "\n",
      "Epoch 3: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1791 - tp: 21916.0000 - fp: 1695.0000 - tn: 21916.0000 - fn: 1695.0000 - accuracy: 0.9282 - val_loss: 0.1566 - val_tp: 5549.0000 - val_fp: 354.0000 - val_tn: 5549.0000 - val_fn: 354.0000 - val_accuracy: 0.9400 - train_sensitivity: 0.9282 - train_specificity: 0.9282 - train_balacc: 0.9282 - val_sensitivity: 0.9400 - val_specificity: 0.9400 - val_balacc: 0.9400\n",
      "Epoch 4/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1808 - tp: 21363.0000 - fp: 1637.0000 - tn: 21363.0000 - fn: 1637.0000 - accuracy: 0.9288 train_balacc 0.929143195967981\n",
      " val_balacc 0.9100457394545146\n",
      "\n",
      "Epoch 4: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1803 - tp: 21938.0000 - fp: 1673.0000 - tn: 21938.0000 - fn: 1673.0000 - accuracy: 0.9291 - val_loss: 0.2271 - val_tp: 5372.0000 - val_fp: 531.0000 - val_tn: 5372.0000 - val_fn: 531.0000 - val_accuracy: 0.9100 - train_sensitivity: 0.9291 - train_specificity: 0.9291 - train_balacc: 0.9291 - val_sensitivity: 0.9100 - val_specificity: 0.9100 - val_balacc: 0.9100\n",
      "Epoch 5/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1835 - tp: 21786.0000 - fp: 1714.0000 - tn: 21786.0000 - fn: 1714.0000 - accuracy: 0.9271 train_balacc 0.9272373046461395\n",
      " val_balacc 0.7741826190072845\n",
      "\n",
      "Epoch 5: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1834 - tp: 21893.0000 - fp: 1718.0000 - tn: 21893.0000 - fn: 1718.0000 - accuracy: 0.9272 - val_loss: 0.7275 - val_tp: 4570.0000 - val_fp: 1333.0000 - val_tn: 4570.0000 - val_fn: 1333.0000 - val_accuracy: 0.7742 - train_sensitivity: 0.9272 - train_specificity: 0.9272 - train_balacc: 0.9272 - val_sensitivity: 0.7742 - val_specificity: 0.7742 - val_balacc: 0.7742\n",
      "Epoch 6/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1796 - tp: 21538.0000 - fp: 1762.0000 - tn: 21538.0000 - fn: 1762.0000 - accuracy: 0.9244 train_balacc 0.9244843505145907\n",
      " val_balacc 0.9246146027443672\n",
      "\n",
      "Epoch 6: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1799 - tp: 21828.0000 - fp: 1783.0000 - tn: 21828.0000 - fn: 1783.0000 - accuracy: 0.9245 - val_loss: 0.1733 - val_tp: 5458.0000 - val_fp: 445.0000 - val_tn: 5458.0000 - val_fn: 445.0000 - val_accuracy: 0.9246 - train_sensitivity: 0.9245 - train_specificity: 0.9245 - train_balacc: 0.9245 - val_sensitivity: 0.9246 - val_specificity: 0.9246 - val_balacc: 0.9246\n",
      "Epoch 7/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1748 - tp: 21380.0000 - fp: 1620.0000 - tn: 21380.0000 - fn: 1620.0000 - accuracy: 0.9296 train_balacc 0.9294396679513786\n",
      " val_balacc 0.9322378451634762\n",
      "\n",
      "Epoch 7: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1746 - tp: 21945.0000 - fp: 1666.0000 - tn: 21945.0000 - fn: 1666.0000 - accuracy: 0.9294 - val_loss: 0.1609 - val_tp: 5503.0000 - val_fp: 400.0000 - val_tn: 5503.0000 - val_fn: 400.0000 - val_accuracy: 0.9322 - train_sensitivity: 0.9294 - train_specificity: 0.9294 - train_balacc: 0.9294 - val_sensitivity: 0.9322 - val_specificity: 0.9322 - val_balacc: 0.9322\n",
      "Epoch 8/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1747 - tp: 21718.0000 - fp: 1682.0000 - tn: 21718.0000 - fn: 1682.0000 - accuracy: 0.9281 train_balacc 0.9281267205963322\n",
      " val_balacc 0.9158055226156192\n",
      "\n",
      "Epoch 8: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1747 - tp: 21914.0000 - fp: 1697.0000 - tn: 21914.0000 - fn: 1697.0000 - accuracy: 0.9281 - val_loss: 0.1741 - val_tp: 5406.0000 - val_fp: 497.0000 - val_tn: 5406.0000 - val_fn: 497.0000 - val_accuracy: 0.9158 - train_sensitivity: 0.9281 - train_specificity: 0.9281 - train_balacc: 0.9281 - val_sensitivity: 0.9158 - val_specificity: 0.9158 - val_balacc: 0.9158\n",
      "Epoch 9/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1733 - tp: 21922.0000 - fp: 1678.0000 - tn: 21922.0000 - fn: 1678.0000 - accuracy: 0.9289 train_balacc 0.9288467239845835\n",
      " val_balacc 0.908012874809419\n",
      "\n",
      "Epoch 9: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1733 - tp: 21931.0000 - fp: 1680.0000 - tn: 21931.0000 - fn: 1680.0000 - accuracy: 0.9288 - val_loss: 0.2003 - val_tp: 5360.0000 - val_fp: 543.0000 - val_tn: 5360.0000 - val_fn: 543.0000 - val_accuracy: 0.9080 - train_sensitivity: 0.9288 - train_specificity: 0.9288 - train_balacc: 0.9288 - val_sensitivity: 0.9080 - val_specificity: 0.9080 - val_balacc: 0.9080\n",
      "Epoch 10/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1722 - tp: 21170.0000 - fp: 1630.0000 - tn: 21170.0000 - fn: 1630.0000 - accuracy: 0.9285 train_balacc 0.9281690737368176\n",
      " val_balacc 0.9015754700999492\n",
      "\n",
      "Epoch 10: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1732 - tp: 21915.0000 - fp: 1696.0000 - tn: 21915.0000 - fn: 1696.0000 - accuracy: 0.9282 - val_loss: 0.2971 - val_tp: 5322.0000 - val_fp: 581.0000 - val_tn: 5322.0000 - val_fn: 581.0000 - val_accuracy: 0.9016 - train_sensitivity: 0.9282 - train_specificity: 0.9282 - train_balacc: 0.9282 - val_sensitivity: 0.9016 - val_specificity: 0.9016 - val_balacc: 0.9016\n",
      "Epoch 11/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1766 - tp: 21707.0000 - fp: 1693.0000 - tn: 21707.0000 - fn: 1693.0000 - accuracy: 0.9276 train_balacc 0.9274914234890517\n",
      " val_balacc 0.8319498560054209\n",
      "\n",
      "Epoch 11: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1770 - tp: 21899.0000 - fp: 1712.0000 - tn: 21899.0000 - fn: 1712.0000 - accuracy: 0.9275 - val_loss: 0.3661 - val_tp: 4911.0000 - val_fp: 992.0000 - val_tn: 4911.0000 - val_fn: 992.0000 - val_accuracy: 0.8319 - train_sensitivity: 0.9275 - train_specificity: 0.9275 - train_balacc: 0.9275 - val_sensitivity: 0.8319 - val_specificity: 0.8319 - val_balacc: 0.8319\n",
      "Epoch 12/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1704 - tp: 21364.0000 - fp: 1636.0000 - tn: 21364.0000 - fn: 1636.0000 - accuracy: 0.9289 train_balacc 0.9289314302655541\n",
      " val_balacc 0.9403693037438591\n",
      "\n",
      "Epoch 12: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1705 - tp: 21933.0000 - fp: 1678.0000 - tn: 21933.0000 - fn: 1678.0000 - accuracy: 0.9289 - val_loss: 0.1536 - val_tp: 5551.0000 - val_fp: 352.0000 - val_tn: 5551.0000 - val_fn: 352.0000 - val_accuracy: 0.9404 - train_sensitivity: 0.9289 - train_specificity: 0.9289 - train_balacc: 0.9289 - val_sensitivity: 0.9404 - val_specificity: 0.9404 - val_balacc: 0.9404\n",
      "Epoch 13/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1730 - tp: 21617.0000 - fp: 1583.0000 - tn: 21617.0000 - fn: 1583.0000 - accuracy: 0.9318 train_balacc 0.9317690906780738\n",
      " val_balacc 0.9491783838726071\n",
      "\n",
      "Epoch 13: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1729 - tp: 22000.0000 - fp: 1611.0000 - tn: 22000.0000 - fn: 1611.0000 - accuracy: 0.9318 - val_loss: 0.1642 - val_tp: 5603.0000 - val_fp: 300.0000 - val_tn: 5603.0000 - val_fn: 300.0000 - val_accuracy: 0.9492 - train_sensitivity: 0.9318 - train_specificity: 0.9318 - train_balacc: 0.9318 - val_sensitivity: 0.9492 - val_specificity: 0.9492 - val_balacc: 0.9492\n",
      "Epoch 14/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1775 - tp: 21167.0000 - fp: 1633.0000 - tn: 21167.0000 - fn: 1633.0000 - accuracy: 0.9284 train_balacc 0.9277455423319639\n",
      " val_balacc 0.948500762324242\n",
      "\n",
      "Epoch 14: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1792 - tp: 21905.0000 - fp: 1706.0000 - tn: 21905.0000 - fn: 1706.0000 - accuracy: 0.9277 - val_loss: 0.1413 - val_tp: 5599.0000 - val_fp: 304.0000 - val_tn: 5599.0000 - val_fn: 304.0000 - val_accuracy: 0.9485 - train_sensitivity: 0.9277 - train_specificity: 0.9277 - train_balacc: 0.9277 - val_sensitivity: 0.9485 - val_specificity: 0.9485 - val_balacc: 0.9485\n",
      "Epoch 15/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1700 - tp: 21477.0000 - fp: 1623.0000 - tn: 21477.0000 - fn: 1623.0000 - accuracy: 0.9297 train_balacc 0.92960908051332\n",
      " val_balacc 0.9483313569371506\n",
      "\n",
      "Epoch 15: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1699 - tp: 21949.0000 - fp: 1662.0000 - tn: 21949.0000 - fn: 1662.0000 - accuracy: 0.9296 - val_loss: 0.1253 - val_tp: 5598.0000 - val_fp: 305.0000 - val_tn: 5598.0000 - val_fn: 305.0000 - val_accuracy: 0.9483 - train_sensitivity: 0.9296 - train_specificity: 0.9296 - train_balacc: 0.9296 - val_sensitivity: 0.9483 - val_specificity: 0.9483 - val_balacc: 0.9483\n",
      "Epoch 16/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1664 - tp: 21438.0000 - fp: 1562.0000 - tn: 21438.0000 - fn: 1562.0000 - accuracy: 0.9321 train_balacc 0.9315996781161323\n",
      " val_balacc 0.9180077926478062\n",
      "\n",
      "Epoch 16: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1673 - tp: 21996.0000 - fp: 1615.0000 - tn: 21996.0000 - fn: 1615.0000 - accuracy: 0.9316 - val_loss: 0.2197 - val_tp: 5419.0000 - val_fp: 484.0000 - val_tn: 5419.0000 - val_fn: 484.0000 - val_accuracy: 0.9180 - train_sensitivity: 0.9316 - train_specificity: 0.9316 - train_balacc: 0.9316 - val_sensitivity: 0.9180 - val_specificity: 0.9180 - val_balacc: 0.9180\n",
      "Epoch 17/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1674 - tp: 21883.0000 - fp: 1617.0000 - tn: 21883.0000 - fn: 1617.0000 - accuracy: 0.9312 train_balacc 0.9311337935707933\n",
      " val_balacc 0.9258004404540064\n",
      "\n",
      "Epoch 17: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1673 - tp: 21985.0000 - fp: 1626.0000 - tn: 21985.0000 - fn: 1626.0000 - accuracy: 0.9311 - val_loss: 0.1716 - val_tp: 5465.0000 - val_fp: 438.0000 - val_tn: 5465.0000 - val_fn: 438.0000 - val_accuracy: 0.9258 - train_sensitivity: 0.9311 - train_specificity: 0.9311 - train_balacc: 0.9311 - val_sensitivity: 0.9258 - val_specificity: 0.9258 - val_balacc: 0.9258\n",
      "Epoch 18/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1760 - tp: 21560.0000 - fp: 1640.0000 - tn: 21560.0000 - fn: 1640.0000 - accuracy: 0.9293 train_balacc 0.9293549616704079\n",
      " val_balacc 0.9488395730984245\n",
      "\n",
      "Epoch 18: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1756 - tp: 21943.0000 - fp: 1668.0000 - tn: 21943.0000 - fn: 1668.0000 - accuracy: 0.9294 - val_loss: 0.1452 - val_tp: 5601.0000 - val_fp: 302.0000 - val_tn: 5601.0000 - val_fn: 302.0000 - val_accuracy: 0.9488 - train_sensitivity: 0.9294 - train_specificity: 0.9294 - train_balacc: 0.9294 - val_sensitivity: 0.9488 - val_specificity: 0.9488 - val_balacc: 0.9488\n",
      "Epoch 19/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1687 - tp: 21991.0000 - fp: 1609.0000 - tn: 21991.0000 - fn: 1609.0000 - accuracy: 0.9318 train_balacc 0.9317690906780738\n",
      " val_balacc 0.941385736066407\n",
      "\n",
      "Epoch 19: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1688 - tp: 22000.0000 - fp: 1611.0000 - tn: 22000.0000 - fn: 1611.0000 - accuracy: 0.9318 - val_loss: 0.1645 - val_tp: 5557.0000 - val_fp: 346.0000 - val_tn: 5557.0000 - val_fn: 346.0000 - val_accuracy: 0.9414 - train_sensitivity: 0.9318 - train_specificity: 0.9318 - train_balacc: 0.9318 - val_sensitivity: 0.9414 - val_specificity: 0.9414 - val_balacc: 0.9414\n",
      "Epoch 20/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1713 - tp: 21326.0000 - fp: 1574.0000 - tn: 21326.0000 - fn: 1574.0000 - accuracy: 0.9313 train_balacc 0.9315996781161323\n",
      " val_balacc 0.8685414196171438\n",
      "\n",
      "Epoch 20: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1708 - tp: 21996.0000 - fp: 1615.0000 - tn: 21996.0000 - fn: 1615.0000 - accuracy: 0.9316 - val_loss: 0.2692 - val_tp: 5127.0000 - val_fp: 776.0000 - val_tn: 5127.0000 - val_fn: 776.0000 - val_accuracy: 0.8685 - train_sensitivity: 0.9316 - train_specificity: 0.9316 - train_balacc: 0.9316 - val_sensitivity: 0.8685 - val_specificity: 0.8685 - val_balacc: 0.8685\n",
      "Epoch 21/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1686 - tp: 21606.0000 - fp: 1594.0000 - tn: 21606.0000 - fn: 1594.0000 - accuracy: 0.9313 train_balacc 0.9313455592732202\n",
      " val_balacc 0.9259698458410978\n",
      "\n",
      "Epoch 21: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1685 - tp: 21990.0000 - fp: 1621.0000 - tn: 21990.0000 - fn: 1621.0000 - accuracy: 0.9313 - val_loss: 0.1853 - val_tp: 5466.0000 - val_fp: 437.0000 - val_tn: 5466.0000 - val_fn: 437.0000 - val_accuracy: 0.9260 - train_sensitivity: 0.9313 - train_specificity: 0.9313 - train_balacc: 0.9313 - val_sensitivity: 0.9260 - val_specificity: 0.9260 - val_balacc: 0.9260\n",
      "Epoch 22/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1724 - tp: 21381.0000 - fp: 1619.0000 - tn: 21381.0000 - fn: 1619.0000 - accuracy: 0.9296 train_balacc 0.9296937867942908\n",
      " val_balacc 0.9302049805183805\n",
      "\n",
      "Epoch 22: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1721 - tp: 21951.0000 - fp: 1660.0000 - tn: 21951.0000 - fn: 1660.0000 - accuracy: 0.9297 - val_loss: 0.1727 - val_tp: 5491.0000 - val_fp: 412.0000 - val_tn: 5491.0000 - val_fn: 412.0000 - val_accuracy: 0.9302 - train_sensitivity: 0.9297 - train_specificity: 0.9297 - train_balacc: 0.9297 - val_sensitivity: 0.9302 - val_specificity: 0.9302 - val_balacc: 0.9302\n",
      "Epoch 23/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1687 - tp: 21707.0000 - fp: 1593.0000 - tn: 21707.0000 - fn: 1593.0000 - accuracy: 0.9316 train_balacc 0.9315573249756469\n",
      " val_balacc 0.907504658648145\n",
      "\n",
      "Epoch 23: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1689 - tp: 21995.0000 - fp: 1616.0000 - tn: 21995.0000 - fn: 1616.0000 - accuracy: 0.9316 - val_loss: 0.2076 - val_tp: 5357.0000 - val_fp: 546.0000 - val_tn: 5357.0000 - val_fn: 546.0000 - val_accuracy: 0.9075 - train_sensitivity: 0.9316 - train_specificity: 0.9316 - train_balacc: 0.9316 - val_sensitivity: 0.9075 - val_specificity: 0.9075 - val_balacc: 0.9075\n",
      "Epoch 24/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1663 - tp: 21408.0000 - fp: 1592.0000 - tn: 21408.0000 - fn: 1592.0000 - accuracy: 0.9308 train_balacc 0.9307102621659396\n",
      " val_balacc 0.9473149246146028\n",
      "\n",
      "Epoch 24: val_balacc did not improve from 0.95392\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1661 - tp: 21975.0000 - fp: 1636.0000 - tn: 21975.0000 - fn: 1636.0000 - accuracy: 0.9307 - val_loss: 0.1241 - val_tp: 5592.0000 - val_fp: 311.0000 - val_tn: 5592.0000 - val_fn: 311.0000 - val_accuracy: 0.9473 - train_sensitivity: 0.9307 - train_specificity: 0.9307 - train_balacc: 0.9307 - val_sensitivity: 0.9473 - val_specificity: 0.9473 - val_balacc: 0.9473\n",
      "Epoch 25/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1695 - tp: 21273.0000 - fp: 1527.0000 - tn: 21273.0000 - fn: 1527.0000 - accuracy: 0.9330 train_balacc 0.9331667443140909\n",
      " val_balacc 0.9569710316788074\n",
      "\n",
      "Epoch 25: val_balacc improved from 0.95392 to 0.95697, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1692 - tp: 22033.0000 - fp: 1578.0000 - tn: 22033.0000 - fn: 1578.0000 - accuracy: 0.9332 - val_loss: 0.1435 - val_tp: 5649.0000 - val_fp: 254.0000 - val_tn: 5649.0000 - val_fn: 254.0000 - val_accuracy: 0.9570 - train_sensitivity: 0.9332 - train_specificity: 0.9332 - train_balacc: 0.9332 - val_sensitivity: 0.9570 - val_specificity: 0.9570 - val_balacc: 0.9570\n",
      "Epoch 26/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1736 - tp: 21829.0000 - fp: 1671.0000 - tn: 21829.0000 - fn: 1671.0000 - accuracy: 0.9289 train_balacc 0.9289314302655541\n",
      " val_balacc 0.9163137387768931\n",
      "\n",
      "Epoch 26: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1736 - tp: 21933.0000 - fp: 1678.0000 - tn: 21933.0000 - fn: 1678.0000 - accuracy: 0.9289 - val_loss: 0.2217 - val_tp: 5409.0000 - val_fp: 494.0000 - val_tn: 5409.0000 - val_fn: 494.0000 - val_accuracy: 0.9163 - train_sensitivity: 0.9289 - train_specificity: 0.9289 - train_balacc: 0.9289 - val_sensitivity: 0.9163 - val_specificity: 0.9163 - val_balacc: 0.9163\n",
      "Epoch 27/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1662 - tp: 21292.0000 - fp: 1508.0000 - tn: 21292.0000 - fn: 1508.0000 - accuracy: 0.9339 train_balacc 0.9339714539833128\n",
      " val_balacc 0.9498560054209724\n",
      "\n",
      "Epoch 27: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1660 - tp: 22052.0000 - fp: 1559.0000 - tn: 22052.0000 - fn: 1559.0000 - accuracy: 0.9340 - val_loss: 0.1571 - val_tp: 5607.0000 - val_fp: 296.0000 - val_tn: 5607.0000 - val_fn: 296.0000 - val_accuracy: 0.9499 - train_sensitivity: 0.9340 - train_specificity: 0.9340 - train_balacc: 0.9340 - val_sensitivity: 0.9499 - val_specificity: 0.9499 - val_balacc: 0.9499\n",
      "Epoch 28/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1731 - tp: 21412.0000 - fp: 1588.0000 - tn: 21412.0000 - fn: 1588.0000 - accuracy: 0.9310 train_balacc 0.9306679090254543\n",
      " val_balacc 0.8783669320684397\n",
      "\n",
      "Epoch 28: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1732 - tp: 21974.0000 - fp: 1637.0000 - tn: 21974.0000 - fn: 1637.0000 - accuracy: 0.9307 - val_loss: 0.2500 - val_tp: 5185.0000 - val_fp: 718.0000 - val_tn: 5185.0000 - val_fn: 718.0000 - val_accuracy: 0.8784 - train_sensitivity: 0.9307 - train_specificity: 0.9307 - train_balacc: 0.9307 - val_sensitivity: 0.8784 - val_specificity: 0.8784 - val_balacc: 0.8784\n",
      "Epoch 29/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1626 - tp: 21265.0000 - fp: 1535.0000 - tn: 21265.0000 - fn: 1535.0000 - accuracy: 0.9327 train_balacc 0.9326585066282664\n",
      " val_balacc 0.9432491953244113\n",
      "\n",
      "Epoch 29: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1624 - tp: 22021.0000 - fp: 1590.0000 - tn: 22021.0000 - fn: 1590.0000 - accuracy: 0.9327 - val_loss: 0.1537 - val_tp: 5568.0000 - val_fp: 335.0000 - val_tn: 5568.0000 - val_fn: 335.0000 - val_accuracy: 0.9432 - train_sensitivity: 0.9327 - train_specificity: 0.9327 - train_balacc: 0.9327 - val_sensitivity: 0.9432 - val_specificity: 0.9432 - val_balacc: 0.9432\n",
      "Epoch 30/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1671 - tp: 21835.0000 - fp: 1565.0000 - tn: 21835.0000 - fn: 1565.0000 - accuracy: 0.9331 train_balacc 0.9329549786116641\n",
      " val_balacc 0.9368117906149416\n",
      "\n",
      "Epoch 30: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1677 - tp: 22028.0000 - fp: 1583.0000 - tn: 22028.0000 - fn: 1583.0000 - accuracy: 0.9330 - val_loss: 0.1793 - val_tp: 5530.0000 - val_fp: 373.0000 - val_tn: 5530.0000 - val_fn: 373.0000 - val_accuracy: 0.9368 - train_sensitivity: 0.9330 - train_specificity: 0.9330 - train_balacc: 0.9330 - val_sensitivity: 0.9368 - val_specificity: 0.9368 - val_balacc: 0.9368\n",
      "Epoch 31/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1649 - tp: 21855.0000 - fp: 1645.0000 - tn: 21855.0000 - fn: 1645.0000 - accuracy: 0.9300 train_balacc 0.930074965058659\n",
      " val_balacc 0.943588006098594\n",
      "\n",
      "Epoch 31: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1646 - tp: 21960.0000 - fp: 1651.0000 - tn: 21960.0000 - fn: 1651.0000 - accuracy: 0.9301 - val_loss: 0.1575 - val_tp: 5570.0000 - val_fp: 333.0000 - val_tn: 5570.0000 - val_fn: 333.0000 - val_accuracy: 0.9436 - train_sensitivity: 0.9301 - train_specificity: 0.9301 - train_balacc: 0.9301 - val_sensitivity: 0.9436 - val_specificity: 0.9436 - val_balacc: 0.9436\n",
      "Epoch 32/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1677 - tp: 21409.0000 - fp: 1591.0000 - tn: 21409.0000 - fn: 1591.0000 - accuracy: 0.9308 train_balacc 0.9304984964635128\n",
      " val_balacc 0.9424021683889547\n",
      "\n",
      "Epoch 32: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1684 - tp: 21970.0000 - fp: 1641.0000 - tn: 21970.0000 - fn: 1641.0000 - accuracy: 0.9305 - val_loss: 0.1620 - val_tp: 5563.0000 - val_fp: 340.0000 - val_tn: 5563.0000 - val_fn: 340.0000 - val_accuracy: 0.9424 - train_sensitivity: 0.9305 - train_specificity: 0.9305 - train_balacc: 0.9305 - val_sensitivity: 0.9424 - val_specificity: 0.9424 - val_balacc: 0.9424\n",
      "Epoch 33/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1673 - tp: 21804.0000 - fp: 1596.0000 - tn: 21804.0000 - fn: 1596.0000 - accuracy: 0.9318 train_balacc 0.9318537969590445\n",
      " val_balacc 0.8666779603591395\n",
      "\n",
      "Epoch 33: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1669 - tp: 22002.0000 - fp: 1609.0000 - tn: 22002.0000 - fn: 1609.0000 - accuracy: 0.9319 - val_loss: 0.4789 - val_tp: 5116.0000 - val_fp: 787.0000 - val_tn: 5116.0000 - val_fn: 787.0000 - val_accuracy: 0.8667 - train_sensitivity: 0.9319 - train_specificity: 0.9319 - train_balacc: 0.9319 - val_sensitivity: 0.8667 - val_specificity: 0.8667 - val_balacc: 0.8667\n",
      "Epoch 34/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1653 - tp: 21733.0000 - fp: 1567.0000 - tn: 21733.0000 - fn: 1567.0000 - accuracy: 0.9327 train_balacc 0.9328702723306933\n",
      " val_balacc 0.8834490936811791\n",
      "\n",
      "Epoch 34: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1650 - tp: 22026.0000 - fp: 1585.0000 - tn: 22026.0000 - fn: 1585.0000 - accuracy: 0.9329 - val_loss: 0.2585 - val_tp: 5215.0000 - val_fp: 688.0000 - val_tn: 5215.0000 - val_fn: 688.0000 - val_accuracy: 0.8834 - train_sensitivity: 0.9329 - train_specificity: 0.9329 - train_balacc: 0.9329 - val_sensitivity: 0.8834 - val_specificity: 0.8834 - val_balacc: 0.8834\n",
      "Epoch 35/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1657 - tp: 21569.0000 - fp: 1531.0000 - tn: 21569.0000 - fn: 1531.0000 - accuracy: 0.9337 train_balacc 0.9337173351404007\n",
      " val_balacc 0.9114009825512451\n",
      "\n",
      "Epoch 35: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1655 - tp: 22046.0000 - fp: 1565.0000 - tn: 22046.0000 - fn: 1565.0000 - accuracy: 0.9337 - val_loss: 0.2207 - val_tp: 5380.0000 - val_fp: 523.0000 - val_tn: 5380.0000 - val_fn: 523.0000 - val_accuracy: 0.9114 - train_sensitivity: 0.9337 - train_specificity: 0.9337 - train_balacc: 0.9337 - val_sensitivity: 0.9114 - val_specificity: 0.9114 - val_balacc: 0.9114\n",
      "Epoch 36/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1671 - tp: 21635.0000 - fp: 1565.0000 - tn: 21635.0000 - fn: 1565.0000 - accuracy: 0.9325 train_balacc 0.9327008597687518\n",
      " val_balacc 0.9366423852278503\n",
      "\n",
      "Epoch 36: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1666 - tp: 22022.0000 - fp: 1589.0000 - tn: 22022.0000 - fn: 1589.0000 - accuracy: 0.9327 - val_loss: 0.1518 - val_tp: 5529.0000 - val_fp: 374.0000 - val_tn: 5529.0000 - val_fn: 374.0000 - val_accuracy: 0.9366 - train_sensitivity: 0.9327 - train_specificity: 0.9327 - train_balacc: 0.9327 - val_sensitivity: 0.9366 - val_specificity: 0.9366 - val_balacc: 0.9366\n",
      "Epoch 37/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1618 - tp: 21605.0000 - fp: 1495.0000 - tn: 21605.0000 - fn: 1495.0000 - accuracy: 0.9353 train_balacc 0.9348608699335056\n",
      " val_balacc 0.9263086566152804\n",
      "\n",
      "Epoch 37: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1619 - tp: 22073.0000 - fp: 1538.0000 - tn: 22073.0000 - fn: 1538.0000 - accuracy: 0.9349 - val_loss: 0.1885 - val_tp: 5468.0000 - val_fp: 435.0000 - val_tn: 5468.0000 - val_fn: 435.0000 - val_accuracy: 0.9263 - train_sensitivity: 0.9349 - train_specificity: 0.9349 - train_balacc: 0.9349 - val_sensitivity: 0.9263 - val_specificity: 0.9263 - val_balacc: 0.9263\n",
      "Epoch 38/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1689 - tp: 21970.0000 - fp: 1641.0000 - tn: 21970.0000 - fn: 1641.0000 - accuracy: 0.9305 train_balacc 0.9304984964635128\n",
      " val_balacc 0.9086904963577842\n",
      "\n",
      "Epoch 38: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1689 - tp: 21970.0000 - fp: 1641.0000 - tn: 21970.0000 - fn: 1641.0000 - accuracy: 0.9305 - val_loss: 0.2124 - val_tp: 5364.0000 - val_fp: 539.0000 - val_tn: 5364.0000 - val_fn: 539.0000 - val_accuracy: 0.9087 - train_sensitivity: 0.9305 - train_specificity: 0.9305 - train_balacc: 0.9305 - val_sensitivity: 0.9087 - val_specificity: 0.9087 - val_balacc: 0.9087\n",
      "Epoch 39/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1635 - tp: 21848.0000 - fp: 1552.0000 - tn: 21848.0000 - fn: 1552.0000 - accuracy: 0.9337 train_balacc 0.9336326288594299\n",
      " val_balacc 0.8858207691004574\n",
      "\n",
      "Epoch 39: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1639 - tp: 22044.0000 - fp: 1567.0000 - tn: 22044.0000 - fn: 1567.0000 - accuracy: 0.9336 - val_loss: 0.2466 - val_tp: 5229.0000 - val_fp: 674.0000 - val_tn: 5229.0000 - val_fn: 674.0000 - val_accuracy: 0.8858 - train_sensitivity: 0.9336 - train_specificity: 0.9336 - train_balacc: 0.9336 - val_sensitivity: 0.8858 - val_specificity: 0.8858 - val_balacc: 0.8858\n",
      "Epoch 40/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1618 - tp: 21500.0000 - fp: 1500.0000 - tn: 21500.0000 - fn: 1500.0000 - accuracy: 0.9348 train_balacc 0.9344373385286519\n",
      " val_balacc 0.9357953582923937\n",
      "\n",
      "Epoch 40: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1632 - tp: 22063.0000 - fp: 1548.0000 - tn: 22063.0000 - fn: 1548.0000 - accuracy: 0.9344 - val_loss: 0.1683 - val_tp: 5524.0000 - val_fp: 379.0000 - val_tn: 5524.0000 - val_fn: 379.0000 - val_accuracy: 0.9358 - train_sensitivity: 0.9344 - train_specificity: 0.9344 - train_balacc: 0.9344 - val_sensitivity: 0.9358 - val_specificity: 0.9358 - val_balacc: 0.9358\n",
      "Epoch 41/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1647 - tp: 21612.0000 - fp: 1588.0000 - tn: 21612.0000 - fn: 1588.0000 - accuracy: 0.9316 train_balacc 0.9316420312566177\n",
      " val_balacc 0.8997120108419447\n",
      "\n",
      "Epoch 41: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1646 - tp: 21997.0000 - fp: 1614.0000 - tn: 21997.0000 - fn: 1614.0000 - accuracy: 0.9316 - val_loss: 0.2344 - val_tp: 5311.0000 - val_fp: 592.0000 - val_tn: 5311.0000 - val_fn: 592.0000 - val_accuracy: 0.8997 - train_sensitivity: 0.9316 - train_specificity: 0.9316 - train_balacc: 0.9316 - val_sensitivity: 0.8997 - val_specificity: 0.8997 - val_balacc: 0.8997\n",
      "Epoch 42/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1717 - tp: 21370.0000 - fp: 1630.0000 - tn: 21370.0000 - fn: 1630.0000 - accuracy: 0.9291 train_balacc 0.9292702553894371\n",
      " val_balacc 0.9456208707436896\n",
      "\n",
      "Epoch 42: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1716 - tp: 21941.0000 - fp: 1670.0000 - tn: 21941.0000 - fn: 1670.0000 - accuracy: 0.9293 - val_loss: 0.1459 - val_tp: 5582.0000 - val_fp: 321.0000 - val_tn: 5582.0000 - val_fn: 321.0000 - val_accuracy: 0.9456 - train_sensitivity: 0.9293 - train_specificity: 0.9293 - train_balacc: 0.9293 - val_sensitivity: 0.9456 - val_specificity: 0.9456 - val_balacc: 0.9456\n",
      "Epoch 43/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1700 - tp: 21631.0000 - fp: 1569.0000 - tn: 21631.0000 - fn: 1569.0000 - accuracy: 0.9324 train_balacc 0.9323620346448689\n",
      " val_balacc 0.950703032356429\n",
      "\n",
      "Epoch 43: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1697 - tp: 22014.0000 - fp: 1597.0000 - tn: 22014.0000 - fn: 1597.0000 - accuracy: 0.9324 - val_loss: 0.1637 - val_tp: 5612.0000 - val_fp: 291.0000 - val_tn: 5612.0000 - val_fn: 291.0000 - val_accuracy: 0.9507 - train_sensitivity: 0.9324 - train_specificity: 0.9324 - train_balacc: 0.9324 - val_sensitivity: 0.9507 - val_specificity: 0.9507 - val_balacc: 0.9507\n",
      "Epoch 44/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1603 - tp: 21526.0000 - fp: 1474.0000 - tn: 21526.0000 - fn: 1474.0000 - accuracy: 0.9359 train_balacc 0.9365126424124349\n",
      " val_balacc 0.9457902761307809\n",
      "\n",
      "Epoch 44: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1596 - tp: 22112.0000 - fp: 1499.0000 - tn: 22112.0000 - fn: 1499.0000 - accuracy: 0.9365 - val_loss: 0.1380 - val_tp: 5583.0000 - val_fp: 320.0000 - val_tn: 5583.0000 - val_fn: 320.0000 - val_accuracy: 0.9458 - train_sensitivity: 0.9365 - train_specificity: 0.9365 - train_balacc: 0.9365 - val_sensitivity: 0.9458 - val_specificity: 0.9458 - val_balacc: 0.9458\n",
      "Epoch 45/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1619 - tp: 21695.0000 - fp: 1505.0000 - tn: 21695.0000 - fn: 1505.0000 - accuracy: 0.9351 train_balacc 0.9349455762144763\n",
      " val_balacc 0.9495171946467897\n",
      "\n",
      "Epoch 45: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1623 - tp: 22075.0000 - fp: 1536.0000 - tn: 22075.0000 - fn: 1536.0000 - accuracy: 0.9349 - val_loss: 0.1324 - val_tp: 5605.0000 - val_fp: 298.0000 - val_tn: 5605.0000 - val_fn: 298.0000 - val_accuracy: 0.9495 - train_sensitivity: 0.9349 - train_specificity: 0.9349 - train_balacc: 0.9349 - val_sensitivity: 0.9495 - val_specificity: 0.9495 - val_balacc: 0.9495\n",
      "Epoch 46/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1661 - tp: 21351.0000 - fp: 1549.0000 - tn: 21351.0000 - fn: 1549.0000 - accuracy: 0.9324 train_balacc 0.9325314472068104\n",
      " val_balacc 0.9114009825512451\n",
      "\n",
      "Epoch 46: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1672 - tp: 22018.0000 - fp: 1593.0000 - tn: 22018.0000 - fn: 1593.0000 - accuracy: 0.9325 - val_loss: 0.2120 - val_tp: 5380.0000 - val_fp: 523.0000 - val_tn: 5380.0000 - val_fn: 523.0000 - val_accuracy: 0.9114 - train_sensitivity: 0.9325 - train_specificity: 0.9325 - train_balacc: 0.9325 - val_sensitivity: 0.9114 - val_specificity: 0.9114 - val_balacc: 0.9114\n",
      "Epoch 47/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1607 - tp: 21303.0000 - fp: 1497.0000 - tn: 21303.0000 - fn: 1497.0000 - accuracy: 0.9343 train_balacc 0.9337596882808861\n",
      " val_balacc 0.9207182788412671\n",
      "\n",
      "Epoch 47: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1614 - tp: 22047.0000 - fp: 1564.0000 - tn: 22047.0000 - fn: 1564.0000 - accuracy: 0.9338 - val_loss: 0.1980 - val_tp: 5435.0000 - val_fp: 468.0000 - val_tn: 5435.0000 - val_fn: 468.0000 - val_accuracy: 0.9207 - train_sensitivity: 0.9338 - train_specificity: 0.9338 - train_balacc: 0.9338 - val_sensitivity: 0.9207 - val_specificity: 0.9207 - val_balacc: 0.9207\n",
      "Epoch 48/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1630 - tp: 21378.0000 - fp: 1522.0000 - tn: 21378.0000 - fn: 1522.0000 - accuracy: 0.9335 train_balacc 0.9340138071237982\n",
      " val_balacc 0.9156361172285279\n",
      "\n",
      "Epoch 48: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1620 - tp: 22053.0000 - fp: 1558.0000 - tn: 22053.0000 - fn: 1558.0000 - accuracy: 0.9340 - val_loss: 0.2136 - val_tp: 5405.0000 - val_fp: 498.0000 - val_tn: 5405.0000 - val_fn: 498.0000 - val_accuracy: 0.9156 - train_sensitivity: 0.9340 - train_specificity: 0.9340 - train_balacc: 0.9340 - val_sensitivity: 0.9156 - val_specificity: 0.9156 - val_balacc: 0.9156\n",
      "Epoch 49/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1686 - tp: 21741.0000 - fp: 1559.0000 - tn: 21741.0000 - fn: 1559.0000 - accuracy: 0.9331 train_balacc 0.9329549786116641\n",
      " val_balacc 0.8925969845841097\n",
      "\n",
      "Epoch 49: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1688 - tp: 22028.0000 - fp: 1583.0000 - tn: 22028.0000 - fn: 1583.0000 - accuracy: 0.9330 - val_loss: 0.2441 - val_tp: 5269.0000 - val_fp: 634.0000 - val_tn: 5269.0000 - val_fn: 634.0000 - val_accuracy: 0.8926 - train_sensitivity: 0.9330 - train_specificity: 0.9330 - train_balacc: 0.9330 - val_sensitivity: 0.8926 - val_specificity: 0.8926 - val_balacc: 0.8926\n",
      "Epoch 50/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1620 - tp: 21422.0000 - fp: 1578.0000 - tn: 21422.0000 - fn: 1578.0000 - accuracy: 0.9314 train_balacc 0.9314726186946762\n",
      " val_balacc 0.9318990343892936\n",
      "\n",
      "Epoch 50: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1622 - tp: 21993.0000 - fp: 1618.0000 - tn: 21993.0000 - fn: 1618.0000 - accuracy: 0.9315 - val_loss: 0.1850 - val_tp: 5501.0000 - val_fp: 402.0000 - val_tn: 5501.0000 - val_fn: 402.0000 - val_accuracy: 0.9319 - train_sensitivity: 0.9315 - train_specificity: 0.9315 - train_balacc: 0.9315 - val_sensitivity: 0.9319 - val_specificity: 0.9319 - val_balacc: 0.9319\n",
      "Epoch 51/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1599 - tp: 21719.0000 - fp: 1481.0000 - tn: 21719.0000 - fn: 1481.0000 - accuracy: 0.9362 train_balacc 0.936173817288552\n",
      " val_balacc 0.8214467220057597\n",
      "\n",
      "Epoch 51: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1612 - tp: 22104.0000 - fp: 1507.0000 - tn: 22104.0000 - fn: 1507.0000 - accuracy: 0.9362 - val_loss: 0.4934 - val_tp: 4849.0000 - val_fp: 1054.0000 - val_tn: 4849.0000 - val_fn: 1054.0000 - val_accuracy: 0.8214 - train_sensitivity: 0.9362 - train_specificity: 0.9362 - train_balacc: 0.9362 - val_sensitivity: 0.8214 - val_specificity: 0.8214 - val_balacc: 0.8214\n",
      "Epoch 52/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1625 - tp: 21718.0000 - fp: 1582.0000 - tn: 21718.0000 - fn: 1582.0000 - accuracy: 0.9321 train_balacc 0.9321502689424421\n",
      " val_balacc 0.935964763679485\n",
      "\n",
      "Epoch 52: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1626 - tp: 22009.0000 - fp: 1602.0000 - tn: 22009.0000 - fn: 1602.0000 - accuracy: 0.9322 - val_loss: 0.1470 - val_tp: 5525.0000 - val_fp: 378.0000 - val_tn: 5525.0000 - val_fn: 378.0000 - val_accuracy: 0.9360 - train_sensitivity: 0.9322 - train_specificity: 0.9322 - train_balacc: 0.9322 - val_sensitivity: 0.9360 - val_specificity: 0.9360 - val_balacc: 0.9360\n",
      "Epoch 53/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1593 - tp: 22082.0000 - fp: 1518.0000 - tn: 22082.0000 - fn: 1518.0000 - accuracy: 0.9357 train_balacc 0.935707932743213\n",
      " val_balacc 0.9208876842283584\n",
      "\n",
      "Epoch 53: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1592 - tp: 22093.0000 - fp: 1518.0000 - tn: 22093.0000 - fn: 1518.0000 - accuracy: 0.9357 - val_loss: 0.1951 - val_tp: 5436.0000 - val_fp: 467.0000 - val_tn: 5436.0000 - val_fn: 467.0000 - val_accuracy: 0.9209 - train_sensitivity: 0.9357 - train_specificity: 0.9357 - train_balacc: 0.9357 - val_sensitivity: 0.9209 - val_specificity: 0.9209 - val_balacc: 0.9209\n",
      "Epoch 54/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1625 - tp: 21268.0000 - fp: 1532.0000 - tn: 21268.0000 - fn: 1532.0000 - accuracy: 0.9328 train_balacc 0.9325738003472958\n",
      " val_balacc 0.9230899542605455\n",
      "\n",
      "Epoch 54: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1649 - tp: 22019.0000 - fp: 1592.0000 - tn: 22019.0000 - fn: 1592.0000 - accuracy: 0.9326 - val_loss: 0.2170 - val_tp: 5449.0000 - val_fp: 454.0000 - val_tn: 5449.0000 - val_fn: 454.0000 - val_accuracy: 0.9231 - train_sensitivity: 0.9326 - train_specificity: 0.9326 - train_balacc: 0.9326 - val_sensitivity: 0.9231 - val_specificity: 0.9231 - val_balacc: 0.9231\n",
      "Epoch 55/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1596 - tp: 21631.0000 - fp: 1469.0000 - tn: 21631.0000 - fn: 1469.0000 - accuracy: 0.9364 train_balacc 0.936173817288552\n",
      " val_balacc 0.9478231407758767\n",
      "\n",
      "Epoch 55: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1598 - tp: 22104.0000 - fp: 1507.0000 - tn: 22104.0000 - fn: 1507.0000 - accuracy: 0.9362 - val_loss: 0.1476 - val_tp: 5595.0000 - val_fp: 308.0000 - val_tn: 5595.0000 - val_fn: 308.0000 - val_accuracy: 0.9478 - train_sensitivity: 0.9362 - train_specificity: 0.9362 - train_balacc: 0.9362 - val_sensitivity: 0.9478 - val_specificity: 0.9478 - val_balacc: 0.9478\n",
      "Epoch 56/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1594 - tp: 21432.0000 - fp: 1468.0000 - tn: 21432.0000 - fn: 1468.0000 - accuracy: 0.9359 train_balacc 0.9357502858836982\n",
      " val_balacc 0.7540233779434186\n",
      "\n",
      "Epoch 56: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1598 - tp: 22094.0000 - fp: 1517.0000 - tn: 22094.0000 - fn: 1517.0000 - accuracy: 0.9358 - val_loss: 1.0457 - val_tp: 4451.0000 - val_fp: 1452.0000 - val_tn: 4451.0000 - val_fn: 1452.0000 - val_accuracy: 0.7540 - train_sensitivity: 0.9358 - train_specificity: 0.9358 - train_balacc: 0.9358 - val_sensitivity: 0.7540 - val_specificity: 0.7540 - val_balacc: 0.7540\n",
      "Epoch 57/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1599 - tp: 21495.0000 - fp: 1505.0000 - tn: 21495.0000 - fn: 1505.0000 - accuracy: 0.9346 train_balacc 0.9345220448096226\n",
      " val_balacc 0.9334236828731154\n",
      "\n",
      "Epoch 57: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1596 - tp: 22065.0000 - fp: 1546.0000 - tn: 22065.0000 - fn: 1546.0000 - accuracy: 0.9345 - val_loss: 0.1781 - val_tp: 5510.0000 - val_fp: 393.0000 - val_tn: 5510.0000 - val_fn: 393.0000 - val_accuracy: 0.9334 - train_sensitivity: 0.9345 - train_specificity: 0.9345 - train_balacc: 0.9345 - val_sensitivity: 0.9334 - val_specificity: 0.9334 - val_balacc: 0.9334\n",
      "Epoch 58/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1544 - tp: 21845.0000 - fp: 1455.0000 - tn: 21845.0000 - fn: 1455.0000 - accuracy: 0.9376 train_balacc 0.9376138240650544\n",
      " val_balacc 0.9230899542605455\n",
      "\n",
      "Epoch 58: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1544 - tp: 22138.0000 - fp: 1473.0000 - tn: 22138.0000 - fn: 1473.0000 - accuracy: 0.9376 - val_loss: 0.2002 - val_tp: 5449.0000 - val_fp: 454.0000 - val_tn: 5449.0000 - val_fn: 454.0000 - val_accuracy: 0.9231 - train_sensitivity: 0.9376 - train_specificity: 0.9376 - train_balacc: 0.9376 - val_sensitivity: 0.9231 - val_specificity: 0.9231 - val_balacc: 0.9231\n",
      "Epoch 59/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1636 - tp: 21378.0000 - fp: 1522.0000 - tn: 21378.0000 - fn: 1522.0000 - accuracy: 0.9335 train_balacc 0.9334208631570031\n",
      " val_balacc 0.9432491953244113\n",
      "\n",
      "Epoch 59: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1635 - tp: 22039.0000 - fp: 1572.0000 - tn: 22039.0000 - fn: 1572.0000 - accuracy: 0.9334 - val_loss: 0.1588 - val_tp: 5568.0000 - val_fp: 335.0000 - val_tn: 5568.0000 - val_fn: 335.0000 - val_accuracy: 0.9432 - train_sensitivity: 0.9334 - train_specificity: 0.9334 - train_balacc: 0.9334 - val_sensitivity: 0.9432 - val_specificity: 0.9432 - val_balacc: 0.9432\n",
      "Epoch 60/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1603 - tp: 21953.0000 - fp: 1547.0000 - tn: 21953.0000 - fn: 1547.0000 - accuracy: 0.9342 train_balacc 0.9342679259667104\n",
      " val_balacc 0.9425715737760461\n",
      "\n",
      "Epoch 60: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1601 - tp: 22059.0000 - fp: 1552.0000 - tn: 22059.0000 - fn: 1552.0000 - accuracy: 0.9343 - val_loss: 0.1547 - val_tp: 5564.0000 - val_fp: 339.0000 - val_tn: 5564.0000 - val_fn: 339.0000 - val_accuracy: 0.9426 - train_sensitivity: 0.9343 - train_specificity: 0.9343 - train_balacc: 0.9343 - val_sensitivity: 0.9426 - val_specificity: 0.9426 - val_balacc: 0.9426\n",
      "Epoch 61/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1562 - tp: 21550.0000 - fp: 1450.0000 - tn: 21550.0000 - fn: 1450.0000 - accuracy: 0.9370 train_balacc 0.936978526957774\n",
      " val_balacc 0.9429103845502287\n",
      "\n",
      "Epoch 61: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1571 - tp: 22123.0000 - fp: 1488.0000 - tn: 22123.0000 - fn: 1488.0000 - accuracy: 0.9370 - val_loss: 0.1690 - val_tp: 5566.0000 - val_fp: 337.0000 - val_tn: 5566.0000 - val_fn: 337.0000 - val_accuracy: 0.9429 - train_sensitivity: 0.9370 - train_specificity: 0.9370 - train_balacc: 0.9370 - val_sensitivity: 0.9429 - val_specificity: 0.9429 - val_balacc: 0.9429\n",
      "Epoch 62/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1551 - tp: 21497.0000 - fp: 1403.0000 - tn: 21497.0000 - fn: 1403.0000 - accuracy: 0.9387 train_balacc 0.9379526491889374\n",
      " val_balacc 0.8966627138743012\n",
      "\n",
      "Epoch 62: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1590 - tp: 22146.0000 - fp: 1465.0000 - tn: 22146.0000 - fn: 1465.0000 - accuracy: 0.9380 - val_loss: 0.2615 - val_tp: 5293.0000 - val_fp: 610.0000 - val_tn: 5293.0000 - val_fn: 610.0000 - val_accuracy: 0.8967 - train_sensitivity: 0.9380 - train_specificity: 0.9380 - train_balacc: 0.9380 - val_sensitivity: 0.8967 - val_specificity: 0.8967 - val_balacc: 0.8967\n",
      "Epoch 63/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1643 - tp: 21555.0000 - fp: 1545.0000 - tn: 21555.0000 - fn: 1545.0000 - accuracy: 0.9331 train_balacc 0.933293803735547\n",
      " val_balacc 0.9357953582923937\n",
      "\n",
      "Epoch 63: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1641 - tp: 22036.0000 - fp: 1575.0000 - tn: 22036.0000 - fn: 1575.0000 - accuracy: 0.9333 - val_loss: 0.1569 - val_tp: 5524.0000 - val_fp: 379.0000 - val_tn: 5524.0000 - val_fn: 379.0000 - val_accuracy: 0.9358 - train_sensitivity: 0.9333 - train_specificity: 0.9333 - train_balacc: 0.9333 - val_sensitivity: 0.9358 - val_specificity: 0.9358 - val_balacc: 0.9358\n",
      "Epoch 64/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1606 - tp: 21609.0000 - fp: 1491.0000 - tn: 21609.0000 - fn: 1491.0000 - accuracy: 0.9355 train_balacc 0.9355808733217568\n",
      " val_balacc 0.8841267152295443\n",
      "\n",
      "Epoch 64: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1608 - tp: 22090.0000 - fp: 1521.0000 - tn: 22090.0000 - fn: 1521.0000 - accuracy: 0.9356 - val_loss: 0.2445 - val_tp: 5219.0000 - val_fp: 684.0000 - val_tn: 5219.0000 - val_fn: 684.0000 - val_accuracy: 0.8841 - train_sensitivity: 0.9356 - train_specificity: 0.9356 - train_balacc: 0.9356 - val_sensitivity: 0.8841 - val_specificity: 0.8841 - val_balacc: 0.8841\n",
      "Epoch 65/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1587 - tp: 21941.0000 - fp: 1459.0000 - tn: 21941.0000 - fn: 1459.0000 - accuracy: 0.9376 train_balacc 0.937571470924569\n",
      " val_balacc 0.9307131966796545\n",
      "\n",
      "Epoch 65: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1587 - tp: 22137.0000 - fp: 1474.0000 - tn: 22137.0000 - fn: 1474.0000 - accuracy: 0.9376 - val_loss: 0.1759 - val_tp: 5494.0000 - val_fp: 409.0000 - val_tn: 5494.0000 - val_fn: 409.0000 - val_accuracy: 0.9307 - train_sensitivity: 0.9376 - train_specificity: 0.9376 - train_balacc: 0.9376 - val_sensitivity: 0.9307 - val_specificity: 0.9307 - val_balacc: 0.9307\n",
      "Epoch 66/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1588 - tp: 21805.0000 - fp: 1495.0000 - tn: 21805.0000 - fn: 1495.0000 - accuracy: 0.9358 train_balacc 0.936173817288552\n",
      " val_balacc 0.9400304929696764\n",
      "\n",
      "Epoch 66: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1584 - tp: 22104.0000 - fp: 1507.0000 - tn: 22104.0000 - fn: 1507.0000 - accuracy: 0.9362 - val_loss: 0.1557 - val_tp: 5549.0000 - val_fp: 354.0000 - val_tn: 5549.0000 - val_fn: 354.0000 - val_accuracy: 0.9400 - train_sensitivity: 0.9362 - train_specificity: 0.9362 - train_balacc: 0.9362 - val_sensitivity: 0.9400 - val_specificity: 0.9400 - val_balacc: 0.9400\n",
      "Epoch 67/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1576 - tp: 21969.0000 - fp: 1531.0000 - tn: 21969.0000 - fn: 1531.0000 - accuracy: 0.9349 train_balacc 0.9346491042310787\n",
      " val_balacc 0.9012366593257666\n",
      "\n",
      "Epoch 67: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1582 - tp: 22068.0000 - fp: 1543.0000 - tn: 22068.0000 - fn: 1543.0000 - accuracy: 0.9346 - val_loss: 0.2149 - val_tp: 5320.0000 - val_fp: 583.0000 - val_tn: 5320.0000 - val_fn: 583.0000 - val_accuracy: 0.9012 - train_sensitivity: 0.9346 - train_specificity: 0.9346 - train_balacc: 0.9346 - val_sensitivity: 0.9012 - val_specificity: 0.9012 - val_balacc: 0.9012\n",
      "Epoch 68/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1544 - tp: 21539.0000 - fp: 1460.0000 - tn: 21540.0000 - fn: 1461.0000 - accuracy: 0.9365 train_balacc 0.9365338189826775\n",
      " val_balacc 0.9132644418092495\n",
      "\n",
      "Epoch 68: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1544 - tp: 22112.0000 - fp: 1498.0000 - tn: 22113.0000 - fn: 1499.0000 - accuracy: 0.9365 - val_loss: 0.2122 - val_tp: 5391.0000 - val_fp: 512.0000 - val_tn: 5391.0000 - val_fn: 512.0000 - val_accuracy: 0.9133 - train_sensitivity: 0.9365 - train_specificity: 0.9366 - train_balacc: 0.9365 - val_sensitivity: 0.9133 - val_specificity: 0.9133 - val_balacc: 0.9133\n",
      "Epoch 69/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1621 - tp: 21937.0000 - fp: 1563.0000 - tn: 21937.0000 - fn: 1563.0000 - accuracy: 0.9335 train_balacc 0.9336326288594299\n",
      " val_balacc 0.9280027104861934\n",
      "\n",
      "Epoch 69: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1618 - tp: 22044.0000 - fp: 1567.0000 - tn: 22044.0000 - fn: 1567.0000 - accuracy: 0.9336 - val_loss: 0.1790 - val_tp: 5478.0000 - val_fp: 425.0000 - val_tn: 5478.0000 - val_fn: 425.0000 - val_accuracy: 0.9280 - train_sensitivity: 0.9336 - train_specificity: 0.9336 - train_balacc: 0.9336 - val_sensitivity: 0.9280 - val_specificity: 0.9280 - val_balacc: 0.9280\n",
      "Epoch 70/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1538 - tp: 21493.0000 - fp: 1407.0000 - tn: 21493.0000 - fn: 1407.0000 - accuracy: 0.9386 train_balacc 0.9385032400152471\n",
      " val_balacc 0.9390140606471286\n",
      "\n",
      "Epoch 70: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1535 - tp: 22159.0000 - fp: 1452.0000 - tn: 22159.0000 - fn: 1452.0000 - accuracy: 0.9385 - val_loss: 0.1467 - val_tp: 5543.0000 - val_fp: 360.0000 - val_tn: 5543.0000 - val_fn: 360.0000 - val_accuracy: 0.9390 - train_sensitivity: 0.9385 - train_specificity: 0.9385 - train_balacc: 0.9385 - val_sensitivity: 0.9390 - val_specificity: 0.9390 - val_balacc: 0.9390\n",
      "Epoch 71/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1605 - tp: 21355.0000 - fp: 1445.0000 - tn: 21355.0000 - fn: 1445.0000 - accuracy: 0.9366 train_balacc 0.9371479395197154\n",
      " val_balacc 0.8712519058106047\n",
      "\n",
      "Epoch 71: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1597 - tp: 22127.0000 - fp: 1484.0000 - tn: 22127.0000 - fn: 1484.0000 - accuracy: 0.9371 - val_loss: 0.3322 - val_tp: 5143.0000 - val_fp: 760.0000 - val_tn: 5143.0000 - val_fn: 760.0000 - val_accuracy: 0.8713 - train_sensitivity: 0.9371 - train_specificity: 0.9371 - train_balacc: 0.9371 - val_sensitivity: 0.8713 - val_specificity: 0.8713 - val_balacc: 0.8713\n",
      "Epoch 72/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1626 - tp: 21962.0000 - fp: 1538.0000 - tn: 21962.0000 - fn: 1538.0000 - accuracy: 0.9346 train_balacc 0.9345220448096226\n",
      " val_balacc 0.9193630357445367\n",
      "\n",
      "Epoch 72: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1626 - tp: 22065.0000 - fp: 1546.0000 - tn: 22065.0000 - fn: 1546.0000 - accuracy: 0.9345 - val_loss: 0.2202 - val_tp: 5427.0000 - val_fp: 476.0000 - val_tn: 5427.0000 - val_fn: 476.0000 - val_accuracy: 0.9194 - train_sensitivity: 0.9345 - train_specificity: 0.9345 - train_balacc: 0.9345 - val_sensitivity: 0.9194 - val_specificity: 0.9194 - val_balacc: 0.9194\n",
      "Epoch 73/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1564 - tp: 21707.0000 - fp: 1493.0000 - tn: 21707.0000 - fn: 1493.0000 - accuracy: 0.9356 train_balacc 0.9350726356359325\n",
      " val_balacc 0.8905641199390141\n",
      "\n",
      "Epoch 73: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1586 - tp: 22078.0000 - fp: 1533.0000 - tn: 22078.0000 - fn: 1533.0000 - accuracy: 0.9351 - val_loss: 0.2291 - val_tp: 5257.0000 - val_fp: 646.0000 - val_tn: 5257.0000 - val_fn: 646.0000 - val_accuracy: 0.8906 - train_sensitivity: 0.9351 - train_specificity: 0.9351 - train_balacc: 0.9351 - val_sensitivity: 0.8906 - val_specificity: 0.8906 - val_balacc: 0.8906\n",
      "Epoch 74/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1545 - tp: 21570.0000 - fp: 1430.0000 - tn: 21570.0000 - fn: 1430.0000 - accuracy: 0.9378 train_balacc 0.9379950023294227\n",
      " val_balacc 0.907504658648145\n",
      "\n",
      "Epoch 74: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1541 - tp: 22147.0000 - fp: 1464.0000 - tn: 22147.0000 - fn: 1464.0000 - accuracy: 0.9380 - val_loss: 0.1932 - val_tp: 5357.0000 - val_fp: 546.0000 - val_tn: 5357.0000 - val_fn: 546.0000 - val_accuracy: 0.9075 - train_sensitivity: 0.9380 - train_specificity: 0.9380 - train_balacc: 0.9380 - val_sensitivity: 0.9075 - val_specificity: 0.9075 - val_balacc: 0.9075\n",
      "Epoch 75/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1538 - tp: 22144.0000 - fp: 1456.0000 - tn: 22144.0000 - fn: 1456.0000 - accuracy: 0.9383 train_balacc 0.9382914743128203\n",
      " val_balacc 0.9415551414534982\n",
      "\n",
      "Epoch 75: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1539 - tp: 22154.0000 - fp: 1457.0000 - tn: 22154.0000 - fn: 1457.0000 - accuracy: 0.9383 - val_loss: 0.1538 - val_tp: 5558.0000 - val_fp: 345.0000 - val_tn: 5558.0000 - val_fn: 345.0000 - val_accuracy: 0.9416 - train_sensitivity: 0.9383 - train_specificity: 0.9383 - train_balacc: 0.9383 - val_sensitivity: 0.9416 - val_specificity: 0.9416 - val_balacc: 0.9416\n",
      "Epoch 76/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1605 - tp: 21359.0000 - fp: 1441.0000 - tn: 21359.0000 - fn: 1441.0000 - accuracy: 0.9368 train_balacc 0.9365126424124349\n",
      " val_balacc 0.9373200067762155\n",
      "\n",
      "Epoch 76: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1605 - tp: 22112.0000 - fp: 1499.0000 - tn: 22112.0000 - fn: 1499.0000 - accuracy: 0.9365 - val_loss: 0.1829 - val_tp: 5533.0000 - val_fp: 370.0000 - val_tn: 5533.0000 - val_fn: 370.0000 - val_accuracy: 0.9373 - train_sensitivity: 0.9365 - train_specificity: 0.9365 - train_balacc: 0.9365 - val_sensitivity: 0.9373 - val_specificity: 0.9373 - val_balacc: 0.9373\n",
      "Epoch 77/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1582 - tp: 21495.0000 - fp: 1505.0000 - tn: 21495.0000 - fn: 1505.0000 - accuracy: 0.9346 train_balacc 0.934564397950108\n",
      " val_balacc 0.9305437912925631\n",
      "\n",
      "Epoch 77: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1577 - tp: 22066.0000 - fp: 1545.0000 - tn: 22066.0000 - fn: 1545.0000 - accuracy: 0.9346 - val_loss: 0.1579 - val_tp: 5493.0000 - val_fp: 410.0000 - val_tn: 5493.0000 - val_fn: 410.0000 - val_accuracy: 0.9305 - train_sensitivity: 0.9346 - train_specificity: 0.9346 - train_balacc: 0.9346 - val_sensitivity: 0.9305 - val_specificity: 0.9305 - val_balacc: 0.9305\n",
      "Epoch 78/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1570 - tp: 21411.0000 - fp: 1489.0000 - tn: 21411.0000 - fn: 1489.0000 - accuracy: 0.9350 train_balacc 0.93536910761933\n",
      " val_balacc 0.8458410977469083\n",
      "\n",
      "Epoch 78: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1565 - tp: 22085.0000 - fp: 1526.0000 - tn: 22085.0000 - fn: 1526.0000 - accuracy: 0.9354 - val_loss: 0.6337 - val_tp: 4993.0000 - val_fp: 910.0000 - val_tn: 4993.0000 - val_fn: 910.0000 - val_accuracy: 0.8458 - train_sensitivity: 0.9354 - train_specificity: 0.9354 - train_balacc: 0.9354 - val_sensitivity: 0.8458 - val_specificity: 0.8458 - val_balacc: 0.8458\n",
      "Epoch 79/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1591 - tp: 21420.0000 - fp: 1380.0000 - tn: 21420.0000 - fn: 1380.0000 - accuracy: 0.9395 train_balacc 0.9393079496844691\n",
      " val_balacc 0.9258004404540064\n",
      "\n",
      "Epoch 79: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1589 - tp: 22178.0000 - fp: 1433.0000 - tn: 22178.0000 - fn: 1433.0000 - accuracy: 0.9393 - val_loss: 0.1787 - val_tp: 5465.0000 - val_fp: 438.0000 - val_tn: 5465.0000 - val_fn: 438.0000 - val_accuracy: 0.9258 - train_sensitivity: 0.9393 - train_specificity: 0.9393 - train_balacc: 0.9393 - val_sensitivity: 0.9258 - val_specificity: 0.9258 - val_balacc: 0.9258\n",
      "Epoch 80/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1632 - tp: 21873.0000 - fp: 1527.0000 - tn: 21873.0000 - fn: 1527.0000 - accuracy: 0.9347 train_balacc 0.9346914573715641\n",
      " val_balacc 0.919532441131628\n",
      "\n",
      "Epoch 80: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1631 - tp: 22069.0000 - fp: 1542.0000 - tn: 22069.0000 - fn: 1542.0000 - accuracy: 0.9347 - val_loss: 0.1783 - val_tp: 5428.0000 - val_fp: 475.0000 - val_tn: 5428.0000 - val_fn: 475.0000 - val_accuracy: 0.9195 - train_sensitivity: 0.9347 - train_specificity: 0.9347 - train_balacc: 0.9347 - val_sensitivity: 0.9195 - val_specificity: 0.9195 - val_balacc: 0.9195\n",
      "Epoch 81/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1582 - tp: 21644.0000 - fp: 1456.0000 - tn: 21644.0000 - fn: 1456.0000 - accuracy: 0.9370 train_balacc 0.9373597052221422\n",
      " val_balacc 0.9258004404540064\n",
      "\n",
      "Epoch 81: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1569 - tp: 22132.0000 - fp: 1479.0000 - tn: 22132.0000 - fn: 1479.0000 - accuracy: 0.9374 - val_loss: 0.1802 - val_tp: 5465.0000 - val_fp: 438.0000 - val_tn: 5465.0000 - val_fn: 438.0000 - val_accuracy: 0.9258 - train_sensitivity: 0.9374 - train_specificity: 0.9374 - train_balacc: 0.9374 - val_sensitivity: 0.9258 - val_specificity: 0.9258 - val_balacc: 0.9258\n",
      "Epoch 82/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1588 - tp: 22070.0000 - fp: 1530.0000 - tn: 22070.0000 - fn: 1530.0000 - accuracy: 0.9352 train_balacc 0.9351996950573885\n",
      " val_balacc 0.9415551414534982\n",
      "\n",
      "Epoch 82: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1588 - tp: 22081.0000 - fp: 1530.0000 - tn: 22081.0000 - fn: 1530.0000 - accuracy: 0.9352 - val_loss: 0.1489 - val_tp: 5558.0000 - val_fp: 345.0000 - val_tn: 5558.0000 - val_fn: 345.0000 - val_accuracy: 0.9416 - train_sensitivity: 0.9352 - train_specificity: 0.9352 - train_balacc: 0.9352 - val_sensitivity: 0.9416 - val_specificity: 0.9416 - val_balacc: 0.9416\n",
      "Epoch 83/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1581 - tp: 21548.0000 - fp: 1452.0000 - tn: 21548.0000 - fn: 1452.0000 - accuracy: 0.9369 train_balacc 0.9368514675363179\n",
      " val_balacc 0.9349483313569371\n",
      "\n",
      "Epoch 83: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1576 - tp: 22120.0000 - fp: 1491.0000 - tn: 22120.0000 - fn: 1491.0000 - accuracy: 0.9369 - val_loss: 0.1652 - val_tp: 5519.0000 - val_fp: 384.0000 - val_tn: 5519.0000 - val_fn: 384.0000 - val_accuracy: 0.9349 - train_sensitivity: 0.9369 - train_specificity: 0.9369 - train_balacc: 0.9369 - val_sensitivity: 0.9349 - val_specificity: 0.9349 - val_balacc: 0.9349\n",
      "Epoch 84/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1546 - tp: 21675.0000 - fp: 1425.0000 - tn: 21675.0000 - fn: 1425.0000 - accuracy: 0.9383 train_balacc 0.938376180593791\n",
      " val_balacc 0.9393528714213112\n",
      "\n",
      "Epoch 84: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1548 - tp: 22156.0000 - fp: 1455.0000 - tn: 22156.0000 - fn: 1455.0000 - accuracy: 0.9384 - val_loss: 0.1787 - val_tp: 5545.0000 - val_fp: 358.0000 - val_tn: 5545.0000 - val_fn: 358.0000 - val_accuracy: 0.9394 - train_sensitivity: 0.9384 - train_specificity: 0.9384 - train_balacc: 0.9384 - val_sensitivity: 0.9394 - val_specificity: 0.9394 - val_balacc: 0.9394\n",
      "Epoch 85/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1586 - tp: 21493.0000 - fp: 1507.0000 - tn: 21493.0000 - fn: 1507.0000 - accuracy: 0.9345 train_balacc 0.934903223073991\n",
      " val_balacc 0.9324072505505675\n",
      "\n",
      "Epoch 85: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1579 - tp: 22074.0000 - fp: 1537.0000 - tn: 22074.0000 - fn: 1537.0000 - accuracy: 0.9349 - val_loss: 0.1655 - val_tp: 5504.0000 - val_fp: 399.0000 - val_tn: 5504.0000 - val_fn: 399.0000 - val_accuracy: 0.9324 - train_sensitivity: 0.9349 - train_specificity: 0.9349 - train_balacc: 0.9349 - val_sensitivity: 0.9324 - val_specificity: 0.9324 - val_balacc: 0.9324\n",
      "Epoch 86/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1554 - tp: 21751.0000 - fp: 1449.0000 - tn: 21751.0000 - fn: 1449.0000 - accuracy: 0.9375 train_balacc 0.9374867646435984\n",
      " val_balacc 0.9486701677113332\n",
      "\n",
      "Epoch 86: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1557 - tp: 22135.0000 - fp: 1476.0000 - tn: 22135.0000 - fn: 1476.0000 - accuracy: 0.9375 - val_loss: 0.1480 - val_tp: 5600.0000 - val_fp: 303.0000 - val_tn: 5600.0000 - val_fn: 303.0000 - val_accuracy: 0.9487 - train_sensitivity: 0.9375 - train_specificity: 0.9375 - train_balacc: 0.9375 - val_sensitivity: 0.9487 - val_specificity: 0.9487 - val_balacc: 0.9487\n",
      "Epoch 87/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1512 - tp: 21561.0000 - fp: 1439.0000 - tn: 21561.0000 - fn: 1439.0000 - accuracy: 0.9374 train_balacc 0.9375291177840837\n",
      " val_balacc 0.9352871421311197\n",
      "\n",
      "Epoch 87: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1506 - tp: 22136.0000 - fp: 1475.0000 - tn: 22136.0000 - fn: 1475.0000 - accuracy: 0.9375 - val_loss: 0.1617 - val_tp: 5521.0000 - val_fp: 382.0000 - val_tn: 5521.0000 - val_fn: 382.0000 - val_accuracy: 0.9353 - train_sensitivity: 0.9375 - train_specificity: 0.9375 - train_balacc: 0.9375 - val_sensitivity: 0.9353 - val_specificity: 0.9353 - val_balacc: 0.9353\n",
      "Epoch 88/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1547 - tp: 21648.0000 - fp: 1452.0000 - tn: 21648.0000 - fn: 1452.0000 - accuracy: 0.9371 train_balacc 0.937444411503113\n",
      " val_balacc 0.8944604438421142\n",
      "\n",
      "Epoch 88: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1539 - tp: 22134.0000 - fp: 1477.0000 - tn: 22134.0000 - fn: 1477.0000 - accuracy: 0.9374 - val_loss: 0.2400 - val_tp: 5280.0000 - val_fp: 623.0000 - val_tn: 5280.0000 - val_fn: 623.0000 - val_accuracy: 0.8945 - train_sensitivity: 0.9374 - train_specificity: 0.9374 - train_balacc: 0.9374 - val_sensitivity: 0.8945 - val_specificity: 0.8945 - val_balacc: 0.8945\n",
      "Epoch 89/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1559 - tp: 22137.0000 - fp: 1463.0000 - tn: 22137.0000 - fn: 1463.0000 - accuracy: 0.9380 train_balacc 0.9380373554699081\n",
      " val_balacc 0.9281721158732847\n",
      "\n",
      "Epoch 89: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1558 - tp: 22148.0000 - fp: 1463.0000 - tn: 22148.0000 - fn: 1463.0000 - accuracy: 0.9380 - val_loss: 0.1903 - val_tp: 5479.0000 - val_fp: 424.0000 - val_tn: 5479.0000 - val_fn: 424.0000 - val_accuracy: 0.9282 - train_sensitivity: 0.9380 - train_specificity: 0.9380 - train_balacc: 0.9380 - val_sensitivity: 0.9282 - val_specificity: 0.9282 - val_balacc: 0.9282\n",
      "Epoch 90/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1594 - tp: 21527.0000 - fp: 1473.0000 - tn: 21527.0000 - fn: 1473.0000 - accuracy: 0.9360 train_balacc 0.935707932743213\n",
      " val_balacc 0.9325766559376588\n",
      "\n",
      "Epoch 90: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1599 - tp: 22093.0000 - fp: 1518.0000 - tn: 22093.0000 - fn: 1518.0000 - accuracy: 0.9357 - val_loss: 0.1730 - val_tp: 5505.0000 - val_fp: 398.0000 - val_tn: 5505.0000 - val_fn: 398.0000 - val_accuracy: 0.9326 - train_sensitivity: 0.9357 - train_specificity: 0.9357 - train_balacc: 0.9357 - val_sensitivity: 0.9326 - val_specificity: 0.9326 - val_balacc: 0.9326\n",
      "Epoch 91/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1601 - tp: 21355.0000 - fp: 1445.0000 - tn: 21355.0000 - fn: 1445.0000 - accuracy: 0.9366 train_balacc 0.9368514675363179\n",
      " val_balacc 0.879552769778079\n",
      "\n",
      "Epoch 91: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1600 - tp: 22120.0000 - fp: 1491.0000 - tn: 22120.0000 - fn: 1491.0000 - accuracy: 0.9369 - val_loss: 0.3120 - val_tp: 5192.0000 - val_fp: 711.0000 - val_tn: 5192.0000 - val_fn: 711.0000 - val_accuracy: 0.8796 - train_sensitivity: 0.9369 - train_specificity: 0.9369 - train_balacc: 0.9369 - val_sensitivity: 0.8796 - val_specificity: 0.8796 - val_balacc: 0.8796\n",
      "Epoch 92/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1516 - tp: 22188.0000 - fp: 1412.0000 - tn: 22188.0000 - fn: 1412.0000 - accuracy: 0.9402 train_balacc 0.9401973656346618\n",
      " val_balacc 0.9515500592918855\n",
      "\n",
      "Epoch 92: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1515 - tp: 22199.0000 - fp: 1412.0000 - tn: 22199.0000 - fn: 1412.0000 - accuracy: 0.9402 - val_loss: 0.1351 - val_tp: 5617.0000 - val_fp: 286.0000 - val_tn: 5617.0000 - val_fn: 286.0000 - val_accuracy: 0.9516 - train_sensitivity: 0.9402 - train_specificity: 0.9402 - train_balacc: 0.9402 - val_sensitivity: 0.9516 - val_specificity: 0.9516 - val_balacc: 0.9516\n",
      "Epoch 93/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1539 - tp: 21455.0000 - fp: 1445.0000 - tn: 21455.0000 - fn: 1445.0000 - accuracy: 0.9369 train_balacc 0.9374867646435984\n",
      " val_balacc 0.9422327630018634\n",
      "\n",
      "Epoch 93: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1533 - tp: 22135.0000 - fp: 1476.0000 - tn: 22135.0000 - fn: 1476.0000 - accuracy: 0.9375 - val_loss: 0.1635 - val_tp: 5562.0000 - val_fp: 341.0000 - val_tn: 5562.0000 - val_fn: 341.0000 - val_accuracy: 0.9422 - train_sensitivity: 0.9375 - train_specificity: 0.9375 - train_balacc: 0.9375 - val_sensitivity: 0.9422 - val_specificity: 0.9422 - val_balacc: 0.9422\n",
      "Epoch 94/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1552 - tp: 21475.0000 - fp: 1425.0000 - tn: 21475.0000 - fn: 1425.0000 - accuracy: 0.9378 train_balacc 0.9378679429079666\n",
      " val_balacc 0.9449432491953245\n",
      "\n",
      "Epoch 94: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1549 - tp: 22144.0000 - fp: 1467.0000 - tn: 22144.0000 - fn: 1467.0000 - accuracy: 0.9379 - val_loss: 0.1319 - val_tp: 5578.0000 - val_fp: 325.0000 - val_tn: 5578.0000 - val_fn: 325.0000 - val_accuracy: 0.9449 - train_sensitivity: 0.9379 - train_specificity: 0.9379 - train_balacc: 0.9379 - val_sensitivity: 0.9449 - val_specificity: 0.9449 - val_balacc: 0.9449\n",
      "Epoch 95/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1540 - tp: 21784.0000 - fp: 1416.0000 - tn: 21784.0000 - fn: 1416.0000 - accuracy: 0.9390 train_balacc 0.9389267714201008\n",
      " val_balacc 0.8617652041334914\n",
      "\n",
      "Epoch 95: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1536 - tp: 22169.0000 - fp: 1442.0000 - tn: 22169.0000 - fn: 1442.0000 - accuracy: 0.9389 - val_loss: 0.2774 - val_tp: 5087.0000 - val_fp: 816.0000 - val_tn: 5087.0000 - val_fn: 816.0000 - val_accuracy: 0.8618 - train_sensitivity: 0.9389 - train_specificity: 0.9389 - train_balacc: 0.9389 - val_sensitivity: 0.8618 - val_specificity: 0.8618 - val_balacc: 0.8618\n",
      "Epoch 96/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1488 - tp: 21607.0000 - fp: 1393.0000 - tn: 21607.0000 - fn: 1393.0000 - accuracy: 0.9394 train_balacc 0.9395620685273813\n",
      " val_balacc 0.912925631035067\n",
      "\n",
      "Epoch 96: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1487 - tp: 22184.0000 - fp: 1427.0000 - tn: 22184.0000 - fn: 1427.0000 - accuracy: 0.9396 - val_loss: 0.1976 - val_tp: 5389.0000 - val_fp: 514.0000 - val_tn: 5389.0000 - val_fn: 514.0000 - val_accuracy: 0.9129 - train_sensitivity: 0.9396 - train_specificity: 0.9396 - train_balacc: 0.9396 - val_sensitivity: 0.9129 - val_specificity: 0.9129 - val_balacc: 0.9129\n",
      "Epoch 97/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1536 - tp: 21947.0000 - fp: 1453.0000 - tn: 21947.0000 - fn: 1453.0000 - accuracy: 0.9379 train_balacc 0.9379526491889374\n",
      " val_balacc 0.749280027104862\n",
      "\n",
      "Epoch 97: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1543 - tp: 22146.0000 - fp: 1465.0000 - tn: 22146.0000 - fn: 1465.0000 - accuracy: 0.9380 - val_loss: 0.7264 - val_tp: 4423.0000 - val_fp: 1480.0000 - val_tn: 4423.0000 - val_fn: 1480.0000 - val_accuracy: 0.7493 - train_sensitivity: 0.9380 - train_specificity: 0.9380 - train_balacc: 0.9380 - val_sensitivity: 0.7493 - val_specificity: 0.7493 - val_balacc: 0.7493\n",
      "Epoch 98/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1521 - tp: 21897.0000 - fp: 1503.0000 - tn: 21897.0000 - fn: 1503.0000 - accuracy: 0.9358 train_balacc 0.9357502858836982\n",
      " val_balacc 0.8854819583262747\n",
      "\n",
      "Epoch 98: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1521 - tp: 22094.0000 - fp: 1517.0000 - tn: 22094.0000 - fn: 1517.0000 - accuracy: 0.9358 - val_loss: 0.2621 - val_tp: 5227.0000 - val_fp: 676.0000 - val_tn: 5227.0000 - val_fn: 676.0000 - val_accuracy: 0.8855 - train_sensitivity: 0.9358 - train_specificity: 0.9358 - train_balacc: 0.9358 - val_sensitivity: 0.8855 - val_specificity: 0.8855 - val_balacc: 0.8855\n",
      "Epoch 99/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1551 - tp: 22115.0000 - fp: 1485.0000 - tn: 22115.0000 - fn: 1485.0000 - accuracy: 0.9371 train_balacc 0.93710558637923\n",
      " val_balacc 0.9456208707436896\n",
      "\n",
      "Epoch 99: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1550 - tp: 22126.0000 - fp: 1485.0000 - tn: 22126.0000 - fn: 1485.0000 - accuracy: 0.9371 - val_loss: 0.1402 - val_tp: 5582.0000 - val_fp: 321.0000 - val_tn: 5582.0000 - val_fn: 321.0000 - val_accuracy: 0.9456 - train_sensitivity: 0.9371 - train_specificity: 0.9371 - train_balacc: 0.9371 - val_sensitivity: 0.9456 - val_specificity: 0.9456 - val_balacc: 0.9456\n",
      "Epoch 100/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1558 - tp: 22101.0000 - fp: 1499.0000 - tn: 22101.0000 - fn: 1499.0000 - accuracy: 0.9365 train_balacc 0.9364702892719495\n",
      " val_balacc 0.931052007453837\n",
      "\n",
      "Epoch 100: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1558 - tp: 22111.0000 - fp: 1500.0000 - tn: 22111.0000 - fn: 1500.0000 - accuracy: 0.9365 - val_loss: 0.1813 - val_tp: 5496.0000 - val_fp: 407.0000 - val_tn: 5496.0000 - val_fn: 407.0000 - val_accuracy: 0.9311 - train_sensitivity: 0.9365 - train_specificity: 0.9365 - train_balacc: 0.9365 - val_sensitivity: 0.9311 - val_specificity: 0.9311 - val_balacc: 0.9311\n",
      "Epoch 101/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1506 - tp: 21586.0000 - fp: 1414.0000 - tn: 21586.0000 - fn: 1414.0000 - accuracy: 0.9385 train_balacc 0.9384608868747618\n",
      " val_balacc 0.938167033711672\n",
      "\n",
      "Epoch 101: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1510 - tp: 22158.0000 - fp: 1453.0000 - tn: 22158.0000 - fn: 1453.0000 - accuracy: 0.9385 - val_loss: 0.1663 - val_tp: 5538.0000 - val_fp: 365.0000 - val_tn: 5538.0000 - val_fn: 365.0000 - val_accuracy: 0.9382 - train_sensitivity: 0.9385 - train_specificity: 0.9385 - train_balacc: 0.9385 - val_sensitivity: 0.9382 - val_specificity: 0.9382 - val_balacc: 0.9382\n",
      "Epoch 102/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1504 - tp: 21561.0000 - fp: 1439.0000 - tn: 21561.0000 - fn: 1439.0000 - accuracy: 0.9374 train_balacc 0.937910296048452\n",
      " val_balacc 0.9120786040996104\n",
      "\n",
      "Epoch 102: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1496 - tp: 22145.0000 - fp: 1466.0000 - tn: 22145.0000 - fn: 1466.0000 - accuracy: 0.9379 - val_loss: 0.2228 - val_tp: 5384.0000 - val_fp: 519.0000 - val_tn: 5384.0000 - val_fn: 519.0000 - val_accuracy: 0.9121 - train_sensitivity: 0.9379 - train_specificity: 0.9379 - train_balacc: 0.9379 - val_sensitivity: 0.9121 - val_specificity: 0.9121 - val_balacc: 0.9121\n",
      "Epoch 103/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1530 - tp: 22054.0000 - fp: 1446.0000 - tn: 22054.0000 - fn: 1446.0000 - accuracy: 0.9385 train_balacc 0.9384185337342764\n",
      " val_balacc 0.8070472641029984\n",
      "\n",
      "Epoch 103: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1529 - tp: 22157.0000 - fp: 1454.0000 - tn: 22157.0000 - fn: 1454.0000 - accuracy: 0.9384 - val_loss: 0.6991 - val_tp: 4764.0000 - val_fp: 1139.0000 - val_tn: 4764.0000 - val_fn: 1139.0000 - val_accuracy: 0.8070 - train_sensitivity: 0.9384 - train_specificity: 0.9384 - train_balacc: 0.9384 - val_sensitivity: 0.8070 - val_specificity: 0.8070 - val_balacc: 0.8070\n",
      "Epoch 104/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1484 - tp: 21877.0000 - fp: 1423.0000 - tn: 21877.0000 - fn: 1423.0000 - accuracy: 0.9389 train_balacc 0.9390114777010715\n",
      " val_balacc 0.8661697441978655\n",
      "\n",
      "Epoch 104: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1484 - tp: 22171.0000 - fp: 1440.0000 - tn: 22171.0000 - fn: 1440.0000 - accuracy: 0.9390 - val_loss: 0.3492 - val_tp: 5113.0000 - val_fp: 790.0000 - val_tn: 5113.0000 - val_fn: 790.0000 - val_accuracy: 0.8662 - train_sensitivity: 0.9390 - train_specificity: 0.9390 - train_balacc: 0.9390 - val_sensitivity: 0.8662 - val_specificity: 0.8662 - val_balacc: 0.8662\n",
      "Epoch 105/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1556 - tp: 21762.0000 - fp: 1438.0000 - tn: 21762.0000 - fn: 1438.0000 - accuracy: 0.9380 train_balacc 0.9378679429079666\n",
      " val_balacc 0.750974080975775\n",
      "\n",
      "Epoch 105: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1562 - tp: 22144.0000 - fp: 1467.0000 - tn: 22144.0000 - fn: 1467.0000 - accuracy: 0.9379 - val_loss: 0.7862 - val_tp: 4433.0000 - val_fp: 1470.0000 - val_tn: 4433.0000 - val_fn: 1470.0000 - val_accuracy: 0.7510 - train_sensitivity: 0.9379 - train_specificity: 0.9379 - train_balacc: 0.9379 - val_sensitivity: 0.7510 - val_specificity: 0.7510 - val_balacc: 0.7510\n",
      "Epoch 106/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1552 - tp: 22074.0000 - fp: 1426.0000 - tn: 22074.0000 - fn: 1426.0000 - accuracy: 0.9393 train_balacc 0.9392232434034984\n",
      " val_balacc 0.9308826020667457\n",
      "\n",
      "Epoch 106: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1557 - tp: 22176.0000 - fp: 1435.0000 - tn: 22176.0000 - fn: 1435.0000 - accuracy: 0.9392 - val_loss: 0.1744 - val_tp: 5495.0000 - val_fp: 408.0000 - val_tn: 5495.0000 - val_fn: 408.0000 - val_accuracy: 0.9309 - train_sensitivity: 0.9392 - train_specificity: 0.9392 - train_balacc: 0.9392 - val_sensitivity: 0.9309 - val_specificity: 0.9309 - val_balacc: 0.9309\n",
      "Epoch 107/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1492 - tp: 22166.0000 - fp: 1434.0000 - tn: 22166.0000 - fn: 1434.0000 - accuracy: 0.9392 train_balacc 0.9392232434034984\n",
      " val_balacc 0.8881924445197358\n",
      "\n",
      "Epoch 107: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1492 - tp: 22176.0000 - fp: 1435.0000 - tn: 22176.0000 - fn: 1435.0000 - accuracy: 0.9392 - val_loss: 0.2590 - val_tp: 5243.0000 - val_fp: 660.0000 - val_tn: 5243.0000 - val_fn: 660.0000 - val_accuracy: 0.8882 - train_sensitivity: 0.9392 - train_specificity: 0.9392 - train_balacc: 0.9392 - val_sensitivity: 0.8882 - val_specificity: 0.8882 - val_balacc: 0.8882\n",
      "Epoch 108/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1463 - tp: 21662.0000 - fp: 1338.0000 - tn: 21662.0000 - fn: 1338.0000 - accuracy: 0.9418 train_balacc 0.9417644318326204\n",
      " val_balacc 0.9329154667118414\n",
      "\n",
      "Epoch 108: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1464 - tp: 22236.0000 - fp: 1375.0000 - tn: 22236.0000 - fn: 1375.0000 - accuracy: 0.9418 - val_loss: 0.1652 - val_tp: 5507.0000 - val_fp: 396.0000 - val_tn: 5507.0000 - val_fn: 396.0000 - val_accuracy: 0.9329 - train_sensitivity: 0.9418 - train_specificity: 0.9418 - train_balacc: 0.9418 - val_sensitivity: 0.9329 - val_specificity: 0.9329 - val_balacc: 0.9329\n",
      "Epoch 109/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1461 - tp: 21529.0000 - fp: 1371.0000 - tn: 21529.0000 - fn: 1371.0000 - accuracy: 0.9401 train_balacc 0.9397314810893228\n",
      " val_balacc 0.945282059969507\n",
      "\n",
      "Epoch 109: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1469 - tp: 22188.0000 - fp: 1423.0000 - tn: 22188.0000 - fn: 1423.0000 - accuracy: 0.9397 - val_loss: 0.1650 - val_tp: 5580.0000 - val_fp: 323.0000 - val_tn: 5580.0000 - val_fn: 323.0000 - val_accuracy: 0.9453 - train_sensitivity: 0.9397 - train_specificity: 0.9397 - train_balacc: 0.9397 - val_sensitivity: 0.9453 - val_specificity: 0.9453 - val_balacc: 0.9453\n",
      "Epoch 110/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1484 - tp: 22199.0000 - fp: 1401.0000 - tn: 22199.0000 - fn: 1401.0000 - accuracy: 0.9406 train_balacc 0.9405785438990301\n",
      " val_balacc 0.9478231407758767\n",
      "\n",
      "Epoch 110: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1485 - tp: 22208.0000 - fp: 1403.0000 - tn: 22208.0000 - fn: 1403.0000 - accuracy: 0.9406 - val_loss: 0.1520 - val_tp: 5595.0000 - val_fp: 308.0000 - val_tn: 5595.0000 - val_fn: 308.0000 - val_accuracy: 0.9478 - train_sensitivity: 0.9406 - train_specificity: 0.9406 - train_balacc: 0.9406 - val_sensitivity: 0.9478 - val_specificity: 0.9478 - val_balacc: 0.9478\n",
      "Epoch 111/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1479 - tp: 21805.0000 - fp: 1395.0000 - tn: 21805.0000 - fn: 1395.0000 - accuracy: 0.9399 train_balacc 0.9397738342298081\n",
      " val_balacc 0.7950194816195155\n",
      "\n",
      "Epoch 111: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1481 - tp: 22189.0000 - fp: 1422.0000 - tn: 22189.0000 - fn: 1422.0000 - accuracy: 0.9398 - val_loss: 1.4606 - val_tp: 4693.0000 - val_fp: 1210.0000 - val_tn: 4693.0000 - val_fn: 1210.0000 - val_accuracy: 0.7950 - train_sensitivity: 0.9398 - train_specificity: 0.9398 - train_balacc: 0.9398 - val_sensitivity: 0.7950 - val_specificity: 0.7950 - val_balacc: 0.7950\n",
      "Epoch 112/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1535 - tp: 21619.0000 - fp: 1381.0000 - tn: 21619.0000 - fn: 1381.0000 - accuracy: 0.9400 train_balacc 0.9404091313370887\n",
      " val_balacc 0.9325766559376588\n",
      "\n",
      "Epoch 112: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1531 - tp: 22204.0000 - fp: 1407.0000 - tn: 22204.0000 - fn: 1407.0000 - accuracy: 0.9404 - val_loss: 0.1741 - val_tp: 5505.0000 - val_fp: 398.0000 - val_tn: 5505.0000 - val_fn: 398.0000 - val_accuracy: 0.9326 - train_sensitivity: 0.9404 - train_specificity: 0.9404 - train_balacc: 0.9404 - val_sensitivity: 0.9326 - val_specificity: 0.9326 - val_balacc: 0.9326\n",
      "Epoch 113/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1492 - tp: 22212.0000 - fp: 1388.0000 - tn: 22212.0000 - fn: 1388.0000 - accuracy: 0.9412 train_balacc 0.9411714878658253\n",
      " val_balacc 0.9268168727765543\n",
      "\n",
      "Epoch 113: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1493 - tp: 22222.0000 - fp: 1389.0000 - tn: 22222.0000 - fn: 1389.0000 - accuracy: 0.9412 - val_loss: 0.1808 - val_tp: 5471.0000 - val_fp: 432.0000 - val_tn: 5471.0000 - val_fn: 432.0000 - val_accuracy: 0.9268 - train_sensitivity: 0.9412 - train_specificity: 0.9412 - train_balacc: 0.9412 - val_sensitivity: 0.9268 - val_specificity: 0.9268 - val_balacc: 0.9268\n",
      "Epoch 114/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1515 - tp: 21526.0000 - fp: 1374.0000 - tn: 21526.0000 - fn: 1374.0000 - accuracy: 0.9400 train_balacc 0.940112659353691\n",
      " val_balacc 0.9324072505505675\n",
      "\n",
      "Epoch 114: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1510 - tp: 22197.0000 - fp: 1414.0000 - tn: 22197.0000 - fn: 1414.0000 - accuracy: 0.9401 - val_loss: 0.1684 - val_tp: 5504.0000 - val_fp: 399.0000 - val_tn: 5504.0000 - val_fn: 399.0000 - val_accuracy: 0.9324 - train_sensitivity: 0.9401 - train_specificity: 0.9401 - train_balacc: 0.9401 - val_sensitivity: 0.9324 - val_specificity: 0.9324 - val_balacc: 0.9324\n",
      "Epoch 115/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1493 - tp: 22006.0000 - fp: 1394.0000 - tn: 22006.0000 - fn: 1394.0000 - accuracy: 0.9404 train_balacc 0.9402820719156325\n",
      " val_balacc 0.9212264950025411\n",
      "\n",
      "Epoch 115: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1499 - tp: 22201.0000 - fp: 1410.0000 - tn: 22201.0000 - fn: 1410.0000 - accuracy: 0.9403 - val_loss: 0.2159 - val_tp: 5438.0000 - val_fp: 465.0000 - val_tn: 5438.0000 - val_fn: 465.0000 - val_accuracy: 0.9212 - train_sensitivity: 0.9403 - train_specificity: 0.9403 - train_balacc: 0.9403 - val_sensitivity: 0.9212 - val_specificity: 0.9212 - val_balacc: 0.9212\n",
      "Epoch 116/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1551 - tp: 21524.0000 - fp: 1376.0000 - tn: 21524.0000 - fn: 1376.0000 - accuracy: 0.9399 train_balacc 0.939646774808352\n",
      " val_balacc 0.9276638997120108\n",
      "\n",
      "Epoch 116: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1556 - tp: 22186.0000 - fp: 1425.0000 - tn: 22186.0000 - fn: 1425.0000 - accuracy: 0.9396 - val_loss: 0.1694 - val_tp: 5476.0000 - val_fp: 427.0000 - val_tn: 5476.0000 - val_fn: 427.0000 - val_accuracy: 0.9277 - train_sensitivity: 0.9396 - train_specificity: 0.9396 - train_balacc: 0.9396 - val_sensitivity: 0.9277 - val_specificity: 0.9277 - val_balacc: 0.9277\n",
      "Epoch 117/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1477 - tp: 21807.0000 - fp: 1393.0000 - tn: 21807.0000 - fn: 1393.0000 - accuracy: 0.9400 train_balacc 0.9394350091059253\n",
      " val_balacc 0.8404201253599864\n",
      "\n",
      "Epoch 117: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1489 - tp: 22181.0000 - fp: 1430.0000 - tn: 22181.0000 - fn: 1430.0000 - accuracy: 0.9394 - val_loss: 0.3511 - val_tp: 4961.0000 - val_fp: 942.0000 - val_tn: 4961.0000 - val_fn: 942.0000 - val_accuracy: 0.8404 - train_sensitivity: 0.9394 - train_specificity: 0.9394 - train_balacc: 0.9394 - val_sensitivity: 0.8404 - val_specificity: 0.8404 - val_balacc: 0.8404\n",
      "Epoch 118/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1541 - tp: 21544.0000 - fp: 1356.0000 - tn: 21544.0000 - fn: 1356.0000 - accuracy: 0.9408 train_balacc 0.9401973656346618\n",
      " val_balacc 0.9318990343892936\n",
      "\n",
      "Epoch 118: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1554 - tp: 22199.0000 - fp: 1412.0000 - tn: 22199.0000 - fn: 1412.0000 - accuracy: 0.9402 - val_loss: 0.1751 - val_tp: 5501.0000 - val_fp: 402.0000 - val_tn: 5501.0000 - val_fn: 402.0000 - val_accuracy: 0.9319 - train_sensitivity: 0.9402 - train_specificity: 0.9402 - train_balacc: 0.9402 - val_sensitivity: 0.9319 - val_specificity: 0.9319 - val_balacc: 0.9319\n",
      "Epoch 119/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1466 - tp: 21742.0000 - fp: 1358.0000 - tn: 21742.0000 - fn: 1358.0000 - accuracy: 0.9412 train_balacc 0.9410020753038838\n",
      " val_balacc 0.891072336100288\n",
      "\n",
      "Epoch 119: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1467 - tp: 22218.0000 - fp: 1393.0000 - tn: 22218.0000 - fn: 1393.0000 - accuracy: 0.9410 - val_loss: 0.2446 - val_tp: 5260.0000 - val_fp: 643.0000 - val_tn: 5260.0000 - val_fn: 643.0000 - val_accuracy: 0.8911 - train_sensitivity: 0.9410 - train_specificity: 0.9410 - train_balacc: 0.9410 - val_sensitivity: 0.8911 - val_specificity: 0.8911 - val_balacc: 0.8911\n",
      "Epoch 120/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1501 - tp: 21504.0000 - fp: 1396.0000 - tn: 21504.0000 - fn: 1396.0000 - accuracy: 0.9390 train_balacc 0.9390538308415569\n",
      " val_balacc 0.9171607657123496\n",
      "\n",
      "Epoch 120: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1505 - tp: 22172.0000 - fp: 1439.0000 - tn: 22172.0000 - fn: 1439.0000 - accuracy: 0.9391 - val_loss: 0.1905 - val_tp: 5414.0000 - val_fp: 489.0000 - val_tn: 5414.0000 - val_fn: 489.0000 - val_accuracy: 0.9172 - train_sensitivity: 0.9391 - train_specificity: 0.9391 - train_balacc: 0.9391 - val_sensitivity: 0.9172 - val_specificity: 0.9172 - val_balacc: 0.9172\n",
      "Epoch 121/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1513 - tp: 21743.0000 - fp: 1357.0000 - tn: 21743.0000 - fn: 1357.0000 - accuracy: 0.9413 train_balacc 0.941383253568252\n",
      " val_balacc 0.8829408775199051\n",
      "\n",
      "Epoch 121: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1511 - tp: 22227.0000 - fp: 1384.0000 - tn: 22227.0000 - fn: 1384.0000 - accuracy: 0.9414 - val_loss: 0.2723 - val_tp: 5212.0000 - val_fp: 691.0000 - val_tn: 5212.0000 - val_fn: 691.0000 - val_accuracy: 0.8829 - train_sensitivity: 0.9414 - train_specificity: 0.9414 - train_balacc: 0.9414 - val_sensitivity: 0.8829 - val_specificity: 0.8829 - val_balacc: 0.8829\n",
      "Epoch 122/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1519 - tp: 22061.0000 - fp: 1439.0000 - tn: 22061.0000 - fn: 1439.0000 - accuracy: 0.9388 train_balacc 0.9386302994367033\n",
      " val_balacc 0.8887006606810096\n",
      "\n",
      "Epoch 122: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1525 - tp: 22162.0000 - fp: 1449.0000 - tn: 22162.0000 - fn: 1449.0000 - accuracy: 0.9386 - val_loss: 0.2421 - val_tp: 5246.0000 - val_fp: 657.0000 - val_tn: 5246.0000 - val_fn: 657.0000 - val_accuracy: 0.8887 - train_sensitivity: 0.9386 - train_specificity: 0.9386 - train_balacc: 0.9386 - val_sensitivity: 0.8887 - val_specificity: 0.8887 - val_balacc: 0.8887\n",
      "Epoch 123/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1477 - tp: 21491.0000 - fp: 1409.0000 - tn: 21491.0000 - fn: 1409.0000 - accuracy: 0.9385 train_balacc 0.9385455931557325\n",
      " val_balacc 0.834152126037608\n",
      "\n",
      "Epoch 123: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1482 - tp: 22160.0000 - fp: 1451.0000 - tn: 22160.0000 - fn: 1451.0000 - accuracy: 0.9385 - val_loss: 0.3825 - val_tp: 4924.0000 - val_fp: 979.0000 - val_tn: 4924.0000 - val_fn: 979.0000 - val_accuracy: 0.8342 - train_sensitivity: 0.9385 - train_specificity: 0.9385 - train_balacc: 0.9385 - val_sensitivity: 0.8342 - val_specificity: 0.8342 - val_balacc: 0.8342\n",
      "Epoch 124/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1475 - tp: 21843.0000 - fp: 1357.0000 - tn: 21843.0000 - fn: 1357.0000 - accuracy: 0.9415 train_balacc 0.9417644318326204\n",
      " val_balacc 0.9020836862612231\n",
      "\n",
      "Epoch 124: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1469 - tp: 22236.0000 - fp: 1375.0000 - tn: 22236.0000 - fn: 1375.0000 - accuracy: 0.9418 - val_loss: 0.2497 - val_tp: 5325.0000 - val_fp: 578.0000 - val_tn: 5325.0000 - val_fn: 578.0000 - val_accuracy: 0.9021 - train_sensitivity: 0.9418 - train_specificity: 0.9418 - train_balacc: 0.9418 - val_sensitivity: 0.9021 - val_specificity: 0.9021 - val_balacc: 0.9021\n",
      "Epoch 125/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1527 - tp: 22162.0000 - fp: 1438.0000 - tn: 22162.0000 - fn: 1438.0000 - accuracy: 0.9391 train_balacc 0.9390114777010715\n",
      " val_balacc 0.8526173132305608\n",
      "\n",
      "Epoch 125: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1528 - tp: 22171.0000 - fp: 1440.0000 - tn: 22171.0000 - fn: 1440.0000 - accuracy: 0.9390 - val_loss: 0.2881 - val_tp: 5033.0000 - val_fp: 870.0000 - val_tn: 5033.0000 - val_fn: 870.0000 - val_accuracy: 0.8526 - train_sensitivity: 0.9390 - train_specificity: 0.9390 - train_balacc: 0.9390 - val_sensitivity: 0.8526 - val_specificity: 0.8526 - val_balacc: 0.8526\n",
      "Epoch 126/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1433 - tp: 21900.0000 - fp: 1300.0000 - tn: 21900.0000 - fn: 1300.0000 - accuracy: 0.9440 train_balacc 0.9443056202617424\n",
      " val_balacc 0.9495171946467897\n",
      "\n",
      "Epoch 126: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1428 - tp: 22296.0000 - fp: 1315.0000 - tn: 22296.0000 - fn: 1315.0000 - accuracy: 0.9443 - val_loss: 0.1305 - val_tp: 5605.0000 - val_fp: 298.0000 - val_tn: 5605.0000 - val_fn: 298.0000 - val_accuracy: 0.9495 - train_sensitivity: 0.9443 - train_specificity: 0.9443 - train_balacc: 0.9443 - val_sensitivity: 0.9495 - val_specificity: 0.9495 - val_balacc: 0.9495\n",
      "Epoch 127/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1508 - tp: 21727.0000 - fp: 1373.0000 - tn: 21727.0000 - fn: 1373.0000 - accuracy: 0.9406 train_balacc 0.9402820719156325\n",
      " val_balacc 0.8763340674233441\n",
      "\n",
      "Epoch 127: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1512 - tp: 22201.0000 - fp: 1410.0000 - tn: 22201.0000 - fn: 1410.0000 - accuracy: 0.9403 - val_loss: 0.2397 - val_tp: 5173.0000 - val_fp: 730.0000 - val_tn: 5173.0000 - val_fn: 730.0000 - val_accuracy: 0.8763 - train_sensitivity: 0.9403 - train_specificity: 0.9403 - train_balacc: 0.9403 - val_sensitivity: 0.8763 - val_specificity: 0.8763 - val_balacc: 0.8763\n",
      "Epoch 128/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1493 - tp: 21499.0000 - fp: 1401.0000 - tn: 21499.0000 - fn: 1401.0000 - accuracy: 0.9388 train_balacc 0.9392655965439838\n",
      " val_balacc 0.9344401151956632\n",
      "\n",
      "Epoch 128: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1485 - tp: 22177.0000 - fp: 1434.0000 - tn: 22177.0000 - fn: 1434.0000 - accuracy: 0.9393 - val_loss: 0.1647 - val_tp: 5516.0000 - val_fp: 387.0000 - val_tn: 5516.0000 - val_fn: 387.0000 - val_accuracy: 0.9344 - train_sensitivity: 0.9393 - train_specificity: 0.9393 - train_balacc: 0.9393 - val_sensitivity: 0.9344 - val_specificity: 0.9344 - val_balacc: 0.9344\n",
      "Epoch 129/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1441 - tp: 22148.0000 - fp: 1352.0000 - tn: 22148.0000 - fn: 1352.0000 - accuracy: 0.9425 train_balacc 0.9423573757994155\n",
      " val_balacc 0.8317804506183296\n",
      "\n",
      "Epoch 129: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1450 - tp: 22250.0000 - fp: 1361.0000 - tn: 22250.0000 - fn: 1361.0000 - accuracy: 0.9424 - val_loss: 0.6733 - val_tp: 4910.0000 - val_fp: 993.0000 - val_tn: 4910.0000 - val_fn: 993.0000 - val_accuracy: 0.8318 - train_sensitivity: 0.9424 - train_specificity: 0.9424 - train_balacc: 0.9424 - val_sensitivity: 0.8318 - val_specificity: 0.8318 - val_balacc: 0.8318\n",
      "Epoch 130/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1479 - tp: 21550.0000 - fp: 1350.0000 - tn: 21550.0000 - fn: 1350.0000 - accuracy: 0.9410 train_balacc 0.9410444284443692\n",
      " val_balacc 0.9354565475182111\n",
      "\n",
      "Epoch 130: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1482 - tp: 22219.0000 - fp: 1392.0000 - tn: 22219.0000 - fn: 1392.0000 - accuracy: 0.9410 - val_loss: 0.1475 - val_tp: 5522.0000 - val_fp: 381.0000 - val_tn: 5522.0000 - val_fn: 381.0000 - val_accuracy: 0.9355 - train_sensitivity: 0.9410 - train_specificity: 0.9410 - train_balacc: 0.9410 - val_sensitivity: 0.9355 - val_specificity: 0.9355 - val_balacc: 0.9355\n",
      "Epoch 131/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1455 - tp: 21500.0000 - fp: 1300.0000 - tn: 21500.0000 - fn: 1300.0000 - accuracy: 0.9430 train_balacc 0.9427385540637838\n",
      " val_balacc 0.9207182788412671\n",
      "\n",
      "Epoch 131: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1452 - tp: 22259.0000 - fp: 1352.0000 - tn: 22259.0000 - fn: 1352.0000 - accuracy: 0.9427 - val_loss: 0.1820 - val_tp: 5435.0000 - val_fp: 468.0000 - val_tn: 5435.0000 - val_fn: 468.0000 - val_accuracy: 0.9207 - train_sensitivity: 0.9427 - train_specificity: 0.9427 - train_balacc: 0.9427 - val_sensitivity: 0.9207 - val_specificity: 0.9207 - val_balacc: 0.9207\n",
      "Epoch 132/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1445 - tp: 21542.0000 - fp: 1358.0000 - tn: 21542.0000 - fn: 1358.0000 - accuracy: 0.9407 train_balacc 0.9407903096014569\n",
      " val_balacc 0.919532441131628\n",
      "\n",
      "Epoch 132: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1441 - tp: 22213.0000 - fp: 1398.0000 - tn: 22213.0000 - fn: 1398.0000 - accuracy: 0.9408 - val_loss: 0.1833 - val_tp: 5428.0000 - val_fp: 475.0000 - val_tn: 5428.0000 - val_fn: 475.0000 - val_accuracy: 0.9195 - train_sensitivity: 0.9408 - train_specificity: 0.9408 - train_balacc: 0.9408 - val_sensitivity: 0.9195 - val_specificity: 0.9195 - val_balacc: 0.9195\n",
      "Epoch 133/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1470 - tp: 22017.0000 - fp: 1383.0000 - tn: 22017.0000 - fn: 1383.0000 - accuracy: 0.9409 train_balacc 0.9409597221633984\n",
      " val_balacc 0.9434186007115026\n",
      "\n",
      "Epoch 133: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1468 - tp: 22217.0000 - fp: 1394.0000 - tn: 22217.0000 - fn: 1394.0000 - accuracy: 0.9410 - val_loss: 0.1717 - val_tp: 5569.0000 - val_fp: 334.0000 - val_tn: 5569.0000 - val_fn: 334.0000 - val_accuracy: 0.9434 - train_sensitivity: 0.9410 - train_specificity: 0.9410 - train_balacc: 0.9410 - val_sensitivity: 0.9434 - val_specificity: 0.9434 - val_balacc: 0.9434\n",
      "Epoch 134/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1471 - tp: 22075.0000 - fp: 1325.0000 - tn: 22075.0000 - fn: 1325.0000 - accuracy: 0.9434 train_balacc 0.9432891448900936\n",
      " val_balacc 0.9324072505505675\n",
      "\n",
      "Epoch 134: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1472 - tp: 22272.0000 - fp: 1339.0000 - tn: 22272.0000 - fn: 1339.0000 - accuracy: 0.9433 - val_loss: 0.1582 - val_tp: 5504.0000 - val_fp: 399.0000 - val_tn: 5504.0000 - val_fn: 399.0000 - val_accuracy: 0.9324 - train_sensitivity: 0.9433 - train_specificity: 0.9433 - train_balacc: 0.9433 - val_sensitivity: 0.9324 - val_specificity: 0.9324 - val_balacc: 0.9324\n",
      "Epoch 135/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1423 - tp: 22323.0000 - fp: 1288.0000 - tn: 22323.0000 - fn: 1288.0000 - accuracy: 0.9454 train_balacc 0.9454491550548473\n",
      " val_balacc 0.8212773166186684\n",
      "\n",
      "Epoch 135: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1423 - tp: 22323.0000 - fp: 1288.0000 - tn: 22323.0000 - fn: 1288.0000 - accuracy: 0.9454 - val_loss: 0.3382 - val_tp: 4848.0000 - val_fp: 1055.0000 - val_tn: 4848.0000 - val_fn: 1055.0000 - val_accuracy: 0.8213 - train_sensitivity: 0.9454 - train_specificity: 0.9454 - train_balacc: 0.9454 - val_sensitivity: 0.8213 - val_specificity: 0.8213 - val_balacc: 0.8213\n",
      "Epoch 136/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1438 - tp: 22232.0000 - fp: 1379.0000 - tn: 22232.0000 - fn: 1379.0000 - accuracy: 0.9416 train_balacc 0.9415950192706789\n",
      " val_balacc 0.8970015246484838\n",
      "\n",
      "Epoch 136: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1438 - tp: 22232.0000 - fp: 1379.0000 - tn: 22232.0000 - fn: 1379.0000 - accuracy: 0.9416 - val_loss: 0.2188 - val_tp: 5295.0000 - val_fp: 608.0000 - val_tn: 5295.0000 - val_fn: 608.0000 - val_accuracy: 0.8970 - train_sensitivity: 0.9416 - train_specificity: 0.9416 - train_balacc: 0.9416 - val_sensitivity: 0.8970 - val_specificity: 0.8970 - val_balacc: 0.8970\n",
      "Epoch 137/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1440 - tp: 22119.0000 - fp: 1381.0000 - tn: 22119.0000 - fn: 1381.0000 - accuracy: 0.9412 train_balacc 0.9412985472872814\n",
      " val_balacc 0.9369811960020329\n",
      "\n",
      "Epoch 137: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1440 - tp: 22225.0000 - fp: 1386.0000 - tn: 22225.0000 - fn: 1386.0000 - accuracy: 0.9413 - val_loss: 0.1556 - val_tp: 5531.0000 - val_fp: 372.0000 - val_tn: 5531.0000 - val_fn: 372.0000 - val_accuracy: 0.9370 - train_sensitivity: 0.9413 - train_specificity: 0.9413 - train_balacc: 0.9413 - val_sensitivity: 0.9370 - val_specificity: 0.9370 - val_balacc: 0.9370\n",
      "Epoch 138/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1462 - tp: 21569.0000 - fp: 1331.0000 - tn: 21569.0000 - fn: 1331.0000 - accuracy: 0.9419 train_balacc 0.9421032569565033\n",
      " val_balacc 0.9273250889378282\n",
      "\n",
      "Epoch 138: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1454 - tp: 22244.0000 - fp: 1367.0000 - tn: 22244.0000 - fn: 1367.0000 - accuracy: 0.9421 - val_loss: 0.1649 - val_tp: 5474.0000 - val_fp: 429.0000 - val_tn: 5474.0000 - val_fn: 429.0000 - val_accuracy: 0.9273 - train_sensitivity: 0.9421 - train_specificity: 0.9421 - train_balacc: 0.9421 - val_sensitivity: 0.9273 - val_specificity: 0.9273 - val_balacc: 0.9273\n",
      "Epoch 139/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1495 - tp: 21726.0000 - fp: 1374.0000 - tn: 21726.0000 - fn: 1374.0000 - accuracy: 0.9405 train_balacc 0.9404938376180594\n",
      " val_balacc 0.9366423852278503\n",
      "\n",
      "Epoch 139: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1493 - tp: 22206.0000 - fp: 1405.0000 - tn: 22206.0000 - fn: 1405.0000 - accuracy: 0.9405 - val_loss: 0.1565 - val_tp: 5529.0000 - val_fp: 374.0000 - val_tn: 5529.0000 - val_fn: 374.0000 - val_accuracy: 0.9366 - train_sensitivity: 0.9405 - train_specificity: 0.9405 - train_balacc: 0.9405 - val_sensitivity: 0.9366 - val_specificity: 0.9366 - val_balacc: 0.9366\n",
      "Epoch 140/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1421 - tp: 21480.0000 - fp: 1320.0000 - tn: 21480.0000 - fn: 1320.0000 - accuracy: 0.9421 train_balacc 0.9423573757994155\n",
      " val_balacc 0.874131797391157\n",
      "\n",
      "Epoch 140: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1420 - tp: 22250.0000 - fp: 1361.0000 - tn: 22250.0000 - fn: 1361.0000 - accuracy: 0.9424 - val_loss: 0.3923 - val_tp: 5160.0000 - val_fp: 743.0000 - val_tn: 5160.0000 - val_fn: 743.0000 - val_accuracy: 0.8741 - train_sensitivity: 0.9424 - train_specificity: 0.9424 - train_balacc: 0.9424 - val_sensitivity: 0.8741 - val_specificity: 0.8741 - val_balacc: 0.8741\n",
      "Epoch 141/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1407 - tp: 22065.0000 - fp: 1335.0000 - tn: 22065.0000 - fn: 1335.0000 - accuracy: 0.9429 train_balacc 0.9429079666257253\n",
      " val_balacc 0.9308826020667457\n",
      "\n",
      "Epoch 141: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1406 - tp: 22263.0000 - fp: 1348.0000 - tn: 22263.0000 - fn: 1348.0000 - accuracy: 0.9429 - val_loss: 0.1645 - val_tp: 5495.0000 - val_fp: 408.0000 - val_tn: 5495.0000 - val_fn: 408.0000 - val_accuracy: 0.9309 - train_sensitivity: 0.9429 - train_specificity: 0.9429 - train_balacc: 0.9429 - val_sensitivity: 0.9309 - val_specificity: 0.9309 - val_balacc: 0.9309\n",
      "Epoch 142/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1484 - tp: 21731.0000 - fp: 1369.0000 - tn: 21731.0000 - fn: 1369.0000 - accuracy: 0.9407 train_balacc 0.940917369022913\n",
      " val_balacc 0.7814670506522108\n",
      "\n",
      "Epoch 142: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1482 - tp: 22216.0000 - fp: 1395.0000 - tn: 22216.0000 - fn: 1395.0000 - accuracy: 0.9409 - val_loss: 0.7598 - val_tp: 4613.0000 - val_fp: 1290.0000 - val_tn: 4613.0000 - val_fn: 1290.0000 - val_accuracy: 0.7815 - train_sensitivity: 0.9409 - train_specificity: 0.9409 - train_balacc: 0.9409 - val_sensitivity: 0.7815 - val_specificity: 0.7815 - val_balacc: 0.7815\n",
      "Epoch 143/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1486 - tp: 21640.0000 - fp: 1360.0000 - tn: 21640.0000 - fn: 1360.0000 - accuracy: 0.9409 train_balacc 0.9410867815848545\n",
      " val_balacc 0.933762493647298\n",
      "\n",
      "Epoch 143: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1481 - tp: 22220.0000 - fp: 1391.0000 - tn: 22220.0000 - fn: 1391.0000 - accuracy: 0.9411 - val_loss: 0.1566 - val_tp: 5512.0000 - val_fp: 391.0000 - val_tn: 5512.0000 - val_fn: 391.0000 - val_accuracy: 0.9338 - train_sensitivity: 0.9411 - train_specificity: 0.9411 - train_balacc: 0.9411 - val_sensitivity: 0.9338 - val_specificity: 0.9338 - val_balacc: 0.9338\n",
      "Epoch 144/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1445 - tp: 21557.0000 - fp: 1343.0000 - tn: 21557.0000 - fn: 1343.0000 - accuracy: 0.9414 train_balacc 0.9413409004277667\n",
      " val_balacc 0.8729459596815179\n",
      "\n",
      "Epoch 144: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1456 - tp: 22226.0000 - fp: 1385.0000 - tn: 22226.0000 - fn: 1385.0000 - accuracy: 0.9413 - val_loss: 0.2864 - val_tp: 5153.0000 - val_fp: 750.0000 - val_tn: 5153.0000 - val_fn: 750.0000 - val_accuracy: 0.8729 - train_sensitivity: 0.9413 - train_specificity: 0.9413 - train_balacc: 0.9413 - val_sensitivity: 0.8729 - val_specificity: 0.8729 - val_balacc: 0.8729\n",
      "Epoch 145/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1418 - tp: 21479.0000 - fp: 1321.0000 - tn: 21479.0000 - fn: 1321.0000 - accuracy: 0.9421 train_balacc 0.9415103129897082\n",
      " val_balacc 0.9107233610028799\n",
      "\n",
      "Epoch 145: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1423 - tp: 22230.0000 - fp: 1381.0000 - tn: 22230.0000 - fn: 1381.0000 - accuracy: 0.9415 - val_loss: 0.2265 - val_tp: 5376.0000 - val_fp: 527.0000 - val_tn: 5376.0000 - val_fn: 527.0000 - val_accuracy: 0.9107 - train_sensitivity: 0.9415 - train_specificity: 0.9415 - train_balacc: 0.9415 - val_sensitivity: 0.9107 - val_specificity: 0.9107 - val_balacc: 0.9107\n",
      "Epoch 146/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1434 - tp: 21614.0000 - fp: 1286.0000 - tn: 21614.0000 - fn: 1286.0000 - accuracy: 0.9438 train_balacc 0.9439667951378595\n",
      " val_balacc 0.8973403354226664\n",
      "\n",
      "Epoch 146: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1431 - tp: 22288.0000 - fp: 1323.0000 - tn: 22288.0000 - fn: 1323.0000 - accuracy: 0.9440 - val_loss: 0.2190 - val_tp: 5297.0000 - val_fp: 606.0000 - val_tn: 5297.0000 - val_fn: 606.0000 - val_accuracy: 0.8973 - train_sensitivity: 0.9440 - train_specificity: 0.9440 - train_balacc: 0.9440 - val_sensitivity: 0.8973 - val_specificity: 0.8973 - val_balacc: 0.8973\n",
      "Epoch 147/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1395 - tp: 21934.0000 - fp: 1366.0000 - tn: 21934.0000 - fn: 1366.0000 - accuracy: 0.9414 train_balacc 0.9413409004277667\n",
      " val_balacc 0.9259698458410978\n",
      "\n",
      "Epoch 147: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1396 - tp: 22226.0000 - fp: 1385.0000 - tn: 22226.0000 - fn: 1385.0000 - accuracy: 0.9413 - val_loss: 0.1721 - val_tp: 5466.0000 - val_fp: 437.0000 - val_tn: 5466.0000 - val_fn: 437.0000 - val_accuracy: 0.9260 - train_sensitivity: 0.9413 - train_specificity: 0.9413 - train_balacc: 0.9413 - val_sensitivity: 0.9260 - val_specificity: 0.9260 - val_balacc: 0.9260\n",
      "Epoch 148/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1456 - tp: 21783.0000 - fp: 1317.0000 - tn: 21783.0000 - fn: 1317.0000 - accuracy: 0.9430 train_balacc 0.9432467917496082\n",
      " val_balacc 0.9041165509063188\n",
      "\n",
      "Epoch 148: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1450 - tp: 22271.0000 - fp: 1340.0000 - tn: 22271.0000 - fn: 1340.0000 - accuracy: 0.9432 - val_loss: 0.2271 - val_tp: 5337.0000 - val_fp: 566.0000 - val_tn: 5337.0000 - val_fn: 566.0000 - val_accuracy: 0.9041 - train_sensitivity: 0.9432 - train_specificity: 0.9432 - train_balacc: 0.9432 - val_sensitivity: 0.9041 - val_specificity: 0.9041 - val_balacc: 0.9041\n",
      "Epoch 149/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1412 - tp: 21968.0000 - fp: 1332.0000 - tn: 21968.0000 - fn: 1332.0000 - accuracy: 0.9428 train_balacc 0.9426538477828131\n",
      " val_balacc 0.9317296290022022\n",
      "\n",
      "Epoch 149: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1411 - tp: 22257.0000 - fp: 1354.0000 - tn: 22257.0000 - fn: 1354.0000 - accuracy: 0.9427 - val_loss: 0.1734 - val_tp: 5500.0000 - val_fp: 403.0000 - val_tn: 5500.0000 - val_fn: 403.0000 - val_accuracy: 0.9317 - train_sensitivity: 0.9427 - train_specificity: 0.9427 - train_balacc: 0.9427 - val_sensitivity: 0.9317 - val_specificity: 0.9317 - val_balacc: 0.9317\n",
      "Epoch 150/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1429 - tp: 21783.0000 - fp: 1317.0000 - tn: 21783.0000 - fn: 1317.0000 - accuracy: 0.9430 train_balacc 0.9430773791876668\n",
      " val_balacc 0.9224123327121803\n",
      "\n",
      "Epoch 150: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1423 - tp: 22267.0000 - fp: 1344.0000 - tn: 22267.0000 - fn: 1344.0000 - accuracy: 0.9431 - val_loss: 0.2029 - val_tp: 5445.0000 - val_fp: 458.0000 - val_tn: 5445.0000 - val_fn: 458.0000 - val_accuracy: 0.9224 - train_sensitivity: 0.9431 - train_specificity: 0.9431 - train_balacc: 0.9431 - val_sensitivity: 0.9224 - val_specificity: 0.9224 - val_balacc: 0.9224\n",
      "Epoch 151/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1438 - tp: 22141.0000 - fp: 1359.0000 - tn: 22141.0000 - fn: 1359.0000 - accuracy: 0.9422 train_balacc 0.9421879632374741\n",
      " val_balacc 0.9139420633576147\n",
      "\n",
      "Epoch 151: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1441 - tp: 22246.0000 - fp: 1365.0000 - tn: 22246.0000 - fn: 1365.0000 - accuracy: 0.9422 - val_loss: 0.2293 - val_tp: 5395.0000 - val_fp: 508.0000 - val_tn: 5395.0000 - val_fn: 508.0000 - val_accuracy: 0.9139 - train_sensitivity: 0.9422 - train_specificity: 0.9422 - train_balacc: 0.9422 - val_sensitivity: 0.9139 - val_specificity: 0.9139 - val_balacc: 0.9139\n",
      "Epoch 152/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1454 - tp: 22035.0000 - fp: 1365.0000 - tn: 22035.0000 - fn: 1365.0000 - accuracy: 0.9417 train_balacc 0.9418491381135912\n",
      " val_balacc 0.8809080128748095\n",
      "\n",
      "Epoch 152: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1450 - tp: 22238.0000 - fp: 1373.0000 - tn: 22238.0000 - fn: 1373.0000 - accuracy: 0.9418 - val_loss: 0.3344 - val_tp: 5200.0000 - val_fp: 703.0000 - val_tn: 5200.0000 - val_fn: 703.0000 - val_accuracy: 0.8809 - train_sensitivity: 0.9418 - train_specificity: 0.9418 - train_balacc: 0.9418 - val_sensitivity: 0.8809 - val_specificity: 0.8809 - val_balacc: 0.8809\n",
      "Epoch 153/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1382 - tp: 22301.0000 - fp: 1299.0000 - tn: 22301.0000 - fn: 1299.0000 - accuracy: 0.9450 train_balacc 0.9449832705095083\n",
      " val_balacc 0.9385058444858546\n",
      "\n",
      "Epoch 153: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1381 - tp: 22312.0000 - fp: 1299.0000 - tn: 22312.0000 - fn: 1299.0000 - accuracy: 0.9450 - val_loss: 0.1492 - val_tp: 5540.0000 - val_fp: 363.0000 - val_tn: 5540.0000 - val_fn: 363.0000 - val_accuracy: 0.9385 - train_sensitivity: 0.9450 - train_specificity: 0.9450 - train_balacc: 0.9450 - val_sensitivity: 0.9385 - val_specificity: 0.9385 - val_balacc: 0.9385\n",
      "Epoch 154/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1390 - tp: 22000.0000 - fp: 1300.0000 - tn: 22000.0000 - fn: 1300.0000 - accuracy: 0.9442 train_balacc 0.9442632671212571\n",
      " val_balacc 0.9047941724546841\n",
      "\n",
      "Epoch 154: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1385 - tp: 22295.0000 - fp: 1316.0000 - tn: 22295.0000 - fn: 1316.0000 - accuracy: 0.9443 - val_loss: 0.2263 - val_tp: 5341.0000 - val_fp: 562.0000 - val_tn: 5341.0000 - val_fn: 562.0000 - val_accuracy: 0.9048 - train_sensitivity: 0.9443 - train_specificity: 0.9443 - train_balacc: 0.9443 - val_sensitivity: 0.9048 - val_specificity: 0.9048 - val_balacc: 0.9048\n",
      "Epoch 155/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1394 - tp: 22174.0000 - fp: 1326.0000 - tn: 22174.0000 - fn: 1326.0000 - accuracy: 0.9436 train_balacc 0.9435009105925204\n",
      " val_balacc 0.9268168727765543\n",
      "\n",
      "Epoch 155: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1397 - tp: 22277.0000 - fp: 1334.0000 - tn: 22277.0000 - fn: 1334.0000 - accuracy: 0.9435 - val_loss: 0.2021 - val_tp: 5471.0000 - val_fp: 432.0000 - val_tn: 5471.0000 - val_fn: 432.0000 - val_accuracy: 0.9268 - train_sensitivity: 0.9435 - train_specificity: 0.9435 - train_balacc: 0.9435 - val_sensitivity: 0.9268 - val_specificity: 0.9268 - val_balacc: 0.9268\n",
      "Epoch 156/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1472 - tp: 22216.0000 - fp: 1395.0000 - tn: 22216.0000 - fn: 1395.0000 - accuracy: 0.9409 train_balacc 0.940917369022913\n",
      " val_balacc 0.9361341690665763\n",
      "\n",
      "Epoch 156: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1472 - tp: 22216.0000 - fp: 1395.0000 - tn: 22216.0000 - fn: 1395.0000 - accuracy: 0.9409 - val_loss: 0.1549 - val_tp: 5526.0000 - val_fp: 377.0000 - val_tn: 5526.0000 - val_fn: 377.0000 - val_accuracy: 0.9361 - train_sensitivity: 0.9409 - train_specificity: 0.9409 - train_balacc: 0.9409 - val_sensitivity: 0.9361 - val_specificity: 0.9361 - val_balacc: 0.9361\n",
      "Epoch 157/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1418 - tp: 21785.0000 - fp: 1315.0000 - tn: 21785.0000 - fn: 1315.0000 - accuracy: 0.9431 train_balacc 0.9431620854686374\n",
      " val_balacc 0.9278333050991021\n",
      "\n",
      "Epoch 157: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1421 - tp: 22269.0000 - fp: 1342.0000 - tn: 22269.0000 - fn: 1342.0000 - accuracy: 0.9432 - val_loss: 0.1788 - val_tp: 5477.0000 - val_fp: 426.0000 - val_tn: 5477.0000 - val_fn: 426.0000 - val_accuracy: 0.9278 - train_sensitivity: 0.9432 - train_specificity: 0.9432 - train_balacc: 0.9432 - val_sensitivity: 0.9278 - val_specificity: 0.9278 - val_balacc: 0.9278\n",
      "Epoch 158/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1395 - tp: 21638.0000 - fp: 1262.0000 - tn: 21638.0000 - fn: 1262.0000 - accuracy: 0.9449 train_balacc 0.9447291516665961\n",
      " val_balacc 0.9379976283245807\n",
      "\n",
      "Epoch 158: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1397 - tp: 22306.0000 - fp: 1305.0000 - tn: 22306.0000 - fn: 1305.0000 - accuracy: 0.9447 - val_loss: 0.1686 - val_tp: 5537.0000 - val_fp: 366.0000 - val_tn: 5537.0000 - val_fn: 366.0000 - val_accuracy: 0.9380 - train_sensitivity: 0.9447 - train_specificity: 0.9447 - train_balacc: 0.9447 - val_sensitivity: 0.9380 - val_specificity: 0.9380 - val_balacc: 0.9380\n",
      "Epoch 159/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1350 - tp: 22043.0000 - fp: 1257.0000 - tn: 22043.0000 - fn: 1257.0000 - accuracy: 0.9461 train_balacc 0.9459150396001863\n",
      " val_balacc 0.8829408775199051\n",
      "\n",
      "Epoch 159: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1348 - tp: 22334.0000 - fp: 1277.0000 - tn: 22334.0000 - fn: 1277.0000 - accuracy: 0.9459 - val_loss: 0.3175 - val_tp: 5212.0000 - val_fp: 691.0000 - val_tn: 5212.0000 - val_fn: 691.0000 - val_accuracy: 0.8829 - train_sensitivity: 0.9459 - train_specificity: 0.9459 - train_balacc: 0.9459 - val_sensitivity: 0.8829 - val_specificity: 0.8829 - val_balacc: 0.8829\n",
      "Epoch 160/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1473 - tp: 21964.0000 - fp: 1336.0000 - tn: 21964.0000 - fn: 1336.0000 - accuracy: 0.9427 train_balacc 0.9426962009232984\n",
      " val_balacc 0.9302049805183805\n",
      "\n",
      "Epoch 160: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1469 - tp: 22258.0000 - fp: 1353.0000 - tn: 22258.0000 - fn: 1353.0000 - accuracy: 0.9427 - val_loss: 0.1669 - val_tp: 5491.0000 - val_fp: 412.0000 - val_tn: 5491.0000 - val_fn: 412.0000 - val_accuracy: 0.9302 - train_sensitivity: 0.9427 - train_specificity: 0.9427 - train_balacc: 0.9427 - val_sensitivity: 0.9302 - val_specificity: 0.9302 - val_balacc: 0.9302\n",
      "Epoch 161/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1422 - tp: 22280.0000 - fp: 1320.0000 - tn: 22280.0000 - fn: 1320.0000 - accuracy: 0.9441 train_balacc 0.9440938545593156\n",
      " val_balacc 0.9329154667118414\n",
      "\n",
      "Epoch 161: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1422 - tp: 22291.0000 - fp: 1320.0000 - tn: 22291.0000 - fn: 1320.0000 - accuracy: 0.9441 - val_loss: 0.1710 - val_tp: 5507.0000 - val_fp: 396.0000 - val_tn: 5507.0000 - val_fn: 396.0000 - val_accuracy: 0.9329 - train_sensitivity: 0.9441 - train_specificity: 0.9441 - train_balacc: 0.9441 - val_sensitivity: 0.9329 - val_specificity: 0.9329 - val_balacc: 0.9329\n",
      "Epoch 162/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1419 - tp: 21885.0000 - fp: 1315.0000 - tn: 21885.0000 - fn: 1315.0000 - accuracy: 0.9433 train_balacc 0.9435432637330058\n",
      " val_balacc 0.812807047264103\n",
      "\n",
      "Epoch 162: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1418 - tp: 22278.0000 - fp: 1333.0000 - tn: 22278.0000 - fn: 1333.0000 - accuracy: 0.9435 - val_loss: 0.5628 - val_tp: 4798.0000 - val_fp: 1105.0000 - val_tn: 4798.0000 - val_fn: 1105.0000 - val_accuracy: 0.8128 - train_sensitivity: 0.9435 - train_specificity: 0.9435 - train_balacc: 0.9435 - val_sensitivity: 0.8128 - val_specificity: 0.8128 - val_balacc: 0.8128\n",
      "Epoch 163/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1428 - tp: 22273.0000 - fp: 1338.0000 - tn: 22273.0000 - fn: 1338.0000 - accuracy: 0.9433 train_balacc 0.9433314980305789\n",
      " val_balacc 0.9373200067762155\n",
      "\n",
      "Epoch 163: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1428 - tp: 22273.0000 - fp: 1338.0000 - tn: 22273.0000 - fn: 1338.0000 - accuracy: 0.9433 - val_loss: 0.1578 - val_tp: 5533.0000 - val_fp: 370.0000 - val_tn: 5533.0000 - val_fn: 370.0000 - val_accuracy: 0.9373 - train_sensitivity: 0.9433 - train_specificity: 0.9433 - train_balacc: 0.9433 - val_sensitivity: 0.9373 - val_specificity: 0.9373 - val_balacc: 0.9373\n",
      "Epoch 164/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1400 - tp: 21661.0000 - fp: 1239.0000 - tn: 21661.0000 - fn: 1239.0000 - accuracy: 0.9459 train_balacc 0.9458303333192156\n",
      " val_balacc 0.9412163306793156\n",
      "\n",
      "Epoch 164: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1397 - tp: 22332.0000 - fp: 1279.0000 - tn: 22332.0000 - fn: 1279.0000 - accuracy: 0.9458 - val_loss: 0.1477 - val_tp: 5556.0000 - val_fp: 347.0000 - val_tn: 5556.0000 - val_fn: 347.0000 - val_accuracy: 0.9412 - train_sensitivity: 0.9458 - train_specificity: 0.9458 - train_balacc: 0.9458 - val_sensitivity: 0.9412 - val_specificity: 0.9412 - val_balacc: 0.9412\n",
      "Epoch 165/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1434 - tp: 21803.0000 - fp: 1297.0000 - tn: 21803.0000 - fn: 1297.0000 - accuracy: 0.9439 train_balacc 0.9439667951378595\n",
      " val_balacc 0.9410469252922243\n",
      "\n",
      "Epoch 165: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1431 - tp: 22288.0000 - fp: 1323.0000 - tn: 22288.0000 - fn: 1323.0000 - accuracy: 0.9440 - val_loss: 0.1709 - val_tp: 5555.0000 - val_fp: 348.0000 - val_tn: 5555.0000 - val_fn: 348.0000 - val_accuracy: 0.9410 - train_sensitivity: 0.9440 - train_specificity: 0.9440 - train_balacc: 0.9440 - val_sensitivity: 0.9410 - val_specificity: 0.9410 - val_balacc: 0.9410\n",
      "Epoch 166/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1401 - tp: 21917.0000 - fp: 1283.0000 - tn: 21917.0000 - fn: 1283.0000 - accuracy: 0.9447 train_balacc 0.9446867985261107\n",
      " val_balacc 0.9202100626799933\n",
      "\n",
      "Epoch 166: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1398 - tp: 22305.0000 - fp: 1306.0000 - tn: 22305.0000 - fn: 1306.0000 - accuracy: 0.9447 - val_loss: 0.1824 - val_tp: 5432.0000 - val_fp: 471.0000 - val_tn: 5432.0000 - val_fn: 471.0000 - val_accuracy: 0.9202 - train_sensitivity: 0.9447 - train_specificity: 0.9447 - train_balacc: 0.9447 - val_sensitivity: 0.9202 - val_specificity: 0.9202 - val_balacc: 0.9202\n",
      "Epoch 167/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1406 - tp: 21665.0000 - fp: 1335.0000 - tn: 21665.0000 - fn: 1335.0000 - accuracy: 0.9420 train_balacc 0.9420185506755326\n",
      " val_balacc 0.9007284431644926\n",
      "\n",
      "Epoch 167: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1404 - tp: 22242.0000 - fp: 1369.0000 - tn: 22242.0000 - fn: 1369.0000 - accuracy: 0.9420 - val_loss: 0.2483 - val_tp: 5317.0000 - val_fp: 586.0000 - val_tn: 5317.0000 - val_fn: 586.0000 - val_accuracy: 0.9007 - train_sensitivity: 0.9420 - train_specificity: 0.9420 - train_balacc: 0.9420 - val_sensitivity: 0.9007 - val_specificity: 0.9007 - val_balacc: 0.9007\n",
      "Epoch 168/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1375 - tp: 21940.0000 - fp: 1260.0000 - tn: 21940.0000 - fn: 1260.0000 - accuracy: 0.9457 train_balacc 0.9457456270382449\n",
      " val_balacc 0.9357953582923937\n",
      "\n",
      "Epoch 168: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1370 - tp: 22330.0000 - fp: 1281.0000 - tn: 22330.0000 - fn: 1281.0000 - accuracy: 0.9457 - val_loss: 0.1684 - val_tp: 5524.0000 - val_fp: 379.0000 - val_tn: 5524.0000 - val_fn: 379.0000 - val_accuracy: 0.9358 - train_sensitivity: 0.9457 - train_specificity: 0.9457 - train_balacc: 0.9457 - val_sensitivity: 0.9358 - val_specificity: 0.9358 - val_balacc: 0.9358\n",
      "Epoch 169/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1410 - tp: 21879.0000 - fp: 1321.0000 - tn: 21879.0000 - fn: 1321.0000 - accuracy: 0.9431 train_balacc 0.9433314980305789\n",
      " val_balacc 0.931052007453837\n",
      "\n",
      "Epoch 169: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1404 - tp: 22273.0000 - fp: 1338.0000 - tn: 22273.0000 - fn: 1338.0000 - accuracy: 0.9433 - val_loss: 0.1665 - val_tp: 5496.0000 - val_fp: 407.0000 - val_tn: 5496.0000 - val_fn: 407.0000 - val_accuracy: 0.9311 - train_sensitivity: 0.9433 - train_specificity: 0.9433 - train_balacc: 0.9433 - val_sensitivity: 0.9311 - val_specificity: 0.9311 - val_balacc: 0.9311\n",
      "Epoch 170/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1364 - tp: 21562.0000 - fp: 1238.0000 - tn: 21562.0000 - fn: 1238.0000 - accuracy: 0.9457 train_balacc 0.9461268053026132\n",
      " val_balacc 0.8805692021006268\n",
      "\n",
      "Epoch 170: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1357 - tp: 22339.0000 - fp: 1272.0000 - tn: 22339.0000 - fn: 1272.0000 - accuracy: 0.9461 - val_loss: 0.4093 - val_tp: 5198.0000 - val_fp: 705.0000 - val_tn: 5198.0000 - val_fn: 705.0000 - val_accuracy: 0.8806 - train_sensitivity: 0.9461 - train_specificity: 0.9461 - train_balacc: 0.9461 - val_sensitivity: 0.8806 - val_specificity: 0.8806 - val_balacc: 0.8806\n",
      "Epoch 171/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1394 - tp: 21535.0000 - fp: 1265.0000 - tn: 21535.0000 - fn: 1265.0000 - accuracy: 0.9445 train_balacc 0.9443479734022278\n",
      " val_balacc 0.9296967643571066\n",
      "\n",
      "Epoch 171: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1398 - tp: 22297.0000 - fp: 1314.0000 - tn: 22297.0000 - fn: 1314.0000 - accuracy: 0.9443 - val_loss: 0.1673 - val_tp: 5488.0000 - val_fp: 415.0000 - val_tn: 5488.0000 - val_fn: 415.0000 - val_accuracy: 0.9297 - train_sensitivity: 0.9443 - train_specificity: 0.9443 - train_balacc: 0.9443 - val_sensitivity: 0.9297 - val_specificity: 0.9297 - val_balacc: 0.9297\n",
      "Epoch 172/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1355 - tp: 21850.0000 - fp: 1250.0000 - tn: 21850.0000 - fn: 1250.0000 - accuracy: 0.9459 train_balacc 0.9457879801787302\n",
      " val_balacc 0.9332542774860241\n",
      "\n",
      "Epoch 172: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1357 - tp: 22331.0000 - fp: 1280.0000 - tn: 22331.0000 - fn: 1280.0000 - accuracy: 0.9458 - val_loss: 0.1902 - val_tp: 5509.0000 - val_fp: 394.0000 - val_tn: 5509.0000 - val_fn: 394.0000 - val_accuracy: 0.9333 - train_sensitivity: 0.9458 - train_specificity: 0.9458 - train_balacc: 0.9458 - val_sensitivity: 0.9333 - val_specificity: 0.9333 - val_balacc: 0.9333\n",
      "Epoch 173/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1391 - tp: 21631.0000 - fp: 1269.0000 - tn: 21631.0000 - fn: 1269.0000 - accuracy: 0.9446 train_balacc 0.9447291516665961\n",
      " val_balacc 0.9149584956801626\n",
      "\n",
      "Epoch 173: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1389 - tp: 22306.0000 - fp: 1305.0000 - tn: 22306.0000 - fn: 1305.0000 - accuracy: 0.9447 - val_loss: 0.2146 - val_tp: 5401.0000 - val_fp: 502.0000 - val_tn: 5401.0000 - val_fn: 502.0000 - val_accuracy: 0.9150 - train_sensitivity: 0.9447 - train_specificity: 0.9447 - train_balacc: 0.9447 - val_sensitivity: 0.9150 - val_specificity: 0.9150 - val_balacc: 0.9150\n",
      "Epoch 174/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1359 - tp: 21587.0000 - fp: 1213.0000 - tn: 21587.0000 - fn: 1213.0000 - accuracy: 0.9468 train_balacc 0.9464232772860107\n",
      " val_balacc 0.8604099610367609\n",
      "\n",
      "Epoch 174: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1364 - tp: 22346.0000 - fp: 1265.0000 - tn: 22346.0000 - fn: 1265.0000 - accuracy: 0.9464 - val_loss: 0.3020 - val_tp: 5079.0000 - val_fp: 824.0000 - val_tn: 5079.0000 - val_fn: 824.0000 - val_accuracy: 0.8604 - train_sensitivity: 0.9464 - train_specificity: 0.9464 - train_balacc: 0.9464 - val_sensitivity: 0.8604 - val_specificity: 0.8604 - val_balacc: 0.8604\n",
      "Epoch 175/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1383 - tp: 21848.0000 - fp: 1252.0000 - tn: 21848.0000 - fn: 1252.0000 - accuracy: 0.9458 train_balacc 0.9457879801787302\n",
      " val_balacc 0.8727765542944266\n",
      "\n",
      "Epoch 175: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1381 - tp: 22331.0000 - fp: 1280.0000 - tn: 22331.0000 - fn: 1280.0000 - accuracy: 0.9458 - val_loss: 0.3212 - val_tp: 5152.0000 - val_fp: 751.0000 - val_tn: 5152.0000 - val_fn: 751.0000 - val_accuracy: 0.8728 - train_sensitivity: 0.9458 - train_specificity: 0.9458 - train_balacc: 0.9458 - val_sensitivity: 0.8728 - val_specificity: 0.8728 - val_balacc: 0.8728\n",
      "Epoch 176/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1373 - tp: 21957.0000 - fp: 1243.0000 - tn: 21957.0000 - fn: 1243.0000 - accuracy: 0.9464 train_balacc 0.9464656304264961\n",
      " val_balacc 0.9371506013891242\n",
      "\n",
      "Epoch 176: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1369 - tp: 22347.0000 - fp: 1264.0000 - tn: 22347.0000 - fn: 1264.0000 - accuracy: 0.9465 - val_loss: 0.1479 - val_tp: 5532.0000 - val_fp: 371.0000 - val_tn: 5532.0000 - val_fn: 371.0000 - val_accuracy: 0.9372 - train_sensitivity: 0.9465 - train_specificity: 0.9465 - train_balacc: 0.9465 - val_sensitivity: 0.9372 - val_specificity: 0.9372 - val_balacc: 0.9372\n",
      "Epoch 177/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1399 - tp: 21725.0000 - fp: 1275.0000 - tn: 21725.0000 - fn: 1275.0000 - accuracy: 0.9446 train_balacc 0.9442632671212571\n",
      " val_balacc 0.8477045570049128\n",
      "\n",
      "Epoch 177: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1397 - tp: 22295.0000 - fp: 1316.0000 - tn: 22295.0000 - fn: 1316.0000 - accuracy: 0.9443 - val_loss: 0.3797 - val_tp: 5004.0000 - val_fp: 899.0000 - val_tn: 5004.0000 - val_fn: 899.0000 - val_accuracy: 0.8477 - train_sensitivity: 0.9443 - train_specificity: 0.9443 - train_balacc: 0.9443 - val_sensitivity: 0.8477 - val_specificity: 0.8477 - val_balacc: 0.8477\n",
      "Epoch 178/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1420 - tp: 21761.0000 - fp: 1339.0000 - tn: 21761.0000 - fn: 1339.0000 - accuracy: 0.9420 train_balacc 0.9420609038160179\n",
      " val_balacc 0.9207182788412671\n",
      "\n",
      "Epoch 178: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1417 - tp: 22243.0000 - fp: 1368.0000 - tn: 22243.0000 - fn: 1368.0000 - accuracy: 0.9421 - val_loss: 0.1953 - val_tp: 5435.0000 - val_fp: 468.0000 - val_tn: 5435.0000 - val_fn: 468.0000 - val_accuracy: 0.9207 - train_sensitivity: 0.9421 - train_specificity: 0.9421 - train_balacc: 0.9421 - val_sensitivity: 0.9207 - val_specificity: 0.9207 - val_balacc: 0.9207\n",
      "Epoch 179/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1346 - tp: 21854.0000 - fp: 1246.0000 - tn: 21854.0000 - fn: 1246.0000 - accuracy: 0.9461 train_balacc 0.9460420990216425\n",
      " val_balacc 0.8692190411655091\n",
      "\n",
      "Epoch 179: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1357 - tp: 22337.0000 - fp: 1274.0000 - tn: 22337.0000 - fn: 1274.0000 - accuracy: 0.9460 - val_loss: 0.2891 - val_tp: 5131.0000 - val_fp: 772.0000 - val_tn: 5131.0000 - val_fn: 772.0000 - val_accuracy: 0.8692 - train_sensitivity: 0.9460 - train_specificity: 0.9460 - train_balacc: 0.9460 - val_sensitivity: 0.8692 - val_specificity: 0.8692 - val_balacc: 0.8692\n",
      "Epoch 180/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1387 - tp: 21622.0000 - fp: 1278.0000 - tn: 21622.0000 - fn: 1278.0000 - accuracy: 0.9442 train_balacc 0.9444750328236838\n",
      " val_balacc 0.7948500762324242\n",
      "\n",
      "Epoch 180: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1386 - tp: 22300.0000 - fp: 1311.0000 - tn: 22300.0000 - fn: 1311.0000 - accuracy: 0.9445 - val_loss: 0.4349 - val_tp: 4692.0000 - val_fp: 1211.0000 - val_tn: 4692.0000 - val_fn: 1211.0000 - val_accuracy: 0.7949 - train_sensitivity: 0.9445 - train_specificity: 0.9445 - train_balacc: 0.9445 - val_sensitivity: 0.7949 - val_specificity: 0.7949 - val_balacc: 0.7949\n",
      "Epoch 181/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1375 - tp: 22338.0000 - fp: 1273.0000 - tn: 22338.0000 - fn: 1273.0000 - accuracy: 0.9461 train_balacc 0.9460844521621278\n",
      " val_balacc 0.9263086566152804\n",
      "\n",
      "Epoch 181: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1375 - tp: 22338.0000 - fp: 1273.0000 - tn: 22338.0000 - fn: 1273.0000 - accuracy: 0.9461 - val_loss: 0.1892 - val_tp: 5468.0000 - val_fp: 435.0000 - val_tn: 5468.0000 - val_fn: 435.0000 - val_accuracy: 0.9263 - train_sensitivity: 0.9461 - train_specificity: 0.9461 - train_balacc: 0.9461 - val_sensitivity: 0.9263 - val_specificity: 0.9263 - val_balacc: 0.9263\n",
      "Epoch 182/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1351 - tp: 21974.0000 - fp: 1226.0000 - tn: 21974.0000 - fn: 1226.0000 - accuracy: 0.9472 train_balacc 0.9467197492694083\n",
      " val_balacc 0.9235981704218195\n",
      "\n",
      "Epoch 182: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1363 - tp: 22353.0000 - fp: 1258.0000 - tn: 22353.0000 - fn: 1258.0000 - accuracy: 0.9467 - val_loss: 0.1806 - val_tp: 5452.0000 - val_fp: 451.0000 - val_tn: 5452.0000 - val_fn: 451.0000 - val_accuracy: 0.9236 - train_sensitivity: 0.9467 - train_specificity: 0.9467 - train_balacc: 0.9467 - val_sensitivity: 0.9236 - val_specificity: 0.9236 - val_balacc: 0.9236\n",
      "Epoch 183/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1392 - tp: 22130.0000 - fp: 1270.0000 - tn: 22130.0000 - fn: 1270.0000 - accuracy: 0.9457 train_balacc 0.9456609207572741\n",
      " val_balacc 0.9369811960020329\n",
      "\n",
      "Epoch 183: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1391 - tp: 22328.0000 - fp: 1283.0000 - tn: 22328.0000 - fn: 1283.0000 - accuracy: 0.9457 - val_loss: 0.1539 - val_tp: 5531.0000 - val_fp: 372.0000 - val_tn: 5531.0000 - val_fn: 372.0000 - val_accuracy: 0.9370 - train_sensitivity: 0.9457 - train_specificity: 0.9457 - train_balacc: 0.9457 - val_sensitivity: 0.9370 - val_specificity: 0.9370 - val_balacc: 0.9370\n",
      "Epoch 184/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1357 - tp: 21884.0000 - fp: 1216.0000 - tn: 21884.0000 - fn: 1216.0000 - accuracy: 0.9474 train_balacc 0.947482105798145\n",
      " val_balacc 0.8675249872945959\n",
      "\n",
      "Epoch 184: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1354 - tp: 22371.0000 - fp: 1240.0000 - tn: 22371.0000 - fn: 1240.0000 - accuracy: 0.9475 - val_loss: 0.3356 - val_tp: 5121.0000 - val_fp: 782.0000 - val_tn: 5121.0000 - val_fn: 782.0000 - val_accuracy: 0.8675 - train_sensitivity: 0.9475 - train_specificity: 0.9475 - train_balacc: 0.9475 - val_sensitivity: 0.8675 - val_specificity: 0.8675 - val_balacc: 0.8675\n",
      "Epoch 185/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1384 - tp: 21850.0000 - fp: 1250.0000 - tn: 21850.0000 - fn: 1250.0000 - accuracy: 0.9459 train_balacc 0.9454491550548473\n",
      " val_balacc 0.9173301710994409\n",
      "\n",
      "Epoch 185: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1393 - tp: 22323.0000 - fp: 1288.0000 - tn: 22323.0000 - fn: 1288.0000 - accuracy: 0.9454 - val_loss: 0.2164 - val_tp: 5415.0000 - val_fp: 488.0000 - val_tn: 5415.0000 - val_fn: 488.0000 - val_accuracy: 0.9173 - train_sensitivity: 0.9454 - train_specificity: 0.9454 - train_balacc: 0.9454 - val_sensitivity: 0.9173 - val_specificity: 0.9173 - val_balacc: 0.9173\n",
      "Epoch 186/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1356 - tp: 22119.0000 - fp: 1281.0000 - tn: 22119.0000 - fn: 1281.0000 - accuracy: 0.9453 train_balacc 0.9451526830714497\n",
      " val_balacc 0.9056411993901406\n",
      "\n",
      "Epoch 186: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1364 - tp: 22316.0000 - fp: 1295.0000 - tn: 22316.0000 - fn: 1295.0000 - accuracy: 0.9452 - val_loss: 0.2038 - val_tp: 5346.0000 - val_fp: 557.0000 - val_tn: 5346.0000 - val_fn: 557.0000 - val_accuracy: 0.9056 - train_sensitivity: 0.9452 - train_specificity: 0.9452 - train_balacc: 0.9452 - val_sensitivity: 0.9056 - val_specificity: 0.9056 - val_balacc: 0.9056\n",
      "Epoch 187/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1405 - tp: 21898.0000 - fp: 1302.0000 - tn: 21898.0000 - fn: 1302.0000 - accuracy: 0.9439 train_balacc 0.943797382575918\n",
      " val_balacc 0.9249534135185499\n",
      "\n",
      "Epoch 187: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1406 - tp: 22284.0000 - fp: 1327.0000 - tn: 22284.0000 - fn: 1327.0000 - accuracy: 0.9438 - val_loss: 0.1841 - val_tp: 5460.0000 - val_fp: 443.0000 - val_tn: 5460.0000 - val_fn: 443.0000 - val_accuracy: 0.9250 - train_sensitivity: 0.9438 - train_specificity: 0.9438 - train_balacc: 0.9438 - val_sensitivity: 0.9250 - val_specificity: 0.9250 - val_balacc: 0.9250\n",
      "Epoch 188/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1413 - tp: 21732.0000 - fp: 1268.0000 - tn: 21732.0000 - fn: 1268.0000 - accuracy: 0.9449 train_balacc 0.9449832705095083\n",
      " val_balacc 0.858207691004574\n",
      "\n",
      "Epoch 188: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1413 - tp: 22312.0000 - fp: 1299.0000 - tn: 22312.0000 - fn: 1299.0000 - accuracy: 0.9450 - val_loss: 0.4030 - val_tp: 5066.0000 - val_fp: 837.0000 - val_tn: 5066.0000 - val_fn: 837.0000 - val_accuracy: 0.8582 - train_sensitivity: 0.9450 - train_specificity: 0.9450 - train_balacc: 0.9450 - val_sensitivity: 0.8582 - val_specificity: 0.8582 - val_balacc: 0.8582\n",
      "Epoch 189/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1323 - tp: 21650.0000 - fp: 1250.0000 - tn: 21650.0000 - fn: 1250.0000 - accuracy: 0.9454 train_balacc 0.9447291516665961\n",
      " val_balacc 0.9420633576147721\n",
      "\n",
      "Epoch 189: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1340 - tp: 22306.0000 - fp: 1305.0000 - tn: 22306.0000 - fn: 1305.0000 - accuracy: 0.9447 - val_loss: 0.1497 - val_tp: 5561.0000 - val_fp: 342.0000 - val_tn: 5561.0000 - val_fn: 342.0000 - val_accuracy: 0.9421 - train_sensitivity: 0.9447 - train_specificity: 0.9447 - train_balacc: 0.9447 - val_sensitivity: 0.9421 - val_specificity: 0.9421 - val_balacc: 0.9421\n",
      "Epoch 190/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1390 - tp: 21563.0000 - fp: 1237.0000 - tn: 21563.0000 - fn: 1237.0000 - accuracy: 0.9457 train_balacc 0.9455762144763035\n",
      " val_balacc 0.9015754700999492\n",
      "\n",
      "Epoch 190: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1390 - tp: 22326.0000 - fp: 1285.0000 - tn: 22326.0000 - fn: 1285.0000 - accuracy: 0.9456 - val_loss: 0.2477 - val_tp: 5322.0000 - val_fp: 581.0000 - val_tn: 5322.0000 - val_fn: 581.0000 - val_accuracy: 0.9016 - train_sensitivity: 0.9456 - train_specificity: 0.9456 - train_balacc: 0.9456 - val_sensitivity: 0.9016 - val_specificity: 0.9016 - val_balacc: 0.9016\n",
      "Epoch 191/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1441 - tp: 21705.0000 - fp: 1295.0000 - tn: 21705.0000 - fn: 1295.0000 - accuracy: 0.9437 train_balacc 0.9437550294354327\n",
      " val_balacc 0.934270709808572\n",
      "\n",
      "Epoch 191: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1440 - tp: 22283.0000 - fp: 1328.0000 - tn: 22283.0000 - fn: 1328.0000 - accuracy: 0.9438 - val_loss: 0.1677 - val_tp: 5515.0000 - val_fp: 388.0000 - val_tn: 5515.0000 - val_fn: 388.0000 - val_accuracy: 0.9343 - train_sensitivity: 0.9438 - train_specificity: 0.9438 - train_balacc: 0.9438 - val_sensitivity: 0.9343 - val_specificity: 0.9343 - val_balacc: 0.9343\n",
      "Epoch 192/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1389 - tp: 22060.0000 - fp: 1240.0000 - tn: 22060.0000 - fn: 1240.0000 - accuracy: 0.9468 train_balacc 0.946677396128923\n",
      " val_balacc 0.9313908182280196\n",
      "\n",
      "Epoch 192: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1388 - tp: 22352.0000 - fp: 1259.0000 - tn: 22352.0000 - fn: 1259.0000 - accuracy: 0.9467 - val_loss: 0.1859 - val_tp: 5498.0000 - val_fp: 405.0000 - val_tn: 5498.0000 - val_fn: 405.0000 - val_accuracy: 0.9314 - train_sensitivity: 0.9467 - train_specificity: 0.9467 - train_balacc: 0.9467 - val_sensitivity: 0.9314 - val_specificity: 0.9314 - val_balacc: 0.9314\n",
      "Epoch 193/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1387 - tp: 22043.0000 - fp: 1257.0000 - tn: 22043.0000 - fn: 1257.0000 - accuracy: 0.9461 train_balacc 0.9461691584430986\n",
      " val_balacc 0.9164831441639845\n",
      "\n",
      "Epoch 193: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1384 - tp: 22340.0000 - fp: 1271.0000 - tn: 22340.0000 - fn: 1271.0000 - accuracy: 0.9462 - val_loss: 0.1882 - val_tp: 5410.0000 - val_fp: 493.0000 - val_tn: 5410.0000 - val_fn: 493.0000 - val_accuracy: 0.9165 - train_sensitivity: 0.9462 - train_specificity: 0.9462 - train_balacc: 0.9462 - val_sensitivity: 0.9165 - val_specificity: 0.9165 - val_balacc: 0.9165\n",
      "Epoch 194/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1327 - tp: 22308.0000 - fp: 1303.0000 - tn: 22308.0000 - fn: 1303.0000 - accuracy: 0.9448 train_balacc 0.9448138579475668\n",
      " val_balacc 0.9324072505505675\n",
      "\n",
      "Epoch 194: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1327 - tp: 22308.0000 - fp: 1303.0000 - tn: 22308.0000 - fn: 1303.0000 - accuracy: 0.9448 - val_loss: 0.1804 - val_tp: 5504.0000 - val_fp: 399.0000 - val_tn: 5504.0000 - val_fn: 399.0000 - val_accuracy: 0.9324 - train_sensitivity: 0.9448 - train_specificity: 0.9448 - train_balacc: 0.9448 - val_sensitivity: 0.9324 - val_specificity: 0.9324 - val_balacc: 0.9324\n",
      "Epoch 195/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1308 - tp: 22000.0000 - fp: 1200.0000 - tn: 22000.0000 - fn: 1200.0000 - accuracy: 0.9483 train_balacc 0.9477785777815425\n",
      " val_balacc 0.9061494155514145\n",
      "\n",
      "Epoch 195: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1313 - tp: 22378.0000 - fp: 1233.0000 - tn: 22378.0000 - fn: 1233.0000 - accuracy: 0.9478 - val_loss: 0.2162 - val_tp: 5349.0000 - val_fp: 554.0000 - val_tn: 5349.0000 - val_fn: 554.0000 - val_accuracy: 0.9061 - train_sensitivity: 0.9478 - train_specificity: 0.9478 - train_balacc: 0.9478 - val_sensitivity: 0.9061 - val_specificity: 0.9061 - val_balacc: 0.9061\n",
      "Epoch 196/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1334 - tp: 21774.0000 - fp: 1226.0000 - tn: 21774.0000 - fn: 1226.0000 - accuracy: 0.9467 train_balacc 0.9465079835669815\n",
      " val_balacc 0.9188548195832628\n",
      "\n",
      "Epoch 196: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1330 - tp: 22348.0000 - fp: 1263.0000 - tn: 22348.0000 - fn: 1263.0000 - accuracy: 0.9465 - val_loss: 0.1869 - val_tp: 5424.0000 - val_fp: 479.0000 - val_tn: 5424.0000 - val_fn: 479.0000 - val_accuracy: 0.9189 - train_sensitivity: 0.9465 - train_specificity: 0.9465 - train_balacc: 0.9465 - val_sensitivity: 0.9189 - val_specificity: 0.9189 - val_balacc: 0.9189\n",
      "Epoch 197/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1337 - tp: 22362.0000 - fp: 1249.0000 - tn: 22362.0000 - fn: 1249.0000 - accuracy: 0.9471 train_balacc 0.9471009275337766\n",
      " val_balacc 0.9308826020667457\n",
      "\n",
      "Epoch 197: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1337 - tp: 22362.0000 - fp: 1249.0000 - tn: 22362.0000 - fn: 1249.0000 - accuracy: 0.9471 - val_loss: 0.1689 - val_tp: 5495.0000 - val_fp: 408.0000 - val_tn: 5495.0000 - val_fn: 408.0000 - val_accuracy: 0.9309 - train_sensitivity: 0.9471 - train_specificity: 0.9471 - train_balacc: 0.9471 - val_sensitivity: 0.9309 - val_specificity: 0.9309 - val_balacc: 0.9309\n",
      "Epoch 198/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1401 - tp: 21792.0000 - fp: 1208.0000 - tn: 21792.0000 - fn: 1208.0000 - accuracy: 0.9475 train_balacc 0.9469315149718351\n",
      " val_balacc 0.9230899542605455\n",
      "\n",
      "Epoch 198: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1412 - tp: 22358.0000 - fp: 1253.0000 - tn: 22358.0000 - fn: 1253.0000 - accuracy: 0.9469 - val_loss: 0.1975 - val_tp: 5449.0000 - val_fp: 454.0000 - val_tn: 5449.0000 - val_fn: 454.0000 - val_accuracy: 0.9231 - train_sensitivity: 0.9469 - train_specificity: 0.9469 - train_balacc: 0.9469 - val_sensitivity: 0.9231 - val_specificity: 0.9231 - val_balacc: 0.9231\n",
      "Epoch 199/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1344 - tp: 22250.0000 - fp: 1250.0000 - tn: 22250.0000 - fn: 1250.0000 - accuracy: 0.9468 train_balacc 0.9468891618313497\n",
      " val_balacc 0.8512620701338303\n",
      "\n",
      "Epoch 199: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1343 - tp: 22357.0000 - fp: 1254.0000 - tn: 22357.0000 - fn: 1254.0000 - accuracy: 0.9469 - val_loss: 0.3227 - val_tp: 5025.0000 - val_fp: 878.0000 - val_tn: 5025.0000 - val_fn: 878.0000 - val_accuracy: 0.8513 - train_sensitivity: 0.9469 - train_specificity: 0.9469 - train_balacc: 0.9469 - val_sensitivity: 0.8513 - val_specificity: 0.8513 - val_balacc: 0.8513\n",
      "Epoch 200/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1387 - tp: 22146.0000 - fp: 1254.0000 - tn: 22146.0000 - fn: 1254.0000 - accuracy: 0.9464 train_balacc 0.9461691584430986\n",
      " val_balacc 0.9215653057767237\n",
      "\n",
      "Epoch 200: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1391 - tp: 22340.0000 - fp: 1271.0000 - tn: 22340.0000 - fn: 1271.0000 - accuracy: 0.9462 - val_loss: 0.2030 - val_tp: 5440.0000 - val_fp: 463.0000 - val_tn: 5440.0000 - val_fn: 463.0000 - val_accuracy: 0.9216 - train_sensitivity: 0.9462 - train_specificity: 0.9462 - train_balacc: 0.9462 - val_sensitivity: 0.9216 - val_specificity: 0.9216 - val_balacc: 0.9216\n",
      "Epoch 201/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1338 - tp: 21866.0000 - fp: 1234.0000 - tn: 21866.0000 - fn: 1234.0000 - accuracy: 0.9466 train_balacc 0.946677396128923\n",
      " val_balacc 0.9398610875825851\n",
      "\n",
      "Epoch 201: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1334 - tp: 22352.0000 - fp: 1259.0000 - tn: 22352.0000 - fn: 1259.0000 - accuracy: 0.9467 - val_loss: 0.1484 - val_tp: 5548.0000 - val_fp: 355.0000 - val_tn: 5548.0000 - val_fn: 355.0000 - val_accuracy: 0.9399 - train_sensitivity: 0.9467 - train_specificity: 0.9467 - train_balacc: 0.9467 - val_sensitivity: 0.9399 - val_specificity: 0.9399 - val_balacc: 0.9399\n",
      "Epoch 202/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1399 - tp: 21967.0000 - fp: 1233.0000 - tn: 21967.0000 - fn: 1233.0000 - accuracy: 0.9469 train_balacc 0.9468468086908645\n",
      " val_balacc 0.9356259529053024\n",
      "\n",
      "Epoch 202: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1398 - tp: 22356.0000 - fp: 1255.0000 - tn: 22356.0000 - fn: 1255.0000 - accuracy: 0.9468 - val_loss: 0.1647 - val_tp: 5523.0000 - val_fp: 380.0000 - val_tn: 5523.0000 - val_fn: 380.0000 - val_accuracy: 0.9356 - train_sensitivity: 0.9468 - train_specificity: 0.9468 - train_balacc: 0.9468 - val_sensitivity: 0.9356 - val_specificity: 0.9356 - val_balacc: 0.9356\n",
      "Epoch 203/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1379 - tp: 22207.0000 - fp: 1293.0000 - tn: 22207.0000 - fn: 1293.0000 - accuracy: 0.9450 train_balacc 0.9450256236499937\n",
      " val_balacc 0.9229205488734542\n",
      "\n",
      "Epoch 203: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1378 - tp: 22313.0000 - fp: 1298.0000 - tn: 22313.0000 - fn: 1298.0000 - accuracy: 0.9450 - val_loss: 0.1870 - val_tp: 5448.0000 - val_fp: 455.0000 - val_tn: 5448.0000 - val_fn: 455.0000 - val_accuracy: 0.9229 - train_sensitivity: 0.9450 - train_specificity: 0.9450 - train_balacc: 0.9450 - val_sensitivity: 0.9229 - val_specificity: 0.9229 - val_balacc: 0.9229\n",
      "Epoch 204/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1323 - tp: 21802.0000 - fp: 1198.0000 - tn: 21802.0000 - fn: 1198.0000 - accuracy: 0.9479 train_balacc 0.9483291686078523\n",
      " val_balacc 0.8770116889717093\n",
      "\n",
      "Epoch 204: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1319 - tp: 22391.0000 - fp: 1220.0000 - tn: 22391.0000 - fn: 1220.0000 - accuracy: 0.9483 - val_loss: 0.3195 - val_tp: 5177.0000 - val_fp: 726.0000 - val_tn: 5177.0000 - val_fn: 726.0000 - val_accuracy: 0.8770 - train_sensitivity: 0.9483 - train_specificity: 0.9483 - train_balacc: 0.9483 - val_sensitivity: 0.8770 - val_specificity: 0.8770 - val_balacc: 0.8770\n",
      "Epoch 205/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1400 - tp: 22187.0000 - fp: 1313.0000 - tn: 22187.0000 - fn: 1313.0000 - accuracy: 0.9441 train_balacc 0.9442632671212571\n",
      " val_balacc 0.936472979840759\n",
      "\n",
      "Epoch 205: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1396 - tp: 22295.0000 - fp: 1316.0000 - tn: 22295.0000 - fn: 1316.0000 - accuracy: 0.9443 - val_loss: 0.1483 - val_tp: 5528.0000 - val_fp: 375.0000 - val_tn: 5528.0000 - val_fn: 375.0000 - val_accuracy: 0.9365 - train_sensitivity: 0.9443 - train_specificity: 0.9443 - train_balacc: 0.9443 - val_sensitivity: 0.9365 - val_specificity: 0.9365 - val_balacc: 0.9365\n",
      "Epoch 206/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1351 - tp: 21912.0000 - fp: 1288.0000 - tn: 21912.0000 - fn: 1288.0000 - accuracy: 0.9445 train_balacc 0.9447291516665961\n",
      " val_balacc 0.935964763679485\n",
      "\n",
      "Epoch 206: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1347 - tp: 22306.0000 - fp: 1305.0000 - tn: 22306.0000 - fn: 1305.0000 - accuracy: 0.9447 - val_loss: 0.1528 - val_tp: 5525.0000 - val_fp: 378.0000 - val_tn: 5525.0000 - val_fn: 378.0000 - val_accuracy: 0.9360 - train_sensitivity: 0.9447 - train_specificity: 0.9447 - train_balacc: 0.9447 - val_sensitivity: 0.9360 - val_specificity: 0.9360 - val_balacc: 0.9360\n",
      "Epoch 207/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1359 - tp: 22336.0000 - fp: 1264.0000 - tn: 22336.0000 - fn: 1264.0000 - accuracy: 0.9464 train_balacc 0.9464656304264961\n",
      " val_balacc 0.920040657292902\n",
      "\n",
      "Epoch 207: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1359 - tp: 22347.0000 - fp: 1264.0000 - tn: 22347.0000 - fn: 1264.0000 - accuracy: 0.9465 - val_loss: 0.2016 - val_tp: 5431.0000 - val_fp: 472.0000 - val_tn: 5431.0000 - val_fn: 472.0000 - val_accuracy: 0.9200 - train_sensitivity: 0.9465 - train_specificity: 0.9465 - train_balacc: 0.9465 - val_sensitivity: 0.9200 - val_specificity: 0.9200 - val_balacc: 0.9200\n",
      "Epoch 208/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1333 - tp: 21773.0000 - fp: 1227.0000 - tn: 21773.0000 - fn: 1227.0000 - accuracy: 0.9467 train_balacc 0.94633857100504\n",
      " val_balacc 0.8959850923259359\n",
      "\n",
      "Epoch 208: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1338 - tp: 22344.0000 - fp: 1267.0000 - tn: 22344.0000 - fn: 1267.0000 - accuracy: 0.9463 - val_loss: 0.2301 - val_tp: 5289.0000 - val_fp: 614.0000 - val_tn: 5289.0000 - val_fn: 614.0000 - val_accuracy: 0.8960 - train_sensitivity: 0.9463 - train_specificity: 0.9463 - train_balacc: 0.9463 - val_sensitivity: 0.8960 - val_specificity: 0.8960 - val_balacc: 0.8960\n",
      "Epoch 209/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1340 - tp: 21818.0000 - fp: 1182.0000 - tn: 21818.0000 - fn: 1182.0000 - accuracy: 0.9486 train_balacc 0.9486256405912499\n",
      " val_balacc 0.9273250889378282\n",
      "\n",
      "Epoch 209: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1341 - tp: 22398.0000 - fp: 1213.0000 - tn: 22398.0000 - fn: 1213.0000 - accuracy: 0.9486 - val_loss: 0.1865 - val_tp: 5474.0000 - val_fp: 429.0000 - val_tn: 5474.0000 - val_fn: 429.0000 - val_accuracy: 0.9273 - train_sensitivity: 0.9486 - train_specificity: 0.9486 - train_balacc: 0.9486 - val_sensitivity: 0.9273 - val_specificity: 0.9273 - val_balacc: 0.9273\n",
      "Epoch 210/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1335 - tp: 21678.0000 - fp: 1222.0000 - tn: 21678.0000 - fn: 1222.0000 - accuracy: 0.9466 train_balacc 0.9467197492694083\n",
      " val_balacc 0.8824326613586312\n",
      "\n",
      "Epoch 210: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1343 - tp: 22353.0000 - fp: 1258.0000 - tn: 22353.0000 - fn: 1258.0000 - accuracy: 0.9467 - val_loss: 0.2560 - val_tp: 5209.0000 - val_fp: 694.0000 - val_tn: 5209.0000 - val_fn: 694.0000 - val_accuracy: 0.8824 - train_sensitivity: 0.9467 - train_specificity: 0.9467 - train_balacc: 0.9467 - val_sensitivity: 0.8824 - val_specificity: 0.8824 - val_balacc: 0.8824\n",
      "Epoch 211/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1334 - tp: 22327.0000 - fp: 1173.0000 - tn: 22327.0000 - fn: 1173.0000 - accuracy: 0.9501 train_balacc 0.9502350599296938\n",
      " val_balacc 0.9156361172285279\n",
      "\n",
      "Epoch 211: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1332 - tp: 22436.0000 - fp: 1175.0000 - tn: 22436.0000 - fn: 1175.0000 - accuracy: 0.9502 - val_loss: 0.1853 - val_tp: 5405.0000 - val_fp: 498.0000 - val_tn: 5405.0000 - val_fn: 498.0000 - val_accuracy: 0.9156 - train_sensitivity: 0.9502 - train_specificity: 0.9502 - train_balacc: 0.9502 - val_sensitivity: 0.9156 - val_specificity: 0.9156 - val_balacc: 0.9156\n",
      "Epoch 212/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1348 - tp: 22396.0000 - fp: 1204.0000 - tn: 22396.0000 - fn: 1204.0000 - accuracy: 0.9490 train_balacc 0.9489644657151328\n",
      " val_balacc 0.8770116889717093\n",
      "\n",
      "Epoch 212: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1348 - tp: 22406.0000 - fp: 1205.0000 - tn: 22406.0000 - fn: 1205.0000 - accuracy: 0.9490 - val_loss: 0.2772 - val_tp: 5177.0000 - val_fp: 726.0000 - val_tn: 5177.0000 - val_fn: 726.0000 - val_accuracy: 0.8770 - train_sensitivity: 0.9490 - train_specificity: 0.9490 - train_balacc: 0.9490 - val_sensitivity: 0.8770 - val_specificity: 0.8770 - val_balacc: 0.8770\n",
      "Epoch 213/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1284 - tp: 21648.0000 - fp: 1152.0000 - tn: 21648.0000 - fn: 1152.0000 - accuracy: 0.9495 train_balacc 0.949345643979501\n",
      " val_balacc 0.8758258512620701\n",
      "\n",
      "Epoch 213: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1285 - tp: 22415.0000 - fp: 1196.0000 - tn: 22415.0000 - fn: 1196.0000 - accuracy: 0.9493 - val_loss: 0.3001 - val_tp: 5170.0000 - val_fp: 733.0000 - val_tn: 5170.0000 - val_fn: 733.0000 - val_accuracy: 0.8758 - train_sensitivity: 0.9493 - train_specificity: 0.9493 - train_balacc: 0.9493 - val_sensitivity: 0.8758 - val_specificity: 0.8758 - val_balacc: 0.8758\n",
      "Epoch 214/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1351 - tp: 22207.0000 - fp: 1293.0000 - tn: 22207.0000 - fn: 1293.0000 - accuracy: 0.9450 train_balacc 0.945067976790479\n",
      " val_balacc 0.9400304929696764\n",
      "\n",
      "Epoch 214: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1349 - tp: 22314.0000 - fp: 1297.0000 - tn: 22314.0000 - fn: 1297.0000 - accuracy: 0.9451 - val_loss: 0.1521 - val_tp: 5549.0000 - val_fp: 354.0000 - val_tn: 5549.0000 - val_fn: 354.0000 - val_accuracy: 0.9400 - train_sensitivity: 0.9451 - train_specificity: 0.9451 - train_balacc: 0.9451 - val_sensitivity: 0.9400 - val_specificity: 0.9400 - val_balacc: 0.9400\n",
      "Epoch 215/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1336 - tp: 21885.0000 - fp: 1215.0000 - tn: 21885.0000 - fn: 1215.0000 - accuracy: 0.9474 train_balacc 0.9476938715005717\n",
      " val_balacc 0.9303743859054718\n",
      "\n",
      "Epoch 215: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1331 - tp: 22376.0000 - fp: 1235.0000 - tn: 22376.0000 - fn: 1235.0000 - accuracy: 0.9477 - val_loss: 0.1723 - val_tp: 5492.0000 - val_fp: 411.0000 - val_tn: 5492.0000 - val_fn: 411.0000 - val_accuracy: 0.9304 - train_sensitivity: 0.9477 - train_specificity: 0.9477 - train_balacc: 0.9477 - val_sensitivity: 0.9304 - val_specificity: 0.9304 - val_balacc: 0.9304\n",
      "Epoch 216/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1361 - tp: 22167.0000 - fp: 1233.0000 - tn: 22167.0000 - fn: 1233.0000 - accuracy: 0.9473 train_balacc 0.9475244589386304\n",
      " val_balacc 0.920040657292902\n",
      "\n",
      "Epoch 216: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1356 - tp: 22372.0000 - fp: 1239.0000 - tn: 22372.0000 - fn: 1239.0000 - accuracy: 0.9475 - val_loss: 0.1982 - val_tp: 5431.0000 - val_fp: 472.0000 - val_tn: 5431.0000 - val_fn: 472.0000 - val_accuracy: 0.9200 - train_sensitivity: 0.9475 - train_specificity: 0.9475 - train_balacc: 0.9475 - val_sensitivity: 0.9200 - val_specificity: 0.9200 - val_balacc: 0.9200\n",
      "Epoch 217/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1368 - tp: 22279.0000 - fp: 1221.0000 - tn: 22279.0000 - fn: 1221.0000 - accuracy: 0.9480 train_balacc 0.9481174029054255\n",
      " val_balacc 0.926647467389463\n",
      "\n",
      "Epoch 217: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1367 - tp: 22386.0000 - fp: 1225.0000 - tn: 22386.0000 - fn: 1225.0000 - accuracy: 0.9481 - val_loss: 0.1896 - val_tp: 5470.0000 - val_fp: 433.0000 - val_tn: 5470.0000 - val_fn: 433.0000 - val_accuracy: 0.9266 - train_sensitivity: 0.9481 - train_specificity: 0.9481 - train_balacc: 0.9481 - val_sensitivity: 0.9266 - val_specificity: 0.9266 - val_balacc: 0.9266\n",
      "Epoch 218/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1306 - tp: 21641.0000 - fp: 1159.0000 - tn: 21641.0000 - fn: 1159.0000 - accuracy: 0.9492 train_balacc 0.9491338782770743\n",
      " val_balacc 0.9341013044214806\n",
      "\n",
      "Epoch 218: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1306 - tp: 22410.0000 - fp: 1201.0000 - tn: 22410.0000 - fn: 1201.0000 - accuracy: 0.9491 - val_loss: 0.1576 - val_tp: 5514.0000 - val_fp: 389.0000 - val_tn: 5514.0000 - val_fn: 389.0000 - val_accuracy: 0.9341 - train_sensitivity: 0.9491 - train_specificity: 0.9491 - train_balacc: 0.9491 - val_sensitivity: 0.9341 - val_specificity: 0.9341 - val_balacc: 0.9341\n",
      "Epoch 219/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1324 - tp: 22392.0000 - fp: 1208.0000 - tn: 22392.0000 - fn: 1208.0000 - accuracy: 0.9488 train_balacc 0.9488374062936766\n",
      " val_balacc 0.9320684397763849\n",
      "\n",
      "Epoch 219: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1324 - tp: 22403.0000 - fp: 1208.0000 - tn: 22403.0000 - fn: 1208.0000 - accuracy: 0.9488 - val_loss: 0.1672 - val_tp: 5502.0000 - val_fp: 401.0000 - val_tn: 5502.0000 - val_fn: 401.0000 - val_accuracy: 0.9321 - train_sensitivity: 0.9488 - train_specificity: 0.9488 - train_balacc: 0.9488 - val_sensitivity: 0.9321 - val_specificity: 0.9321 - val_balacc: 0.9321\n",
      "Epoch 220/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1427 - tp: 21750.0000 - fp: 1250.0000 - tn: 21750.0000 - fn: 1250.0000 - accuracy: 0.9457 train_balacc 0.9456185676167888\n",
      " val_balacc 0.9085210909706929\n",
      "\n",
      "Epoch 220: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1423 - tp: 22327.0000 - fp: 1284.0000 - tn: 22327.0000 - fn: 1284.0000 - accuracy: 0.9456 - val_loss: 0.2310 - val_tp: 5363.0000 - val_fp: 540.0000 - val_tn: 5363.0000 - val_fn: 540.0000 - val_accuracy: 0.9085 - train_sensitivity: 0.9456 - train_specificity: 0.9456 - train_balacc: 0.9456 - val_sensitivity: 0.9085 - val_specificity: 0.9085 - val_balacc: 0.9085\n",
      "Epoch 221/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1372 - tp: 21886.0000 - fp: 1214.0000 - tn: 21886.0000 - fn: 1214.0000 - accuracy: 0.9474 train_balacc 0.9476938715005717\n",
      " val_balacc 0.8209385058444858\n",
      "\n",
      "Epoch 221: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1360 - tp: 22376.0000 - fp: 1235.0000 - tn: 22376.0000 - fn: 1235.0000 - accuracy: 0.9477 - val_loss: 0.4799 - val_tp: 4846.0000 - val_fp: 1057.0000 - val_tn: 4846.0000 - val_fn: 1057.0000 - val_accuracy: 0.8209 - train_sensitivity: 0.9477 - train_specificity: 0.9477 - train_balacc: 0.9477 - val_sensitivity: 0.8209 - val_specificity: 0.8209 - val_balacc: 0.8209\n",
      "Epoch 222/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1347 - tp: 21567.0000 - fp: 1233.0000 - tn: 21567.0000 - fn: 1233.0000 - accuracy: 0.9459 train_balacc 0.9457879801787302\n",
      " val_balacc 0.8563442317465696\n",
      "\n",
      "Epoch 222: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1351 - tp: 22331.0000 - fp: 1280.0000 - tn: 22331.0000 - fn: 1280.0000 - accuracy: 0.9458 - val_loss: 0.3727 - val_tp: 5055.0000 - val_fp: 848.0000 - val_tn: 5055.0000 - val_fn: 848.0000 - val_accuracy: 0.8563 - train_sensitivity: 0.9458 - train_specificity: 0.9458 - train_balacc: 0.9458 - val_sensitivity: 0.8563 - val_specificity: 0.8563 - val_balacc: 0.8563\n",
      "Epoch 223/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1315 - tp: 21841.0000 - fp: 1159.0000 - tn: 21841.0000 - fn: 1159.0000 - accuracy: 0.9496 train_balacc 0.9490915251365889\n",
      " val_balacc 0.7199728951380654\n",
      "\n",
      "Epoch 223: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1319 - tp: 22409.0000 - fp: 1202.0000 - tn: 22409.0000 - fn: 1202.0000 - accuracy: 0.9491 - val_loss: 1.8451 - val_tp: 4250.0000 - val_fp: 1653.0000 - val_tn: 4250.0000 - val_fn: 1653.0000 - val_accuracy: 0.7200 - train_sensitivity: 0.9491 - train_specificity: 0.9491 - train_balacc: 0.9491 - val_sensitivity: 0.7200 - val_specificity: 0.7200 - val_balacc: 0.7200\n",
      "Epoch 224/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1271 - tp: 22003.0000 - fp: 1197.0000 - tn: 22003.0000 - fn: 1197.0000 - accuracy: 0.9484 train_balacc 0.9486679937317352\n",
      " val_balacc 0.9268168727765543\n",
      "\n",
      "Epoch 224: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1265 - tp: 22399.0000 - fp: 1212.0000 - tn: 22399.0000 - fn: 1212.0000 - accuracy: 0.9487 - val_loss: 0.1815 - val_tp: 5471.0000 - val_fp: 432.0000 - val_tn: 5471.0000 - val_fn: 432.0000 - val_accuracy: 0.9268 - train_sensitivity: 0.9487 - train_specificity: 0.9487 - train_balacc: 0.9487 - val_sensitivity: 0.9268 - val_specificity: 0.9268 - val_balacc: 0.9268\n",
      "Epoch 225/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1282 - tp: 21750.0000 - fp: 1150.0000 - tn: 21750.0000 - fn: 1150.0000 - accuracy: 0.9498 train_balacc 0.9496421159628986\n",
      " val_balacc 0.9346095205827545\n",
      "\n",
      "Epoch 225: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1285 - tp: 22422.0000 - fp: 1189.0000 - tn: 22422.0000 - fn: 1189.0000 - accuracy: 0.9496 - val_loss: 0.1650 - val_tp: 5517.0000 - val_fp: 386.0000 - val_tn: 5517.0000 - val_fn: 386.0000 - val_accuracy: 0.9346 - train_sensitivity: 0.9496 - train_specificity: 0.9496 - train_balacc: 0.9496 - val_sensitivity: 0.9346 - val_specificity: 0.9346 - val_balacc: 0.9346\n",
      "Epoch 226/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1318 - tp: 21856.0000 - fp: 1244.0000 - tn: 21856.0000 - fn: 1244.0000 - accuracy: 0.9461 train_balacc 0.9461691584430986\n",
      " val_balacc 0.8983567677452143\n",
      "\n",
      "Epoch 226: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1320 - tp: 22340.0000 - fp: 1271.0000 - tn: 22340.0000 - fn: 1271.0000 - accuracy: 0.9462 - val_loss: 0.2139 - val_tp: 5303.0000 - val_fp: 600.0000 - val_tn: 5303.0000 - val_fn: 600.0000 - val_accuracy: 0.8984 - train_sensitivity: 0.9462 - train_specificity: 0.9462 - train_balacc: 0.9462 - val_sensitivity: 0.8984 - val_specificity: 0.8984 - val_balacc: 0.8984\n",
      "Epoch 227/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1292 - tp: 22413.0000 - fp: 1187.0000 - tn: 22413.0000 - fn: 1187.0000 - accuracy: 0.9497 train_balacc 0.949684469103384\n",
      " val_balacc 0.7482635947823141\n",
      "\n",
      "Epoch 227: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1296 - tp: 22423.0000 - fp: 1188.0000 - tn: 22423.0000 - fn: 1188.0000 - accuracy: 0.9497 - val_loss: 0.5693 - val_tp: 4417.0000 - val_fp: 1486.0000 - val_tn: 4417.0000 - val_fn: 1486.0000 - val_accuracy: 0.7483 - train_sensitivity: 0.9497 - train_specificity: 0.9497 - train_balacc: 0.9497 - val_sensitivity: 0.7483 - val_specificity: 0.7483 - val_balacc: 0.7483\n",
      "Epoch 228/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1256 - tp: 21933.0000 - fp: 1167.0000 - tn: 21933.0000 - fn: 1167.0000 - accuracy: 0.9495 train_balacc 0.949345643979501\n",
      " val_balacc 0.9274944943249195\n",
      "\n",
      "Epoch 228: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1270 - tp: 22415.0000 - fp: 1196.0000 - tn: 22415.0000 - fn: 1196.0000 - accuracy: 0.9493 - val_loss: 0.1911 - val_tp: 5475.0000 - val_fp: 428.0000 - val_tn: 5475.0000 - val_fn: 428.0000 - val_accuracy: 0.9275 - train_sensitivity: 0.9493 - train_specificity: 0.9493 - train_balacc: 0.9493 - val_sensitivity: 0.9275 - val_specificity: 0.9275 - val_balacc: 0.9275\n",
      "Epoch 229/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1292 - tp: 21644.0000 - fp: 1156.0000 - tn: 21644.0000 - fn: 1156.0000 - accuracy: 0.9493 train_balacc 0.9490915251365889\n",
      " val_balacc 0.9244451973572759\n",
      "\n",
      "Epoch 229: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1288 - tp: 22409.0000 - fp: 1202.0000 - tn: 22409.0000 - fn: 1202.0000 - accuracy: 0.9491 - val_loss: 0.1736 - val_tp: 5457.0000 - val_fp: 446.0000 - val_tn: 5457.0000 - val_fn: 446.0000 - val_accuracy: 0.9244 - train_sensitivity: 0.9491 - train_specificity: 0.9491 - train_balacc: 0.9491 - val_sensitivity: 0.9244 - val_specificity: 0.9244 - val_balacc: 0.9244\n",
      "Epoch 230/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1360 - tp: 21785.0000 - fp: 1215.0000 - tn: 21785.0000 - fn: 1215.0000 - accuracy: 0.9472 train_balacc 0.9473126932362035\n",
      " val_balacc 0.9274944943249195\n",
      "\n",
      "Epoch 230: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1355 - tp: 22367.0000 - fp: 1244.0000 - tn: 22367.0000 - fn: 1244.0000 - accuracy: 0.9473 - val_loss: 0.1805 - val_tp: 5475.0000 - val_fp: 428.0000 - val_tn: 5475.0000 - val_fn: 428.0000 - val_accuracy: 0.9275 - train_sensitivity: 0.9473 - train_specificity: 0.9473 - train_balacc: 0.9473 - val_sensitivity: 0.9275 - val_specificity: 0.9275 - val_balacc: 0.9275\n",
      "Epoch 231/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1293 - tp: 21814.0000 - fp: 1186.0000 - tn: 21814.0000 - fn: 1186.0000 - accuracy: 0.9484 train_balacc 0.9486256405912499\n",
      " val_balacc 0.9278333050991021\n",
      "\n",
      "Epoch 231: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1291 - tp: 22398.0000 - fp: 1213.0000 - tn: 22398.0000 - fn: 1213.0000 - accuracy: 0.9486 - val_loss: 0.1780 - val_tp: 5477.0000 - val_fp: 426.0000 - val_tn: 5477.0000 - val_fn: 426.0000 - val_accuracy: 0.9278 - train_sensitivity: 0.9486 - train_specificity: 0.9486 - train_balacc: 0.9486 - val_sensitivity: 0.9278 - val_specificity: 0.9278 - val_balacc: 0.9278\n",
      "Epoch 232/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1331 - tp: 21611.0000 - fp: 1189.0000 - tn: 21611.0000 - fn: 1189.0000 - accuracy: 0.9479 train_balacc 0.9476938715005717\n",
      " val_balacc 0.8319498560054209\n",
      "\n",
      "Epoch 232: val_balacc did not improve from 0.95697\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1337 - tp: 22376.0000 - fp: 1235.0000 - tn: 22376.0000 - fn: 1235.0000 - accuracy: 0.9477 - val_loss: 0.6037 - val_tp: 4911.0000 - val_fp: 992.0000 - val_tn: 4911.0000 - val_fn: 992.0000 - val_accuracy: 0.8319 - train_sensitivity: 0.9477 - train_specificity: 0.9477 - train_balacc: 0.9477 - val_sensitivity: 0.8319 - val_specificity: 0.8319 - val_balacc: 0.8319\n",
      "Size of the training fold is 23611\n",
      "Size of the validation fold is 5903\n",
      "Class imbalance in Train is 0.46%\n",
      "Class imbalance in Validation is 0.46%\n",
      "Epoch 1/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1623 - tp: 22188.0000 - fp: 1412.0000 - tn: 22188.0000 - fn: 1412.0000 - accuracy: 0.9402 train_balacc 0.9401550124941764\n",
      " val_balacc 0.9136032525834321\n",
      "\n",
      "Epoch 1: val_balacc improved from -inf to 0.91360, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1625 - tp: 22198.0000 - fp: 1413.0000 - tn: 22198.0000 - fn: 1413.0000 - accuracy: 0.9402 - val_loss: 0.2270 - val_tp: 5393.0000 - val_fp: 510.0000 - val_tn: 5393.0000 - val_fn: 510.0000 - val_accuracy: 0.9136 - train_sensitivity: 0.9402 - train_specificity: 0.9402 - train_balacc: 0.9402 - val_sensitivity: 0.9136 - val_specificity: 0.9136 - val_balacc: 0.9136\n",
      "Epoch 2/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1607 - tp: 21532.0000 - fp: 1468.0000 - tn: 21532.0000 - fn: 1468.0000 - accuracy: 0.9362 train_balacc 0.9363432298504935\n",
      " val_balacc 0.9332542774860241\n",
      "\n",
      "Epoch 2: val_balacc improved from 0.91360 to 0.93325, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1604 - tp: 22108.0000 - fp: 1503.0000 - tn: 22108.0000 - fn: 1503.0000 - accuracy: 0.9363 - val_loss: 0.1502 - val_tp: 5509.0000 - val_fp: 394.0000 - val_tn: 5509.0000 - val_fn: 394.0000 - val_accuracy: 0.9333 - train_sensitivity: 0.9363 - train_specificity: 0.9363 - train_balacc: 0.9363 - val_sensitivity: 0.9333 - val_specificity: 0.9333 - val_balacc: 0.9333\n",
      "Epoch 3/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1603 - tp: 21957.0000 - fp: 1443.0000 - tn: 21957.0000 - fn: 1443.0000 - accuracy: 0.9383 train_balacc 0.9385032400152471\n",
      " val_balacc 0.9674741656784686\n",
      "\n",
      "Epoch 3: val_balacc improved from 0.93325 to 0.96747, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1600 - tp: 22159.0000 - fp: 1452.0000 - tn: 22159.0000 - fn: 1452.0000 - accuracy: 0.9385 - val_loss: 0.1204 - val_tp: 5711.0000 - val_fp: 192.0000 - val_tn: 5711.0000 - val_fn: 192.0000 - val_accuracy: 0.9675 - train_sensitivity: 0.9385 - train_specificity: 0.9385 - train_balacc: 0.9385 - val_sensitivity: 0.9675 - val_specificity: 0.9675 - val_balacc: 0.9675\n",
      "Epoch 4/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1535 - tp: 21883.0000 - fp: 1417.0000 - tn: 21883.0000 - fn: 1417.0000 - accuracy: 0.9392 train_balacc 0.9393503028249545\n",
      " val_balacc 0.9318990343892936\n",
      "\n",
      "Epoch 4: val_balacc did not improve from 0.96747\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1529 - tp: 22179.0000 - fp: 1432.0000 - tn: 22179.0000 - fn: 1432.0000 - accuracy: 0.9394 - val_loss: 0.1481 - val_tp: 5501.0000 - val_fp: 402.0000 - val_tn: 5501.0000 - val_fn: 402.0000 - val_accuracy: 0.9319 - train_sensitivity: 0.9394 - train_specificity: 0.9394 - train_balacc: 0.9394 - val_sensitivity: 0.9319 - val_specificity: 0.9319 - val_balacc: 0.9319\n",
      "Epoch 5/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1566 - tp: 21965.0000 - fp: 1435.0000 - tn: 21965.0000 - fn: 1435.0000 - accuracy: 0.9387 train_balacc 0.9389691245605861\n",
      " val_balacc 0.9530747077757072\n",
      "\n",
      "Epoch 5: val_balacc did not improve from 0.96747\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1559 - tp: 22170.0000 - fp: 1441.0000 - tn: 22170.0000 - fn: 1441.0000 - accuracy: 0.9390 - val_loss: 0.1293 - val_tp: 5626.0000 - val_fp: 277.0000 - val_tn: 5626.0000 - val_fn: 277.0000 - val_accuracy: 0.9531 - train_sensitivity: 0.9390 - train_specificity: 0.9390 - train_balacc: 0.9390 - val_sensitivity: 0.9531 - val_specificity: 0.9531 - val_balacc: 0.9531\n",
      "Epoch 6/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1581 - tp: 21561.0000 - fp: 1439.0000 - tn: 21561.0000 - fn: 1439.0000 - accuracy: 0.9374 train_balacc 0.937444411503113\n",
      " val_balacc 0.9608673555819075\n",
      "\n",
      "Epoch 6: val_balacc did not improve from 0.96747\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1577 - tp: 22134.0000 - fp: 1477.0000 - tn: 22134.0000 - fn: 1477.0000 - accuracy: 0.9374 - val_loss: 0.1302 - val_tp: 5672.0000 - val_fp: 231.0000 - val_tn: 5672.0000 - val_fn: 231.0000 - val_accuracy: 0.9609 - train_sensitivity: 0.9374 - train_specificity: 0.9374 - train_balacc: 0.9374 - val_sensitivity: 0.9609 - val_specificity: 0.9609 - val_balacc: 0.9609\n",
      "Epoch 7/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1507 - tp: 21544.0000 - fp: 1356.0000 - tn: 21544.0000 - fn: 1356.0000 - accuracy: 0.9408 train_balacc 0.9408326627419423\n",
      " val_balacc 0.8082331018126376\n",
      "\n",
      "Epoch 7: val_balacc did not improve from 0.96747\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1502 - tp: 22214.0000 - fp: 1397.0000 - tn: 22214.0000 - fn: 1397.0000 - accuracy: 0.9408 - val_loss: 0.6678 - val_tp: 4771.0000 - val_fp: 1132.0000 - val_tn: 4771.0000 - val_fn: 1132.0000 - val_accuracy: 0.8082 - train_sensitivity: 0.9408 - train_specificity: 0.9408 - train_balacc: 0.9408 - val_sensitivity: 0.8082 - val_specificity: 0.8082 - val_balacc: 0.8082\n",
      "Epoch 8/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1553 - tp: 21873.0000 - fp: 1427.0000 - tn: 21873.0000 - fn: 1427.0000 - accuracy: 0.9388 train_balacc 0.9388844182796154\n",
      " val_balacc 0.9778078942910384\n",
      "\n",
      "Epoch 8: val_balacc improved from 0.96747 to 0.97781, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1547 - tp: 22168.0000 - fp: 1443.0000 - tn: 22168.0000 - fn: 1443.0000 - accuracy: 0.9389 - val_loss: 0.0812 - val_tp: 5772.0000 - val_fp: 131.0000 - val_tn: 5772.0000 - val_fn: 131.0000 - val_accuracy: 0.9778 - train_sensitivity: 0.9389 - train_specificity: 0.9389 - train_balacc: 0.9389 - val_sensitivity: 0.9778 - val_specificity: 0.9778 - val_balacc: 0.9778\n",
      "Epoch 9/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1541 - tp: 21870.0000 - fp: 1430.0000 - tn: 21870.0000 - fn: 1430.0000 - accuracy: 0.9386 train_balacc 0.9389691245605861\n",
      " val_balacc 0.9427409791631374\n",
      "\n",
      "Epoch 9: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1536 - tp: 22170.0000 - fp: 1441.0000 - tn: 22170.0000 - fn: 1441.0000 - accuracy: 0.9390 - val_loss: 0.1488 - val_tp: 5565.0000 - val_fp: 338.0000 - val_tn: 5565.0000 - val_fn: 338.0000 - val_accuracy: 0.9427 - train_sensitivity: 0.9390 - train_specificity: 0.9390 - train_balacc: 0.9390 - val_sensitivity: 0.9427 - val_specificity: 0.9427 - val_balacc: 0.9427\n",
      "Epoch 10/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1500 - tp: 21746.0000 - fp: 1354.0000 - tn: 21746.0000 - fn: 1354.0000 - accuracy: 0.9414 train_balacc 0.9410867815848545\n",
      " val_balacc 0.9017448754870405\n",
      "\n",
      "Epoch 10: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1506 - tp: 22220.0000 - fp: 1391.0000 - tn: 22220.0000 - fn: 1391.0000 - accuracy: 0.9411 - val_loss: 0.2176 - val_tp: 5323.0000 - val_fp: 580.0000 - val_tn: 5323.0000 - val_fn: 580.0000 - val_accuracy: 0.9017 - train_sensitivity: 0.9411 - train_specificity: 0.9411 - train_balacc: 0.9411 - val_sensitivity: 0.9017 - val_specificity: 0.9017 - val_balacc: 0.9017\n",
      "Epoch 11/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1495 - tp: 22213.0000 - fp: 1398.0000 - tn: 22213.0000 - fn: 1398.0000 - accuracy: 0.9408 train_balacc 0.9407903096014569\n",
      " val_balacc 0.9468067084533288\n",
      "\n",
      "Epoch 11: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1495 - tp: 22213.0000 - fp: 1398.0000 - tn: 22213.0000 - fn: 1398.0000 - accuracy: 0.9408 - val_loss: 0.1404 - val_tp: 5589.0000 - val_fp: 314.0000 - val_tn: 5589.0000 - val_fn: 314.0000 - val_accuracy: 0.9468 - train_sensitivity: 0.9408 - train_specificity: 0.9408 - train_balacc: 0.9408 - val_sensitivity: 0.9468 - val_specificity: 0.9468 - val_balacc: 0.9468\n",
      "Epoch 12/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1474 - tp: 21610.0000 - fp: 1390.0000 - tn: 21610.0000 - fn: 1390.0000 - accuracy: 0.9396 train_balacc 0.9397314810893228\n",
      " val_balacc 0.9191936303574454\n",
      "\n",
      "Epoch 12: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1469 - tp: 22188.0000 - fp: 1423.0000 - tn: 22188.0000 - fn: 1423.0000 - accuracy: 0.9397 - val_loss: 0.1750 - val_tp: 5426.0000 - val_fp: 477.0000 - val_tn: 5426.0000 - val_fn: 477.0000 - val_accuracy: 0.9192 - train_sensitivity: 0.9397 - train_specificity: 0.9397 - train_balacc: 0.9397 - val_sensitivity: 0.9192 - val_specificity: 0.9192 - val_balacc: 0.9192\n",
      "Epoch 13/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1502 - tp: 22115.0000 - fp: 1385.0000 - tn: 22115.0000 - fn: 1385.0000 - accuracy: 0.9411 train_balacc 0.9411714878658253\n",
      " val_balacc 0.9534135185498899\n",
      "\n",
      "Epoch 13: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1501 - tp: 22222.0000 - fp: 1389.0000 - tn: 22222.0000 - fn: 1389.0000 - accuracy: 0.9412 - val_loss: 0.1227 - val_tp: 5628.0000 - val_fp: 275.0000 - val_tn: 5628.0000 - val_fn: 275.0000 - val_accuracy: 0.9534 - train_sensitivity: 0.9412 - train_specificity: 0.9412 - train_balacc: 0.9412 - val_sensitivity: 0.9534 - val_specificity: 0.9534 - val_balacc: 0.9534\n",
      "Epoch 14/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1473 - tp: 22266.0000 - fp: 1345.0000 - tn: 22266.0000 - fn: 1345.0000 - accuracy: 0.9430 train_balacc 0.9430350260471814\n",
      " val_balacc 0.9415551414534982\n",
      "\n",
      "Epoch 14: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1473 - tp: 22266.0000 - fp: 1345.0000 - tn: 22266.0000 - fn: 1345.0000 - accuracy: 0.9430 - val_loss: 0.1366 - val_tp: 5558.0000 - val_fp: 345.0000 - val_tn: 5558.0000 - val_fn: 345.0000 - val_accuracy: 0.9416 - train_sensitivity: 0.9430 - train_specificity: 0.9430 - train_balacc: 0.9430 - val_sensitivity: 0.9416 - val_specificity: 0.9416 - val_balacc: 0.9416\n",
      "Epoch 15/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1488 - tp: 22077.0000 - fp: 1423.0000 - tn: 22077.0000 - fn: 1423.0000 - accuracy: 0.9394 train_balacc 0.9393503028249545\n",
      " val_balacc 0.9561240047433508\n",
      "\n",
      "Epoch 15: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1489 - tp: 22179.0000 - fp: 1432.0000 - tn: 22179.0000 - fn: 1432.0000 - accuracy: 0.9394 - val_loss: 0.1159 - val_tp: 5644.0000 - val_fp: 259.0000 - val_tn: 5644.0000 - val_fn: 259.0000 - val_accuracy: 0.9561 - train_sensitivity: 0.9394 - train_specificity: 0.9394 - train_balacc: 0.9394 - val_sensitivity: 0.9561 - val_specificity: 0.9561 - val_balacc: 0.9561\n",
      "Epoch 16/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1458 - tp: 21634.0000 - fp: 1366.0000 - tn: 21634.0000 - fn: 1366.0000 - accuracy: 0.9406 train_balacc 0.9405361907585448\n",
      " val_balacc 0.9637472471624597\n",
      "\n",
      "Epoch 16: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1459 - tp: 22207.0000 - fp: 1404.0000 - tn: 22207.0000 - fn: 1404.0000 - accuracy: 0.9405 - val_loss: 0.1085 - val_tp: 5689.0000 - val_fp: 214.0000 - val_tn: 5689.0000 - val_fn: 214.0000 - val_accuracy: 0.9637 - train_sensitivity: 0.9405 - train_specificity: 0.9405 - train_balacc: 0.9405 - val_sensitivity: 0.9637 - val_specificity: 0.9637 - val_balacc: 0.9637\n",
      "Epoch 17/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1491 - tp: 21645.0000 - fp: 1355.0000 - tn: 21645.0000 - fn: 1355.0000 - accuracy: 0.9411 train_balacc 0.9408750158824277\n",
      " val_balacc 0.9291885481958326\n",
      "\n",
      "Epoch 17: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1492 - tp: 22215.0000 - fp: 1396.0000 - tn: 22215.0000 - fn: 1396.0000 - accuracy: 0.9409 - val_loss: 0.1685 - val_tp: 5485.0000 - val_fp: 418.0000 - val_tn: 5485.0000 - val_fn: 418.0000 - val_accuracy: 0.9292 - train_sensitivity: 0.9409 - train_specificity: 0.9409 - train_balacc: 0.9409 - val_sensitivity: 0.9292 - val_specificity: 0.9292 - val_balacc: 0.9292\n",
      "Epoch 18/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1502 - tp: 22187.0000 - fp: 1424.0000 - tn: 22187.0000 - fn: 1424.0000 - accuracy: 0.9397 train_balacc 0.9396891279488374\n",
      " val_balacc 0.9701846518719295\n",
      "\n",
      "Epoch 18: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1502 - tp: 22187.0000 - fp: 1424.0000 - tn: 22187.0000 - fn: 1424.0000 - accuracy: 0.9397 - val_loss: 0.1088 - val_tp: 5727.0000 - val_fp: 176.0000 - val_tn: 5727.0000 - val_fn: 176.0000 - val_accuracy: 0.9702 - train_sensitivity: 0.9397 - train_specificity: 0.9397 - train_balacc: 0.9397 - val_sensitivity: 0.9702 - val_specificity: 0.9702 - val_balacc: 0.9702\n",
      "Epoch 19/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1521 - tp: 21613.0000 - fp: 1387.0000 - tn: 21613.0000 - fn: 1387.0000 - accuracy: 0.9397 train_balacc 0.9400279530727204\n",
      " val_balacc 0.9510418431306116\n",
      "\n",
      "Epoch 19: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1518 - tp: 22195.0000 - fp: 1416.0000 - tn: 22195.0000 - fn: 1416.0000 - accuracy: 0.9400 - val_loss: 0.1281 - val_tp: 5614.0000 - val_fp: 289.0000 - val_tn: 5614.0000 - val_fn: 289.0000 - val_accuracy: 0.9510 - train_sensitivity: 0.9400 - train_specificity: 0.9400 - train_balacc: 0.9400 - val_sensitivity: 0.9510 - val_specificity: 0.9510 - val_balacc: 0.9510\n",
      "Epoch 20/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1440 - tp: 21747.0000 - fp: 1353.0000 - tn: 21747.0000 - fn: 1353.0000 - accuracy: 0.9414 train_balacc 0.9413409004277667\n",
      " val_balacc 0.9657801118075555\n",
      "\n",
      "Epoch 20: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1449 - tp: 22226.0000 - fp: 1385.0000 - tn: 22226.0000 - fn: 1385.0000 - accuracy: 0.9413 - val_loss: 0.1111 - val_tp: 5701.0000 - val_fp: 202.0000 - val_tn: 5701.0000 - val_fn: 202.0000 - val_accuracy: 0.9658 - train_sensitivity: 0.9413 - train_specificity: 0.9413 - train_balacc: 0.9413 - val_sensitivity: 0.9658 - val_specificity: 0.9658 - val_balacc: 0.9658\n",
      "Epoch 21/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1494 - tp: 21705.0000 - fp: 1395.0000 - tn: 21705.0000 - fn: 1395.0000 - accuracy: 0.9396 train_balacc 0.939646774808352\n",
      " val_balacc 0.9579874640013553\n",
      "\n",
      "Epoch 21: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1489 - tp: 22186.0000 - fp: 1425.0000 - tn: 22186.0000 - fn: 1425.0000 - accuracy: 0.9396 - val_loss: 0.1170 - val_tp: 5655.0000 - val_fp: 248.0000 - val_tn: 5655.0000 - val_fn: 248.0000 - val_accuracy: 0.9580 - train_sensitivity: 0.9396 - train_specificity: 0.9396 - train_balacc: 0.9396 - val_sensitivity: 0.9580 - val_specificity: 0.9580 - val_balacc: 0.9580\n",
      "Epoch 22/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1474 - tp: 21709.0000 - fp: 1291.0000 - tn: 21709.0000 - fn: 1291.0000 - accuracy: 0.9439 train_balacc 0.9436703231544619\n",
      " val_balacc 0.9398610875825851\n",
      "\n",
      "Epoch 22: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1474 - tp: 22281.0000 - fp: 1330.0000 - tn: 22281.0000 - fn: 1330.0000 - accuracy: 0.9437 - val_loss: 0.1862 - val_tp: 5548.0000 - val_fp: 355.0000 - val_tn: 5548.0000 - val_fn: 355.0000 - val_accuracy: 0.9399 - train_sensitivity: 0.9437 - train_specificity: 0.9437 - train_balacc: 0.9437 - val_sensitivity: 0.9399 - val_specificity: 0.9399 - val_balacc: 0.9399\n",
      "Epoch 23/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1474 - tp: 22226.0000 - fp: 1374.0000 - tn: 22226.0000 - fn: 1374.0000 - accuracy: 0.9418 train_balacc 0.941722078692135\n",
      " val_balacc 0.9158055226156192\n",
      "\n",
      "Epoch 23: val_balacc did not improve from 0.97781\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1475 - tp: 22235.0000 - fp: 1376.0000 - tn: 22235.0000 - fn: 1376.0000 - accuracy: 0.9417 - val_loss: 0.1734 - val_tp: 5406.0000 - val_fp: 497.0000 - val_tn: 5406.0000 - val_fn: 497.0000 - val_accuracy: 0.9158 - train_sensitivity: 0.9417 - train_specificity: 0.9417 - train_balacc: 0.9417 - val_sensitivity: 0.9158 - val_specificity: 0.9158 - val_balacc: 0.9158\n",
      "Epoch 24/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1484 - tp: 21896.0000 - fp: 1404.0000 - tn: 21896.0000 - fn: 1404.0000 - accuracy: 0.9397 train_balacc 0.939180890263013\n",
      " val_balacc 0.9784855158394037\n",
      "\n",
      "Epoch 24: val_balacc improved from 0.97781 to 0.97849, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1489 - tp: 22175.0000 - fp: 1436.0000 - tn: 22175.0000 - fn: 1436.0000 - accuracy: 0.9392 - val_loss: 0.0837 - val_tp: 5776.0000 - val_fp: 127.0000 - val_tn: 5776.0000 - val_fn: 127.0000 - val_accuracy: 0.9785 - train_sensitivity: 0.9392 - train_specificity: 0.9392 - train_balacc: 0.9392 - val_sensitivity: 0.9785 - val_specificity: 0.9785 - val_balacc: 0.9785\n",
      "Epoch 25/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1443 - tp: 21856.0000 - fp: 1344.0000 - tn: 21856.0000 - fn: 1344.0000 - accuracy: 0.9421 train_balacc 0.9419761975350472\n",
      " val_balacc 0.8522785024563782\n",
      "\n",
      "Epoch 25: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1447 - tp: 22241.0000 - fp: 1370.0000 - tn: 22241.0000 - fn: 1370.0000 - accuracy: 0.9420 - val_loss: 0.3730 - val_tp: 5031.0000 - val_fp: 872.0000 - val_tn: 5031.0000 - val_fn: 872.0000 - val_accuracy: 0.8523 - train_sensitivity: 0.9420 - train_specificity: 0.9420 - train_balacc: 0.9420 - val_sensitivity: 0.8523 - val_specificity: 0.8523 - val_balacc: 0.8523\n",
      "Epoch 26/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1478 - tp: 21613.0000 - fp: 1387.0000 - tn: 21613.0000 - fn: 1387.0000 - accuracy: 0.9397 train_balacc 0.9394773622464105\n",
      " val_balacc 0.972048111129934\n",
      "\n",
      "Epoch 26: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1490 - tp: 22182.0000 - fp: 1429.0000 - tn: 22182.0000 - fn: 1429.0000 - accuracy: 0.9395 - val_loss: 0.0838 - val_tp: 5738.0000 - val_fp: 165.0000 - val_tn: 5738.0000 - val_fn: 165.0000 - val_accuracy: 0.9720 - train_sensitivity: 0.9395 - train_specificity: 0.9395 - train_balacc: 0.9395 - val_sensitivity: 0.9720 - val_specificity: 0.9720 - val_balacc: 0.9720\n",
      "Epoch 27/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1417 - tp: 21918.0000 - fp: 1282.0000 - tn: 21918.0000 - fn: 1282.0000 - accuracy: 0.9447 train_balacc 0.9448985642285376\n",
      " val_balacc 0.8827714721328138\n",
      "\n",
      "Epoch 27: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1420 - tp: 22310.0000 - fp: 1301.0000 - tn: 22310.0000 - fn: 1301.0000 - accuracy: 0.9449 - val_loss: 0.2480 - val_tp: 5211.0000 - val_fp: 692.0000 - val_tn: 5211.0000 - val_fn: 692.0000 - val_accuracy: 0.8828 - train_sensitivity: 0.9449 - train_specificity: 0.9449 - train_balacc: 0.9449 - val_sensitivity: 0.8828 - val_specificity: 0.8828 - val_balacc: 0.8828\n",
      "Epoch 28/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1440 - tp: 21777.0000 - fp: 1323.0000 - tn: 21777.0000 - fn: 1323.0000 - accuracy: 0.9427 train_balacc 0.9426114946423277\n",
      " val_balacc 0.9676435710655599\n",
      "\n",
      "Epoch 28: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1444 - tp: 22256.0000 - fp: 1355.0000 - tn: 22256.0000 - fn: 1355.0000 - accuracy: 0.9426 - val_loss: 0.1100 - val_tp: 5712.0000 - val_fp: 191.0000 - val_tn: 5712.0000 - val_fn: 191.0000 - val_accuracy: 0.9676 - train_sensitivity: 0.9426 - train_specificity: 0.9426 - train_balacc: 0.9426 - val_sensitivity: 0.9676 - val_specificity: 0.9676 - val_balacc: 0.9676\n",
      "Epoch 29/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1456 - tp: 21757.0000 - fp: 1343.0000 - tn: 21757.0000 - fn: 1343.0000 - accuracy: 0.9419 train_balacc 0.9421879632374741\n",
      " val_balacc 0.9481619515500593\n",
      "\n",
      "Epoch 29: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1451 - tp: 22246.0000 - fp: 1365.0000 - tn: 22246.0000 - fn: 1365.0000 - accuracy: 0.9422 - val_loss: 0.1461 - val_tp: 5597.0000 - val_fp: 306.0000 - val_tn: 5597.0000 - val_fn: 306.0000 - val_accuracy: 0.9482 - train_sensitivity: 0.9422 - train_specificity: 0.9422 - train_balacc: 0.9422 - val_sensitivity: 0.9482 - val_specificity: 0.9482 - val_balacc: 0.9482\n",
      "Epoch 30/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1505 - tp: 21632.0000 - fp: 1368.0000 - tn: 21632.0000 - fn: 1368.0000 - accuracy: 0.9405 train_balacc 0.9403667781966033\n",
      " val_balacc 0.9278333050991021\n",
      "\n",
      "Epoch 30: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1506 - tp: 22203.0000 - fp: 1408.0000 - tn: 22203.0000 - fn: 1408.0000 - accuracy: 0.9404 - val_loss: 0.1853 - val_tp: 5477.0000 - val_fp: 426.0000 - val_tn: 5477.0000 - val_fn: 426.0000 - val_accuracy: 0.9278 - train_sensitivity: 0.9404 - train_specificity: 0.9404 - train_balacc: 0.9404 - val_sensitivity: 0.9278 - val_specificity: 0.9278 - val_balacc: 0.9278\n",
      "Epoch 31/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1418 - tp: 21837.0000 - fp: 1363.0000 - tn: 21837.0000 - fn: 1363.0000 - accuracy: 0.9413 train_balacc 0.9412985472872814\n",
      " val_balacc 0.8920887684228358\n",
      "\n",
      "Epoch 31: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1416 - tp: 22225.0000 - fp: 1386.0000 - tn: 22225.0000 - fn: 1386.0000 - accuracy: 0.9413 - val_loss: 0.2341 - val_tp: 5266.0000 - val_fp: 637.0000 - val_tn: 5266.0000 - val_fn: 637.0000 - val_accuracy: 0.8921 - train_sensitivity: 0.9413 - train_specificity: 0.9413 - train_balacc: 0.9413 - val_sensitivity: 0.8921 - val_specificity: 0.8921 - val_balacc: 0.8921\n",
      "Epoch 32/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1415 - tp: 21520.0000 - fp: 1280.0000 - tn: 21520.0000 - fn: 1280.0000 - accuracy: 0.9439 train_balacc 0.9434585574520351\n",
      " val_balacc 0.9634084363882771\n",
      "\n",
      "Epoch 32: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1428 - tp: 22276.0000 - fp: 1335.0000 - tn: 22276.0000 - fn: 1335.0000 - accuracy: 0.9435 - val_loss: 0.1141 - val_tp: 5687.0000 - val_fp: 216.0000 - val_tn: 5687.0000 - val_fn: 216.0000 - val_accuracy: 0.9634 - train_sensitivity: 0.9435 - train_specificity: 0.9435 - train_balacc: 0.9435 - val_sensitivity: 0.9634 - val_specificity: 0.9634 - val_balacc: 0.9634\n",
      "Epoch 33/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1347 - tp: 22372.0000 - fp: 1239.0000 - tn: 22372.0000 - fn: 1239.0000 - accuracy: 0.9475 train_balacc 0.9475244589386304\n",
      " val_balacc 0.8258512620701338\n",
      "\n",
      "Epoch 33: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1347 - tp: 22372.0000 - fp: 1239.0000 - tn: 22372.0000 - fn: 1239.0000 - accuracy: 0.9475 - val_loss: 0.4913 - val_tp: 4875.0000 - val_fp: 1028.0000 - val_tn: 4875.0000 - val_fn: 1028.0000 - val_accuracy: 0.8259 - train_sensitivity: 0.9475 - train_specificity: 0.9475 - train_balacc: 0.9475 - val_sensitivity: 0.8259 - val_specificity: 0.8259 - val_balacc: 0.8259\n",
      "Epoch 34/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1423 - tp: 21579.0000 - fp: 1321.0000 - tn: 21579.0000 - fn: 1321.0000 - accuracy: 0.9423 train_balacc 0.942526788361357\n",
      " val_balacc 0.9588344909368118\n",
      "\n",
      "Epoch 34: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1425 - tp: 22254.0000 - fp: 1357.0000 - tn: 22254.0000 - fn: 1357.0000 - accuracy: 0.9425 - val_loss: 0.1074 - val_tp: 5660.0000 - val_fp: 243.0000 - val_tn: 5660.0000 - val_fn: 243.0000 - val_accuracy: 0.9588 - train_sensitivity: 0.9425 - train_specificity: 0.9425 - train_balacc: 0.9425 - val_sensitivity: 0.9588 - val_specificity: 0.9588 - val_balacc: 0.9588\n",
      "Epoch 35/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1410 - tp: 22315.0000 - fp: 1296.0000 - tn: 22315.0000 - fn: 1296.0000 - accuracy: 0.9451 train_balacc 0.9451103299309643\n",
      " val_balacc 0.9593427070980857\n",
      "\n",
      "Epoch 35: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1410 - tp: 22315.0000 - fp: 1296.0000 - tn: 22315.0000 - fn: 1296.0000 - accuracy: 0.9451 - val_loss: 0.1295 - val_tp: 5663.0000 - val_fp: 240.0000 - val_tn: 5663.0000 - val_fn: 240.0000 - val_accuracy: 0.9593 - train_sensitivity: 0.9451 - train_specificity: 0.9451 - train_balacc: 0.9451 - val_sensitivity: 0.9593 - val_specificity: 0.9593 - val_balacc: 0.9593\n",
      "Epoch 36/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1424 - tp: 22281.0000 - fp: 1319.0000 - tn: 22281.0000 - fn: 1319.0000 - accuracy: 0.9441 train_balacc 0.9441362076998009\n",
      " val_balacc 0.9535829239369812\n",
      "\n",
      "Epoch 36: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1424 - tp: 22292.0000 - fp: 1319.0000 - tn: 22292.0000 - fn: 1319.0000 - accuracy: 0.9441 - val_loss: 0.1284 - val_tp: 5629.0000 - val_fp: 274.0000 - val_tn: 5629.0000 - val_fn: 274.0000 - val_accuracy: 0.9536 - train_sensitivity: 0.9441 - train_specificity: 0.9441 - train_balacc: 0.9441 - val_sensitivity: 0.9536 - val_specificity: 0.9536 - val_balacc: 0.9536\n",
      "Epoch 37/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1404 - tp: 21867.0000 - fp: 1333.0000 - tn: 21867.0000 - fn: 1333.0000 - accuracy: 0.9425 train_balacc 0.9427385540637838\n",
      " val_balacc 0.9639166525495511\n",
      "\n",
      "Epoch 37: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1400 - tp: 22259.0000 - fp: 1352.0000 - tn: 22259.0000 - fn: 1352.0000 - accuracy: 0.9427 - val_loss: 0.1026 - val_tp: 5690.0000 - val_fp: 213.0000 - val_tn: 5690.0000 - val_fn: 213.0000 - val_accuracy: 0.9639 - train_sensitivity: 0.9427 - train_specificity: 0.9427 - train_balacc: 0.9427 - val_sensitivity: 0.9639 - val_specificity: 0.9639 - val_balacc: 0.9639\n",
      "Epoch 38/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1371 - tp: 21545.0000 - fp: 1255.0000 - tn: 21545.0000 - fn: 1255.0000 - accuracy: 0.9450 train_balacc 0.9448985642285376\n",
      " val_balacc 0.9490089784855158\n",
      "\n",
      "Epoch 38: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1373 - tp: 22310.0000 - fp: 1301.0000 - tn: 22310.0000 - fn: 1301.0000 - accuracy: 0.9449 - val_loss: 0.1444 - val_tp: 5602.0000 - val_fp: 301.0000 - val_tn: 5602.0000 - val_fn: 301.0000 - val_accuracy: 0.9490 - train_sensitivity: 0.9449 - train_specificity: 0.9449 - train_balacc: 0.9449 - val_sensitivity: 0.9490 - val_specificity: 0.9490 - val_balacc: 0.9490\n",
      "Epoch 39/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1425 - tp: 22191.0000 - fp: 1309.0000 - tn: 22191.0000 - fn: 1309.0000 - accuracy: 0.9443 train_balacc 0.9442632671212571\n",
      " val_balacc 0.8809080128748095\n",
      "\n",
      "Epoch 39: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1425 - tp: 22295.0000 - fp: 1316.0000 - tn: 22295.0000 - fn: 1316.0000 - accuracy: 0.9443 - val_loss: 0.2898 - val_tp: 5200.0000 - val_fp: 703.0000 - val_tn: 5200.0000 - val_fn: 703.0000 - val_accuracy: 0.8809 - train_sensitivity: 0.9443 - train_specificity: 0.9443 - train_balacc: 0.9443 - val_sensitivity: 0.8809 - val_specificity: 0.8809 - val_balacc: 0.8809\n",
      "Epoch 40/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1376 - tp: 21693.0000 - fp: 1307.0000 - tn: 21693.0000 - fn: 1307.0000 - accuracy: 0.9432 train_balacc 0.9429926729066961\n",
      " val_balacc 0.9588344909368118\n",
      "\n",
      "Epoch 40: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1387 - tp: 22265.0000 - fp: 1346.0000 - tn: 22265.0000 - fn: 1346.0000 - accuracy: 0.9430 - val_loss: 0.1062 - val_tp: 5660.0000 - val_fp: 243.0000 - val_tn: 5660.0000 - val_fn: 243.0000 - val_accuracy: 0.9588 - train_sensitivity: 0.9430 - train_specificity: 0.9430 - train_balacc: 0.9430 - val_sensitivity: 0.9588 - val_specificity: 0.9588 - val_balacc: 0.9588\n",
      "Epoch 41/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1394 - tp: 21753.0000 - fp: 1247.0000 - tn: 21753.0000 - fn: 1247.0000 - accuracy: 0.9458 train_balacc 0.9458303333192156\n",
      " val_balacc 0.9161443333898018\n",
      "\n",
      "Epoch 41: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1392 - tp: 22332.0000 - fp: 1279.0000 - tn: 22332.0000 - fn: 1279.0000 - accuracy: 0.9458 - val_loss: 0.2078 - val_tp: 5408.0000 - val_fp: 495.0000 - val_tn: 5408.0000 - val_fn: 495.0000 - val_accuracy: 0.9161 - train_sensitivity: 0.9458 - train_specificity: 0.9458 - train_balacc: 0.9458 - val_sensitivity: 0.9161 - val_specificity: 0.9161 - val_balacc: 0.9161\n",
      "Epoch 42/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1370 - tp: 21982.0000 - fp: 1218.0000 - tn: 21982.0000 - fn: 1218.0000 - accuracy: 0.9475 train_balacc 0.9473973995171742\n",
      " val_balacc 0.948500762324242\n",
      "\n",
      "Epoch 42: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1377 - tp: 22369.0000 - fp: 1242.0000 - tn: 22369.0000 - fn: 1242.0000 - accuracy: 0.9474 - val_loss: 0.1350 - val_tp: 5599.0000 - val_fp: 304.0000 - val_tn: 5599.0000 - val_fn: 304.0000 - val_accuracy: 0.9485 - train_sensitivity: 0.9474 - train_specificity: 0.9474 - train_balacc: 0.9474 - val_sensitivity: 0.9485 - val_specificity: 0.9485 - val_balacc: 0.9485\n",
      "Epoch 43/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1429 - tp: 22328.0000 - fp: 1272.0000 - tn: 22328.0000 - fn: 1272.0000 - accuracy: 0.9461 train_balacc 0.9461268053026132\n",
      " val_balacc 0.9662883279688295\n",
      "\n",
      "Epoch 43: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1429 - tp: 22339.0000 - fp: 1272.0000 - tn: 22339.0000 - fn: 1272.0000 - accuracy: 0.9461 - val_loss: 0.0891 - val_tp: 5704.0000 - val_fp: 199.0000 - val_tn: 5704.0000 - val_fn: 199.0000 - val_accuracy: 0.9663 - train_sensitivity: 0.9461 - train_specificity: 0.9461 - train_balacc: 0.9461 - val_sensitivity: 0.9663 - val_specificity: 0.9663 - val_balacc: 0.9663\n",
      "Epoch 44/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1442 - tp: 21907.0000 - fp: 1293.0000 - tn: 21907.0000 - fn: 1293.0000 - accuracy: 0.9443 train_balacc 0.9444750328236838\n",
      " val_balacc 0.9500254108080637\n",
      "\n",
      "Epoch 44: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1433 - tp: 22300.0000 - fp: 1311.0000 - tn: 22300.0000 - fn: 1311.0000 - accuracy: 0.9445 - val_loss: 0.1294 - val_tp: 5608.0000 - val_fp: 295.0000 - val_tn: 5608.0000 - val_fn: 295.0000 - val_accuracy: 0.9500 - train_sensitivity: 0.9445 - train_specificity: 0.9445 - train_balacc: 0.9445 - val_sensitivity: 0.9500 - val_specificity: 0.9500 - val_balacc: 0.9500\n",
      "Epoch 45/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1381 - tp: 21876.0000 - fp: 1224.0000 - tn: 21876.0000 - fn: 1224.0000 - accuracy: 0.9470 train_balacc 0.9470585743932912\n",
      " val_balacc 0.9667965441301033\n",
      "\n",
      "Epoch 45: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1376 - tp: 22361.0000 - fp: 1250.0000 - tn: 22361.0000 - fn: 1250.0000 - accuracy: 0.9471 - val_loss: 0.1012 - val_tp: 5707.0000 - val_fp: 196.0000 - val_tn: 5707.0000 - val_fn: 196.0000 - val_accuracy: 0.9668 - train_sensitivity: 0.9471 - train_specificity: 0.9471 - train_balacc: 0.9471 - val_sensitivity: 0.9668 - val_specificity: 0.9668 - val_balacc: 0.9668\n",
      "Epoch 46/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1371 - tp: 21547.0000 - fp: 1253.0000 - tn: 21547.0000 - fn: 1253.0000 - accuracy: 0.9450 train_balacc 0.9448562110880522\n",
      " val_balacc 0.9244451973572759\n",
      "\n",
      "Epoch 46: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1377 - tp: 22309.0000 - fp: 1302.0000 - tn: 22309.0000 - fn: 1302.0000 - accuracy: 0.9449 - val_loss: 0.1871 - val_tp: 5457.0000 - val_fp: 446.0000 - val_tn: 5457.0000 - val_fn: 446.0000 - val_accuracy: 0.9244 - train_sensitivity: 0.9449 - train_specificity: 0.9449 - train_balacc: 0.9449 - val_sensitivity: 0.9244 - val_specificity: 0.9244 - val_balacc: 0.9244\n",
      "Epoch 47/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1384 - tp: 21717.0000 - fp: 1283.0000 - tn: 21717.0000 - fn: 1283.0000 - accuracy: 0.9442 train_balacc 0.9445597391046546\n",
      " val_balacc 0.9456208707436896\n",
      "\n",
      "Epoch 47: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1382 - tp: 22302.0000 - fp: 1309.0000 - tn: 22302.0000 - fn: 1309.0000 - accuracy: 0.9446 - val_loss: 0.1265 - val_tp: 5582.0000 - val_fp: 321.0000 - val_tn: 5582.0000 - val_fn: 321.0000 - val_accuracy: 0.9456 - train_sensitivity: 0.9446 - train_specificity: 0.9446 - train_balacc: 0.9446 - val_sensitivity: 0.9456 - val_specificity: 0.9456 - val_balacc: 0.9456\n",
      "Epoch 48/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1345 - tp: 21809.0000 - fp: 1191.0000 - tn: 21809.0000 - fn: 1191.0000 - accuracy: 0.9482 train_balacc 0.9483715217483376\n",
      " val_balacc 0.8714213111976961\n",
      "\n",
      "Epoch 48: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1343 - tp: 22392.0000 - fp: 1219.0000 - tn: 22392.0000 - fn: 1219.0000 - accuracy: 0.9484 - val_loss: 0.4217 - val_tp: 5144.0000 - val_fp: 759.0000 - val_tn: 5144.0000 - val_fn: 759.0000 - val_accuracy: 0.8714 - train_sensitivity: 0.9484 - train_specificity: 0.9484 - train_balacc: 0.9484 - val_sensitivity: 0.8714 - val_specificity: 0.8714 - val_balacc: 0.8714\n",
      "Epoch 49/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1429 - tp: 22007.0000 - fp: 1293.0000 - tn: 22007.0000 - fn: 1293.0000 - accuracy: 0.9445 train_balacc 0.9443056202617424\n",
      " val_balacc 0.9549381670337117\n",
      "\n",
      "Epoch 49: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1436 - tp: 22296.0000 - fp: 1315.0000 - tn: 22296.0000 - fn: 1315.0000 - accuracy: 0.9443 - val_loss: 0.1205 - val_tp: 5637.0000 - val_fp: 266.0000 - val_tn: 5637.0000 - val_fn: 266.0000 - val_accuracy: 0.9549 - train_sensitivity: 0.9443 - train_specificity: 0.9443 - train_balacc: 0.9443 - val_sensitivity: 0.9549 - val_specificity: 0.9549 - val_balacc: 0.9549\n",
      "Epoch 50/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1352 - tp: 22388.0000 - fp: 1212.0000 - tn: 22388.0000 - fn: 1212.0000 - accuracy: 0.9486 train_balacc 0.9486679937317352\n",
      " val_balacc 0.9625614094528206\n",
      "\n",
      "Epoch 50: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1352 - tp: 22399.0000 - fp: 1212.0000 - tn: 22399.0000 - fn: 1212.0000 - accuracy: 0.9487 - val_loss: 0.1023 - val_tp: 5682.0000 - val_fp: 221.0000 - val_tn: 5682.0000 - val_fn: 221.0000 - val_accuracy: 0.9626 - train_sensitivity: 0.9487 - train_specificity: 0.9487 - train_balacc: 0.9487 - val_sensitivity: 0.9626 - val_specificity: 0.9626 - val_balacc: 0.9626\n",
      "Epoch 51/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1363 - tp: 21951.0000 - fp: 1249.0000 - tn: 21951.0000 - fn: 1249.0000 - accuracy: 0.9462 train_balacc 0.9457879801787302\n",
      " val_balacc 0.872437743520244\n",
      "\n",
      "Epoch 51: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1369 - tp: 22331.0000 - fp: 1280.0000 - tn: 22331.0000 - fn: 1280.0000 - accuracy: 0.9458 - val_loss: 0.3198 - val_tp: 5150.0000 - val_fp: 753.0000 - val_tn: 5150.0000 - val_fn: 753.0000 - val_accuracy: 0.8724 - train_sensitivity: 0.9458 - train_specificity: 0.9458 - train_balacc: 0.9458 - val_sensitivity: 0.8724 - val_specificity: 0.8724 - val_balacc: 0.8724\n",
      "Epoch 52/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1403 - tp: 21643.0000 - fp: 1257.0000 - tn: 21643.0000 - fn: 1257.0000 - accuracy: 0.9451 train_balacc 0.9452373893524205\n",
      " val_balacc 0.9125868202608843\n",
      "\n",
      "Epoch 52: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1397 - tp: 22318.0000 - fp: 1293.0000 - tn: 22318.0000 - fn: 1293.0000 - accuracy: 0.9452 - val_loss: 0.1962 - val_tp: 5387.0000 - val_fp: 516.0000 - val_tn: 5387.0000 - val_fn: 516.0000 - val_accuracy: 0.9126 - train_sensitivity: 0.9452 - train_specificity: 0.9452 - train_balacc: 0.9452 - val_sensitivity: 0.9126 - val_specificity: 0.9126 - val_balacc: 0.9126\n",
      "Epoch 53/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1394 - tp: 21945.0000 - fp: 1255.0000 - tn: 21945.0000 - fn: 1255.0000 - accuracy: 0.9459 train_balacc 0.9456609207572741\n",
      " val_balacc 0.9610367609689988\n",
      "\n",
      "Epoch 53: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1400 - tp: 22328.0000 - fp: 1283.0000 - tn: 22328.0000 - fn: 1283.0000 - accuracy: 0.9457 - val_loss: 0.1341 - val_tp: 5673.0000 - val_fp: 230.0000 - val_tn: 5673.0000 - val_fn: 230.0000 - val_accuracy: 0.9610 - train_sensitivity: 0.9457 - train_specificity: 0.9457 - train_balacc: 0.9457 - val_sensitivity: 0.9610 - val_specificity: 0.9610 - val_balacc: 0.9610\n",
      "Epoch 54/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1437 - tp: 22122.0000 - fp: 1278.0000 - tn: 22122.0000 - fn: 1278.0000 - accuracy: 0.9454 train_balacc 0.9454915081953327\n",
      " val_balacc 0.9562934101304421\n",
      "\n",
      "Epoch 54: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1434 - tp: 22324.0000 - fp: 1287.0000 - tn: 22324.0000 - fn: 1287.0000 - accuracy: 0.9455 - val_loss: 0.1165 - val_tp: 5645.0000 - val_fp: 258.0000 - val_tn: 5645.0000 - val_fn: 258.0000 - val_accuracy: 0.9563 - train_sensitivity: 0.9455 - train_specificity: 0.9455 - train_balacc: 0.9455 - val_sensitivity: 0.9563 - val_specificity: 0.9563 - val_balacc: 0.9563\n",
      "Epoch 55/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1331 - tp: 21673.0000 - fp: 1227.0000 - tn: 21673.0000 - fn: 1227.0000 - accuracy: 0.9464 train_balacc 0.9464232772860107\n",
      " val_balacc 0.9335930882602067\n",
      "\n",
      "Epoch 55: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1328 - tp: 22346.0000 - fp: 1265.0000 - tn: 22346.0000 - fn: 1265.0000 - accuracy: 0.9464 - val_loss: 0.1715 - val_tp: 5511.0000 - val_fp: 392.0000 - val_tn: 5511.0000 - val_fn: 392.0000 - val_accuracy: 0.9336 - train_sensitivity: 0.9464 - train_specificity: 0.9464 - train_balacc: 0.9464 - val_sensitivity: 0.9336 - val_specificity: 0.9336 - val_balacc: 0.9336\n",
      "Epoch 56/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1394 - tp: 21914.0000 - fp: 1286.0000 - tn: 21914.0000 - fn: 1286.0000 - accuracy: 0.9446 train_balacc 0.9448138579475668\n",
      " val_balacc 0.9696764357106556\n",
      "\n",
      "Epoch 56: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1388 - tp: 22308.0000 - fp: 1303.0000 - tn: 22308.0000 - fn: 1303.0000 - accuracy: 0.9448 - val_loss: 0.0973 - val_tp: 5724.0000 - val_fp: 179.0000 - val_tn: 5724.0000 - val_fn: 179.0000 - val_accuracy: 0.9697 - train_sensitivity: 0.9448 - train_specificity: 0.9448 - train_balacc: 0.9448 - val_sensitivity: 0.9697 - val_specificity: 0.9697 - val_balacc: 0.9697\n",
      "Epoch 57/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1315 - tp: 22076.0000 - fp: 1224.0000 - tn: 22076.0000 - fn: 1224.0000 - accuracy: 0.9475 train_balacc 0.9474397526576596\n",
      " val_balacc 0.8758258512620701\n",
      "\n",
      "Epoch 57: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1314 - tp: 22370.0000 - fp: 1241.0000 - tn: 22370.0000 - fn: 1241.0000 - accuracy: 0.9474 - val_loss: 0.3357 - val_tp: 5170.0000 - val_fp: 733.0000 - val_tn: 5170.0000 - val_fn: 733.0000 - val_accuracy: 0.8758 - train_sensitivity: 0.9474 - train_specificity: 0.9474 - train_balacc: 0.9474 - val_sensitivity: 0.8758 - val_specificity: 0.8758 - val_balacc: 0.8758\n",
      "Epoch 58/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1377 - tp: 21863.0000 - fp: 1237.0000 - tn: 21863.0000 - fn: 1237.0000 - accuracy: 0.9465 train_balacc 0.9464232772860107\n",
      " val_balacc 0.9393528714213112\n",
      "\n",
      "Epoch 58: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1384 - tp: 22346.0000 - fp: 1265.0000 - tn: 22346.0000 - fn: 1265.0000 - accuracy: 0.9464 - val_loss: 0.1542 - val_tp: 5545.0000 - val_fp: 358.0000 - val_tn: 5545.0000 - val_fn: 358.0000 - val_accuracy: 0.9394 - train_sensitivity: 0.9464 - train_specificity: 0.9464 - train_balacc: 0.9464 - val_sensitivity: 0.9394 - val_specificity: 0.9394 - val_balacc: 0.9394\n",
      "Epoch 59/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1321 - tp: 22275.0000 - fp: 1225.0000 - tn: 22275.0000 - fn: 1225.0000 - accuracy: 0.9479 train_balacc 0.9478632840625132\n",
      " val_balacc 0.957818058614264\n",
      "\n",
      "Epoch 59: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1321 - tp: 22380.0000 - fp: 1231.0000 - tn: 22380.0000 - fn: 1231.0000 - accuracy: 0.9479 - val_loss: 0.1052 - val_tp: 5654.0000 - val_fp: 249.0000 - val_tn: 5654.0000 - val_fn: 249.0000 - val_accuracy: 0.9578 - train_sensitivity: 0.9479 - train_specificity: 0.9479 - train_balacc: 0.9479 - val_sensitivity: 0.9578 - val_specificity: 0.9578 - val_balacc: 0.9578\n",
      "Epoch 60/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1444 - tp: 22103.0000 - fp: 1297.0000 - tn: 22103.0000 - fn: 1297.0000 - accuracy: 0.9446 train_balacc 0.94460209224514\n",
      " val_balacc 0.9659495171946468\n",
      "\n",
      "Epoch 60: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1444 - tp: 22303.0000 - fp: 1308.0000 - tn: 22303.0000 - fn: 1308.0000 - accuracy: 0.9446 - val_loss: 0.1072 - val_tp: 5702.0000 - val_fp: 201.0000 - val_tn: 5702.0000 - val_fn: 201.0000 - val_accuracy: 0.9659 - train_sensitivity: 0.9446 - train_specificity: 0.9446 - train_balacc: 0.9446 - val_sensitivity: 0.9659 - val_specificity: 0.9659 - val_balacc: 0.9659\n",
      "Epoch 61/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1345 - tp: 22341.0000 - fp: 1259.0000 - tn: 22341.0000 - fn: 1259.0000 - accuracy: 0.9467 train_balacc 0.9466350429884376\n",
      " val_balacc 0.9400304929696764\n",
      "\n",
      "Epoch 61: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1345 - tp: 22351.0000 - fp: 1260.0000 - tn: 22351.0000 - fn: 1260.0000 - accuracy: 0.9466 - val_loss: 0.1472 - val_tp: 5549.0000 - val_fp: 354.0000 - val_tn: 5549.0000 - val_fn: 354.0000 - val_accuracy: 0.9400 - train_sensitivity: 0.9466 - train_specificity: 0.9466 - train_balacc: 0.9466 - val_sensitivity: 0.9400 - val_specificity: 0.9400 - val_balacc: 0.9400\n",
      "Epoch 62/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1387 - tp: 21997.0000 - fp: 1203.0000 - tn: 21997.0000 - fn: 1203.0000 - accuracy: 0.9481 train_balacc 0.9484562280293084\n",
      " val_balacc 0.9329154667118414\n",
      "\n",
      "Epoch 62: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1382 - tp: 22394.0000 - fp: 1217.0000 - tn: 22394.0000 - fn: 1217.0000 - accuracy: 0.9485 - val_loss: 0.1782 - val_tp: 5507.0000 - val_fp: 396.0000 - val_tn: 5507.0000 - val_fn: 396.0000 - val_accuracy: 0.9329 - train_sensitivity: 0.9485 - train_specificity: 0.9485 - train_balacc: 0.9485 - val_sensitivity: 0.9329 - val_specificity: 0.9329 - val_balacc: 0.9329\n",
      "Epoch 63/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1269 - tp: 21847.0000 - fp: 1153.0000 - tn: 21847.0000 - fn: 1153.0000 - accuracy: 0.9499 train_balacc 0.9499809410867815\n",
      " val_balacc 0.9689988141622904\n",
      "\n",
      "Epoch 63: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1270 - tp: 22430.0000 - fp: 1181.0000 - tn: 22430.0000 - fn: 1181.0000 - accuracy: 0.9500 - val_loss: 0.0958 - val_tp: 5720.0000 - val_fp: 183.0000 - val_tn: 5720.0000 - val_fn: 183.0000 - val_accuracy: 0.9690 - train_sensitivity: 0.9500 - train_specificity: 0.9500 - train_balacc: 0.9500 - val_sensitivity: 0.9690 - val_specificity: 0.9690 - val_balacc: 0.9690\n",
      "Epoch 64/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1350 - tp: 21686.0000 - fp: 1214.0000 - tn: 21686.0000 - fn: 1214.0000 - accuracy: 0.9470 train_balacc 0.947143280674262\n",
      " val_balacc 0.938167033711672\n",
      "\n",
      "Epoch 64: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1347 - tp: 22363.0000 - fp: 1248.0000 - tn: 22363.0000 - fn: 1248.0000 - accuracy: 0.9471 - val_loss: 0.1425 - val_tp: 5538.0000 - val_fp: 365.0000 - val_tn: 5538.0000 - val_fn: 365.0000 - val_accuracy: 0.9382 - train_sensitivity: 0.9471 - train_specificity: 0.9471 - train_balacc: 0.9471 - val_sensitivity: 0.9382 - val_specificity: 0.9382 - val_balacc: 0.9382\n",
      "Epoch 65/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1275 - tp: 21796.0000 - fp: 1204.0000 - tn: 21796.0000 - fn: 1204.0000 - accuracy: 0.9477 train_balacc 0.947947990343484\n",
      " val_balacc 0.7743520243943758\n",
      "\n",
      "Epoch 65: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1271 - tp: 22382.0000 - fp: 1229.0000 - tn: 22382.0000 - fn: 1229.0000 - accuracy: 0.9479 - val_loss: 0.6907 - val_tp: 4571.0000 - val_fp: 1332.0000 - val_tn: 4571.0000 - val_fn: 1332.0000 - val_accuracy: 0.7744 - train_sensitivity: 0.9479 - train_specificity: 0.9479 - train_balacc: 0.9479 - val_sensitivity: 0.7744 - val_specificity: 0.7744 - val_balacc: 0.7744\n",
      "Epoch 66/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1320 - tp: 22197.0000 - fp: 1203.0000 - tn: 22197.0000 - fn: 1203.0000 - accuracy: 0.9486 train_balacc 0.9484985811697937\n",
      " val_balacc 0.8651533118753176\n",
      "\n",
      "Epoch 66: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1324 - tp: 22395.0000 - fp: 1216.0000 - tn: 22395.0000 - fn: 1216.0000 - accuracy: 0.9485 - val_loss: 0.3799 - val_tp: 5107.0000 - val_fp: 796.0000 - val_tn: 5107.0000 - val_fn: 796.0000 - val_accuracy: 0.8652 - train_sensitivity: 0.9485 - train_specificity: 0.9485 - train_balacc: 0.9485 - val_sensitivity: 0.8652 - val_specificity: 0.8652 - val_balacc: 0.8652\n",
      "Epoch 67/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1378 - tp: 21537.0000 - fp: 1263.0000 - tn: 21537.0000 - fn: 1263.0000 - accuracy: 0.9446 train_balacc 0.9447715048070815\n",
      " val_balacc 0.973742165000847\n",
      "\n",
      "Epoch 67: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1377 - tp: 22307.0000 - fp: 1304.0000 - tn: 22307.0000 - fn: 1304.0000 - accuracy: 0.9448 - val_loss: 0.0852 - val_tp: 5748.0000 - val_fp: 155.0000 - val_tn: 5748.0000 - val_fn: 155.0000 - val_accuracy: 0.9737 - train_sensitivity: 0.9448 - train_specificity: 0.9448 - train_balacc: 0.9448 - val_sensitivity: 0.9737 - val_specificity: 0.9737 - val_balacc: 0.9737\n",
      "Epoch 68/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1287 - tp: 21911.0000 - fp: 1189.0000 - tn: 21911.0000 - fn: 1189.0000 - accuracy: 0.9485 train_balacc 0.9485409343102791\n",
      " val_balacc 0.9749280027104862\n",
      "\n",
      "Epoch 68: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1286 - tp: 22396.0000 - fp: 1215.0000 - tn: 22396.0000 - fn: 1215.0000 - accuracy: 0.9485 - val_loss: 0.0889 - val_tp: 5755.0000 - val_fp: 148.0000 - val_tn: 5755.0000 - val_fn: 148.0000 - val_accuracy: 0.9749 - train_sensitivity: 0.9485 - train_specificity: 0.9485 - train_balacc: 0.9485 - val_sensitivity: 0.9749 - val_specificity: 0.9749 - val_balacc: 0.9749\n",
      "Epoch 69/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1319 - tp: 21588.0000 - fp: 1212.0000 - tn: 21588.0000 - fn: 1212.0000 - accuracy: 0.9468 train_balacc 0.9470162212528059\n",
      " val_balacc 0.9283415212603761\n",
      "\n",
      "Epoch 69: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1318 - tp: 22360.0000 - fp: 1251.0000 - tn: 22360.0000 - fn: 1251.0000 - accuracy: 0.9470 - val_loss: 0.1655 - val_tp: 5480.0000 - val_fp: 423.0000 - val_tn: 5480.0000 - val_fn: 423.0000 - val_accuracy: 0.9283 - train_sensitivity: 0.9470 - train_specificity: 0.9470 - train_balacc: 0.9470 - val_sensitivity: 0.9283 - val_specificity: 0.9283 - val_balacc: 0.9283\n",
      "Epoch 70/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1329 - tp: 21899.0000 - fp: 1201.0000 - tn: 21899.0000 - fn: 1201.0000 - accuracy: 0.9480 train_balacc 0.9479903434839694\n",
      " val_balacc 0.9562934101304421\n",
      "\n",
      "Epoch 70: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1334 - tp: 22383.0000 - fp: 1228.0000 - tn: 22383.0000 - fn: 1228.0000 - accuracy: 0.9480 - val_loss: 0.1247 - val_tp: 5645.0000 - val_fp: 258.0000 - val_tn: 5645.0000 - val_fn: 258.0000 - val_accuracy: 0.9563 - train_sensitivity: 0.9480 - train_specificity: 0.9480 - train_balacc: 0.9480 - val_sensitivity: 0.9563 - val_specificity: 0.9563 - val_balacc: 0.9563\n",
      "Epoch 71/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1282 - tp: 22127.0000 - fp: 1173.0000 - tn: 22127.0000 - fn: 1173.0000 - accuracy: 0.9497 train_balacc 0.9492609376985304\n",
      " val_balacc 0.8946298492292055\n",
      "\n",
      "Epoch 71: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1286 - tp: 22413.0000 - fp: 1198.0000 - tn: 22413.0000 - fn: 1198.0000 - accuracy: 0.9493 - val_loss: 0.3262 - val_tp: 5281.0000 - val_fp: 622.0000 - val_tn: 5281.0000 - val_fn: 622.0000 - val_accuracy: 0.8946 - train_sensitivity: 0.9493 - train_specificity: 0.9493 - train_balacc: 0.9493 - val_sensitivity: 0.8946 - val_specificity: 0.8946 - val_balacc: 0.8946\n",
      "Epoch 72/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1320 - tp: 21895.0000 - fp: 1205.0000 - tn: 21895.0000 - fn: 1205.0000 - accuracy: 0.9478 train_balacc 0.9476938715005717\n",
      " val_balacc 0.8043367779095375\n",
      "\n",
      "Epoch 72: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1319 - tp: 22376.0000 - fp: 1235.0000 - tn: 22376.0000 - fn: 1235.0000 - accuracy: 0.9477 - val_loss: 1.0946 - val_tp: 4748.0000 - val_fp: 1155.0000 - val_tn: 4748.0000 - val_fn: 1155.0000 - val_accuracy: 0.8043 - train_sensitivity: 0.9477 - train_specificity: 0.9477 - train_balacc: 0.9477 - val_sensitivity: 0.8043 - val_specificity: 0.8043 - val_balacc: 0.8043\n",
      "Epoch 73/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1372 - tp: 21694.0000 - fp: 1206.0000 - tn: 21694.0000 - fn: 1206.0000 - accuracy: 0.9473 train_balacc 0.9473550463766889\n",
      " val_balacc 0.9369811960020329\n",
      "\n",
      "Epoch 73: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1369 - tp: 22368.0000 - fp: 1243.0000 - tn: 22368.0000 - fn: 1243.0000 - accuracy: 0.9474 - val_loss: 0.1733 - val_tp: 5531.0000 - val_fp: 372.0000 - val_tn: 5531.0000 - val_fn: 372.0000 - val_accuracy: 0.9370 - train_sensitivity: 0.9474 - train_specificity: 0.9474 - train_balacc: 0.9474 - val_sensitivity: 0.9370 - val_specificity: 0.9370 - val_balacc: 0.9370\n",
      "Epoch 74/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1303 - tp: 21949.0000 - fp: 1151.0000 - tn: 21949.0000 - fn: 1151.0000 - accuracy: 0.9502 train_balacc 0.9496421159628986\n",
      " val_balacc 0.9566322209046247\n",
      "\n",
      "Epoch 74: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1307 - tp: 22422.0000 - fp: 1189.0000 - tn: 22422.0000 - fn: 1189.0000 - accuracy: 0.9496 - val_loss: 0.1073 - val_tp: 5647.0000 - val_fp: 256.0000 - val_tn: 5647.0000 - val_fn: 256.0000 - val_accuracy: 0.9566 - train_sensitivity: 0.9496 - train_specificity: 0.9496 - train_balacc: 0.9496 - val_sensitivity: 0.9566 - val_specificity: 0.9566 - val_balacc: 0.9566\n",
      "Epoch 75/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1327 - tp: 21812.0000 - fp: 1188.0000 - tn: 21812.0000 - fn: 1188.0000 - accuracy: 0.9483 train_balacc 0.9482868154673669\n",
      " val_balacc 0.8578688802303913\n",
      "\n",
      "Epoch 75: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1328 - tp: 22390.0000 - fp: 1221.0000 - tn: 22390.0000 - fn: 1221.0000 - accuracy: 0.9483 - val_loss: 0.6187 - val_tp: 5064.0000 - val_fp: 839.0000 - val_tn: 5064.0000 - val_fn: 839.0000 - val_accuracy: 0.8579 - train_sensitivity: 0.9483 - train_specificity: 0.9483 - train_balacc: 0.9483 - val_sensitivity: 0.8579 - val_specificity: 0.8579 - val_balacc: 0.8579\n",
      "Epoch 76/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1292 - tp: 22124.0000 - fp: 1176.0000 - tn: 22124.0000 - fn: 1176.0000 - accuracy: 0.9495 train_balacc 0.949345643979501\n",
      " val_balacc 0.8695578519396917\n",
      "\n",
      "Epoch 76: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1296 - tp: 22415.0000 - fp: 1196.0000 - tn: 22415.0000 - fn: 1196.0000 - accuracy: 0.9493 - val_loss: 0.3002 - val_tp: 5133.0000 - val_fp: 770.0000 - val_tn: 5133.0000 - val_fn: 770.0000 - val_accuracy: 0.8696 - train_sensitivity: 0.9493 - train_specificity: 0.9493 - train_balacc: 0.9493 - val_sensitivity: 0.8696 - val_specificity: 0.8696 - val_balacc: 0.8696\n",
      "Epoch 77/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1357 - tp: 21935.0000 - fp: 1265.0000 - tn: 21935.0000 - fn: 1265.0000 - accuracy: 0.9455 train_balacc 0.9456609207572741\n",
      " val_balacc 0.922242927325089\n",
      "\n",
      "Epoch 77: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1358 - tp: 22328.0000 - fp: 1283.0000 - tn: 22328.0000 - fn: 1283.0000 - accuracy: 0.9457 - val_loss: 0.2292 - val_tp: 5444.0000 - val_fp: 459.0000 - val_tn: 5444.0000 - val_fn: 459.0000 - val_accuracy: 0.9222 - train_sensitivity: 0.9457 - train_specificity: 0.9457 - train_balacc: 0.9457 - val_sensitivity: 0.9222 - val_specificity: 0.9222 - val_balacc: 0.9222\n",
      "Epoch 78/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1313 - tp: 21613.0000 - fp: 1187.0000 - tn: 21613.0000 - fn: 1187.0000 - accuracy: 0.9479 train_balacc 0.9480750497649401\n",
      " val_balacc 0.9300355751312892\n",
      "\n",
      "Epoch 78: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1306 - tp: 22385.0000 - fp: 1226.0000 - tn: 22385.0000 - fn: 1226.0000 - accuracy: 0.9481 - val_loss: 0.1801 - val_tp: 5490.0000 - val_fp: 413.0000 - val_tn: 5490.0000 - val_fn: 413.0000 - val_accuracy: 0.9300 - train_sensitivity: 0.9481 - train_specificity: 0.9481 - train_balacc: 0.9481 - val_sensitivity: 0.9300 - val_specificity: 0.9300 - val_balacc: 0.9300\n",
      "Epoch 79/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1332 - tp: 22044.0000 - fp: 1256.0000 - tn: 22044.0000 - fn: 1256.0000 - accuracy: 0.9461 train_balacc 0.9462538647240692\n",
      " val_balacc 0.8746400135524309\n",
      "\n",
      "Epoch 79: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1331 - tp: 22342.0000 - fp: 1269.0000 - tn: 22342.0000 - fn: 1269.0000 - accuracy: 0.9463 - val_loss: 0.2765 - val_tp: 5163.0000 - val_fp: 740.0000 - val_tn: 5163.0000 - val_fn: 740.0000 - val_accuracy: 0.8746 - train_sensitivity: 0.9463 - train_specificity: 0.9463 - train_balacc: 0.9463 - val_sensitivity: 0.8746 - val_specificity: 0.8746 - val_balacc: 0.8746\n",
      "Epoch 80/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1361 - tp: 21790.0000 - fp: 1210.0000 - tn: 21790.0000 - fn: 1210.0000 - accuracy: 0.9474 train_balacc 0.9473550463766889\n",
      " val_balacc 0.9063188209385058\n",
      "\n",
      "Epoch 80: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1358 - tp: 22368.0000 - fp: 1243.0000 - tn: 22368.0000 - fn: 1243.0000 - accuracy: 0.9474 - val_loss: 0.2479 - val_tp: 5350.0000 - val_fp: 553.0000 - val_tn: 5350.0000 - val_fn: 553.0000 - val_accuracy: 0.9063 - train_sensitivity: 0.9474 - train_specificity: 0.9474 - train_balacc: 0.9474 - val_sensitivity: 0.9063 - val_specificity: 0.9063 - val_balacc: 0.9063\n",
      "Epoch 81/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1266 - tp: 22029.0000 - fp: 1171.0000 - tn: 22029.0000 - fn: 1171.0000 - accuracy: 0.9495 train_balacc 0.9491338782770743\n",
      " val_balacc 0.8810774182619008\n",
      "\n",
      "Epoch 81: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1275 - tp: 22410.0000 - fp: 1201.0000 - tn: 22410.0000 - fn: 1201.0000 - accuracy: 0.9491 - val_loss: 0.2721 - val_tp: 5201.0000 - val_fp: 702.0000 - val_tn: 5201.0000 - val_fn: 702.0000 - val_accuracy: 0.8811 - train_sensitivity: 0.9491 - train_specificity: 0.9491 - train_balacc: 0.9491 - val_sensitivity: 0.8811 - val_specificity: 0.8811 - val_balacc: 0.8811\n",
      "Epoch 82/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1361 - tp: 22249.0000 - fp: 1251.0000 - tn: 22249.0000 - fn: 1251.0000 - accuracy: 0.9468 train_balacc 0.9469738681123205\n",
      " val_balacc 0.9591733017109945\n",
      "\n",
      "Epoch 82: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1358 - tp: 22359.0000 - fp: 1252.0000 - tn: 22359.0000 - fn: 1252.0000 - accuracy: 0.9470 - val_loss: 0.1073 - val_tp: 5662.0000 - val_fp: 241.0000 - val_tn: 5662.0000 - val_fn: 241.0000 - val_accuracy: 0.9592 - train_sensitivity: 0.9470 - train_specificity: 0.9470 - train_balacc: 0.9470 - val_sensitivity: 0.9592 - val_specificity: 0.9592 - val_balacc: 0.9592\n",
      "Epoch 83/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1294 - tp: 22005.0000 - fp: 1195.0000 - tn: 22005.0000 - fn: 1195.0000 - accuracy: 0.9485 train_balacc 0.948413874888823\n",
      " val_balacc 0.8405895307470778\n",
      "\n",
      "Epoch 83: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1292 - tp: 22393.0000 - fp: 1218.0000 - tn: 22393.0000 - fn: 1218.0000 - accuracy: 0.9484 - val_loss: 0.4194 - val_tp: 4962.0000 - val_fp: 941.0000 - val_tn: 4962.0000 - val_fn: 941.0000 - val_accuracy: 0.8406 - train_sensitivity: 0.9484 - train_specificity: 0.9484 - train_balacc: 0.9484 - val_sensitivity: 0.8406 - val_specificity: 0.8406 - val_balacc: 0.8406\n",
      "Epoch 84/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1267 - tp: 22374.0000 - fp: 1226.0000 - tn: 22374.0000 - fn: 1226.0000 - accuracy: 0.9481 train_balacc 0.9480326966244547\n",
      " val_balacc 0.9581568693884466\n",
      "\n",
      "Epoch 84: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1267 - tp: 22384.0000 - fp: 1227.0000 - tn: 22384.0000 - fn: 1227.0000 - accuracy: 0.9480 - val_loss: 0.1069 - val_tp: 5656.0000 - val_fp: 247.0000 - val_tn: 5656.0000 - val_fn: 247.0000 - val_accuracy: 0.9582 - train_sensitivity: 0.9480 - train_specificity: 0.9480 - train_balacc: 0.9480 - val_sensitivity: 0.9582 - val_specificity: 0.9582 - val_balacc: 0.9582\n",
      "Epoch 85/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1308 - tp: 21805.0000 - fp: 1195.0000 - tn: 21805.0000 - fn: 1195.0000 - accuracy: 0.9480 train_balacc 0.9483291686078523\n",
      " val_balacc 0.931052007453837\n",
      "\n",
      "Epoch 85: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1299 - tp: 22391.0000 - fp: 1220.0000 - tn: 22391.0000 - fn: 1220.0000 - accuracy: 0.9483 - val_loss: 0.1585 - val_tp: 5496.0000 - val_fp: 407.0000 - val_tn: 5496.0000 - val_fn: 407.0000 - val_accuracy: 0.9311 - train_sensitivity: 0.9483 - train_specificity: 0.9483 - train_balacc: 0.9483 - val_sensitivity: 0.9311 - val_specificity: 0.9311 - val_balacc: 0.9311\n",
      "Epoch 86/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1322 - tp: 22441.0000 - fp: 1159.0000 - tn: 22441.0000 - fn: 1159.0000 - accuracy: 0.9509 train_balacc 0.9508703570369743\n",
      " val_balacc 0.8207691004573946\n",
      "\n",
      "Epoch 86: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1322 - tp: 22451.0000 - fp: 1160.0000 - tn: 22451.0000 - fn: 1160.0000 - accuracy: 0.9509 - val_loss: 0.4544 - val_tp: 4845.0000 - val_fp: 1058.0000 - val_tn: 4845.0000 - val_fn: 1058.0000 - val_accuracy: 0.8208 - train_sensitivity: 0.9509 - train_specificity: 0.9509 - train_balacc: 0.9509 - val_sensitivity: 0.8208 - val_specificity: 0.8208 - val_balacc: 0.8208\n",
      "Epoch 87/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1326 - tp: 21871.0000 - fp: 1229.0000 - tn: 21871.0000 - fn: 1229.0000 - accuracy: 0.9468 train_balacc 0.9468468086908645\n",
      " val_balacc 0.9568016262917161\n",
      "\n",
      "Epoch 87: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1324 - tp: 22356.0000 - fp: 1255.0000 - tn: 22356.0000 - fn: 1255.0000 - accuracy: 0.9468 - val_loss: 0.1305 - val_tp: 5648.0000 - val_fp: 255.0000 - val_tn: 5648.0000 - val_fn: 255.0000 - val_accuracy: 0.9568 - train_sensitivity: 0.9468 - train_specificity: 0.9468 - train_balacc: 0.9468 - val_sensitivity: 0.9568 - val_specificity: 0.9568 - val_balacc: 0.9568\n",
      "Epoch 88/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1308 - tp: 21896.0000 - fp: 1104.0000 - tn: 21896.0000 - fn: 1104.0000 - accuracy: 0.9520 train_balacc 0.9516750667061963\n",
      " val_balacc 0.9630696256140945\n",
      "\n",
      "Epoch 88: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1305 - tp: 22470.0000 - fp: 1141.0000 - tn: 22470.0000 - fn: 1141.0000 - accuracy: 0.9517 - val_loss: 0.1129 - val_tp: 5685.0000 - val_fp: 218.0000 - val_tn: 5685.0000 - val_fn: 218.0000 - val_accuracy: 0.9631 - train_sensitivity: 0.9517 - train_specificity: 0.9517 - train_balacc: 0.9517 - val_sensitivity: 0.9631 - val_specificity: 0.9631 - val_balacc: 0.9631\n",
      "Epoch 89/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1257 - tp: 22330.0000 - fp: 1170.0000 - tn: 22330.0000 - fn: 1170.0000 - accuracy: 0.9502 train_balacc 0.9501927067892084\n",
      " val_balacc 0.9290191428087413\n",
      "\n",
      "Epoch 89: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1260 - tp: 22435.0000 - fp: 1176.0000 - tn: 22435.0000 - fn: 1176.0000 - accuracy: 0.9502 - val_loss: 0.1879 - val_tp: 5484.0000 - val_fp: 419.0000 - val_tn: 5484.0000 - val_fn: 419.0000 - val_accuracy: 0.9290 - train_sensitivity: 0.9502 - train_specificity: 0.9502 - train_balacc: 0.9502 - val_sensitivity: 0.9290 - val_specificity: 0.9290 - val_balacc: 0.9290\n",
      "Epoch 90/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1250 - tp: 21938.0000 - fp: 1162.0000 - tn: 21938.0000 - fn: 1162.0000 - accuracy: 0.9497 train_balacc 0.9498962348058109\n",
      " val_balacc 0.8006098593935287\n",
      "\n",
      "Epoch 90: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1252 - tp: 22428.0000 - fp: 1183.0000 - tn: 22428.0000 - fn: 1183.0000 - accuracy: 0.9499 - val_loss: 0.5747 - val_tp: 4726.0000 - val_fp: 1177.0000 - val_tn: 4726.0000 - val_fn: 1177.0000 - val_accuracy: 0.8006 - train_sensitivity: 0.9499 - train_specificity: 0.9499 - train_balacc: 0.9499 - val_sensitivity: 0.8006 - val_specificity: 0.8006 - val_balacc: 0.8006\n",
      "Epoch 91/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1306 - tp: 22282.0000 - fp: 1218.0000 - tn: 22282.0000 - fn: 1218.0000 - accuracy: 0.9482 train_balacc 0.9482021091863961\n",
      " val_balacc 0.9620531932915467\n",
      "\n",
      "Epoch 91: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1304 - tp: 22388.0000 - fp: 1223.0000 - tn: 22388.0000 - fn: 1223.0000 - accuracy: 0.9482 - val_loss: 0.1106 - val_tp: 5679.0000 - val_fp: 224.0000 - val_tn: 5679.0000 - val_fn: 224.0000 - val_accuracy: 0.9621 - train_sensitivity: 0.9482 - train_specificity: 0.9482 - train_balacc: 0.9482 - val_sensitivity: 0.9621 - val_specificity: 0.9621 - val_balacc: 0.9621\n",
      "Epoch 92/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1259 - tp: 21753.0000 - fp: 1147.0000 - tn: 21753.0000 - fn: 1147.0000 - accuracy: 0.9499 train_balacc 0.9500656473677523\n",
      " val_balacc 0.957818058614264\n",
      "\n",
      "Epoch 92: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1259 - tp: 22432.0000 - fp: 1179.0000 - tn: 22432.0000 - fn: 1179.0000 - accuracy: 0.9501 - val_loss: 0.1081 - val_tp: 5654.0000 - val_fp: 249.0000 - val_tn: 5654.0000 - val_fn: 249.0000 - val_accuracy: 0.9578 - train_sensitivity: 0.9501 - train_specificity: 0.9501 - train_balacc: 0.9501 - val_sensitivity: 0.9578 - val_specificity: 0.9578 - val_balacc: 0.9578\n",
      "Epoch 93/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1364 - tp: 21980.0000 - fp: 1220.0000 - tn: 21980.0000 - fn: 1220.0000 - accuracy: 0.9474 train_balacc 0.9477362246410571\n",
      " val_balacc 0.8990343892935795\n",
      "\n",
      "Epoch 93: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1361 - tp: 22377.0000 - fp: 1234.0000 - tn: 22377.0000 - fn: 1234.0000 - accuracy: 0.9477 - val_loss: 0.2589 - val_tp: 5307.0000 - val_fp: 596.0000 - val_tn: 5307.0000 - val_fn: 596.0000 - val_accuracy: 0.8990 - train_sensitivity: 0.9477 - train_specificity: 0.9477 - train_balacc: 0.9477 - val_sensitivity: 0.8990 - val_specificity: 0.8990 - val_balacc: 0.8990\n",
      "Epoch 94/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1285 - tp: 21631.0000 - fp: 1169.0000 - tn: 21631.0000 - fn: 1169.0000 - accuracy: 0.9487 train_balacc 0.948752700012706\n",
      " val_balacc 0.9623920040657293\n",
      "\n",
      "Epoch 94: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1292 - tp: 22401.0000 - fp: 1210.0000 - tn: 22401.0000 - fn: 1210.0000 - accuracy: 0.9488 - val_loss: 0.0949 - val_tp: 5681.0000 - val_fp: 222.0000 - val_tn: 5681.0000 - val_fn: 222.0000 - val_accuracy: 0.9624 - train_sensitivity: 0.9488 - train_specificity: 0.9488 - train_balacc: 0.9488 - val_sensitivity: 0.9624 - val_specificity: 0.9624 - val_balacc: 0.9624\n",
      "Epoch 95/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1309 - tp: 21949.0000 - fp: 1151.0000 - tn: 21949.0000 - fn: 1151.0000 - accuracy: 0.9502 train_balacc 0.9499809410867815\n",
      " val_balacc 0.9512112485177029\n",
      "\n",
      "Epoch 95: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1323 - tp: 22430.0000 - fp: 1181.0000 - tn: 22430.0000 - fn: 1181.0000 - accuracy: 0.9500 - val_loss: 0.1265 - val_tp: 5615.0000 - val_fp: 288.0000 - val_tn: 5615.0000 - val_fn: 288.0000 - val_accuracy: 0.9512 - train_sensitivity: 0.9500 - train_specificity: 0.9500 - train_balacc: 0.9500 - val_sensitivity: 0.9512 - val_specificity: 0.9512 - val_balacc: 0.9512\n",
      "Epoch 96/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1201 - tp: 21886.0000 - fp: 1114.0000 - tn: 21886.0000 - fn: 1114.0000 - accuracy: 0.9516 train_balacc 0.9512938884418279\n",
      " val_balacc 0.9357953582923937\n",
      "\n",
      "Epoch 96: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1205 - tp: 22461.0000 - fp: 1150.0000 - tn: 22461.0000 - fn: 1150.0000 - accuracy: 0.9513 - val_loss: 0.1693 - val_tp: 5524.0000 - val_fp: 379.0000 - val_tn: 5524.0000 - val_fn: 379.0000 - val_accuracy: 0.9358 - train_sensitivity: 0.9513 - train_specificity: 0.9513 - train_balacc: 0.9513 - val_sensitivity: 0.9358 - val_specificity: 0.9358 - val_balacc: 0.9358\n",
      "Epoch 97/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1262 - tp: 22250.0000 - fp: 1150.0000 - tn: 22250.0000 - fn: 1150.0000 - accuracy: 0.9509 train_balacc 0.9506585913345474\n",
      " val_balacc 0.9349483313569371\n",
      "\n",
      "Epoch 97: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1264 - tp: 22446.0000 - fp: 1165.0000 - tn: 22446.0000 - fn: 1165.0000 - accuracy: 0.9507 - val_loss: 0.1521 - val_tp: 5519.0000 - val_fp: 384.0000 - val_tn: 5519.0000 - val_fn: 384.0000 - val_accuracy: 0.9349 - train_sensitivity: 0.9507 - train_specificity: 0.9507 - train_balacc: 0.9507 - val_sensitivity: 0.9349 - val_specificity: 0.9349 - val_balacc: 0.9349\n",
      "Epoch 98/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1230 - tp: 21972.0000 - fp: 1128.0000 - tn: 21972.0000 - fn: 1128.0000 - accuracy: 0.9512 train_balacc 0.9514633010037694\n",
      " val_balacc 0.9405387091309504\n",
      "\n",
      "Epoch 98: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1220 - tp: 22465.0000 - fp: 1146.0000 - tn: 22465.0000 - fn: 1146.0000 - accuracy: 0.9515 - val_loss: 0.1485 - val_tp: 5552.0000 - val_fp: 351.0000 - val_tn: 5552.0000 - val_fn: 351.0000 - val_accuracy: 0.9405 - train_sensitivity: 0.9515 - train_specificity: 0.9515 - train_balacc: 0.9515 - val_sensitivity: 0.9405 - val_specificity: 0.9405 - val_balacc: 0.9405\n",
      "Epoch 99/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1295 - tp: 22309.0000 - fp: 1191.0000 - tn: 22309.0000 - fn: 1191.0000 - accuracy: 0.9493 train_balacc 0.9493879971199864\n",
      " val_balacc 0.9491783838726071\n",
      "\n",
      "Epoch 99: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1293 - tp: 22416.0000 - fp: 1195.0000 - tn: 22416.0000 - fn: 1195.0000 - accuracy: 0.9494 - val_loss: 0.1225 - val_tp: 5603.0000 - val_fp: 300.0000 - val_tn: 5603.0000 - val_fn: 300.0000 - val_accuracy: 0.9492 - train_sensitivity: 0.9494 - train_specificity: 0.9494 - train_balacc: 0.9494 - val_sensitivity: 0.9492 - val_specificity: 0.9492 - val_balacc: 0.9492\n",
      "Epoch 100/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1321 - tp: 22118.0000 - fp: 1182.0000 - tn: 22118.0000 - fn: 1182.0000 - accuracy: 0.9493 train_balacc 0.949218584558045\n",
      " val_balacc 0.9081822801965103\n",
      "\n",
      "Epoch 100: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1320 - tp: 22412.0000 - fp: 1199.0000 - tn: 22412.0000 - fn: 1199.0000 - accuracy: 0.9492 - val_loss: 0.2387 - val_tp: 5361.0000 - val_fp: 542.0000 - val_tn: 5361.0000 - val_fn: 542.0000 - val_accuracy: 0.9082 - train_sensitivity: 0.9492 - train_specificity: 0.9492 - train_balacc: 0.9492 - val_sensitivity: 0.9082 - val_specificity: 0.9082 - val_balacc: 0.9082\n",
      "Epoch 101/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1276 - tp: 21984.0000 - fp: 1216.0000 - tn: 21984.0000 - fn: 1216.0000 - accuracy: 0.9476 train_balacc 0.9476515183600864\n",
      " val_balacc 0.955107572420803\n",
      "\n",
      "Epoch 101: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1272 - tp: 22375.0000 - fp: 1236.0000 - tn: 22375.0000 - fn: 1236.0000 - accuracy: 0.9477 - val_loss: 0.1198 - val_tp: 5638.0000 - val_fp: 265.0000 - val_tn: 5638.0000 - val_fn: 265.0000 - val_accuracy: 0.9551 - train_sensitivity: 0.9477 - train_specificity: 0.9477 - train_balacc: 0.9477 - val_sensitivity: 0.9551 - val_specificity: 0.9551 - val_balacc: 0.9551\n",
      "Epoch 102/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1277 - tp: 21943.0000 - fp: 1157.0000 - tn: 21943.0000 - fn: 1157.0000 - accuracy: 0.9499 train_balacc 0.9496421159628986\n",
      " val_balacc 0.9659495171946468\n",
      "\n",
      "Epoch 102: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1283 - tp: 22422.0000 - fp: 1189.0000 - tn: 22422.0000 - fn: 1189.0000 - accuracy: 0.9496 - val_loss: 0.0994 - val_tp: 5702.0000 - val_fp: 201.0000 - val_tn: 5702.0000 - val_fn: 201.0000 - val_accuracy: 0.9659 - train_sensitivity: 0.9496 - train_specificity: 0.9496 - train_balacc: 0.9496 - val_sensitivity: 0.9659 - val_specificity: 0.9659 - val_balacc: 0.9659\n",
      "Epoch 103/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1259 - tp: 21894.0000 - fp: 1106.0000 - tn: 21894.0000 - fn: 1106.0000 - accuracy: 0.9519 train_balacc 0.9513785947227987\n",
      " val_balacc 0.9227511434863629\n",
      "\n",
      "Epoch 103: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1266 - tp: 22463.0000 - fp: 1148.0000 - tn: 22463.0000 - fn: 1148.0000 - accuracy: 0.9514 - val_loss: 0.1832 - val_tp: 5447.0000 - val_fp: 456.0000 - val_tn: 5447.0000 - val_fn: 456.0000 - val_accuracy: 0.9228 - train_sensitivity: 0.9514 - train_specificity: 0.9514 - train_balacc: 0.9514 - val_sensitivity: 0.9228 - val_specificity: 0.9228 - val_balacc: 0.9228\n",
      "Epoch 104/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1277 - tp: 22338.0000 - fp: 1162.0000 - tn: 22338.0000 - fn: 1162.0000 - accuracy: 0.9506 train_balacc 0.9504468256321206\n",
      " val_balacc 0.9429103845502287\n",
      "\n",
      "Epoch 104: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1278 - tp: 22441.0000 - fp: 1170.0000 - tn: 22441.0000 - fn: 1170.0000 - accuracy: 0.9504 - val_loss: 0.1551 - val_tp: 5566.0000 - val_fp: 337.0000 - val_tn: 5566.0000 - val_fn: 337.0000 - val_accuracy: 0.9429 - train_sensitivity: 0.9504 - train_specificity: 0.9504 - train_balacc: 0.9504 - val_sensitivity: 0.9429 - val_specificity: 0.9429 - val_balacc: 0.9429\n",
      "Epoch 105/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1252 - tp: 22245.0000 - fp: 1155.0000 - tn: 22245.0000 - fn: 1155.0000 - accuracy: 0.9506 train_balacc 0.9507856507560035\n",
      " val_balacc 0.9178383872607149\n",
      "\n",
      "Epoch 105: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1249 - tp: 22449.0000 - fp: 1162.0000 - tn: 22449.0000 - fn: 1162.0000 - accuracy: 0.9508 - val_loss: 0.1912 - val_tp: 5418.0000 - val_fp: 485.0000 - val_tn: 5418.0000 - val_fn: 485.0000 - val_accuracy: 0.9178 - train_sensitivity: 0.9508 - train_specificity: 0.9508 - train_balacc: 0.9508 - val_sensitivity: 0.9178 - val_specificity: 0.9178 - val_balacc: 0.9178\n",
      "Epoch 106/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1281 - tp: 21948.0000 - fp: 1152.0000 - tn: 21948.0000 - fn: 1152.0000 - accuracy: 0.9501 train_balacc 0.950489178772606\n",
      " val_balacc 0.962222598678638\n",
      "\n",
      "Epoch 106: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1275 - tp: 22442.0000 - fp: 1169.0000 - tn: 22442.0000 - fn: 1169.0000 - accuracy: 0.9505 - val_loss: 0.1100 - val_tp: 5680.0000 - val_fp: 223.0000 - val_tn: 5680.0000 - val_fn: 223.0000 - val_accuracy: 0.9622 - train_sensitivity: 0.9505 - train_specificity: 0.9505 - train_balacc: 0.9505 - val_sensitivity: 0.9622 - val_specificity: 0.9622 - val_balacc: 0.9622\n",
      "Epoch 107/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1293 - tp: 21878.0000 - fp: 1122.0000 - tn: 21878.0000 - fn: 1122.0000 - accuracy: 0.9512 train_balacc 0.950955063317945\n",
      " val_balacc 0.962222598678638\n",
      "\n",
      "Epoch 107: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1297 - tp: 22453.0000 - fp: 1158.0000 - tn: 22453.0000 - fn: 1158.0000 - accuracy: 0.9510 - val_loss: 0.1024 - val_tp: 5680.0000 - val_fp: 223.0000 - val_tn: 5680.0000 - val_fn: 223.0000 - val_accuracy: 0.9622 - train_sensitivity: 0.9510 - train_specificity: 0.9510 - train_balacc: 0.9510 - val_sensitivity: 0.9622 - val_specificity: 0.9622 - val_balacc: 0.9622\n",
      "Epoch 108/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1218 - tp: 22464.0000 - fp: 1136.0000 - tn: 22464.0000 - fn: 1136.0000 - accuracy: 0.9519 train_balacc 0.9518868324086232\n",
      " val_balacc 0.9493477892596984\n",
      "\n",
      "Epoch 108: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1217 - tp: 22475.0000 - fp: 1136.0000 - tn: 22475.0000 - fn: 1136.0000 - accuracy: 0.9519 - val_loss: 0.1243 - val_tp: 5604.0000 - val_fp: 299.0000 - val_tn: 5604.0000 - val_fn: 299.0000 - val_accuracy: 0.9493 - train_sensitivity: 0.9519 - train_specificity: 0.9519 - train_balacc: 0.9519 - val_sensitivity: 0.9493 - val_specificity: 0.9493 - val_balacc: 0.9493\n",
      "Epoch 109/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1354 - tp: 22216.0000 - fp: 1184.0000 - tn: 22216.0000 - fn: 1184.0000 - accuracy: 0.9494 train_balacc 0.9495150565414425\n",
      " val_balacc 0.9500254108080637\n",
      "\n",
      "Epoch 109: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1355 - tp: 22419.0000 - fp: 1192.0000 - tn: 22419.0000 - fn: 1192.0000 - accuracy: 0.9495 - val_loss: 0.1183 - val_tp: 5608.0000 - val_fp: 295.0000 - val_tn: 5608.0000 - val_fn: 295.0000 - val_accuracy: 0.9500 - train_sensitivity: 0.9495 - train_specificity: 0.9495 - train_balacc: 0.9495 - val_sensitivity: 0.9500 - val_specificity: 0.9500 - val_balacc: 0.9500\n",
      "Epoch 110/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1228 - tp: 22276.0000 - fp: 1124.0000 - tn: 22276.0000 - fn: 1124.0000 - accuracy: 0.9520 train_balacc 0.9518021261276524\n",
      " val_balacc 0.9422327630018634\n",
      "\n",
      "Epoch 110: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1230 - tp: 22473.0000 - fp: 1138.0000 - tn: 22473.0000 - fn: 1138.0000 - accuracy: 0.9518 - val_loss: 0.1307 - val_tp: 5562.0000 - val_fp: 341.0000 - val_tn: 5562.0000 - val_fn: 341.0000 - val_accuracy: 0.9422 - train_sensitivity: 0.9518 - train_specificity: 0.9518 - train_balacc: 0.9518 - val_sensitivity: 0.9422 - val_specificity: 0.9422 - val_balacc: 0.9422\n",
      "Epoch 111/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1271 - tp: 21772.0000 - fp: 1128.0000 - tn: 21772.0000 - fn: 1128.0000 - accuracy: 0.9507 train_balacc 0.9509974164584304\n",
      " val_balacc 0.9596815178722683\n",
      "\n",
      "Epoch 111: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1266 - tp: 22454.0000 - fp: 1157.0000 - tn: 22454.0000 - fn: 1157.0000 - accuracy: 0.9510 - val_loss: 0.1085 - val_tp: 5665.0000 - val_fp: 238.0000 - val_tn: 5665.0000 - val_fn: 238.0000 - val_accuracy: 0.9597 - train_sensitivity: 0.9510 - train_specificity: 0.9510 - train_balacc: 0.9510 - val_sensitivity: 0.9597 - val_specificity: 0.9597 - val_balacc: 0.9597\n",
      "Epoch 112/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1297 - tp: 21859.0000 - fp: 1141.0000 - tn: 21859.0000 - fn: 1141.0000 - accuracy: 0.9504 train_balacc 0.9505315319130914\n",
      " val_balacc 0.9569710316788074\n",
      "\n",
      "Epoch 112: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1301 - tp: 22443.0000 - fp: 1168.0000 - tn: 22443.0000 - fn: 1168.0000 - accuracy: 0.9505 - val_loss: 0.1204 - val_tp: 5649.0000 - val_fp: 254.0000 - val_tn: 5649.0000 - val_fn: 254.0000 - val_accuracy: 0.9570 - train_sensitivity: 0.9505 - train_specificity: 0.9505 - train_balacc: 0.9505 - val_sensitivity: 0.9570 - val_specificity: 0.9570 - val_balacc: 0.9570\n",
      "Epoch 113/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1309 - tp: 22107.0000 - fp: 1193.0000 - tn: 22107.0000 - fn: 1193.0000 - accuracy: 0.9488 train_balacc 0.9484562280293084\n",
      " val_balacc 0.8892088768422836\n",
      "\n",
      "Epoch 113: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1318 - tp: 22394.0000 - fp: 1217.0000 - tn: 22394.0000 - fn: 1217.0000 - accuracy: 0.9485 - val_loss: 0.2375 - val_tp: 5249.0000 - val_fp: 654.0000 - val_tn: 5249.0000 - val_fn: 654.0000 - val_accuracy: 0.8892 - train_sensitivity: 0.9485 - train_specificity: 0.9485 - train_balacc: 0.9485 - val_sensitivity: 0.8892 - val_specificity: 0.8892 - val_balacc: 0.8892\n",
      "Epoch 114/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1235 - tp: 22330.0000 - fp: 1170.0000 - tn: 22330.0000 - fn: 1170.0000 - accuracy: 0.9502 train_balacc 0.9501927067892084\n",
      " val_balacc 0.9268168727765543\n",
      "\n",
      "Epoch 114: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1236 - tp: 22435.0000 - fp: 1176.0000 - tn: 22435.0000 - fn: 1176.0000 - accuracy: 0.9502 - val_loss: 0.1809 - val_tp: 5471.0000 - val_fp: 432.0000 - val_tn: 5471.0000 - val_fn: 432.0000 - val_accuracy: 0.9268 - train_sensitivity: 0.9502 - train_specificity: 0.9502 - train_balacc: 0.9502 - val_sensitivity: 0.9268 - val_specificity: 0.9268 - val_balacc: 0.9268\n",
      "Epoch 115/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1282 - tp: 22029.0000 - fp: 1171.0000 - tn: 22029.0000 - fn: 1171.0000 - accuracy: 0.9495 train_balacc 0.9495997628224133\n",
      " val_balacc 0.9520582754531595\n",
      "\n",
      "Epoch 115: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1280 - tp: 22421.0000 - fp: 1190.0000 - tn: 22421.0000 - fn: 1190.0000 - accuracy: 0.9496 - val_loss: 0.1250 - val_tp: 5620.0000 - val_fp: 283.0000 - val_tn: 5620.0000 - val_fn: 283.0000 - val_accuracy: 0.9521 - train_sensitivity: 0.9496 - train_specificity: 0.9496 - train_balacc: 0.9496 - val_sensitivity: 0.9521 - val_specificity: 0.9521 - val_balacc: 0.9521\n",
      "Epoch 116/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1211 - tp: 22178.0000 - fp: 1122.0000 - tn: 22178.0000 - fn: 1122.0000 - accuracy: 0.9518 train_balacc 0.9515480072847402\n",
      " val_balacc 0.935964763679485\n",
      "\n",
      "Epoch 116: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1218 - tp: 22467.0000 - fp: 1144.0000 - tn: 22467.0000 - fn: 1144.0000 - accuracy: 0.9515 - val_loss: 0.1470 - val_tp: 5525.0000 - val_fp: 378.0000 - val_tn: 5525.0000 - val_fn: 378.0000 - val_accuracy: 0.9360 - train_sensitivity: 0.9515 - train_specificity: 0.9515 - train_balacc: 0.9515 - val_sensitivity: 0.9360 - val_specificity: 0.9360 - val_balacc: 0.9360\n",
      "Epoch 117/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1257 - tp: 22446.0000 - fp: 1165.0000 - tn: 22446.0000 - fn: 1165.0000 - accuracy: 0.9507 train_balacc 0.9506585913345474\n",
      " val_balacc 0.959512112485177\n",
      "\n",
      "Epoch 117: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1257 - tp: 22446.0000 - fp: 1165.0000 - tn: 22446.0000 - fn: 1165.0000 - accuracy: 0.9507 - val_loss: 0.1075 - val_tp: 5664.0000 - val_fp: 239.0000 - val_tn: 5664.0000 - val_fn: 239.0000 - val_accuracy: 0.9595 - train_sensitivity: 0.9507 - train_specificity: 0.9507 - train_balacc: 0.9507 - val_sensitivity: 0.9595 - val_specificity: 0.9595 - val_balacc: 0.9595\n",
      "Epoch 118/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1239 - tp: 22264.0000 - fp: 1136.0000 - tn: 22264.0000 - fn: 1136.0000 - accuracy: 0.9515 train_balacc 0.9515056541442548\n",
      " val_balacc 0.9395222768084025\n",
      "\n",
      "Epoch 118: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1248 - tp: 22466.0000 - fp: 1145.0000 - tn: 22466.0000 - fn: 1145.0000 - accuracy: 0.9515 - val_loss: 0.1495 - val_tp: 5546.0000 - val_fp: 357.0000 - val_tn: 5546.0000 - val_fn: 357.0000 - val_accuracy: 0.9395 - train_sensitivity: 0.9515 - train_specificity: 0.9515 - train_balacc: 0.9515 - val_sensitivity: 0.9395 - val_specificity: 0.9395 - val_balacc: 0.9395\n",
      "Epoch 119/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1234 - tp: 22064.0000 - fp: 1136.0000 - tn: 22064.0000 - fn: 1136.0000 - accuracy: 0.9510 train_balacc 0.9507856507560035\n",
      " val_balacc 0.8704048788751483\n",
      "\n",
      "Epoch 119: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1240 - tp: 22449.0000 - fp: 1162.0000 - tn: 22449.0000 - fn: 1162.0000 - accuracy: 0.9508 - val_loss: 0.3421 - val_tp: 5138.0000 - val_fp: 765.0000 - val_tn: 5138.0000 - val_fn: 765.0000 - val_accuracy: 0.8704 - train_sensitivity: 0.9508 - train_specificity: 0.9508 - train_balacc: 0.9508 - val_sensitivity: 0.8704 - val_specificity: 0.8704 - val_balacc: 0.8704\n",
      "Epoch 120/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1205 - tp: 22248.0000 - fp: 1152.0000 - tn: 22248.0000 - fn: 1152.0000 - accuracy: 0.9508 train_balacc 0.9506585913345474\n",
      " val_balacc 0.8046755886837201\n",
      "\n",
      "Epoch 120: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1209 - tp: 22446.0000 - fp: 1165.0000 - tn: 22446.0000 - fn: 1165.0000 - accuracy: 0.9507 - val_loss: 0.5218 - val_tp: 4750.0000 - val_fp: 1153.0000 - val_tn: 4750.0000 - val_fn: 1153.0000 - val_accuracy: 0.8047 - train_sensitivity: 0.9507 - train_specificity: 0.9507 - train_balacc: 0.9507 - val_sensitivity: 0.8047 - val_specificity: 0.8047 - val_balacc: 0.8047\n",
      "Epoch 121/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1292 - tp: 22436.0000 - fp: 1175.0000 - tn: 22436.0000 - fn: 1175.0000 - accuracy: 0.9502 train_balacc 0.9502350599296938\n",
      " val_balacc 0.927155683550737\n",
      "\n",
      "Epoch 121: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1292 - tp: 22436.0000 - fp: 1175.0000 - tn: 22436.0000 - fn: 1175.0000 - accuracy: 0.9502 - val_loss: 0.1760 - val_tp: 5473.0000 - val_fp: 430.0000 - val_tn: 5473.0000 - val_fn: 430.0000 - val_accuracy: 0.9272 - train_sensitivity: 0.9502 - train_specificity: 0.9502 - train_balacc: 0.9502 - val_sensitivity: 0.9272 - val_specificity: 0.9272 - val_balacc: 0.9272\n",
      "Epoch 122/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1219 - tp: 22085.0000 - fp: 1115.0000 - tn: 22085.0000 - fn: 1115.0000 - accuracy: 0.9519 train_balacc 0.9520985981110499\n",
      " val_balacc 0.9105539556157886\n",
      "\n",
      "Epoch 122: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1216 - tp: 22480.0000 - fp: 1131.0000 - tn: 22480.0000 - fn: 1131.0000 - accuracy: 0.9521 - val_loss: 0.2119 - val_tp: 5375.0000 - val_fp: 528.0000 - val_tn: 5375.0000 - val_fn: 528.0000 - val_accuracy: 0.9106 - train_sensitivity: 0.9521 - train_specificity: 0.9521 - train_balacc: 0.9521 - val_sensitivity: 0.9106 - val_specificity: 0.9106 - val_balacc: 0.9106\n",
      "Epoch 123/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1294 - tp: 21939.0000 - fp: 1161.0000 - tn: 21939.0000 - fn: 1161.0000 - accuracy: 0.9497 train_balacc 0.9499385879462963\n",
      " val_balacc 0.9513806539047942\n",
      "\n",
      "Epoch 123: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1286 - tp: 22429.0000 - fp: 1182.0000 - tn: 22429.0000 - fn: 1182.0000 - accuracy: 0.9499 - val_loss: 0.1271 - val_tp: 5616.0000 - val_fp: 287.0000 - val_tn: 5616.0000 - val_fn: 287.0000 - val_accuracy: 0.9514 - train_sensitivity: 0.9499 - train_specificity: 0.9499 - train_balacc: 0.9499 - val_sensitivity: 0.9514 - val_specificity: 0.9514 - val_balacc: 0.9514\n",
      "Epoch 124/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1275 - tp: 21742.0000 - fp: 1158.0000 - tn: 21742.0000 - fn: 1158.0000 - accuracy: 0.9494 train_balacc 0.9495150565414425\n",
      " val_balacc 0.9566322209046247\n",
      "\n",
      "Epoch 124: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1273 - tp: 22419.0000 - fp: 1192.0000 - tn: 22419.0000 - fn: 1192.0000 - accuracy: 0.9495 - val_loss: 0.1053 - val_tp: 5647.0000 - val_fp: 256.0000 - val_tn: 5647.0000 - val_fn: 256.0000 - val_accuracy: 0.9566 - train_sensitivity: 0.9495 - train_specificity: 0.9495 - train_balacc: 0.9495 - val_sensitivity: 0.9566 - val_specificity: 0.9566 - val_balacc: 0.9566\n",
      "Epoch 125/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1186 - tp: 22493.0000 - fp: 1107.0000 - tn: 22493.0000 - fn: 1107.0000 - accuracy: 0.9531 train_balacc 0.9530727203422134\n",
      " val_balacc 0.9339318990343893\n",
      "\n",
      "Epoch 125: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1186 - tp: 22503.0000 - fp: 1108.0000 - tn: 22503.0000 - fn: 1108.0000 - accuracy: 0.9531 - val_loss: 0.1669 - val_tp: 5513.0000 - val_fp: 390.0000 - val_tn: 5513.0000 - val_fn: 390.0000 - val_accuracy: 0.9339 - train_sensitivity: 0.9531 - train_specificity: 0.9531 - train_balacc: 0.9531 - val_sensitivity: 0.9339 - val_specificity: 0.9339 - val_balacc: 0.9339\n",
      "Epoch 126/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1254 - tp: 22003.0000 - fp: 1097.0000 - tn: 22003.0000 - fn: 1097.0000 - accuracy: 0.9525 train_balacc 0.9526915420778451\n",
      " val_balacc 0.9571404370658987\n",
      "\n",
      "Epoch 126: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1247 - tp: 22494.0000 - fp: 1117.0000 - tn: 22494.0000 - fn: 1117.0000 - accuracy: 0.9527 - val_loss: 0.1149 - val_tp: 5650.0000 - val_fp: 253.0000 - val_tn: 5650.0000 - val_fn: 253.0000 - val_accuracy: 0.9571 - train_sensitivity: 0.9527 - train_specificity: 0.9527 - train_balacc: 0.9527 - val_sensitivity: 0.9571 - val_specificity: 0.9571 - val_balacc: 0.9571\n",
      "Epoch 127/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1221 - tp: 22222.0000 - fp: 1078.0000 - tn: 22222.0000 - fn: 1078.0000 - accuracy: 0.9537 train_balacc 0.9536656643090086\n",
      " val_balacc 0.9454514653565983\n",
      "\n",
      "Epoch 127: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1225 - tp: 22517.0000 - fp: 1094.0000 - tn: 22517.0000 - fn: 1094.0000 - accuracy: 0.9537 - val_loss: 0.1343 - val_tp: 5581.0000 - val_fp: 322.0000 - val_tn: 5581.0000 - val_fn: 322.0000 - val_accuracy: 0.9455 - train_sensitivity: 0.9537 - train_specificity: 0.9537 - train_balacc: 0.9537 - val_sensitivity: 0.9455 - val_specificity: 0.9455 - val_balacc: 0.9455\n",
      "Epoch 128/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1260 - tp: 21974.0000 - fp: 1126.0000 - tn: 21974.0000 - fn: 1126.0000 - accuracy: 0.9513 train_balacc 0.9516327135657109\n",
      " val_balacc 0.9147890902930713\n",
      "\n",
      "Epoch 128: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1251 - tp: 22469.0000 - fp: 1142.0000 - tn: 22469.0000 - fn: 1142.0000 - accuracy: 0.9516 - val_loss: 0.2057 - val_tp: 5400.0000 - val_fp: 503.0000 - val_tn: 5400.0000 - val_fn: 503.0000 - val_accuracy: 0.9148 - train_sensitivity: 0.9516 - train_specificity: 0.9516 - train_balacc: 0.9516 - val_sensitivity: 0.9148 - val_specificity: 0.9148 - val_balacc: 0.9148\n",
      "Epoch 129/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1256 - tp: 22234.0000 - fp: 1166.0000 - tn: 22234.0000 - fn: 1166.0000 - accuracy: 0.9502 train_balacc 0.9504044724916353\n",
      " val_balacc 0.9115703879383364\n",
      "\n",
      "Epoch 129: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1252 - tp: 22440.0000 - fp: 1171.0000 - tn: 22440.0000 - fn: 1171.0000 - accuracy: 0.9504 - val_loss: 0.2570 - val_tp: 5381.0000 - val_fp: 522.0000 - val_tn: 5381.0000 - val_fn: 522.0000 - val_accuracy: 0.9116 - train_sensitivity: 0.9504 - train_specificity: 0.9504 - train_balacc: 0.9504 - val_sensitivity: 0.9116 - val_specificity: 0.9116 - val_balacc: 0.9116\n",
      "Epoch 130/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1217 - tp: 22261.0000 - fp: 1139.0000 - tn: 22261.0000 - fn: 1139.0000 - accuracy: 0.9513 train_balacc 0.9513785947227987\n",
      " val_balacc 0.7181094358800609\n",
      "\n",
      "Epoch 130: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1219 - tp: 22463.0000 - fp: 1148.0000 - tn: 22463.0000 - fn: 1148.0000 - accuracy: 0.9514 - val_loss: 1.2258 - val_tp: 4239.0000 - val_fp: 1664.0000 - val_tn: 4239.0000 - val_fn: 1664.0000 - val_accuracy: 0.7181 - train_sensitivity: 0.9514 - train_specificity: 0.9514 - train_balacc: 0.9514 - val_sensitivity: 0.7181 - val_specificity: 0.7181 - val_balacc: 0.7181\n",
      "Epoch 131/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1194 - tp: 22491.0000 - fp: 1120.0000 - tn: 22491.0000 - fn: 1120.0000 - accuracy: 0.9526 train_balacc 0.9525644826563889\n",
      " val_balacc 0.9554463831949856\n",
      "\n",
      "Epoch 131: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1194 - tp: 22491.0000 - fp: 1120.0000 - tn: 22491.0000 - fn: 1120.0000 - accuracy: 0.9526 - val_loss: 0.1314 - val_tp: 5640.0000 - val_fp: 263.0000 - val_tn: 5640.0000 - val_fn: 263.0000 - val_accuracy: 0.9554 - train_sensitivity: 0.9526 - train_specificity: 0.9526 - train_balacc: 0.9526 - val_sensitivity: 0.9554 - val_specificity: 0.9554 - val_balacc: 0.9554\n",
      "Epoch 132/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1228 - tp: 22300.0000 - fp: 1100.0000 - tn: 22300.0000 - fn: 1100.0000 - accuracy: 0.9530 train_balacc 0.9528609546397866\n",
      " val_balacc 0.950703032356429\n",
      "\n",
      "Epoch 132: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1225 - tp: 22498.0000 - fp: 1113.0000 - tn: 22498.0000 - fn: 1113.0000 - accuracy: 0.9529 - val_loss: 0.1171 - val_tp: 5612.0000 - val_fp: 291.0000 - val_tn: 5612.0000 - val_fn: 291.0000 - val_accuracy: 0.9507 - train_sensitivity: 0.9529 - train_specificity: 0.9529 - train_balacc: 0.9529 - val_sensitivity: 0.9507 - val_specificity: 0.9507 - val_balacc: 0.9507\n",
      "Epoch 133/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1262 - tp: 21788.0000 - fp: 1112.0000 - tn: 21788.0000 - fn: 1112.0000 - accuracy: 0.9514 train_balacc 0.9517174198466817\n",
      " val_balacc 0.9540911400982551\n",
      "\n",
      "Epoch 133: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1251 - tp: 22471.0000 - fp: 1140.0000 - tn: 22471.0000 - fn: 1140.0000 - accuracy: 0.9517 - val_loss: 0.1219 - val_tp: 5632.0000 - val_fp: 271.0000 - val_tn: 5632.0000 - val_fn: 271.0000 - val_accuracy: 0.9541 - train_sensitivity: 0.9517 - train_specificity: 0.9517 - train_balacc: 0.9517 - val_sensitivity: 0.9541 - val_specificity: 0.9541 - val_balacc: 0.9541\n",
      "Epoch 134/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1210 - tp: 22133.0000 - fp: 1067.0000 - tn: 22133.0000 - fn: 1067.0000 - accuracy: 0.9540 train_balacc 0.9537927237304646\n",
      " val_balacc 0.9495171946467897\n",
      "\n",
      "Epoch 134: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1211 - tp: 22520.0000 - fp: 1091.0000 - tn: 22520.0000 - fn: 1091.0000 - accuracy: 0.9538 - val_loss: 0.1398 - val_tp: 5605.0000 - val_fp: 298.0000 - val_tn: 5605.0000 - val_fn: 298.0000 - val_accuracy: 0.9495 - train_sensitivity: 0.9538 - train_specificity: 0.9538 - train_balacc: 0.9538 - val_sensitivity: 0.9495 - val_specificity: 0.9495 - val_balacc: 0.9495\n",
      "Epoch 135/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1271 - tp: 22172.0000 - fp: 1128.0000 - tn: 22172.0000 - fn: 1128.0000 - accuracy: 0.9516 train_balacc 0.9517174198466817\n",
      " val_balacc 0.9554463831949856\n",
      "\n",
      "Epoch 135: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1265 - tp: 22471.0000 - fp: 1140.0000 - tn: 22471.0000 - fn: 1140.0000 - accuracy: 0.9517 - val_loss: 0.1099 - val_tp: 5640.0000 - val_fp: 263.0000 - val_tn: 5640.0000 - val_fn: 263.0000 - val_accuracy: 0.9554 - train_sensitivity: 0.9517 - train_specificity: 0.9517 - train_balacc: 0.9517 - val_sensitivity: 0.9554 - val_specificity: 0.9554 - val_balacc: 0.9554\n",
      "Epoch 136/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1245 - tp: 21798.0000 - fp: 1102.0000 - tn: 21798.0000 - fn: 1102.0000 - accuracy: 0.9519 train_balacc 0.9519715386895938\n",
      " val_balacc 0.9344401151956632\n",
      "\n",
      "Epoch 136: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1242 - tp: 22477.0000 - fp: 1134.0000 - tn: 22477.0000 - fn: 1134.0000 - accuracy: 0.9520 - val_loss: 0.1553 - val_tp: 5516.0000 - val_fp: 387.0000 - val_tn: 5516.0000 - val_fn: 387.0000 - val_accuracy: 0.9344 - train_sensitivity: 0.9520 - train_specificity: 0.9520 - train_balacc: 0.9520 - val_sensitivity: 0.9344 - val_specificity: 0.9344 - val_balacc: 0.9344\n",
      "Epoch 137/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1242 - tp: 22187.0000 - fp: 1113.0000 - tn: 22187.0000 - fn: 1113.0000 - accuracy: 0.9522 train_balacc 0.952225657532506\n",
      " val_balacc 0.9491783838726071\n",
      "\n",
      "Epoch 137: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1240 - tp: 22483.0000 - fp: 1128.0000 - tn: 22483.0000 - fn: 1128.0000 - accuracy: 0.9522 - val_loss: 0.1304 - val_tp: 5603.0000 - val_fp: 300.0000 - val_tn: 5603.0000 - val_fn: 300.0000 - val_accuracy: 0.9492 - train_sensitivity: 0.9522 - train_specificity: 0.9522 - train_balacc: 0.9522 - val_sensitivity: 0.9492 - val_specificity: 0.9492 - val_balacc: 0.9492\n",
      "Epoch 138/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1180 - tp: 22424.0000 - fp: 1076.0000 - tn: 22424.0000 - fn: 1076.0000 - accuracy: 0.9542 train_balacc 0.9542586082758037\n",
      " val_balacc 0.9512112485177029\n",
      "\n",
      "Epoch 138: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1181 - tp: 22531.0000 - fp: 1080.0000 - tn: 22531.0000 - fn: 1080.0000 - accuracy: 0.9543 - val_loss: 0.1243 - val_tp: 5615.0000 - val_fp: 288.0000 - val_tn: 5615.0000 - val_fn: 288.0000 - val_accuracy: 0.9512 - train_sensitivity: 0.9543 - train_specificity: 0.9543 - train_balacc: 0.9543 - val_sensitivity: 0.9512 - val_specificity: 0.9512 - val_balacc: 0.9512\n",
      "Epoch 139/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1204 - tp: 22409.0000 - fp: 1091.0000 - tn: 22409.0000 - fn: 1091.0000 - accuracy: 0.9536 train_balacc 0.9535386048875524\n",
      " val_balacc 0.9224123327121803\n",
      "\n",
      "Epoch 139: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1206 - tp: 22514.0000 - fp: 1097.0000 - tn: 22514.0000 - fn: 1097.0000 - accuracy: 0.9535 - val_loss: 0.1824 - val_tp: 5445.0000 - val_fp: 458.0000 - val_tn: 5445.0000 - val_fn: 458.0000 - val_accuracy: 0.9224 - train_sensitivity: 0.9535 - train_specificity: 0.9535 - train_balacc: 0.9535 - val_sensitivity: 0.9224 - val_specificity: 0.9224 - val_balacc: 0.9224\n",
      "Epoch 140/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1198 - tp: 22307.0000 - fp: 1093.0000 - tn: 22307.0000 - fn: 1093.0000 - accuracy: 0.9533 train_balacc 0.9534538986065817\n",
      " val_balacc 0.941385736066407\n",
      "\n",
      "Epoch 140: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1194 - tp: 22512.0000 - fp: 1099.0000 - tn: 22512.0000 - fn: 1099.0000 - accuracy: 0.9535 - val_loss: 0.1507 - val_tp: 5557.0000 - val_fp: 346.0000 - val_tn: 5557.0000 - val_fn: 346.0000 - val_accuracy: 0.9414 - train_sensitivity: 0.9535 - train_specificity: 0.9535 - train_balacc: 0.9535 - val_sensitivity: 0.9414 - val_specificity: 0.9414 - val_balacc: 0.9414\n",
      "Epoch 141/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1214 - tp: 22301.0000 - fp: 1099.0000 - tn: 22301.0000 - fn: 1099.0000 - accuracy: 0.9530 train_balacc 0.9530727203422134\n",
      " val_balacc 0.9139420633576147\n",
      "\n",
      "Epoch 141: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1211 - tp: 22503.0000 - fp: 1108.0000 - tn: 22503.0000 - fn: 1108.0000 - accuracy: 0.9531 - val_loss: 0.2012 - val_tp: 5395.0000 - val_fp: 508.0000 - val_tn: 5395.0000 - val_fn: 508.0000 - val_accuracy: 0.9139 - train_sensitivity: 0.9531 - train_specificity: 0.9531 - train_balacc: 0.9531 - val_sensitivity: 0.9139 - val_specificity: 0.9139 - val_balacc: 0.9139\n",
      "Epoch 142/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1196 - tp: 22309.0000 - fp: 1091.0000 - tn: 22309.0000 - fn: 1091.0000 - accuracy: 0.9534 train_balacc 0.9531997797636694\n",
      " val_balacc 0.9542605454853464\n",
      "\n",
      "Epoch 142: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1200 - tp: 22506.0000 - fp: 1105.0000 - tn: 22506.0000 - fn: 1105.0000 - accuracy: 0.9532 - val_loss: 0.1256 - val_tp: 5633.0000 - val_fp: 270.0000 - val_tn: 5633.0000 - val_fn: 270.0000 - val_accuracy: 0.9543 - train_sensitivity: 0.9532 - train_specificity: 0.9532 - train_balacc: 0.9532 - val_sensitivity: 0.9543 - val_specificity: 0.9543 - val_balacc: 0.9543\n",
      "Epoch 143/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1204 - tp: 21797.0000 - fp: 1103.0000 - tn: 21797.0000 - fn: 1103.0000 - accuracy: 0.9518 train_balacc 0.9519715386895938\n",
      " val_balacc 0.9281721158732847\n",
      "\n",
      "Epoch 143: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1204 - tp: 22477.0000 - fp: 1134.0000 - tn: 22477.0000 - fn: 1134.0000 - accuracy: 0.9520 - val_loss: 0.1711 - val_tp: 5479.0000 - val_fp: 424.0000 - val_tn: 5479.0000 - val_fn: 424.0000 - val_accuracy: 0.9282 - train_sensitivity: 0.9520 - train_specificity: 0.9520 - train_balacc: 0.9520 - val_sensitivity: 0.9282 - val_specificity: 0.9282 - val_balacc: 0.9282\n",
      "Epoch 144/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1213 - tp: 22342.0000 - fp: 1158.0000 - tn: 22342.0000 - fn: 1158.0000 - accuracy: 0.9507 train_balacc 0.9507009444750328\n",
      " val_balacc 0.9474843300016941\n",
      "\n",
      "Epoch 144: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1215 - tp: 22447.0000 - fp: 1164.0000 - tn: 22447.0000 - fn: 1164.0000 - accuracy: 0.9507 - val_loss: 0.1332 - val_tp: 5593.0000 - val_fp: 310.0000 - val_tn: 5593.0000 - val_fn: 310.0000 - val_accuracy: 0.9475 - train_sensitivity: 0.9507 - train_specificity: 0.9507 - train_balacc: 0.9507 - val_sensitivity: 0.9475 - val_specificity: 0.9475 - val_balacc: 0.9475\n",
      "Epoch 145/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1153 - tp: 21879.0000 - fp: 1021.0000 - tn: 21879.0000 - fn: 1021.0000 - accuracy: 0.9554 train_balacc 0.9552750836474525\n",
      " val_balacc 0.9491783838726071\n",
      "\n",
      "Epoch 145: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1151 - tp: 22555.0000 - fp: 1056.0000 - tn: 22555.0000 - fn: 1056.0000 - accuracy: 0.9553 - val_loss: 0.1348 - val_tp: 5603.0000 - val_fp: 300.0000 - val_tn: 5603.0000 - val_fn: 300.0000 - val_accuracy: 0.9492 - train_sensitivity: 0.9553 - train_specificity: 0.9553 - train_balacc: 0.9553 - val_sensitivity: 0.9492 - val_specificity: 0.9492 - val_balacc: 0.9492\n",
      "Epoch 146/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1243 - tp: 21967.0000 - fp: 1133.0000 - tn: 21967.0000 - fn: 1133.0000 - accuracy: 0.9510 train_balacc 0.9511668290203719\n",
      " val_balacc 0.9446044384211418\n",
      "\n",
      "Epoch 146: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1238 - tp: 22458.0000 - fp: 1153.0000 - tn: 22458.0000 - fn: 1153.0000 - accuracy: 0.9512 - val_loss: 0.1432 - val_tp: 5576.0000 - val_fp: 327.0000 - val_tn: 5576.0000 - val_fn: 327.0000 - val_accuracy: 0.9446 - train_sensitivity: 0.9512 - train_specificity: 0.9512 - train_balacc: 0.9512 - val_sensitivity: 0.9446 - val_specificity: 0.9446 - val_balacc: 0.9446\n",
      "Epoch 147/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1169 - tp: 22306.0000 - fp: 1094.0000 - tn: 22306.0000 - fn: 1094.0000 - accuracy: 0.9532 train_balacc 0.9529033077802719\n",
      " val_balacc 0.9474843300016941\n",
      "\n",
      "Epoch 147: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1175 - tp: 22499.0000 - fp: 1112.0000 - tn: 22499.0000 - fn: 1112.0000 - accuracy: 0.9529 - val_loss: 0.1263 - val_tp: 5593.0000 - val_fp: 310.0000 - val_tn: 5593.0000 - val_fn: 310.0000 - val_accuracy: 0.9475 - train_sensitivity: 0.9529 - train_specificity: 0.9529 - train_balacc: 0.9529 - val_sensitivity: 0.9475 - val_specificity: 0.9475 - val_balacc: 0.9475\n",
      "Epoch 148/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1164 - tp: 22586.0000 - fp: 1014.0000 - tn: 22586.0000 - fn: 1014.0000 - accuracy: 0.9570 train_balacc 0.9570115624073525\n",
      " val_balacc 0.9312214128409283\n",
      "\n",
      "Epoch 148: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1164 - tp: 22596.0000 - fp: 1015.0000 - tn: 22596.0000 - fn: 1015.0000 - accuracy: 0.9570 - val_loss: 0.1565 - val_tp: 5497.0000 - val_fp: 406.0000 - val_tn: 5497.0000 - val_fn: 406.0000 - val_accuracy: 0.9312 - train_sensitivity: 0.9570 - train_specificity: 0.9570 - train_balacc: 0.9570 - val_sensitivity: 0.9312 - val_specificity: 0.9312 - val_balacc: 0.9312\n",
      "Epoch 149/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1170 - tp: 21828.0000 - fp: 1072.0000 - tn: 21828.0000 - fn: 1072.0000 - accuracy: 0.9532 train_balacc 0.9533268391851256\n",
      " val_balacc 0.9562934101304421\n",
      "\n",
      "Epoch 149: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1165 - tp: 22509.0000 - fp: 1102.0000 - tn: 22509.0000 - fn: 1102.0000 - accuracy: 0.9533 - val_loss: 0.1198 - val_tp: 5645.0000 - val_fp: 258.0000 - val_tn: 5645.0000 - val_fn: 258.0000 - val_accuracy: 0.9563 - train_sensitivity: 0.9533 - train_specificity: 0.9533 - train_balacc: 0.9533 - val_sensitivity: 0.9563 - val_specificity: 0.9563 - val_balacc: 0.9563\n",
      "Epoch 150/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1216 - tp: 21728.0000 - fp: 1072.0000 - tn: 21728.0000 - fn: 1072.0000 - accuracy: 0.9530 train_balacc 0.9534115454660963\n",
      " val_balacc 0.9518888700660681\n",
      "\n",
      "Epoch 150: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1200 - tp: 22511.0000 - fp: 1100.0000 - tn: 22511.0000 - fn: 1100.0000 - accuracy: 0.9534 - val_loss: 0.1172 - val_tp: 5619.0000 - val_fp: 284.0000 - val_tn: 5619.0000 - val_fn: 284.0000 - val_accuracy: 0.9519 - train_sensitivity: 0.9534 - train_specificity: 0.9534 - train_balacc: 0.9534 - val_sensitivity: 0.9519 - val_specificity: 0.9519 - val_balacc: 0.9519\n",
      "Epoch 151/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1184 - tp: 22164.0000 - fp: 1036.0000 - tn: 22164.0000 - fn: 1036.0000 - accuracy: 0.9553 train_balacc 0.9551480242259963\n",
      " val_balacc 0.95730984245299\n",
      "\n",
      "Epoch 151: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1192 - tp: 22552.0000 - fp: 1059.0000 - tn: 22552.0000 - fn: 1059.0000 - accuracy: 0.9551 - val_loss: 0.1122 - val_tp: 5651.0000 - val_fp: 252.0000 - val_tn: 5651.0000 - val_fn: 252.0000 - val_accuracy: 0.9573 - train_sensitivity: 0.9551 - train_specificity: 0.9551 - train_balacc: 0.9551 - val_sensitivity: 0.9573 - val_specificity: 0.9573 - val_balacc: 0.9573\n",
      "Epoch 152/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1145 - tp: 22159.0000 - fp: 1041.0000 - tn: 22159.0000 - fn: 1041.0000 - accuracy: 0.9551 train_balacc 0.9549786116640548\n",
      " val_balacc 0.9429103845502287\n",
      "\n",
      "Epoch 152: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1154 - tp: 22548.0000 - fp: 1063.0000 - tn: 22548.0000 - fn: 1063.0000 - accuracy: 0.9550 - val_loss: 0.1355 - val_tp: 5566.0000 - val_fp: 337.0000 - val_tn: 5566.0000 - val_fn: 337.0000 - val_accuracy: 0.9429 - train_sensitivity: 0.9550 - train_specificity: 0.9550 - train_balacc: 0.9550 - val_sensitivity: 0.9429 - val_specificity: 0.9429 - val_balacc: 0.9429\n",
      "Epoch 153/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1198 - tp: 22486.0000 - fp: 1114.0000 - tn: 22486.0000 - fn: 1114.0000 - accuracy: 0.9528 train_balacc 0.9527338952183304\n",
      " val_balacc 0.9305437912925631\n",
      "\n",
      "Epoch 153: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1199 - tp: 22495.0000 - fp: 1116.0000 - tn: 22495.0000 - fn: 1116.0000 - accuracy: 0.9527 - val_loss: 0.1590 - val_tp: 5493.0000 - val_fp: 410.0000 - val_tn: 5493.0000 - val_fn: 410.0000 - val_accuracy: 0.9305 - train_sensitivity: 0.9527 - train_specificity: 0.9527 - train_balacc: 0.9527 - val_sensitivity: 0.9305 - val_specificity: 0.9305 - val_balacc: 0.9305\n",
      "Epoch 154/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1175 - tp: 22547.0000 - fp: 1053.0000 - tn: 22547.0000 - fn: 1053.0000 - accuracy: 0.9554 train_balacc 0.9553597899284232\n",
      " val_balacc 0.936472979840759\n",
      "\n",
      "Epoch 154: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1175 - tp: 22557.0000 - fp: 1054.0000 - tn: 22557.0000 - fn: 1054.0000 - accuracy: 0.9554 - val_loss: 0.1583 - val_tp: 5528.0000 - val_fp: 375.0000 - val_tn: 5528.0000 - val_fn: 375.0000 - val_accuracy: 0.9365 - train_sensitivity: 0.9554 - train_specificity: 0.9554 - train_balacc: 0.9554 - val_sensitivity: 0.9365 - val_specificity: 0.9365 - val_balacc: 0.9365\n",
      "Epoch 155/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1219 - tp: 22215.0000 - fp: 1085.0000 - tn: 22215.0000 - fn: 1085.0000 - accuracy: 0.9534 train_balacc 0.9531997797636694\n",
      " val_balacc 0.8090801287480942\n",
      "\n",
      "Epoch 155: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1222 - tp: 22506.0000 - fp: 1105.0000 - tn: 22506.0000 - fn: 1105.0000 - accuracy: 0.9532 - val_loss: 0.5817 - val_tp: 4776.0000 - val_fp: 1127.0000 - val_tn: 4776.0000 - val_fn: 1127.0000 - val_accuracy: 0.8091 - train_sensitivity: 0.9532 - train_specificity: 0.9532 - train_balacc: 0.9532 - val_sensitivity: 0.8091 - val_specificity: 0.8091 - val_balacc: 0.8091\n",
      "Epoch 156/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1216 - tp: 22223.0000 - fp: 1077.0000 - tn: 22223.0000 - fn: 1077.0000 - accuracy: 0.9538 train_balacc 0.9538774300114353\n",
      " val_balacc 0.9496866000338811\n",
      "\n",
      "Epoch 156: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1214 - tp: 22522.0000 - fp: 1089.0000 - tn: 22522.0000 - fn: 1089.0000 - accuracy: 0.9539 - val_loss: 0.1430 - val_tp: 5606.0000 - val_fp: 297.0000 - val_tn: 5606.0000 - val_fn: 297.0000 - val_accuracy: 0.9497 - train_sensitivity: 0.9539 - train_specificity: 0.9539 - train_balacc: 0.9539 - val_sensitivity: 0.9497 - val_specificity: 0.9497 - val_balacc: 0.9497\n",
      "Epoch 157/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1212 - tp: 21856.0000 - fp: 1044.0000 - tn: 21856.0000 - fn: 1044.0000 - accuracy: 0.9544 train_balacc 0.954639786540172\n",
      " val_balacc 0.9346095205827545\n",
      "\n",
      "Epoch 157: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1207 - tp: 22540.0000 - fp: 1071.0000 - tn: 22540.0000 - fn: 1071.0000 - accuracy: 0.9546 - val_loss: 0.1732 - val_tp: 5517.0000 - val_fp: 386.0000 - val_tn: 5517.0000 - val_fn: 386.0000 - val_accuracy: 0.9346 - train_sensitivity: 0.9546 - train_specificity: 0.9546 - train_balacc: 0.9546 - val_sensitivity: 0.9346 - val_specificity: 0.9346 - val_balacc: 0.9346\n",
      "Epoch 158/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1199 - tp: 21704.0000 - fp: 1096.0000 - tn: 21704.0000 - fn: 1096.0000 - accuracy: 0.9519 train_balacc 0.952225657532506\n",
      " val_balacc 0.935964763679485\n",
      "\n",
      "Epoch 158: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1192 - tp: 22483.0000 - fp: 1128.0000 - tn: 22483.0000 - fn: 1128.0000 - accuracy: 0.9522 - val_loss: 0.1731 - val_tp: 5525.0000 - val_fp: 378.0000 - val_tn: 5525.0000 - val_fn: 378.0000 - val_accuracy: 0.9360 - train_sensitivity: 0.9522 - train_specificity: 0.9522 - train_balacc: 0.9522 - val_sensitivity: 0.9360 - val_specificity: 0.9360 - val_balacc: 0.9360\n",
      "Epoch 159/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1183 - tp: 22542.0000 - fp: 1058.0000 - tn: 22542.0000 - fn: 1058.0000 - accuracy: 0.9552 train_balacc 0.9551903773664817\n",
      " val_balacc 0.9437574114856853\n",
      "\n",
      "Epoch 159: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1183 - tp: 22553.0000 - fp: 1058.0000 - tn: 22553.0000 - fn: 1058.0000 - accuracy: 0.9552 - val_loss: 0.1359 - val_tp: 5571.0000 - val_fp: 332.0000 - val_tn: 5571.0000 - val_fn: 332.0000 - val_accuracy: 0.9438 - train_sensitivity: 0.9552 - train_specificity: 0.9552 - train_balacc: 0.9552 - val_sensitivity: 0.9438 - val_specificity: 0.9438 - val_balacc: 0.9438\n",
      "Epoch 160/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1135 - tp: 22354.0000 - fp: 1046.0000 - tn: 22354.0000 - fn: 1046.0000 - accuracy: 0.9553 train_balacc 0.9551903773664817\n",
      " val_balacc 0.9481619515500593\n",
      "\n",
      "Epoch 160: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1139 - tp: 22553.0000 - fp: 1058.0000 - tn: 22553.0000 - fn: 1058.0000 - accuracy: 0.9552 - val_loss: 0.1230 - val_tp: 5597.0000 - val_fp: 306.0000 - val_tn: 5597.0000 - val_fn: 306.0000 - val_accuracy: 0.9482 - train_sensitivity: 0.9552 - train_specificity: 0.9552 - train_balacc: 0.9552 - val_sensitivity: 0.9482 - val_specificity: 0.9482 - val_balacc: 0.9482\n",
      "Epoch 161/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1141 - tp: 21926.0000 - fp: 974.0000 - tn: 21926.0000 - fn: 974.0000 - accuracy: 0.9575 train_balacc 0.9571386218288086\n",
      " val_balacc 0.9291885481958326\n",
      "\n",
      "Epoch 161: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1142 - tp: 22599.0000 - fp: 1012.0000 - tn: 22599.0000 - fn: 1012.0000 - accuracy: 0.9571 - val_loss: 0.1728 - val_tp: 5485.0000 - val_fp: 418.0000 - val_tn: 5485.0000 - val_fn: 418.0000 - val_accuracy: 0.9292 - train_sensitivity: 0.9571 - train_specificity: 0.9571 - train_balacc: 0.9571 - val_sensitivity: 0.9292 - val_specificity: 0.9292 - val_balacc: 0.9292\n",
      "Epoch 162/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1167 - tp: 21851.0000 - fp: 1049.0000 - tn: 21851.0000 - fn: 1049.0000 - accuracy: 0.9542 train_balacc 0.9543433145567743\n",
      " val_balacc 0.9461290869049636\n",
      "\n",
      "Epoch 162: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1174 - tp: 22533.0000 - fp: 1078.0000 - tn: 22533.0000 - fn: 1078.0000 - accuracy: 0.9543 - val_loss: 0.1239 - val_tp: 5585.0000 - val_fp: 318.0000 - val_tn: 5585.0000 - val_fn: 318.0000 - val_accuracy: 0.9461 - train_sensitivity: 0.9543 - train_specificity: 0.9543 - train_balacc: 0.9543 - val_sensitivity: 0.9461 - val_specificity: 0.9461 - val_balacc: 0.9461\n",
      "Epoch 163/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1138 - tp: 22316.0000 - fp: 1084.0000 - tn: 22316.0000 - fn: 1084.0000 - accuracy: 0.9537 train_balacc 0.9536233111685232\n",
      " val_balacc 0.9100457394545146\n",
      "\n",
      "Epoch 163: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1144 - tp: 22516.0000 - fp: 1095.0000 - tn: 22516.0000 - fn: 1095.0000 - accuracy: 0.9536 - val_loss: 0.2080 - val_tp: 5372.0000 - val_fp: 531.0000 - val_tn: 5372.0000 - val_fn: 531.0000 - val_accuracy: 0.9100 - train_sensitivity: 0.9536 - train_specificity: 0.9536 - train_balacc: 0.9536 - val_sensitivity: 0.9100 - val_specificity: 0.9100 - val_balacc: 0.9100\n",
      "Epoch 164/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1108 - tp: 22266.0000 - fp: 1034.0000 - tn: 22266.0000 - fn: 1034.0000 - accuracy: 0.9556 train_balacc 0.9554868493498793\n",
      " val_balacc 0.9525664916144333\n",
      "\n",
      "Epoch 164: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1113 - tp: 22560.0000 - fp: 1051.0000 - tn: 22560.0000 - fn: 1051.0000 - accuracy: 0.9555 - val_loss: 0.1345 - val_tp: 5623.0000 - val_fp: 280.0000 - val_tn: 5623.0000 - val_fn: 280.0000 - val_accuracy: 0.9526 - train_sensitivity: 0.9555 - train_specificity: 0.9555 - train_balacc: 0.9555 - val_sensitivity: 0.9526 - val_specificity: 0.9526 - val_balacc: 0.9526\n",
      "Epoch 165/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1182 - tp: 22429.0000 - fp: 1071.0000 - tn: 22429.0000 - fn: 1071.0000 - accuracy: 0.9544 train_balacc 0.9544280208377451\n",
      " val_balacc 0.9190242249703541\n",
      "\n",
      "Epoch 165: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1180 - tp: 22535.0000 - fp: 1076.0000 - tn: 22535.0000 - fn: 1076.0000 - accuracy: 0.9544 - val_loss: 0.1969 - val_tp: 5425.0000 - val_fp: 478.0000 - val_tn: 5425.0000 - val_fn: 478.0000 - val_accuracy: 0.9190 - train_sensitivity: 0.9544 - train_specificity: 0.9544 - train_balacc: 0.9544 - val_sensitivity: 0.9190 - val_specificity: 0.9190 - val_balacc: 0.9190\n",
      "Epoch 166/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1170 - tp: 22543.0000 - fp: 1057.0000 - tn: 22543.0000 - fn: 1057.0000 - accuracy: 0.9552 train_balacc 0.9552327305069671\n",
      " val_balacc 0.9617143825173641\n",
      "\n",
      "Epoch 166: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1170 - tp: 22554.0000 - fp: 1057.0000 - tn: 22554.0000 - fn: 1057.0000 - accuracy: 0.9552 - val_loss: 0.1026 - val_tp: 5677.0000 - val_fp: 226.0000 - val_tn: 5677.0000 - val_fn: 226.0000 - val_accuracy: 0.9617 - train_sensitivity: 0.9552 - train_specificity: 0.9552 - train_balacc: 0.9552 - val_sensitivity: 0.9617 - val_specificity: 0.9617 - val_balacc: 0.9617\n",
      "Epoch 167/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1125 - tp: 21822.0000 - fp: 978.0000 - tn: 21822.0000 - fn: 978.0000 - accuracy: 0.9571 train_balacc 0.957180974969294\n",
      " val_balacc 0.9532441131627986\n",
      "\n",
      "Epoch 167: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1125 - tp: 22600.0000 - fp: 1011.0000 - tn: 22600.0000 - fn: 1011.0000 - accuracy: 0.9572 - val_loss: 0.1304 - val_tp: 5627.0000 - val_fp: 276.0000 - val_tn: 5627.0000 - val_fn: 276.0000 - val_accuracy: 0.9532 - train_sensitivity: 0.9572 - train_specificity: 0.9572 - train_balacc: 0.9572 - val_sensitivity: 0.9532 - val_specificity: 0.9532 - val_balacc: 0.9532\n",
      "Epoch 168/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1162 - tp: 22197.0000 - fp: 1003.0000 - tn: 22197.0000 - fn: 1003.0000 - accuracy: 0.9568 train_balacc 0.9565880310024988\n",
      " val_balacc 0.9368117906149416\n",
      "\n",
      "Epoch 168: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1168 - tp: 22586.0000 - fp: 1025.0000 - tn: 22586.0000 - fn: 1025.0000 - accuracy: 0.9566 - val_loss: 0.1446 - val_tp: 5530.0000 - val_fp: 373.0000 - val_tn: 5530.0000 - val_fn: 373.0000 - val_accuracy: 0.9368 - train_sensitivity: 0.9566 - train_specificity: 0.9566 - train_balacc: 0.9566 - val_sensitivity: 0.9368 - val_specificity: 0.9368 - val_balacc: 0.9368\n",
      "Epoch 169/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1122 - tp: 22571.0000 - fp: 1040.0000 - tn: 22571.0000 - fn: 1040.0000 - accuracy: 0.9560 train_balacc 0.9559527338952183\n",
      " val_balacc 0.9447738438082331\n",
      "\n",
      "Epoch 169: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1122 - tp: 22571.0000 - fp: 1040.0000 - tn: 22571.0000 - fn: 1040.0000 - accuracy: 0.9560 - val_loss: 0.1378 - val_tp: 5577.0000 - val_fp: 326.0000 - val_tn: 5577.0000 - val_fn: 326.0000 - val_accuracy: 0.9448 - train_sensitivity: 0.9560 - train_specificity: 0.9560 - train_balacc: 0.9560 - val_sensitivity: 0.9448 - val_specificity: 0.9448 - val_balacc: 0.9448\n",
      "Epoch 170/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1141 - tp: 22287.0000 - fp: 1013.0000 - tn: 22287.0000 - fn: 1013.0000 - accuracy: 0.9565 train_balacc 0.9566303841429842\n",
      " val_balacc 0.9247840081314586\n",
      "\n",
      "Epoch 170: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1139 - tp: 22587.0000 - fp: 1024.0000 - tn: 22587.0000 - fn: 1024.0000 - accuracy: 0.9566 - val_loss: 0.1860 - val_tp: 5459.0000 - val_fp: 444.0000 - val_tn: 5459.0000 - val_fn: 444.0000 - val_accuracy: 0.9248 - train_sensitivity: 0.9566 - train_specificity: 0.9566 - train_balacc: 0.9566 - val_sensitivity: 0.9248 - val_specificity: 0.9248 - val_balacc: 0.9248\n",
      "Epoch 171/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1182 - tp: 22152.0000 - fp: 1048.0000 - tn: 22152.0000 - fn: 1048.0000 - accuracy: 0.9548 train_balacc 0.9549362585235696\n",
      " val_balacc 0.94307978993732\n",
      "\n",
      "Epoch 171: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1178 - tp: 22547.0000 - fp: 1064.0000 - tn: 22547.0000 - fn: 1064.0000 - accuracy: 0.9549 - val_loss: 0.1686 - val_tp: 5567.0000 - val_fp: 336.0000 - val_tn: 5567.0000 - val_fn: 336.0000 - val_accuracy: 0.9431 - train_sensitivity: 0.9549 - train_specificity: 0.9549 - train_balacc: 0.9549 - val_sensitivity: 0.9431 - val_specificity: 0.9431 - val_balacc: 0.9431\n",
      "Epoch 172/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1180 - tp: 22522.0000 - fp: 1089.0000 - tn: 22522.0000 - fn: 1089.0000 - accuracy: 0.9539 train_balacc 0.9538774300114353\n",
      " val_balacc 0.9554463831949856\n",
      "\n",
      "Epoch 172: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1180 - tp: 22522.0000 - fp: 1089.0000 - tn: 22522.0000 - fn: 1089.0000 - accuracy: 0.9539 - val_loss: 0.1173 - val_tp: 5640.0000 - val_fp: 263.0000 - val_tn: 5640.0000 - val_fn: 263.0000 - val_accuracy: 0.9554 - train_sensitivity: 0.9539 - train_specificity: 0.9539 - train_balacc: 0.9539 - val_sensitivity: 0.9554 - val_specificity: 0.9554 - val_balacc: 0.9554\n",
      "Epoch 173/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1094 - tp: 22504.0000 - fp: 996.0000 - tn: 22504.0000 - fn: 996.0000 - accuracy: 0.9576 train_balacc 0.9575198000931769\n",
      " val_balacc 0.9405387091309504\n",
      "\n",
      "Epoch 173: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1097 - tp: 22608.0000 - fp: 1003.0000 - tn: 22608.0000 - fn: 1003.0000 - accuracy: 0.9575 - val_loss: 0.1646 - val_tp: 5552.0000 - val_fp: 351.0000 - val_tn: 5552.0000 - val_fn: 351.0000 - val_accuracy: 0.9405 - train_sensitivity: 0.9575 - train_specificity: 0.9575 - train_balacc: 0.9575 - val_sensitivity: 0.9405 - val_specificity: 0.9405 - val_balacc: 0.9405\n",
      "Epoch 174/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1112 - tp: 21891.0000 - fp: 1009.0000 - tn: 21891.0000 - fn: 1009.0000 - accuracy: 0.9559 train_balacc 0.9562068527381306\n",
      " val_balacc 0.8959850923259359\n",
      "\n",
      "Epoch 174: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1113 - tp: 22577.0000 - fp: 1034.0000 - tn: 22577.0000 - fn: 1034.0000 - accuracy: 0.9562 - val_loss: 0.2393 - val_tp: 5289.0000 - val_fp: 614.0000 - val_tn: 5289.0000 - val_fn: 614.0000 - val_accuracy: 0.8960 - train_sensitivity: 0.9562 - train_specificity: 0.9562 - train_balacc: 0.9562 - val_sensitivity: 0.8960 - val_specificity: 0.8960 - val_balacc: 0.8960\n",
      "Epoch 175/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1140 - tp: 22187.0000 - fp: 1013.0000 - tn: 22187.0000 - fn: 1013.0000 - accuracy: 0.9563 train_balacc 0.9565033247215281\n",
      " val_balacc 0.8800609859393529\n",
      "\n",
      "Epoch 175: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1131 - tp: 22584.0000 - fp: 1027.0000 - tn: 22584.0000 - fn: 1027.0000 - accuracy: 0.9565 - val_loss: 0.3995 - val_tp: 5195.0000 - val_fp: 708.0000 - val_tn: 5195.0000 - val_fn: 708.0000 - val_accuracy: 0.8801 - train_sensitivity: 0.9565 - train_specificity: 0.9565 - train_balacc: 0.9565 - val_sensitivity: 0.8801 - val_specificity: 0.8801 - val_balacc: 0.8801\n",
      "Epoch 176/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1131 - tp: 22279.0000 - fp: 1021.0000 - tn: 22279.0000 - fn: 1021.0000 - accuracy: 0.9562 train_balacc 0.9560797933166745\n",
      " val_balacc 0.9491783838726071\n",
      "\n",
      "Epoch 176: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1131 - tp: 22574.0000 - fp: 1037.0000 - tn: 22574.0000 - fn: 1037.0000 - accuracy: 0.9561 - val_loss: 0.1282 - val_tp: 5603.0000 - val_fp: 300.0000 - val_tn: 5603.0000 - val_fn: 300.0000 - val_accuracy: 0.9492 - train_sensitivity: 0.9561 - train_specificity: 0.9561 - train_balacc: 0.9561 - val_sensitivity: 0.9492 - val_specificity: 0.9492 - val_balacc: 0.9492\n",
      "Epoch 177/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1146 - tp: 22287.0000 - fp: 1013.0000 - tn: 22287.0000 - fn: 1013.0000 - accuracy: 0.9565 train_balacc 0.9564609715810427\n",
      " val_balacc 0.9469761138404201\n",
      "\n",
      "Epoch 177: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1149 - tp: 22583.0000 - fp: 1028.0000 - tn: 22583.0000 - fn: 1028.0000 - accuracy: 0.9565 - val_loss: 0.1251 - val_tp: 5590.0000 - val_fp: 313.0000 - val_tn: 5590.0000 - val_fn: 313.0000 - val_accuracy: 0.9470 - train_sensitivity: 0.9565 - train_specificity: 0.9565 - train_balacc: 0.9565 - val_sensitivity: 0.9470 - val_specificity: 0.9470 - val_balacc: 0.9470\n",
      "Epoch 178/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1154 - tp: 22279.0000 - fp: 1021.0000 - tn: 22279.0000 - fn: 1021.0000 - accuracy: 0.9562 train_balacc 0.9559527338952183\n",
      " val_balacc 0.9002202270032187\n",
      "\n",
      "Epoch 178: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1158 - tp: 22571.0000 - fp: 1040.0000 - tn: 22571.0000 - fn: 1040.0000 - accuracy: 0.9560 - val_loss: 0.2256 - val_tp: 5314.0000 - val_fp: 589.0000 - val_tn: 5314.0000 - val_fn: 589.0000 - val_accuracy: 0.9002 - train_sensitivity: 0.9560 - train_specificity: 0.9560 - train_balacc: 0.9560 - val_sensitivity: 0.9002 - val_specificity: 0.9002 - val_balacc: 0.9002\n",
      "Epoch 179/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1150 - tp: 22401.0000 - fp: 999.0000 - tn: 22401.0000 - fn: 999.0000 - accuracy: 0.9573 train_balacc 0.9572233281097794\n",
      " val_balacc 0.9544299508724378\n",
      "\n",
      "Epoch 179: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1150 - tp: 22601.0000 - fp: 1010.0000 - tn: 22601.0000 - fn: 1010.0000 - accuracy: 0.9572 - val_loss: 0.1240 - val_tp: 5634.0000 - val_fp: 269.0000 - val_tn: 5634.0000 - val_fn: 269.0000 - val_accuracy: 0.9544 - train_sensitivity: 0.9572 - train_specificity: 0.9572 - train_balacc: 0.9572 - val_sensitivity: 0.9544 - val_specificity: 0.9544 - val_balacc: 0.9544\n",
      "Epoch 180/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1090 - tp: 22323.0000 - fp: 977.0000 - tn: 22323.0000 - fn: 977.0000 - accuracy: 0.9581 train_balacc 0.9583245097623989\n",
      " val_balacc 0.9219041165509063\n",
      "\n",
      "Epoch 180: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1084 - tp: 22627.0000 - fp: 984.0000 - tn: 22627.0000 - fn: 984.0000 - accuracy: 0.9583 - val_loss: 0.2232 - val_tp: 5442.0000 - val_fp: 461.0000 - val_tn: 5442.0000 - val_fn: 461.0000 - val_accuracy: 0.9219 - train_sensitivity: 0.9583 - train_specificity: 0.9583 - train_balacc: 0.9583 - val_sensitivity: 0.9219 - val_specificity: 0.9219 - val_balacc: 0.9219\n",
      "Epoch 181/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1172 - tp: 21929.0000 - fp: 971.0000 - tn: 21929.0000 - fn: 971.0000 - accuracy: 0.9576 train_balacc 0.957180974969294\n",
      " val_balacc 0.9190242249703541\n",
      "\n",
      "Epoch 181: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1176 - tp: 22600.0000 - fp: 1011.0000 - tn: 22600.0000 - fn: 1011.0000 - accuracy: 0.9572 - val_loss: 0.2148 - val_tp: 5425.0000 - val_fp: 478.0000 - val_tn: 5425.0000 - val_fn: 478.0000 - val_accuracy: 0.9190 - train_sensitivity: 0.9572 - train_specificity: 0.9572 - train_balacc: 0.9572 - val_sensitivity: 0.9190 - val_specificity: 0.9190 - val_balacc: 0.9190\n",
      "Epoch 182/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1160 - tp: 22574.0000 - fp: 1026.0000 - tn: 22574.0000 - fn: 1026.0000 - accuracy: 0.9565 train_balacc 0.9565456778620135\n",
      " val_balacc 0.9420633576147721\n",
      "\n",
      "Epoch 182: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1159 - tp: 22585.0000 - fp: 1026.0000 - tn: 22585.0000 - fn: 1026.0000 - accuracy: 0.9565 - val_loss: 0.1450 - val_tp: 5561.0000 - val_fp: 342.0000 - val_tn: 5561.0000 - val_fn: 342.0000 - val_accuracy: 0.9421 - train_sensitivity: 0.9565 - train_specificity: 0.9565 - train_balacc: 0.9565 - val_sensitivity: 0.9421 - val_specificity: 0.9421 - val_balacc: 0.9421\n",
      "Epoch 183/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1152 - tp: 22530.0000 - fp: 1070.0000 - tn: 22530.0000 - fn: 1070.0000 - accuracy: 0.9547 train_balacc 0.954639786540172\n",
      " val_balacc 0.8458410977469083\n",
      "\n",
      "Epoch 183: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1152 - tp: 22540.0000 - fp: 1071.0000 - tn: 22540.0000 - fn: 1071.0000 - accuracy: 0.9546 - val_loss: 0.4171 - val_tp: 4993.0000 - val_fp: 910.0000 - val_tn: 4993.0000 - val_fn: 910.0000 - val_accuracy: 0.8458 - train_sensitivity: 0.9546 - train_specificity: 0.9546 - train_balacc: 0.9546 - val_sensitivity: 0.8458 - val_specificity: 0.8458 - val_balacc: 0.8458\n",
      "Epoch 184/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1099 - tp: 22610.0000 - fp: 990.0000 - tn: 22610.0000 - fn: 990.0000 - accuracy: 0.9581 train_balacc 0.9580280377790014\n",
      " val_balacc 0.9285109266474674\n",
      "\n",
      "Epoch 184: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1100 - tp: 22620.0000 - fp: 991.0000 - tn: 22620.0000 - fn: 991.0000 - accuracy: 0.9580 - val_loss: 0.1682 - val_tp: 5481.0000 - val_fp: 422.0000 - val_tn: 5481.0000 - val_fn: 422.0000 - val_accuracy: 0.9285 - train_sensitivity: 0.9580 - train_specificity: 0.9580 - train_balacc: 0.9580 - val_sensitivity: 0.9285 - val_specificity: 0.9285 - val_balacc: 0.9285\n",
      "Epoch 185/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1118 - tp: 22367.0000 - fp: 1033.0000 - tn: 22367.0000 - fn: 1033.0000 - accuracy: 0.9559 train_balacc 0.9558256744737622\n",
      " val_balacc 0.9388446552600372\n",
      "\n",
      "Epoch 185: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1118 - tp: 22568.0000 - fp: 1043.0000 - tn: 22568.0000 - fn: 1043.0000 - accuracy: 0.9558 - val_loss: 0.1534 - val_tp: 5542.0000 - val_fp: 361.0000 - val_tn: 5542.0000 - val_fn: 361.0000 - val_accuracy: 0.9388 - train_sensitivity: 0.9558 - train_specificity: 0.9558 - train_balacc: 0.9558 - val_sensitivity: 0.9388 - val_specificity: 0.9388 - val_balacc: 0.9388\n",
      "Epoch 186/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1103 - tp: 22436.0000 - fp: 964.0000 - tn: 22436.0000 - fn: 964.0000 - accuracy: 0.9588 train_balacc 0.9587903943077379\n",
      " val_balacc 0.9473149246146028\n",
      "\n",
      "Epoch 186: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1102 - tp: 22638.0000 - fp: 973.0000 - tn: 22638.0000 - fn: 973.0000 - accuracy: 0.9588 - val_loss: 0.1288 - val_tp: 5592.0000 - val_fp: 311.0000 - val_tn: 5592.0000 - val_fn: 311.0000 - val_accuracy: 0.9473 - train_sensitivity: 0.9588 - train_specificity: 0.9588 - train_balacc: 0.9588 - val_sensitivity: 0.9473 - val_specificity: 0.9473 - val_balacc: 0.9473\n",
      "Epoch 187/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1106 - tp: 22631.0000 - fp: 980.0000 - tn: 22631.0000 - fn: 980.0000 - accuracy: 0.9585 train_balacc 0.9584939223243404\n",
      " val_balacc 0.9486701677113332\n",
      "\n",
      "Epoch 187: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1106 - tp: 22631.0000 - fp: 980.0000 - tn: 22631.0000 - fn: 980.0000 - accuracy: 0.9585 - val_loss: 0.1205 - val_tp: 5600.0000 - val_fp: 303.0000 - val_tn: 5600.0000 - val_fn: 303.0000 - val_accuracy: 0.9487 - train_sensitivity: 0.9585 - train_specificity: 0.9585 - train_balacc: 0.9585 - val_sensitivity: 0.9487 - val_specificity: 0.9487 - val_balacc: 0.9487\n",
      "Epoch 188/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1181 - tp: 21944.0000 - fp: 1056.0000 - tn: 21944.0000 - fn: 1056.0000 - accuracy: 0.9541 train_balacc 0.9543433145567743\n",
      " val_balacc 0.9329154667118414\n",
      "\n",
      "Epoch 188: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1178 - tp: 22533.0000 - fp: 1078.0000 - tn: 22533.0000 - fn: 1078.0000 - accuracy: 0.9543 - val_loss: 0.1808 - val_tp: 5507.0000 - val_fp: 396.0000 - val_tn: 5507.0000 - val_fn: 396.0000 - val_accuracy: 0.9329 - train_sensitivity: 0.9543 - train_specificity: 0.9543 - train_balacc: 0.9543 - val_sensitivity: 0.9329 - val_specificity: 0.9329 - val_balacc: 0.9329\n",
      "Epoch 189/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1142 - tp: 21799.0000 - fp: 1001.0000 - tn: 21799.0000 - fn: 1001.0000 - accuracy: 0.9561 train_balacc 0.9562915590191012\n",
      " val_balacc 0.9535829239369812\n",
      "\n",
      "Epoch 189: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1134 - tp: 22579.0000 - fp: 1032.0000 - tn: 22579.0000 - fn: 1032.0000 - accuracy: 0.9563 - val_loss: 0.1175 - val_tp: 5629.0000 - val_fp: 274.0000 - val_tn: 5629.0000 - val_fn: 274.0000 - val_accuracy: 0.9536 - train_sensitivity: 0.9563 - train_specificity: 0.9563 - train_balacc: 0.9563 - val_sensitivity: 0.9536 - val_specificity: 0.9536 - val_balacc: 0.9536\n",
      "Epoch 190/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1125 - tp: 22288.0000 - fp: 1012.0000 - tn: 22288.0000 - fn: 1012.0000 - accuracy: 0.9566 train_balacc 0.956376265300072\n",
      " val_balacc 0.9390140606471286\n",
      "\n",
      "Epoch 190: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1125 - tp: 22581.0000 - fp: 1030.0000 - tn: 22581.0000 - fn: 1030.0000 - accuracy: 0.9564 - val_loss: 0.1522 - val_tp: 5543.0000 - val_fp: 360.0000 - val_tn: 5543.0000 - val_fn: 360.0000 - val_accuracy: 0.9390 - train_sensitivity: 0.9564 - train_specificity: 0.9564 - train_balacc: 0.9564 - val_sensitivity: 0.9390 - val_specificity: 0.9390 - val_balacc: 0.9390\n",
      "Epoch 191/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1115 - tp: 22106.0000 - fp: 994.0000 - tn: 22106.0000 - fn: 994.0000 - accuracy: 0.9570 train_balacc 0.9571386218288086\n",
      " val_balacc 0.9540911400982551\n",
      "\n",
      "Epoch 191: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1112 - tp: 22599.0000 - fp: 1012.0000 - tn: 22599.0000 - fn: 1012.0000 - accuracy: 0.9571 - val_loss: 0.1230 - val_tp: 5632.0000 - val_fp: 271.0000 - val_tn: 5632.0000 - val_fn: 271.0000 - val_accuracy: 0.9541 - train_sensitivity: 0.9571 - train_specificity: 0.9571 - train_balacc: 0.9571 - val_sensitivity: 0.9541 - val_specificity: 0.9541 - val_balacc: 0.9541\n",
      "Epoch 192/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1091 - tp: 22059.0000 - fp: 941.0000 - tn: 22059.0000 - fn: 941.0000 - accuracy: 0.9591 train_balacc 0.9584939223243404\n",
      " val_balacc 0.9552769778078943\n",
      "\n",
      "Epoch 192: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1099 - tp: 22631.0000 - fp: 980.0000 - tn: 22631.0000 - fn: 980.0000 - accuracy: 0.9585 - val_loss: 0.1205 - val_tp: 5639.0000 - val_fp: 264.0000 - val_tn: 5639.0000 - val_fn: 264.0000 - val_accuracy: 0.9553 - train_sensitivity: 0.9585 - train_specificity: 0.9585 - train_balacc: 0.9585 - val_sensitivity: 0.9553 - val_specificity: 0.9553 - val_balacc: 0.9553\n",
      "Epoch 193/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1137 - tp: 22531.0000 - fp: 1069.0000 - tn: 22531.0000 - fn: 1069.0000 - accuracy: 0.9547 train_balacc 0.9547244928211427\n",
      " val_balacc 0.9386752498729459\n",
      "\n",
      "Epoch 193: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1137 - tp: 22542.0000 - fp: 1069.0000 - tn: 22542.0000 - fn: 1069.0000 - accuracy: 0.9547 - val_loss: 0.1442 - val_tp: 5541.0000 - val_fp: 362.0000 - val_tn: 5541.0000 - val_fn: 362.0000 - val_accuracy: 0.9387 - train_sensitivity: 0.9547 - train_specificity: 0.9547 - train_balacc: 0.9547 - val_sensitivity: 0.9387 - val_specificity: 0.9387 - val_balacc: 0.9387\n",
      "Epoch 194/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1118 - tp: 22316.0000 - fp: 984.0000 - tn: 22316.0000 - fn: 984.0000 - accuracy: 0.9578 train_balacc 0.9577739189360891\n",
      " val_balacc 0.8826020667457225\n",
      "\n",
      "Epoch 194: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1121 - tp: 22614.0000 - fp: 997.0000 - tn: 22614.0000 - fn: 997.0000 - accuracy: 0.9578 - val_loss: 0.3019 - val_tp: 5210.0000 - val_fp: 693.0000 - val_tn: 5210.0000 - val_fn: 693.0000 - val_accuracy: 0.8826 - train_sensitivity: 0.9578 - train_specificity: 0.9578 - train_balacc: 0.9578 - val_sensitivity: 0.8826 - val_specificity: 0.8826 - val_balacc: 0.8826\n",
      "Epoch 195/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1128 - tp: 21978.0000 - fp: 1022.0000 - tn: 21978.0000 - fn: 1022.0000 - accuracy: 0.9556 train_balacc 0.9554868493498793\n",
      " val_balacc 0.9396916821954938\n",
      "\n",
      "Epoch 195: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1129 - tp: 22560.0000 - fp: 1051.0000 - tn: 22560.0000 - fn: 1051.0000 - accuracy: 0.9555 - val_loss: 0.1492 - val_tp: 5547.0000 - val_fp: 356.0000 - val_tn: 5547.0000 - val_fn: 356.0000 - val_accuracy: 0.9397 - train_sensitivity: 0.9555 - train_specificity: 0.9555 - train_balacc: 0.9555 - val_sensitivity: 0.9397 - val_specificity: 0.9397 - val_balacc: 0.9397\n",
      "Epoch 196/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1092 - tp: 22317.0000 - fp: 983.0000 - tn: 22317.0000 - fn: 983.0000 - accuracy: 0.9578 train_balacc 0.9575198000931769\n",
      " val_balacc 0.9418939522276808\n",
      "\n",
      "Epoch 196: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1097 - tp: 22608.0000 - fp: 1003.0000 - tn: 22608.0000 - fn: 1003.0000 - accuracy: 0.9575 - val_loss: 0.1376 - val_tp: 5560.0000 - val_fp: 343.0000 - val_tn: 5560.0000 - val_fn: 343.0000 - val_accuracy: 0.9419 - train_sensitivity: 0.9575 - train_specificity: 0.9575 - train_balacc: 0.9575 - val_sensitivity: 0.9419 - val_specificity: 0.9419 - val_balacc: 0.9419\n",
      "Epoch 197/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1106 - tp: 22229.0000 - fp: 971.0000 - tn: 22229.0000 - fn: 971.0000 - accuracy: 0.9581 train_balacc 0.9579009783575452\n",
      " val_balacc 0.9095375232932408\n",
      "\n",
      "Epoch 197: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1113 - tp: 22617.0000 - fp: 994.0000 - tn: 22617.0000 - fn: 994.0000 - accuracy: 0.9579 - val_loss: 0.1931 - val_tp: 5369.0000 - val_fp: 534.0000 - val_tn: 5369.0000 - val_fn: 534.0000 - val_accuracy: 0.9095 - train_sensitivity: 0.9579 - train_specificity: 0.9579 - train_balacc: 0.9579 - val_sensitivity: 0.9095 - val_specificity: 0.9095 - val_balacc: 0.9095\n",
      "Epoch 198/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1167 - tp: 22069.0000 - fp: 1031.0000 - tn: 22069.0000 - fn: 1031.0000 - accuracy: 0.9554 train_balacc 0.9555715556308501\n",
      " val_balacc 0.9449432491953245\n",
      "\n",
      "Epoch 198: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1160 - tp: 22562.0000 - fp: 1049.0000 - tn: 22562.0000 - fn: 1049.0000 - accuracy: 0.9556 - val_loss: 0.1365 - val_tp: 5578.0000 - val_fp: 325.0000 - val_tn: 5578.0000 - val_fn: 325.0000 - val_accuracy: 0.9449 - train_sensitivity: 0.9556 - train_specificity: 0.9556 - train_balacc: 0.9556 - val_sensitivity: 0.9449 - val_specificity: 0.9449 - val_balacc: 0.9449\n",
      "Epoch 199/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1169 - tp: 22128.0000 - fp: 972.0000 - tn: 22128.0000 - fn: 972.0000 - accuracy: 0.9579 train_balacc 0.9577315657956037\n",
      " val_balacc 0.8085719125868203\n",
      "\n",
      "Epoch 199: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1166 - tp: 22613.0000 - fp: 998.0000 - tn: 22613.0000 - fn: 998.0000 - accuracy: 0.9577 - val_loss: 0.7160 - val_tp: 4773.0000 - val_fp: 1130.0000 - val_tn: 4773.0000 - val_fn: 1130.0000 - val_accuracy: 0.8086 - train_sensitivity: 0.9577 - train_specificity: 0.9577 - train_balacc: 0.9577 - val_sensitivity: 0.8086 - val_specificity: 0.8086 - val_balacc: 0.8086\n",
      "Epoch 200/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1084 - tp: 22017.0000 - fp: 983.0000 - tn: 22017.0000 - fn: 983.0000 - accuracy: 0.9573 train_balacc 0.956376265300072\n",
      " val_balacc 0.9198712519058106\n",
      "\n",
      "Epoch 200: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1101 - tp: 22581.0000 - fp: 1030.0000 - tn: 22581.0000 - fn: 1030.0000 - accuracy: 0.9564 - val_loss: 0.2134 - val_tp: 5430.0000 - val_fp: 473.0000 - val_tn: 5430.0000 - val_fn: 473.0000 - val_accuracy: 0.9199 - train_sensitivity: 0.9564 - train_specificity: 0.9564 - train_balacc: 0.9564 - val_sensitivity: 0.9199 - val_specificity: 0.9199 - val_balacc: 0.9199\n",
      "Epoch 201/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1131 - tp: 22164.0000 - fp: 1036.0000 - tn: 22164.0000 - fn: 1036.0000 - accuracy: 0.9553 train_balacc 0.9551480242259963\n",
      " val_balacc 0.8336439098763341\n",
      "\n",
      "Epoch 201: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1137 - tp: 22552.0000 - fp: 1059.0000 - tn: 22552.0000 - fn: 1059.0000 - accuracy: 0.9551 - val_loss: 0.3902 - val_tp: 4921.0000 - val_fp: 982.0000 - val_tn: 4921.0000 - val_fn: 982.0000 - val_accuracy: 0.8336 - train_sensitivity: 0.9551 - train_specificity: 0.9551 - train_balacc: 0.9551 - val_sensitivity: 0.8336 - val_specificity: 0.8336 - val_balacc: 0.8336\n",
      "Epoch 202/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1109 - tp: 22213.0000 - fp: 987.0000 - tn: 22213.0000 - fn: 987.0000 - accuracy: 0.9575 train_balacc 0.9571386218288086\n",
      " val_balacc 0.9537523293240725\n",
      "\n",
      "Epoch 202: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1115 - tp: 22599.0000 - fp: 1012.0000 - tn: 22599.0000 - fn: 1012.0000 - accuracy: 0.9571 - val_loss: 0.1251 - val_tp: 5630.0000 - val_fp: 273.0000 - val_tn: 5630.0000 - val_fn: 273.0000 - val_accuracy: 0.9538 - train_sensitivity: 0.9571 - train_specificity: 0.9571 - train_balacc: 0.9571 - val_sensitivity: 0.9538 - val_specificity: 0.9538 - val_balacc: 0.9538\n",
      "Epoch 203/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1141 - tp: 22016.0000 - fp: 984.0000 - tn: 22016.0000 - fn: 984.0000 - accuracy: 0.9572 train_balacc 0.9574774469526915\n",
      " val_balacc 0.9300355751312892\n",
      "\n",
      "Epoch 203: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1136 - tp: 22607.0000 - fp: 1004.0000 - tn: 22607.0000 - fn: 1004.0000 - accuracy: 0.9575 - val_loss: 0.1731 - val_tp: 5490.0000 - val_fp: 413.0000 - val_tn: 5490.0000 - val_fn: 413.0000 - val_accuracy: 0.9300 - train_sensitivity: 0.9575 - train_specificity: 0.9575 - train_balacc: 0.9575 - val_sensitivity: 0.9300 - val_specificity: 0.9300 - val_balacc: 0.9300\n",
      "Epoch 204/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1157 - tp: 22055.0000 - fp: 1045.0000 - tn: 22055.0000 - fn: 1045.0000 - accuracy: 0.9548 train_balacc 0.9549362585235696\n",
      " val_balacc 0.9415551414534982\n",
      "\n",
      "Epoch 204: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1154 - tp: 22547.0000 - fp: 1064.0000 - tn: 22547.0000 - fn: 1064.0000 - accuracy: 0.9549 - val_loss: 0.1548 - val_tp: 5558.0000 - val_fp: 345.0000 - val_tn: 5558.0000 - val_fn: 345.0000 - val_accuracy: 0.9416 - train_sensitivity: 0.9549 - train_specificity: 0.9549 - train_balacc: 0.9549 - val_sensitivity: 0.9416 - val_specificity: 0.9416 - val_balacc: 0.9416\n",
      "Epoch 205/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1075 - tp: 22392.0000 - fp: 1008.0000 - tn: 22392.0000 - fn: 1008.0000 - accuracy: 0.9569 train_balacc 0.9568845029858964\n",
      " val_balacc 0.9600203286464509\n",
      "\n",
      "Epoch 205: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1075 - tp: 22593.0000 - fp: 1018.0000 - tn: 22593.0000 - fn: 1018.0000 - accuracy: 0.9569 - val_loss: 0.1033 - val_tp: 5667.0000 - val_fp: 236.0000 - val_tn: 5667.0000 - val_fn: 236.0000 - val_accuracy: 0.9600 - train_sensitivity: 0.9569 - train_specificity: 0.9569 - train_balacc: 0.9569 - val_sensitivity: 0.9600 - val_specificity: 0.9600 - val_balacc: 0.9600\n",
      "Epoch 206/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1122 - tp: 22120.0000 - fp: 980.0000 - tn: 22120.0000 - fn: 980.0000 - accuracy: 0.9576 train_balacc 0.9574774469526915\n",
      " val_balacc 0.9161443333898018\n",
      "\n",
      "Epoch 206: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1128 - tp: 22607.0000 - fp: 1004.0000 - tn: 22607.0000 - fn: 1004.0000 - accuracy: 0.9575 - val_loss: 0.1940 - val_tp: 5408.0000 - val_fp: 495.0000 - val_tn: 5408.0000 - val_fn: 495.0000 - val_accuracy: 0.9161 - train_sensitivity: 0.9575 - train_specificity: 0.9575 - train_balacc: 0.9575 - val_sensitivity: 0.9161 - val_specificity: 0.9161 - val_balacc: 0.9161\n",
      "Epoch 207/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1102 - tp: 22588.0000 - fp: 1012.0000 - tn: 22588.0000 - fn: 1012.0000 - accuracy: 0.9571 train_balacc 0.9571386218288086\n",
      " val_balacc 0.940877519905133\n",
      "\n",
      "Epoch 207: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1102 - tp: 22599.0000 - fp: 1012.0000 - tn: 22599.0000 - fn: 1012.0000 - accuracy: 0.9571 - val_loss: 0.1431 - val_tp: 5554.0000 - val_fp: 349.0000 - val_tn: 5554.0000 - val_fn: 349.0000 - val_accuracy: 0.9409 - train_sensitivity: 0.9571 - train_specificity: 0.9571 - train_balacc: 0.9571 - val_sensitivity: 0.9409 - val_specificity: 0.9409 - val_balacc: 0.9409\n",
      "Epoch 208/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1088 - tp: 22033.0000 - fp: 967.0000 - tn: 22033.0000 - fn: 967.0000 - accuracy: 0.9580 train_balacc 0.9580703909194866\n",
      " val_balacc 0.92884973742165\n",
      "\n",
      "Epoch 208: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1081 - tp: 22621.0000 - fp: 990.0000 - tn: 22621.0000 - fn: 990.0000 - accuracy: 0.9581 - val_loss: 0.1719 - val_tp: 5483.0000 - val_fp: 420.0000 - val_tn: 5483.0000 - val_fn: 420.0000 - val_accuracy: 0.9288 - train_sensitivity: 0.9581 - train_specificity: 0.9581 - train_balacc: 0.9581 - val_sensitivity: 0.9288 - val_specificity: 0.9288 - val_balacc: 0.9288\n",
      "Epoch 209/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1069 - tp: 22246.0000 - fp: 954.0000 - tn: 22246.0000 - fn: 954.0000 - accuracy: 0.9589 train_balacc 0.9587903943077379\n",
      " val_balacc 0.9234287650347281\n",
      "\n",
      "Epoch 209: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1070 - tp: 22638.0000 - fp: 973.0000 - tn: 22638.0000 - fn: 973.0000 - accuracy: 0.9588 - val_loss: 0.2313 - val_tp: 5451.0000 - val_fp: 452.0000 - val_tn: 5451.0000 - val_fn: 452.0000 - val_accuracy: 0.9234 - train_sensitivity: 0.9588 - train_specificity: 0.9588 - train_balacc: 0.9588 - val_sensitivity: 0.9234 - val_specificity: 0.9234 - val_balacc: 0.9234\n",
      "Epoch 210/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1095 - tp: 22039.0000 - fp: 961.0000 - tn: 22039.0000 - fn: 961.0000 - accuracy: 0.9582 train_balacc 0.9581974503409428\n",
      " val_balacc 0.9376588175503981\n",
      "\n",
      "Epoch 210: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1094 - tp: 22624.0000 - fp: 987.0000 - tn: 22624.0000 - fn: 987.0000 - accuracy: 0.9582 - val_loss: 0.1544 - val_tp: 5535.0000 - val_fp: 368.0000 - val_tn: 5535.0000 - val_fn: 368.0000 - val_accuracy: 0.9377 - train_sensitivity: 0.9582 - train_specificity: 0.9582 - train_balacc: 0.9582 - val_sensitivity: 0.9377 - val_specificity: 0.9377 - val_balacc: 0.9377\n",
      "Epoch 211/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1128 - tp: 22338.0000 - fp: 962.0000 - tn: 22338.0000 - fn: 962.0000 - accuracy: 0.9587 train_balacc 0.9586633348862819\n",
      " val_balacc 0.8793833643909876\n",
      "\n",
      "Epoch 211: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1138 - tp: 22635.0000 - fp: 976.0000 - tn: 22635.0000 - fn: 976.0000 - accuracy: 0.9587 - val_loss: 0.3297 - val_tp: 5191.0000 - val_fp: 712.0000 - val_tn: 5191.0000 - val_fn: 712.0000 - val_accuracy: 0.8794 - train_sensitivity: 0.9587 - train_specificity: 0.9587 - train_balacc: 0.9587 - val_sensitivity: 0.8794 - val_specificity: 0.8794 - val_balacc: 0.8794\n",
      "Epoch 212/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1065 - tp: 22350.0000 - fp: 950.0000 - tn: 22350.0000 - fn: 950.0000 - accuracy: 0.9592 train_balacc 0.9591292194316209\n",
      " val_balacc 0.9481619515500593\n",
      "\n",
      "Epoch 212: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1066 - tp: 22646.0000 - fp: 965.0000 - tn: 22646.0000 - fn: 965.0000 - accuracy: 0.9591 - val_loss: 0.1325 - val_tp: 5597.0000 - val_fp: 306.0000 - val_tn: 5597.0000 - val_fn: 306.0000 - val_accuracy: 0.9482 - train_sensitivity: 0.9591 - train_specificity: 0.9591 - train_balacc: 0.9591 - val_sensitivity: 0.9482 - val_specificity: 0.9482 - val_balacc: 0.9482\n",
      "Epoch 213/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1067 - tp: 22242.0000 - fp: 958.0000 - tn: 22242.0000 - fn: 958.0000 - accuracy: 0.9587 train_balacc 0.9586633348862819\n",
      " val_balacc 0.8224631543283076\n",
      "\n",
      "Epoch 213: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1090 - tp: 22635.0000 - fp: 976.0000 - tn: 22635.0000 - fn: 976.0000 - accuracy: 0.9587 - val_loss: 0.5071 - val_tp: 4855.0000 - val_fp: 1048.0000 - val_tn: 4855.0000 - val_fn: 1048.0000 - val_accuracy: 0.8225 - train_sensitivity: 0.9587 - train_specificity: 0.9587 - train_balacc: 0.9587 - val_sensitivity: 0.8225 - val_specificity: 0.8225 - val_balacc: 0.8225\n",
      "Epoch 214/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1131 - tp: 22518.0000 - fp: 982.0000 - tn: 22518.0000 - fn: 982.0000 - accuracy: 0.9582 train_balacc 0.9580703909194866\n",
      " val_balacc 0.9317296290022022\n",
      "\n",
      "Epoch 214: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1134 - tp: 22621.0000 - fp: 990.0000 - tn: 22621.0000 - fn: 990.0000 - accuracy: 0.9581 - val_loss: 0.1644 - val_tp: 5500.0000 - val_fp: 403.0000 - val_tn: 5500.0000 - val_fn: 403.0000 - val_accuracy: 0.9317 - train_sensitivity: 0.9581 - train_specificity: 0.9581 - train_balacc: 0.9581 - val_sensitivity: 0.9317 - val_specificity: 0.9317 - val_balacc: 0.9317\n",
      "Epoch 215/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1068 - tp: 22583.0000 - fp: 1017.0000 - tn: 22583.0000 - fn: 1017.0000 - accuracy: 0.9569 train_balacc 0.9569268561263817\n",
      " val_balacc 0.9537523293240725\n",
      "\n",
      "Epoch 215: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1067 - tp: 22594.0000 - fp: 1017.0000 - tn: 22594.0000 - fn: 1017.0000 - accuracy: 0.9569 - val_loss: 0.1144 - val_tp: 5630.0000 - val_fp: 273.0000 - val_tn: 5630.0000 - val_fn: 273.0000 - val_accuracy: 0.9538 - train_sensitivity: 0.9569 - train_specificity: 0.9569 - train_balacc: 0.9569 - val_sensitivity: 0.9538 - val_specificity: 0.9538 - val_balacc: 0.9538\n",
      "Epoch 216/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1124 - tp: 22504.0000 - fp: 996.0000 - tn: 22504.0000 - fn: 996.0000 - accuracy: 0.9576 train_balacc 0.9575621532336622\n",
      " val_balacc 0.9000508216161274\n",
      "\n",
      "Epoch 216: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1130 - tp: 22609.0000 - fp: 1002.0000 - tn: 22609.0000 - fn: 1002.0000 - accuracy: 0.9576 - val_loss: 0.2494 - val_tp: 5313.0000 - val_fp: 590.0000 - val_tn: 5313.0000 - val_fn: 590.0000 - val_accuracy: 0.9001 - train_sensitivity: 0.9576 - train_specificity: 0.9576 - train_balacc: 0.9576 - val_sensitivity: 0.9001 - val_specificity: 0.9001 - val_balacc: 0.9001\n",
      "Epoch 217/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1112 - tp: 22513.0000 - fp: 987.0000 - tn: 22513.0000 - fn: 987.0000 - accuracy: 0.9580 train_balacc 0.9580280377790014\n",
      " val_balacc 0.9163137387768931\n",
      "\n",
      "Epoch 217: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1111 - tp: 22620.0000 - fp: 991.0000 - tn: 22620.0000 - fn: 991.0000 - accuracy: 0.9580 - val_loss: 0.1880 - val_tp: 5409.0000 - val_fp: 494.0000 - val_tn: 5409.0000 - val_fn: 494.0000 - val_accuracy: 0.9163 - train_sensitivity: 0.9580 - train_specificity: 0.9580 - train_balacc: 0.9580 - val_sensitivity: 0.9163 - val_specificity: 0.9163 - val_balacc: 0.9163\n",
      "Epoch 218/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1079 - tp: 21890.0000 - fp: 910.0000 - tn: 21890.0000 - fn: 910.0000 - accuracy: 0.9601 train_balacc 0.9601456948032696\n",
      " val_balacc 0.9278333050991021\n",
      "\n",
      "Epoch 218: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1074 - tp: 22670.0000 - fp: 941.0000 - tn: 22670.0000 - fn: 941.0000 - accuracy: 0.9601 - val_loss: 0.1751 - val_tp: 5477.0000 - val_fp: 426.0000 - val_tn: 5477.0000 - val_fn: 426.0000 - val_accuracy: 0.9278 - train_sensitivity: 0.9601 - train_specificity: 0.9601 - train_balacc: 0.9601 - val_sensitivity: 0.9278 - val_specificity: 0.9278 - val_balacc: 0.9278\n",
      "Epoch 219/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1040 - tp: 22535.0000 - fp: 965.0000 - tn: 22535.0000 - fn: 965.0000 - accuracy: 0.9589 train_balacc 0.958917453729194\n",
      " val_balacc 0.929357953582924\n",
      "\n",
      "Epoch 219: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1040 - tp: 22641.0000 - fp: 970.0000 - tn: 22641.0000 - fn: 970.0000 - accuracy: 0.9589 - val_loss: 0.1670 - val_tp: 5486.0000 - val_fp: 417.0000 - val_tn: 5486.0000 - val_fn: 417.0000 - val_accuracy: 0.9294 - train_sensitivity: 0.9589 - train_specificity: 0.9589 - train_balacc: 0.9589 - val_sensitivity: 0.9294 - val_specificity: 0.9294 - val_balacc: 0.9294\n",
      "Epoch 220/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1062 - tp: 22547.0000 - fp: 953.0000 - tn: 22547.0000 - fn: 953.0000 - accuracy: 0.9594 train_balacc 0.9594256914150184\n",
      " val_balacc 0.9032695239708622\n",
      "\n",
      "Epoch 220: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1061 - tp: 22653.0000 - fp: 958.0000 - tn: 22653.0000 - fn: 958.0000 - accuracy: 0.9594 - val_loss: 0.3103 - val_tp: 5332.0000 - val_fp: 571.0000 - val_tn: 5332.0000 - val_fn: 571.0000 - val_accuracy: 0.9033 - train_sensitivity: 0.9594 - train_specificity: 0.9594 - train_balacc: 0.9594 - val_sensitivity: 0.9033 - val_specificity: 0.9033 - val_balacc: 0.9033\n",
      "Epoch 221/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1099 - tp: 22606.0000 - fp: 994.0000 - tn: 22606.0000 - fn: 994.0000 - accuracy: 0.9579 train_balacc 0.9578586252170599\n",
      " val_balacc 0.9383364390987633\n",
      "\n",
      "Epoch 221: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1099 - tp: 22616.0000 - fp: 995.0000 - tn: 22616.0000 - fn: 995.0000 - accuracy: 0.9579 - val_loss: 0.1600 - val_tp: 5539.0000 - val_fp: 364.0000 - val_tn: 5539.0000 - val_fn: 364.0000 - val_accuracy: 0.9383 - train_sensitivity: 0.9579 - train_specificity: 0.9579 - train_balacc: 0.9579 - val_sensitivity: 0.9383 - val_specificity: 0.9383 - val_balacc: 0.9383\n",
      "Epoch 222/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1060 - tp: 22280.0000 - fp: 920.0000 - tn: 22280.0000 - fn: 920.0000 - accuracy: 0.9603 train_balacc 0.9603151073652111\n",
      " val_balacc 0.9508724377435203\n",
      "\n",
      "Epoch 222: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1062 - tp: 22674.0000 - fp: 937.0000 - tn: 22674.0000 - fn: 937.0000 - accuracy: 0.9603 - val_loss: 0.1251 - val_tp: 5613.0000 - val_fp: 290.0000 - val_tn: 5613.0000 - val_fn: 290.0000 - val_accuracy: 0.9509 - train_sensitivity: 0.9603 - train_specificity: 0.9603 - train_balacc: 0.9603 - val_sensitivity: 0.9509 - val_specificity: 0.9509 - val_balacc: 0.9509\n",
      "Epoch 223/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1075 - tp: 21930.0000 - fp: 970.0000 - tn: 21930.0000 - fn: 970.0000 - accuracy: 0.9576 train_balacc 0.9574774469526915\n",
      " val_balacc 0.9454514653565983\n",
      "\n",
      "Epoch 223: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1077 - tp: 22607.0000 - fp: 1004.0000 - tn: 22607.0000 - fn: 1004.0000 - accuracy: 0.9575 - val_loss: 0.1345 - val_tp: 5581.0000 - val_fp: 322.0000 - val_tn: 5581.0000 - val_fn: 322.0000 - val_accuracy: 0.9455 - train_sensitivity: 0.9575 - train_specificity: 0.9575 - train_balacc: 0.9575 - val_sensitivity: 0.9455 - val_specificity: 0.9455 - val_balacc: 0.9455\n",
      "Epoch 224/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1104 - tp: 22622.0000 - fp: 989.0000 - tn: 22622.0000 - fn: 989.0000 - accuracy: 0.9581 train_balacc 0.958112744059972\n",
      " val_balacc 0.9258004404540064\n",
      "\n",
      "Epoch 224: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1104 - tp: 22622.0000 - fp: 989.0000 - tn: 22622.0000 - fn: 989.0000 - accuracy: 0.9581 - val_loss: 0.1645 - val_tp: 5465.0000 - val_fp: 438.0000 - val_tn: 5465.0000 - val_fn: 438.0000 - val_accuracy: 0.9258 - train_sensitivity: 0.9581 - train_specificity: 0.9581 - train_balacc: 0.9581 - val_sensitivity: 0.9258 - val_specificity: 0.9258 - val_balacc: 0.9258\n",
      "Epoch 225/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1083 - tp: 22230.0000 - fp: 970.0000 - tn: 22230.0000 - fn: 970.0000 - accuracy: 0.9582 train_balacc 0.9584092160433696\n",
      " val_balacc 0.9513806539047942\n",
      "\n",
      "Epoch 225: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1082 - tp: 22629.0000 - fp: 982.0000 - tn: 22629.0000 - fn: 982.0000 - accuracy: 0.9584 - val_loss: 0.1251 - val_tp: 5616.0000 - val_fp: 287.0000 - val_tn: 5616.0000 - val_fn: 287.0000 - val_accuracy: 0.9514 - train_sensitivity: 0.9584 - train_specificity: 0.9584 - train_balacc: 0.9584 - val_sensitivity: 0.9514 - val_specificity: 0.9514 - val_balacc: 0.9514\n",
      "Epoch 226/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1021 - tp: 22315.0000 - fp: 885.0000 - tn: 22315.0000 - fn: 885.0000 - accuracy: 0.9619 train_balacc 0.9618398204226843\n",
      " val_balacc 0.9535829239369812\n",
      "\n",
      "Epoch 226: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1020 - tp: 22710.0000 - fp: 901.0000 - tn: 22710.0000 - fn: 901.0000 - accuracy: 0.9618 - val_loss: 0.1161 - val_tp: 5629.0000 - val_fp: 274.0000 - val_tn: 5629.0000 - val_fn: 274.0000 - val_accuracy: 0.9536 - train_sensitivity: 0.9618 - train_specificity: 0.9618 - train_balacc: 0.9618 - val_sensitivity: 0.9536 - val_specificity: 0.9536 - val_balacc: 0.9536\n",
      "Epoch 227/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1071 - tp: 21969.0000 - fp: 931.0000 - tn: 21969.0000 - fn: 931.0000 - accuracy: 0.9593 train_balacc 0.9593409851340476\n",
      " val_balacc 0.9274944943249195\n",
      "\n",
      "Epoch 227: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1065 - tp: 22651.0000 - fp: 960.0000 - tn: 22651.0000 - fn: 960.0000 - accuracy: 0.9593 - val_loss: 0.1880 - val_tp: 5475.0000 - val_fp: 428.0000 - val_tn: 5475.0000 - val_fn: 428.0000 - val_accuracy: 0.9275 - train_sensitivity: 0.9593 - train_specificity: 0.9593 - train_balacc: 0.9593 - val_sensitivity: 0.9275 - val_specificity: 0.9275 - val_balacc: 0.9275\n",
      "Epoch 228/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1027 - tp: 22657.0000 - fp: 943.0000 - tn: 22657.0000 - fn: 943.0000 - accuracy: 0.9600 train_balacc 0.9599762822413282\n",
      " val_balacc 0.9073352532610537\n",
      "\n",
      "Epoch 228: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1027 - tp: 22666.0000 - fp: 945.0000 - tn: 22666.0000 - fn: 945.0000 - accuracy: 0.9600 - val_loss: 0.2081 - val_tp: 5356.0000 - val_fp: 547.0000 - val_tn: 5356.0000 - val_fn: 547.0000 - val_accuracy: 0.9073 - train_sensitivity: 0.9600 - train_specificity: 0.9600 - train_balacc: 0.9600 - val_sensitivity: 0.9073 - val_specificity: 0.9073 - val_balacc: 0.9073\n",
      "Epoch 229/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1045 - tp: 22113.0000 - fp: 987.0000 - tn: 22113.0000 - fn: 987.0000 - accuracy: 0.9573 train_balacc 0.9576045063741476\n",
      " val_balacc 0.9446044384211418\n",
      "\n",
      "Epoch 229: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1045 - tp: 22610.0000 - fp: 1001.0000 - tn: 22610.0000 - fn: 1001.0000 - accuracy: 0.9576 - val_loss: 0.1345 - val_tp: 5576.0000 - val_fp: 327.0000 - val_tn: 5576.0000 - val_fn: 327.0000 - val_accuracy: 0.9446 - train_sensitivity: 0.9576 - train_specificity: 0.9576 - train_balacc: 0.9576 - val_sensitivity: 0.9446 - val_specificity: 0.9446 - val_balacc: 0.9446\n",
      "Epoch 230/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1069 - tp: 22081.0000 - fp: 919.0000 - tn: 22081.0000 - fn: 919.0000 - accuracy: 0.9600 train_balacc 0.959722163398416\n",
      " val_balacc 0.9320684397763849\n",
      "\n",
      "Epoch 230: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1075 - tp: 22660.0000 - fp: 951.0000 - tn: 22660.0000 - fn: 951.0000 - accuracy: 0.9597 - val_loss: 0.1585 - val_tp: 5502.0000 - val_fp: 401.0000 - val_tn: 5502.0000 - val_fn: 401.0000 - val_accuracy: 0.9321 - train_sensitivity: 0.9597 - train_specificity: 0.9597 - train_balacc: 0.9597 - val_sensitivity: 0.9321 - val_specificity: 0.9321 - val_balacc: 0.9321\n",
      "Epoch 231/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1059 - tp: 21867.0000 - fp: 933.0000 - tn: 21867.0000 - fn: 933.0000 - accuracy: 0.9591 train_balacc 0.9590021600101648\n",
      " val_balacc 0.9149584956801626\n",
      "\n",
      "Epoch 231: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1061 - tp: 22643.0000 - fp: 968.0000 - tn: 22643.0000 - fn: 968.0000 - accuracy: 0.9590 - val_loss: 0.2192 - val_tp: 5401.0000 - val_fp: 502.0000 - val_tn: 5401.0000 - val_fn: 502.0000 - val_accuracy: 0.9150 - train_sensitivity: 0.9590 - train_specificity: 0.9590 - train_balacc: 0.9590 - val_sensitivity: 0.9150 - val_specificity: 0.9150 - val_balacc: 0.9150\n",
      "Epoch 232/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1025 - tp: 22097.0000 - fp: 903.0000 - tn: 22097.0000 - fn: 903.0000 - accuracy: 0.9607 train_balacc 0.960992757612977\n",
      " val_balacc 0.9456208707436896\n",
      "\n",
      "Epoch 232: val_balacc did not improve from 0.97849\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1021 - tp: 22690.0000 - fp: 921.0000 - tn: 22690.0000 - fn: 921.0000 - accuracy: 0.9610 - val_loss: 0.1325 - val_tp: 5582.0000 - val_fp: 321.0000 - val_tn: 5582.0000 - val_fn: 321.0000 - val_accuracy: 0.9456 - train_sensitivity: 0.9610 - train_specificity: 0.9610 - train_balacc: 0.9610 - val_sensitivity: 0.9456 - val_specificity: 0.9456 - val_balacc: 0.9456\n",
      "Size of the training fold is 23611\n",
      "Size of the validation fold is 5903\n",
      "Class imbalance in Train is 0.46%\n",
      "Class imbalance in Validation is 0.46%\n",
      "Epoch 1/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1306 - tp: 22485.0000 - fp: 1127.0000 - tn: 22485.0000 - fn: 1127.0000 - accuracy: 0.9523 train_balacc 0.9522700321870236\n",
      " val_balacc 0.9676380887834632\n",
      "\n",
      "Epoch 1: val_balacc improved from -inf to 0.96764, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 0.1306 - tp: 22485.0000 - fp: 1127.0000 - tn: 22485.0000 - fn: 1127.0000 - accuracy: 0.9523 - val_loss: 0.0911 - val_tp: 5711.0000 - val_fp: 191.0000 - val_tn: 5711.0000 - val_fn: 191.0000 - val_accuracy: 0.9676 - train_sensitivity: 0.9523 - train_specificity: 0.9523 - train_balacc: 0.9523 - val_sensitivity: 0.9676 - val_specificity: 0.9676 - val_balacc: 0.9676\n",
      "Epoch 2/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1279 - tp: 22241.0000 - fp: 1159.0000 - tn: 22241.0000 - fn: 1159.0000 - accuracy: 0.9505 train_balacc 0.950448924275792\n",
      " val_balacc 0.9827177228058286\n",
      "\n",
      "Epoch 2: val_balacc improved from 0.96764 to 0.98272, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1277 - tp: 22442.0000 - fp: 1170.0000 - tn: 22442.0000 - fn: 1170.0000 - accuracy: 0.9504 - val_loss: 0.0683 - val_tp: 5800.0000 - val_fp: 102.0000 - val_tn: 5800.0000 - val_fn: 102.0000 - val_accuracy: 0.9827 - train_sensitivity: 0.9504 - train_specificity: 0.9504 - train_balacc: 0.9504 - val_sensitivity: 0.9827 - val_specificity: 0.9827 - val_balacc: 0.9827\n",
      "Epoch 3/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1257 - tp: 22466.0000 - fp: 1146.0000 - tn: 22466.0000 - fn: 1146.0000 - accuracy: 0.9515 train_balacc 0.9514653565983399\n",
      " val_balacc 0.9623856319891562\n",
      "\n",
      "Epoch 3: val_balacc did not improve from 0.98272\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1257 - tp: 22466.0000 - fp: 1146.0000 - tn: 22466.0000 - fn: 1146.0000 - accuracy: 0.9515 - val_loss: 0.1110 - val_tp: 5680.0000 - val_fp: 222.0000 - val_tn: 5680.0000 - val_fn: 222.0000 - val_accuracy: 0.9624 - train_sensitivity: 0.9515 - train_specificity: 0.9515 - train_balacc: 0.9515 - val_sensitivity: 0.9624 - val_specificity: 0.9624 - val_balacc: 0.9624\n",
      "Epoch 4/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1311 - tp: 21675.0000 - fp: 1125.0000 - tn: 21675.0000 - fn: 1125.0000 - accuracy: 0.9507 train_balacc 0.9502371675419279\n",
      " val_balacc 0.8925787868519146\n",
      "\n",
      "Epoch 4: val_balacc did not improve from 0.98272\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1315 - tp: 22437.0000 - fp: 1175.0000 - tn: 22437.0000 - fn: 1175.0000 - accuracy: 0.9502 - val_loss: 0.2260 - val_tp: 5268.0000 - val_fp: 634.0000 - val_tn: 5268.0000 - val_fn: 634.0000 - val_accuracy: 0.8926 - train_sensitivity: 0.9502 - train_specificity: 0.9502 - train_balacc: 0.9502 - val_sensitivity: 0.8926 - val_specificity: 0.8926 - val_balacc: 0.8926\n",
      "Epoch 5/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1290 - tp: 21848.0000 - fp: 1152.0000 - tn: 21848.0000 - fn: 1152.0000 - accuracy: 0.9499 train_balacc 0.9498560054209724\n",
      " val_balacc 0.9340901389359539\n",
      "\n",
      "Epoch 5: val_balacc did not improve from 0.98272\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1295 - tp: 22428.0000 - fp: 1184.0000 - tn: 22428.0000 - fn: 1184.0000 - accuracy: 0.9499 - val_loss: 0.1356 - val_tp: 5513.0000 - val_fp: 389.0000 - val_tn: 5513.0000 - val_fn: 389.0000 - val_accuracy: 0.9341 - train_sensitivity: 0.9499 - train_specificity: 0.9499 - train_balacc: 0.9499 - val_sensitivity: 0.9341 - val_specificity: 0.9341 - val_balacc: 0.9341\n",
      "Epoch 6/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1183 - tp: 22129.0000 - fp: 1071.0000 - tn: 22129.0000 - fn: 1071.0000 - accuracy: 0.9538 train_balacc 0.9537946806708454\n",
      " val_balacc 0.9550999661131819\n",
      "\n",
      "Epoch 6: val_balacc did not improve from 0.98272\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1185 - tp: 22521.0000 - fp: 1091.0000 - tn: 22521.0000 - fn: 1091.0000 - accuracy: 0.9538 - val_loss: 0.1084 - val_tp: 5637.0000 - val_fp: 265.0000 - val_tn: 5637.0000 - val_fn: 265.0000 - val_accuracy: 0.9551 - train_sensitivity: 0.9538 - train_specificity: 0.9538 - train_balacc: 0.9538 - val_sensitivity: 0.9551 - val_specificity: 0.9551 - val_balacc: 0.9551\n",
      "Epoch 7/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1204 - tp: 21798.0000 - fp: 1102.0000 - tn: 21798.0000 - fn: 1102.0000 - accuracy: 0.9519 train_balacc 0.9518041673725225\n",
      " val_balacc 0.9849203659776347\n",
      "\n",
      "Epoch 7: val_balacc improved from 0.98272 to 0.98492, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1204 - tp: 22474.0000 - fp: 1138.0000 - tn: 22474.0000 - fn: 1138.0000 - accuracy: 0.9518 - val_loss: 0.0650 - val_tp: 5813.0000 - val_fp: 89.0000 - val_tn: 5813.0000 - val_fn: 89.0000 - val_accuracy: 0.9849 - train_sensitivity: 0.9518 - train_specificity: 0.9518 - train_balacc: 0.9518 - val_sensitivity: 0.9849 - val_specificity: 0.9849 - val_balacc: 0.9849\n",
      "Epoch 8/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1214 - tp: 21976.0000 - fp: 1124.0000 - tn: 21976.0000 - fn: 1124.0000 - accuracy: 0.9513 train_balacc 0.9512959512112485\n",
      " val_balacc 0.9861064046086072\n",
      "\n",
      "Epoch 8: val_balacc improved from 0.98492 to 0.98611, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1215 - tp: 22462.0000 - fp: 1150.0000 - tn: 22462.0000 - fn: 1150.0000 - accuracy: 0.9513 - val_loss: 0.0582 - val_tp: 5820.0000 - val_fp: 82.0000 - val_tn: 5820.0000 - val_fn: 82.0000 - val_accuracy: 0.9861 - train_sensitivity: 0.9513 - train_specificity: 0.9513 - train_balacc: 0.9513 - val_sensitivity: 0.9861 - val_specificity: 0.9861 - val_balacc: 0.9861\n",
      "Epoch 9/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1240 - tp: 22468.0000 - fp: 1132.0000 - tn: 22468.0000 - fn: 1132.0000 - accuracy: 0.9520 train_balacc 0.9520582754531595\n",
      " val_balacc 0.9413758048119282\n",
      "\n",
      "Epoch 9: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1240 - tp: 22480.0000 - fp: 1132.0000 - tn: 22480.0000 - fn: 1132.0000 - accuracy: 0.9521 - val_loss: 0.1258 - val_tp: 5556.0000 - val_fp: 346.0000 - val_tn: 5556.0000 - val_fn: 346.0000 - val_accuracy: 0.9414 - train_sensitivity: 0.9521 - train_specificity: 0.9521 - train_balacc: 0.9521 - val_sensitivity: 0.9414 - val_specificity: 0.9414 - val_balacc: 0.9414\n",
      "Epoch 10/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1204 - tp: 21877.0000 - fp: 1023.0000 - tn: 21877.0000 - fn: 1023.0000 - accuracy: 0.9553 train_balacc 0.9555310858885313\n",
      " val_balacc 0.9413758048119282\n",
      "\n",
      "Epoch 10: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1200 - tp: 22562.0000 - fp: 1050.0000 - tn: 22562.0000 - fn: 1050.0000 - accuracy: 0.9555 - val_loss: 0.1502 - val_tp: 5556.0000 - val_fp: 346.0000 - val_tn: 5556.0000 - val_fn: 346.0000 - val_accuracy: 0.9414 - train_sensitivity: 0.9555 - train_specificity: 0.9555 - train_balacc: 0.9555 - val_sensitivity: 0.9414 - val_specificity: 0.9414 - val_balacc: 0.9414\n",
      "Epoch 11/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1259 - tp: 22281.0000 - fp: 1119.0000 - tn: 22281.0000 - fn: 1119.0000 - accuracy: 0.9522 train_balacc 0.9520159241063866\n",
      " val_balacc 0.9728905455777702\n",
      "\n",
      "Epoch 11: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1264 - tp: 22479.0000 - fp: 1133.0000 - tn: 22479.0000 - fn: 1133.0000 - accuracy: 0.9520 - val_loss: 0.1080 - val_tp: 5742.0000 - val_fp: 160.0000 - val_tn: 5742.0000 - val_fn: 160.0000 - val_accuracy: 0.9729 - train_sensitivity: 0.9520 - train_specificity: 0.9520 - train_balacc: 0.9520 - val_sensitivity: 0.9729 - val_specificity: 0.9729 - val_balacc: 0.9729\n",
      "Epoch 12/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1230 - tp: 22373.0000 - fp: 1127.0000 - tn: 22373.0000 - fn: 1127.0000 - accuracy: 0.9520 train_balacc 0.9519735727596138\n",
      " val_balacc 0.9772958319213826\n",
      "\n",
      "Epoch 12: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1234 - tp: 22478.0000 - fp: 1134.0000 - tn: 22478.0000 - fn: 1134.0000 - accuracy: 0.9520 - val_loss: 0.0824 - val_tp: 5768.0000 - val_fp: 134.0000 - val_tn: 5768.0000 - val_fn: 134.0000 - val_accuracy: 0.9773 - train_sensitivity: 0.9520 - train_specificity: 0.9520 - train_balacc: 0.9520 - val_sensitivity: 0.9773 - val_specificity: 0.9773 - val_balacc: 0.9773\n",
      "Epoch 13/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1211 - tp: 22455.0000 - fp: 1145.0000 - tn: 22455.0000 - fn: 1145.0000 - accuracy: 0.9515 train_balacc 0.9515077079451126\n",
      " val_balacc 0.9756014910199933\n",
      "\n",
      "Epoch 13: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1211 - tp: 22467.0000 - fp: 1145.0000 - tn: 22467.0000 - fn: 1145.0000 - accuracy: 0.9515 - val_loss: 0.0807 - val_tp: 5758.0000 - val_fp: 144.0000 - val_tn: 5758.0000 - val_fn: 144.0000 - val_accuracy: 0.9756 - train_sensitivity: 0.9515 - train_specificity: 0.9515 - train_balacc: 0.9515 - val_sensitivity: 0.9756 - val_specificity: 0.9756 - val_balacc: 0.9756\n",
      "Epoch 14/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1227 - tp: 21823.0000 - fp: 1077.0000 - tn: 21823.0000 - fn: 1077.0000 - accuracy: 0.9530 train_balacc 0.9527782483482975\n",
      " val_balacc 0.9301931548627584\n",
      "\n",
      "Epoch 14: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1227 - tp: 22497.0000 - fp: 1115.0000 - tn: 22497.0000 - fn: 1115.0000 - accuracy: 0.9528 - val_loss: 0.1681 - val_tp: 5490.0000 - val_fp: 412.0000 - val_tn: 5490.0000 - val_fn: 412.0000 - val_accuracy: 0.9302 - train_sensitivity: 0.9528 - train_specificity: 0.9528 - train_balacc: 0.9528 - val_sensitivity: 0.9302 - val_specificity: 0.9302 - val_balacc: 0.9302\n",
      "Epoch 15/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1261 - tp: 22472.0000 - fp: 1140.0000 - tn: 22472.0000 - fn: 1140.0000 - accuracy: 0.9517 train_balacc 0.9517194646789768\n",
      " val_balacc 0.9806845137241613\n",
      "\n",
      "Epoch 15: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1261 - tp: 22472.0000 - fp: 1140.0000 - tn: 22472.0000 - fn: 1140.0000 - accuracy: 0.9517 - val_loss: 0.0656 - val_tp: 5788.0000 - val_fp: 114.0000 - val_tn: 5788.0000 - val_fn: 114.0000 - val_accuracy: 0.9807 - train_sensitivity: 0.9517 - train_specificity: 0.9517 - train_balacc: 0.9517 - val_sensitivity: 0.9807 - val_specificity: 0.9807 - val_balacc: 0.9807\n",
      "Epoch 16/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1178 - tp: 21865.0000 - fp: 1035.0000 - tn: 21865.0000 - fn: 1035.0000 - accuracy: 0.9548 train_balacc 0.9546417076063018\n",
      " val_balacc 0.9723822433073535\n",
      "\n",
      "Epoch 16: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1203 - tp: 22541.0000 - fp: 1071.0000 - tn: 22541.0000 - fn: 1071.0000 - accuracy: 0.9546 - val_loss: 0.0982 - val_tp: 5739.0000 - val_fp: 163.0000 - val_tn: 5739.0000 - val_fn: 163.0000 - val_accuracy: 0.9724 - train_sensitivity: 0.9546 - train_specificity: 0.9546 - train_balacc: 0.9546 - val_sensitivity: 0.9724 - val_specificity: 0.9724 - val_balacc: 0.9724\n",
      "Epoch 17/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1174 - tp: 22411.0000 - fp: 1089.0000 - tn: 22411.0000 - fn: 1089.0000 - accuracy: 0.9537 train_balacc 0.9537099779772997\n",
      " val_balacc 0.9325652321247034\n",
      "\n",
      "Epoch 17: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1177 - tp: 22519.0000 - fp: 1093.0000 - tn: 22519.0000 - fn: 1093.0000 - accuracy: 0.9537 - val_loss: 0.1632 - val_tp: 5504.0000 - val_fp: 398.0000 - val_tn: 5504.0000 - val_fn: 398.0000 - val_accuracy: 0.9326 - train_sensitivity: 0.9537 - train_specificity: 0.9537 - train_balacc: 0.9537 - val_sensitivity: 0.9326 - val_specificity: 0.9326 - val_balacc: 0.9326\n",
      "Epoch 18/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1157 - tp: 22322.0000 - fp: 1078.0000 - tn: 22322.0000 - fn: 1078.0000 - accuracy: 0.9539 train_balacc 0.9542181941385736\n",
      " val_balacc 0.9767875296509658\n",
      "\n",
      "Epoch 18: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1152 - tp: 22531.0000 - fp: 1081.0000 - tn: 22531.0000 - fn: 1081.0000 - accuracy: 0.9542 - val_loss: 0.0723 - val_tp: 5765.0000 - val_fp: 137.0000 - val_tn: 5765.0000 - val_fn: 137.0000 - val_accuracy: 0.9768 - train_sensitivity: 0.9542 - train_specificity: 0.9542 - train_balacc: 0.9542 - val_sensitivity: 0.9768 - val_specificity: 0.9768 - val_balacc: 0.9768\n",
      "Epoch 19/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1186 - tp: 21861.0000 - fp: 1039.0000 - tn: 21861.0000 - fn: 1039.0000 - accuracy: 0.9546 train_balacc 0.9546840589530747\n",
      " val_balacc 0.97610979329041\n",
      "\n",
      "Epoch 19: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1216 - tp: 22542.0000 - fp: 1070.0000 - tn: 22542.0000 - fn: 1070.0000 - accuracy: 0.9547 - val_loss: 0.0801 - val_tp: 5761.0000 - val_fp: 141.0000 - val_tn: 5761.0000 - val_fn: 141.0000 - val_accuracy: 0.9761 - train_sensitivity: 0.9547 - train_specificity: 0.9547 - train_balacc: 0.9547 - val_sensitivity: 0.9761 - val_specificity: 0.9761 - val_balacc: 0.9761\n",
      "Epoch 20/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1160 - tp: 21942.0000 - fp: 1058.0000 - tn: 21942.0000 - fn: 1058.0000 - accuracy: 0.9540 train_balacc 0.9537099779772997\n",
      " val_balacc 0.9830565909861064\n",
      "\n",
      "Epoch 20: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1178 - tp: 22519.0000 - fp: 1093.0000 - tn: 22519.0000 - fn: 1093.0000 - accuracy: 0.9537 - val_loss: 0.0870 - val_tp: 5802.0000 - val_fp: 100.0000 - val_tn: 5802.0000 - val_fn: 100.0000 - val_accuracy: 0.9831 - train_sensitivity: 0.9537 - train_specificity: 0.9537 - train_balacc: 0.9537 - val_sensitivity: 0.9831 - val_specificity: 0.9831 - val_balacc: 0.9831\n",
      "Epoch 21/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1141 - tp: 21783.0000 - fp: 1017.0000 - tn: 21783.0000 - fn: 1017.0000 - accuracy: 0.9554 train_balacc 0.9556581399288497\n",
      " val_balacc 0.9745848864791596\n",
      "\n",
      "Epoch 21: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1137 - tp: 22565.0000 - fp: 1047.0000 - tn: 22565.0000 - fn: 1047.0000 - accuracy: 0.9557 - val_loss: 0.0820 - val_tp: 5752.0000 - val_fp: 150.0000 - val_tn: 5752.0000 - val_fn: 150.0000 - val_accuracy: 0.9746 - train_sensitivity: 0.9557 - train_specificity: 0.9557 - train_balacc: 0.9557 - val_sensitivity: 0.9746 - val_specificity: 0.9746 - val_balacc: 0.9746\n",
      "Epoch 22/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1218 - tp: 22025.0000 - fp: 1075.0000 - tn: 22025.0000 - fn: 1075.0000 - accuracy: 0.9535 train_balacc 0.9537946806708454\n",
      " val_balacc 0.9522195865808201\n",
      "\n",
      "Epoch 22: val_balacc did not improve from 0.98611\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1209 - tp: 22521.0000 - fp: 1091.0000 - tn: 22521.0000 - fn: 1091.0000 - accuracy: 0.9538 - val_loss: 0.1192 - val_tp: 5620.0000 - val_fp: 282.0000 - val_tn: 5620.0000 - val_fn: 282.0000 - val_accuracy: 0.9522 - train_sensitivity: 0.9538 - train_specificity: 0.9538 - train_balacc: 0.9538 - val_sensitivity: 0.9522 - val_specificity: 0.9522 - val_balacc: 0.9522\n",
      "Epoch 23/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1147 - tp: 21976.0000 - fp: 1024.0000 - tn: 21976.0000 - fn: 1024.0000 - accuracy: 0.9555 train_balacc 0.9554463831949856\n",
      " val_balacc 0.9872924432395798\n",
      "\n",
      "Epoch 23: val_balacc improved from 0.98611 to 0.98729, saving model to cnn_model.h5\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1146 - tp: 22560.0000 - fp: 1052.0000 - tn: 22560.0000 - fn: 1052.0000 - accuracy: 0.9554 - val_loss: 0.0619 - val_tp: 5827.0000 - val_fp: 75.0000 - val_tn: 5827.0000 - val_fn: 75.0000 - val_accuracy: 0.9873 - train_sensitivity: 0.9554 - train_specificity: 0.9554 - train_balacc: 0.9554 - val_sensitivity: 0.9873 - val_specificity: 0.9873 - val_balacc: 0.9873\n",
      "Epoch 24/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1186 - tp: 22313.0000 - fp: 1087.0000 - tn: 22313.0000 - fn: 1087.0000 - accuracy: 0.9535 train_balacc 0.9534558698966628\n",
      " val_balacc 0.9601829888173501\n",
      "\n",
      "Epoch 24: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.1186 - tp: 22513.0000 - fp: 1099.0000 - tn: 22513.0000 - fn: 1099.0000 - accuracy: 0.9535 - val_loss: 0.1029 - val_tp: 5667.0000 - val_fp: 235.0000 - val_tn: 5667.0000 - val_fn: 235.0000 - val_accuracy: 0.9602 - train_sensitivity: 0.9535 - train_specificity: 0.9535 - train_balacc: 0.9535 - val_sensitivity: 0.9602 - val_specificity: 0.9602 - val_balacc: 0.9602\n",
      "Epoch 25/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1148 - tp: 22041.0000 - fp: 1059.0000 - tn: 22041.0000 - fn: 1059.0000 - accuracy: 0.9542 train_balacc 0.9539217347111638\n",
      " val_balacc 0.9185022026431718\n",
      "\n",
      "Epoch 25: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1152 - tp: 22524.0000 - fp: 1088.0000 - tn: 22524.0000 - fn: 1088.0000 - accuracy: 0.9539 - val_loss: 0.1863 - val_tp: 5421.0000 - val_fp: 481.0000 - val_tn: 5421.0000 - val_fn: 481.0000 - val_accuracy: 0.9185 - train_sensitivity: 0.9539 - train_specificity: 0.9539 - train_balacc: 0.9539 - val_sensitivity: 0.9185 - val_specificity: 0.9185 - val_balacc: 0.9185\n",
      "Epoch 26/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1163 - tp: 22573.0000 - fp: 1027.0000 - tn: 22573.0000 - fn: 1027.0000 - accuracy: 0.9565 train_balacc 0.9564628155175334\n",
      " val_balacc 0.9733988478481871\n",
      "\n",
      "Epoch 26: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1163 - tp: 22584.0000 - fp: 1028.0000 - tn: 22584.0000 - fn: 1028.0000 - accuracy: 0.9565 - val_loss: 0.0940 - val_tp: 5745.0000 - val_fp: 157.0000 - val_tn: 5745.0000 - val_fn: 157.0000 - val_accuracy: 0.9734 - train_sensitivity: 0.9565 - train_specificity: 0.9565 - train_balacc: 0.9565 - val_sensitivity: 0.9734 - val_specificity: 0.9734 - val_balacc: 0.9734\n",
      "Epoch 27/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1174 - tp: 22444.0000 - fp: 1056.0000 - tn: 22444.0000 - fn: 1056.0000 - accuracy: 0.9551 train_balacc 0.9549805183804845\n",
      " val_balacc 0.9803456455438835\n",
      "\n",
      "Epoch 27: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1176 - tp: 22549.0000 - fp: 1063.0000 - tn: 22549.0000 - fn: 1063.0000 - accuracy: 0.9550 - val_loss: 0.0676 - val_tp: 5786.0000 - val_fp: 116.0000 - val_tn: 5786.0000 - val_fn: 116.0000 - val_accuracy: 0.9803 - train_sensitivity: 0.9550 - train_specificity: 0.9550 - train_balacc: 0.9550 - val_sensitivity: 0.9803 - val_specificity: 0.9803 - val_balacc: 0.9803\n",
      "Epoch 28/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1180 - tp: 22547.0000 - fp: 1053.0000 - tn: 22547.0000 - fn: 1053.0000 - accuracy: 0.9554 train_balacc 0.95536168050144\n",
      " val_balacc 0.9689935615045747\n",
      "\n",
      "Epoch 28: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1180 - tp: 22558.0000 - fp: 1054.0000 - tn: 22558.0000 - fn: 1054.0000 - accuracy: 0.9554 - val_loss: 0.0926 - val_tp: 5719.0000 - val_fp: 183.0000 - val_tn: 5719.0000 - val_fn: 183.0000 - val_accuracy: 0.9690 - train_sensitivity: 0.9554 - train_specificity: 0.9554 - train_balacc: 0.9554 - val_sensitivity: 0.9690 - val_specificity: 0.9690 - val_balacc: 0.9690\n",
      "Epoch 29/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1179 - tp: 21837.0000 - fp: 1063.0000 - tn: 21837.0000 - fn: 1063.0000 - accuracy: 0.9536 train_balacc 0.9540911400982551\n",
      " val_balacc 0.9837343273466621\n",
      "\n",
      "Epoch 29: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1174 - tp: 22528.0000 - fp: 1084.0000 - tn: 22528.0000 - fn: 1084.0000 - accuracy: 0.9541 - val_loss: 0.0593 - val_tp: 5806.0000 - val_fp: 96.0000 - val_tn: 5806.0000 - val_fn: 96.0000 - val_accuracy: 0.9837 - train_sensitivity: 0.9541 - train_specificity: 0.9541 - train_balacc: 0.9541 - val_sensitivity: 0.9837 - val_specificity: 0.9837 - val_balacc: 0.9837\n",
      "Epoch 30/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1231 - tp: 22016.0000 - fp: 1084.0000 - tn: 22016.0000 - fn: 1084.0000 - accuracy: 0.9531 train_balacc 0.9533288158563442\n",
      " val_balacc 0.9542527956624873\n",
      "\n",
      "Epoch 30: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1222 - tp: 22510.0000 - fp: 1102.0000 - tn: 22510.0000 - fn: 1102.0000 - accuracy: 0.9533 - val_loss: 0.1322 - val_tp: 5632.0000 - val_fp: 270.0000 - val_tn: 5632.0000 - val_fn: 270.0000 - val_accuracy: 0.9543 - train_sensitivity: 0.9533 - train_specificity: 0.9533 - train_balacc: 0.9533 - val_sensitivity: 0.9543 - val_specificity: 0.9543 - val_balacc: 0.9543\n",
      "Epoch 31/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1156 - tp: 21870.0000 - fp: 1030.0000 - tn: 21870.0000 - fn: 1030.0000 - accuracy: 0.9550 train_balacc 0.9551499237675758\n",
      " val_balacc 0.9772958319213826\n",
      "\n",
      "Epoch 31: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1152 - tp: 22553.0000 - fp: 1059.0000 - tn: 22553.0000 - fn: 1059.0000 - accuracy: 0.9551 - val_loss: 0.0800 - val_tp: 5768.0000 - val_fp: 134.0000 - val_tn: 5768.0000 - val_fn: 134.0000 - val_accuracy: 0.9773 - train_sensitivity: 0.9551 - train_specificity: 0.9551 - train_balacc: 0.9551 - val_sensitivity: 0.9773 - val_specificity: 0.9773 - val_balacc: 0.9773\n",
      "Epoch 32/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1145 - tp: 22258.0000 - fp: 1042.0000 - tn: 22258.0000 - fn: 1042.0000 - accuracy: 0.9553 train_balacc 0.9554040318482128\n",
      " val_balacc 0.9427312775330396\n",
      "\n",
      "Epoch 32: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1141 - tp: 22559.0000 - fp: 1053.0000 - tn: 22559.0000 - fn: 1053.0000 - accuracy: 0.9554 - val_loss: 0.1593 - val_tp: 5564.0000 - val_fp: 338.0000 - val_tn: 5564.0000 - val_fn: 338.0000 - val_accuracy: 0.9427 - train_sensitivity: 0.9554 - train_specificity: 0.9554 - train_balacc: 0.9554 - val_sensitivity: 0.9427 - val_specificity: 0.9427 - val_balacc: 0.9427\n",
      "Epoch 33/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1175 - tp: 22130.0000 - fp: 1070.0000 - tn: 22130.0000 - fn: 1070.0000 - accuracy: 0.9539 train_balacc 0.9537946806708454\n",
      " val_balacc 0.9518807184005422\n",
      "\n",
      "Epoch 33: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1173 - tp: 22521.0000 - fp: 1091.0000 - tn: 22521.0000 - fn: 1091.0000 - accuracy: 0.9538 - val_loss: 0.1073 - val_tp: 5618.0000 - val_fp: 284.0000 - val_tn: 5618.0000 - val_fn: 284.0000 - val_accuracy: 0.9519 - train_sensitivity: 0.9538 - train_specificity: 0.9538 - train_balacc: 0.9538 - val_sensitivity: 0.9519 - val_specificity: 0.9519 - val_balacc: 0.9519\n",
      "Epoch 34/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1146 - tp: 21984.0000 - fp: 1016.0000 - tn: 21984.0000 - fn: 1016.0000 - accuracy: 0.9558 train_balacc 0.9557851939691682\n",
      " val_balacc 0.9667909183327685\n",
      "\n",
      "Epoch 34: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1154 - tp: 22568.0000 - fp: 1044.0000 - tn: 22568.0000 - fn: 1044.0000 - accuracy: 0.9558 - val_loss: 0.1035 - val_tp: 5706.0000 - val_fp: 196.0000 - val_tn: 5706.0000 - val_fn: 196.0000 - val_accuracy: 0.9668 - train_sensitivity: 0.9558 - train_specificity: 0.9558 - train_balacc: 0.9558 - val_sensitivity: 0.9668 - val_specificity: 0.9668 - val_balacc: 0.9668\n",
      "Epoch 35/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1164 - tp: 21862.0000 - fp: 1038.0000 - tn: 21862.0000 - fn: 1038.0000 - accuracy: 0.9547 train_balacc 0.9543028968321192\n",
      " val_balacc 0.9654354456116571\n",
      "\n",
      "Epoch 35: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1172 - tp: 22533.0000 - fp: 1079.0000 - tn: 22533.0000 - fn: 1079.0000 - accuracy: 0.9543 - val_loss: 0.0918 - val_tp: 5698.0000 - val_fp: 204.0000 - val_tn: 5698.0000 - val_fn: 204.0000 - val_accuracy: 0.9654 - train_sensitivity: 0.9543 - train_specificity: 0.9543 - train_balacc: 0.9543 - val_sensitivity: 0.9654 - val_specificity: 0.9654 - val_balacc: 0.9654\n",
      "Epoch 36/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1092 - tp: 22025.0000 - fp: 975.0000 - tn: 22025.0000 - fn: 975.0000 - accuracy: 0.9576 train_balacc 0.9576486532271726\n",
      " val_balacc 0.9415452389020671\n",
      "\n",
      "Epoch 36: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1097 - tp: 22612.0000 - fp: 1000.0000 - tn: 22612.0000 - fn: 1000.0000 - accuracy: 0.9576 - val_loss: 0.1559 - val_tp: 5557.0000 - val_fp: 345.0000 - val_tn: 5557.0000 - val_fn: 345.0000 - val_accuracy: 0.9415 - train_sensitivity: 0.9576 - train_specificity: 0.9576 - train_balacc: 0.9576 - val_sensitivity: 0.9415 - val_specificity: 0.9415 - val_balacc: 0.9415\n",
      "Epoch 37/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1155 - tp: 22578.0000 - fp: 1022.0000 - tn: 22578.0000 - fn: 1022.0000 - accuracy: 0.9567 train_balacc 0.9567169235981704\n",
      " val_balacc 0.9749237546594375\n",
      "\n",
      "Epoch 37: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1155 - tp: 22590.0000 - fp: 1022.0000 - tn: 22590.0000 - fn: 1022.0000 - accuracy: 0.9567 - val_loss: 0.0910 - val_tp: 5754.0000 - val_fp: 148.0000 - val_tn: 5754.0000 - val_fn: 148.0000 - val_accuracy: 0.9749 - train_sensitivity: 0.9567 - train_specificity: 0.9567 - train_balacc: 0.9567 - val_sensitivity: 0.9749 - val_specificity: 0.9749 - val_balacc: 0.9749\n",
      "Epoch 38/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1109 - tp: 22570.0000 - fp: 1030.0000 - tn: 22570.0000 - fn: 1030.0000 - accuracy: 0.9564 train_balacc 0.956335761477215\n",
      " val_balacc 0.9639105388004067\n",
      "\n",
      "Epoch 38: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1110 - tp: 22581.0000 - fp: 1031.0000 - tn: 22581.0000 - fn: 1031.0000 - accuracy: 0.9563 - val_loss: 0.1023 - val_tp: 5689.0000 - val_fp: 213.0000 - val_tn: 5689.0000 - val_fn: 213.0000 - val_accuracy: 0.9639 - train_sensitivity: 0.9563 - train_specificity: 0.9563 - train_balacc: 0.9563 - val_sensitivity: 0.9639 - val_specificity: 0.9639 - val_balacc: 0.9639\n",
      "Epoch 39/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1148 - tp: 21785.0000 - fp: 1015.0000 - tn: 21785.0000 - fn: 1015.0000 - accuracy: 0.9555 train_balacc 0.9557004912756225\n",
      " val_balacc 0.9678075228736022\n",
      "\n",
      "Epoch 39: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1144 - tp: 22566.0000 - fp: 1046.0000 - tn: 22566.0000 - fn: 1046.0000 - accuracy: 0.9557 - val_loss: 0.1007 - val_tp: 5712.0000 - val_fp: 190.0000 - val_tn: 5712.0000 - val_fn: 190.0000 - val_accuracy: 0.9678 - train_sensitivity: 0.9557 - train_specificity: 0.9557 - train_balacc: 0.9557 - val_sensitivity: 0.9678 - val_specificity: 0.9678 - val_balacc: 0.9678\n",
      "Epoch 40/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1120 - tp: 22053.0000 - fp: 1047.0000 - tn: 22053.0000 - fn: 1047.0000 - accuracy: 0.9547 train_balacc 0.954853464340166\n",
      " val_balacc 0.9566248729244324\n",
      "\n",
      "Epoch 40: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1115 - tp: 22546.0000 - fp: 1066.0000 - tn: 22546.0000 - fn: 1066.0000 - accuracy: 0.9549 - val_loss: 0.1041 - val_tp: 5646.0000 - val_fp: 256.0000 - val_tn: 5646.0000 - val_fn: 256.0000 - val_accuracy: 0.9566 - train_sensitivity: 0.9549 - train_specificity: 0.9549 - train_balacc: 0.9549 - val_sensitivity: 0.9566 - val_specificity: 0.9566 - val_balacc: 0.9566\n",
      "Epoch 41/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1108 - tp: 22297.0000 - fp: 1003.0000 - tn: 22297.0000 - fn: 1003.0000 - accuracy: 0.9570 train_balacc 0.9569286803320346\n",
      " val_balacc 0.9659437478820738\n",
      "\n",
      "Epoch 41: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1105 - tp: 22595.0000 - fp: 1017.0000 - tn: 22595.0000 - fn: 1017.0000 - accuracy: 0.9569 - val_loss: 0.0998 - val_tp: 5701.0000 - val_fp: 201.0000 - val_tn: 5701.0000 - val_fn: 201.0000 - val_accuracy: 0.9659 - train_sensitivity: 0.9569 - train_specificity: 0.9569 - train_balacc: 0.9569 - val_sensitivity: 0.9659 - val_specificity: 0.9659 - val_balacc: 0.9659\n",
      "Epoch 42/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1170 - tp: 21891.0000 - fp: 1009.0000 - tn: 21891.0000 - fn: 1009.0000 - accuracy: 0.9559 train_balacc 0.9562934101304421\n",
      " val_balacc 0.9696712978651305\n",
      "\n",
      "Epoch 42: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1162 - tp: 22580.0000 - fp: 1032.0000 - tn: 22580.0000 - fn: 1032.0000 - accuracy: 0.9563 - val_loss: 0.0832 - val_tp: 5723.0000 - val_fp: 179.0000 - val_tn: 5723.0000 - val_fn: 179.0000 - val_accuracy: 0.9697 - train_sensitivity: 0.9563 - train_specificity: 0.9563 - train_balacc: 0.9563 - val_sensitivity: 0.9697 - val_specificity: 0.9697 - val_balacc: 0.9697\n",
      "Epoch 43/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1149 - tp: 21793.0000 - fp: 1007.0000 - tn: 21793.0000 - fn: 1007.0000 - accuracy: 0.9558 train_balacc 0.9562510587836693\n",
      " val_balacc 0.9827177228058286\n",
      "\n",
      "Epoch 43: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1146 - tp: 22579.0000 - fp: 1033.0000 - tn: 22579.0000 - fn: 1033.0000 - accuracy: 0.9563 - val_loss: 0.0630 - val_tp: 5800.0000 - val_fp: 102.0000 - val_tn: 5800.0000 - val_fn: 102.0000 - val_accuracy: 0.9827 - train_sensitivity: 0.9563 - train_specificity: 0.9563 - train_balacc: 0.9563 - val_sensitivity: 0.9827 - val_specificity: 0.9827 - val_balacc: 0.9827\n",
      "Epoch 44/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1088 - tp: 22421.0000 - fp: 979.0000 - tn: 22421.0000 - fn: 979.0000 - accuracy: 0.9582 train_balacc 0.9581568693884466\n",
      " val_balacc 0.8866485936970518\n",
      "\n",
      "Epoch 44: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1092 - tp: 22624.0000 - fp: 988.0000 - tn: 22624.0000 - fn: 988.0000 - accuracy: 0.9582 - val_loss: 0.2556 - val_tp: 5233.0000 - val_fp: 669.0000 - val_tn: 5233.0000 - val_fn: 669.0000 - val_accuracy: 0.8866 - train_sensitivity: 0.9582 - train_specificity: 0.9582 - train_balacc: 0.9582 - val_sensitivity: 0.8866 - val_specificity: 0.8866 - val_balacc: 0.8866\n",
      "Epoch 45/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1088 - tp: 22639.0000 - fp: 961.0000 - tn: 22639.0000 - fn: 961.0000 - accuracy: 0.9593 train_balacc 0.95925800440454\n",
      " val_balacc 0.9327346662148425\n",
      "\n",
      "Epoch 45: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1088 - tp: 22650.0000 - fp: 962.0000 - tn: 22650.0000 - fn: 962.0000 - accuracy: 0.9593 - val_loss: 0.1736 - val_tp: 5505.0000 - val_fp: 397.0000 - val_tn: 5505.0000 - val_fn: 397.0000 - val_accuracy: 0.9327 - train_sensitivity: 0.9593 - train_specificity: 0.9593 - train_balacc: 0.9593 - val_sensitivity: 0.9327 - val_specificity: 0.9327 - val_balacc: 0.9327\n",
      "Epoch 46/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1129 - tp: 22133.0000 - fp: 967.0000 - tn: 22133.0000 - fn: 967.0000 - accuracy: 0.9581 train_balacc 0.9579874640013553\n",
      " val_balacc 0.8669942392409353\n",
      "\n",
      "Epoch 46: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1130 - tp: 22620.0000 - fp: 992.0000 - tn: 22620.0000 - fn: 992.0000 - accuracy: 0.9580 - val_loss: 0.3353 - val_tp: 5117.0000 - val_fp: 785.0000 - val_tn: 5117.0000 - val_fn: 785.0000 - val_accuracy: 0.8670 - train_sensitivity: 0.9580 - train_specificity: 0.9580 - train_balacc: 0.9580 - val_sensitivity: 0.8670 - val_specificity: 0.8670 - val_balacc: 0.8670\n",
      "Epoch 47/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1124 - tp: 21954.0000 - fp: 946.0000 - tn: 21954.0000 - fn: 946.0000 - accuracy: 0.9587 train_balacc 0.9586227342029476\n",
      " val_balacc 0.9518807184005422\n",
      "\n",
      "Epoch 47: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1122 - tp: 22635.0000 - fp: 977.0000 - tn: 22635.0000 - fn: 977.0000 - accuracy: 0.9586 - val_loss: 0.1248 - val_tp: 5618.0000 - val_fp: 284.0000 - val_tn: 5618.0000 - val_fn: 284.0000 - val_accuracy: 0.9519 - train_sensitivity: 0.9586 - train_specificity: 0.9586 - train_balacc: 0.9586 - val_sensitivity: 0.9519 - val_specificity: 0.9519 - val_balacc: 0.9519\n",
      "Epoch 48/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1086 - tp: 21962.0000 - fp: 938.0000 - tn: 21962.0000 - fn: 938.0000 - accuracy: 0.9590 train_balacc 0.958792139590039\n",
      " val_balacc 0.9027448322602508\n",
      "\n",
      "Epoch 48: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1092 - tp: 22639.0000 - fp: 973.0000 - tn: 22639.0000 - fn: 973.0000 - accuracy: 0.9588 - val_loss: 0.2508 - val_tp: 5328.0000 - val_fp: 574.0000 - val_tn: 5328.0000 - val_fn: 574.0000 - val_accuracy: 0.9027 - train_sensitivity: 0.9588 - train_specificity: 0.9588 - train_balacc: 0.9588 - val_sensitivity: 0.9027 - val_specificity: 0.9027 - val_balacc: 0.9027\n",
      "Epoch 49/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1103 - tp: 22499.0000 - fp: 1001.0000 - tn: 22499.0000 - fn: 1001.0000 - accuracy: 0.9574 train_balacc 0.95730984245299\n",
      " val_balacc 0.9733988478481871\n",
      "\n",
      "Epoch 49: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1105 - tp: 22604.0000 - fp: 1008.0000 - tn: 22604.0000 - fn: 1008.0000 - accuracy: 0.9573 - val_loss: 0.0754 - val_tp: 5745.0000 - val_fp: 157.0000 - val_tn: 5745.0000 - val_fn: 157.0000 - val_accuracy: 0.9734 - train_sensitivity: 0.9573 - train_specificity: 0.9573 - train_balacc: 0.9573 - val_sensitivity: 0.9734 - val_specificity: 0.9734 - val_balacc: 0.9734\n",
      "Epoch 50/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1171 - tp: 22342.0000 - fp: 1058.0000 - tn: 22342.0000 - fn: 1058.0000 - accuracy: 0.9548 train_balacc 0.954853464340166\n",
      " val_balacc 0.9459505252456795\n",
      "\n",
      "Epoch 50: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1172 - tp: 22546.0000 - fp: 1066.0000 - tn: 22546.0000 - fn: 1066.0000 - accuracy: 0.9549 - val_loss: 0.1480 - val_tp: 5583.0000 - val_fp: 319.0000 - val_tn: 5583.0000 - val_fn: 319.0000 - val_accuracy: 0.9460 - train_sensitivity: 0.9549 - train_specificity: 0.9549 - train_balacc: 0.9549 - val_sensitivity: 0.9460 - val_specificity: 0.9460 - val_balacc: 0.9460\n",
      "Epoch 51/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1133 - tp: 21819.0000 - fp: 981.0000 - tn: 21819.0000 - fn: 981.0000 - accuracy: 0.9570 train_balacc 0.9570133830255803\n",
      " val_balacc 0.973568281938326\n",
      "\n",
      "Epoch 51: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1136 - tp: 22597.0000 - fp: 1015.0000 - tn: 22597.0000 - fn: 1015.0000 - accuracy: 0.9570 - val_loss: 0.0853 - val_tp: 5746.0000 - val_fp: 156.0000 - val_tn: 5746.0000 - val_fn: 156.0000 - val_accuracy: 0.9736 - train_sensitivity: 0.9570 - train_specificity: 0.9570 - train_balacc: 0.9570 - val_sensitivity: 0.9736 - val_specificity: 0.9736 - val_balacc: 0.9736\n",
      "Epoch 52/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1102 - tp: 21835.0000 - fp: 965.0000 - tn: 21835.0000 - fn: 965.0000 - accuracy: 0.9577 train_balacc 0.957055734372353\n",
      " val_balacc 0.931209759403592\n",
      "\n",
      "Epoch 52: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1114 - tp: 22598.0000 - fp: 1014.0000 - tn: 22598.0000 - fn: 1014.0000 - accuracy: 0.9571 - val_loss: 0.1654 - val_tp: 5496.0000 - val_fp: 406.0000 - val_tn: 5496.0000 - val_fn: 406.0000 - val_accuracy: 0.9312 - train_sensitivity: 0.9571 - train_specificity: 0.9571 - train_balacc: 0.9571 - val_sensitivity: 0.9312 - val_specificity: 0.9312 - val_balacc: 0.9312\n",
      "Epoch 53/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1090 - tp: 22231.0000 - fp: 969.0000 - tn: 22231.0000 - fn: 969.0000 - accuracy: 0.9582 train_balacc 0.9583262747755379\n",
      " val_balacc 0.9717045069467977\n",
      "\n",
      "Epoch 53: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1086 - tp: 22628.0000 - fp: 984.0000 - tn: 22628.0000 - fn: 984.0000 - accuracy: 0.9583 - val_loss: 0.0670 - val_tp: 5735.0000 - val_fp: 167.0000 - val_tn: 5735.0000 - val_fn: 167.0000 - val_accuracy: 0.9717 - train_sensitivity: 0.9583 - train_specificity: 0.9583 - train_balacc: 0.9583 - val_sensitivity: 0.9717 - val_specificity: 0.9717 - val_balacc: 0.9717\n",
      "Epoch 54/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1075 - tp: 21937.0000 - fp: 963.0000 - tn: 21937.0000 - fn: 963.0000 - accuracy: 0.9579 train_balacc 0.9579027613078096\n",
      " val_balacc 0.9627245001694341\n",
      "\n",
      "Epoch 54: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1076 - tp: 22618.0000 - fp: 994.0000 - tn: 22618.0000 - fn: 994.0000 - accuracy: 0.9579 - val_loss: 0.1034 - val_tp: 5682.0000 - val_fp: 220.0000 - val_tn: 5682.0000 - val_fn: 220.0000 - val_accuracy: 0.9627 - train_sensitivity: 0.9579 - train_specificity: 0.9579 - train_balacc: 0.9579 - val_sensitivity: 0.9627 - val_specificity: 0.9627 - val_balacc: 0.9627\n",
      "Epoch 55/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1177 - tp: 22144.0000 - fp: 1056.0000 - tn: 22144.0000 - fn: 1056.0000 - accuracy: 0.9545 train_balacc 0.9546840589530747\n",
      " val_balacc 0.9696712978651305\n",
      "\n",
      "Epoch 55: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1171 - tp: 22542.0000 - fp: 1070.0000 - tn: 22542.0000 - fn: 1070.0000 - accuracy: 0.9547 - val_loss: 0.0895 - val_tp: 5723.0000 - val_fp: 179.0000 - val_tn: 5723.0000 - val_fn: 179.0000 - val_accuracy: 0.9697 - train_sensitivity: 0.9547 - train_specificity: 0.9547 - train_balacc: 0.9547 - val_sensitivity: 0.9697 - val_specificity: 0.9697 - val_balacc: 0.9697\n",
      "Epoch 56/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1044 - tp: 21970.0000 - fp: 930.0000 - tn: 21970.0000 - fn: 930.0000 - accuracy: 0.9594 train_balacc 0.9594274097916313\n",
      " val_balacc 0.9057946458827516\n",
      "\n",
      "Epoch 56: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1043 - tp: 22654.0000 - fp: 958.0000 - tn: 22654.0000 - fn: 958.0000 - accuracy: 0.9594 - val_loss: 0.2086 - val_tp: 5346.0000 - val_fp: 556.0000 - val_tn: 5346.0000 - val_fn: 556.0000 - val_accuracy: 0.9058 - train_sensitivity: 0.9594 - train_specificity: 0.9594 - train_balacc: 0.9594 - val_sensitivity: 0.9058 - val_specificity: 0.9058 - val_balacc: 0.9058\n",
      "Epoch 57/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1117 - tp: 22178.0000 - fp: 1022.0000 - tn: 22178.0000 - fn: 1022.0000 - accuracy: 0.9559 train_balacc 0.9559545993562595\n",
      " val_balacc 0.9647577092511013\n",
      "\n",
      "Epoch 57: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1117 - tp: 22572.0000 - fp: 1040.0000 - tn: 22572.0000 - fn: 1040.0000 - accuracy: 0.9560 - val_loss: 0.0957 - val_tp: 5694.0000 - val_fp: 208.0000 - val_tn: 5694.0000 - val_fn: 208.0000 - val_accuracy: 0.9648 - train_sensitivity: 0.9560 - train_specificity: 0.9560 - train_balacc: 0.9560 - val_sensitivity: 0.9648 - val_specificity: 0.9648 - val_balacc: 0.9648\n",
      "Epoch 58/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1096 - tp: 22309.0000 - fp: 991.0000 - tn: 22309.0000 - fn: 991.0000 - accuracy: 0.9575 train_balacc 0.9577333559207183\n",
      " val_balacc 0.9674686546933243\n",
      "\n",
      "Epoch 58: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1089 - tp: 22614.0000 - fp: 998.0000 - tn: 22614.0000 - fn: 998.0000 - accuracy: 0.9577 - val_loss: 0.0996 - val_tp: 5710.0000 - val_fp: 192.0000 - val_tn: 5710.0000 - val_fn: 192.0000 - val_accuracy: 0.9675 - train_sensitivity: 0.9577 - train_specificity: 0.9577 - train_balacc: 0.9577 - val_sensitivity: 0.9675 - val_specificity: 0.9675 - val_balacc: 0.9675\n",
      "Epoch 59/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1114 - tp: 22294.0000 - fp: 1006.0000 - tn: 22294.0000 - fn: 1006.0000 - accuracy: 0.9568 train_balacc 0.9567592749449433\n",
      " val_balacc 0.9686546933242969\n",
      "\n",
      "Epoch 59: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1115 - tp: 22591.0000 - fp: 1021.0000 - tn: 22591.0000 - fn: 1021.0000 - accuracy: 0.9568 - val_loss: 0.0875 - val_tp: 5717.0000 - val_fp: 185.0000 - val_tn: 5717.0000 - val_fn: 185.0000 - val_accuracy: 0.9687 - train_sensitivity: 0.9568 - train_specificity: 0.9568 - train_balacc: 0.9568 - val_sensitivity: 0.9687 - val_specificity: 0.9687 - val_balacc: 0.9687\n",
      "Epoch 60/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1060 - tp: 22626.0000 - fp: 974.0000 - tn: 22626.0000 - fn: 974.0000 - accuracy: 0.9587 train_balacc 0.9587497882432662\n",
      " val_balacc 0.9737377160284649\n",
      "\n",
      "Epoch 60: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1060 - tp: 22638.0000 - fp: 974.0000 - tn: 22638.0000 - fn: 974.0000 - accuracy: 0.9587 - val_loss: 0.0805 - val_tp: 5747.0000 - val_fp: 155.0000 - val_tn: 5747.0000 - val_fn: 155.0000 - val_accuracy: 0.9737 - train_sensitivity: 0.9587 - train_specificity: 0.9587 - train_balacc: 0.9587 - val_sensitivity: 0.9737 - val_specificity: 0.9737 - val_balacc: 0.9737\n",
      "Epoch 61/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1093 - tp: 21984.0000 - fp: 916.0000 - tn: 21984.0000 - fn: 916.0000 - accuracy: 0.9600 train_balacc 0.9594697611384042\n",
      " val_balacc 0.9542527956624873\n",
      "\n",
      "Epoch 61: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1104 - tp: 22655.0000 - fp: 957.0000 - tn: 22655.0000 - fn: 957.0000 - accuracy: 0.9595 - val_loss: 0.1148 - val_tp: 5632.0000 - val_fp: 270.0000 - val_tn: 5632.0000 - val_fn: 270.0000 - val_accuracy: 0.9543 - train_sensitivity: 0.9595 - train_specificity: 0.9595 - train_balacc: 0.9595 - val_sensitivity: 0.9543 - val_specificity: 0.9543 - val_balacc: 0.9543\n",
      "Epoch 62/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1086 - tp: 22157.0000 - fp: 943.0000 - tn: 22157.0000 - fn: 943.0000 - accuracy: 0.9592 train_balacc 0.9591733017109945\n",
      " val_balacc 0.9833954591663843\n",
      "\n",
      "Epoch 62: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1083 - tp: 22648.0000 - fp: 964.0000 - tn: 22648.0000 - fn: 964.0000 - accuracy: 0.9592 - val_loss: 0.0640 - val_tp: 5804.0000 - val_fp: 98.0000 - val_tn: 5804.0000 - val_fn: 98.0000 - val_accuracy: 0.9834 - train_sensitivity: 0.9592 - train_specificity: 0.9592 - train_balacc: 0.9592 - val_sensitivity: 0.9834 - val_specificity: 0.9834 - val_balacc: 0.9834\n",
      "Epoch 63/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1095 - tp: 21841.0000 - fp: 959.0000 - tn: 21841.0000 - fn: 959.0000 - accuracy: 0.9579 train_balacc 0.957818058614264\n",
      " val_balacc 0.7836326668925788\n",
      "\n",
      "Epoch 63: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1099 - tp: 22616.0000 - fp: 996.0000 - tn: 22616.0000 - fn: 996.0000 - accuracy: 0.9578 - val_loss: 0.7958 - val_tp: 4625.0000 - val_fp: 1277.0000 - val_tn: 4625.0000 - val_fn: 1277.0000 - val_accuracy: 0.7836 - train_sensitivity: 0.9578 - train_specificity: 0.9578 - train_balacc: 0.9578 - val_sensitivity: 0.7836 - val_specificity: 0.7836 - val_balacc: 0.7836\n",
      "Epoch 64/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1113 - tp: 22214.0000 - fp: 986.0000 - tn: 22214.0000 - fn: 986.0000 - accuracy: 0.9575 train_balacc 0.9574792478400813\n",
      " val_balacc 0.9405286343612335\n",
      "\n",
      "Epoch 64: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1114 - tp: 22608.0000 - fp: 1004.0000 - tn: 22608.0000 - fn: 1004.0000 - accuracy: 0.9575 - val_loss: 0.1423 - val_tp: 5551.0000 - val_fp: 351.0000 - val_tn: 5551.0000 - val_fn: 351.0000 - val_accuracy: 0.9405 - train_sensitivity: 0.9575 - train_specificity: 0.9575 - train_balacc: 0.9575 - val_sensitivity: 0.9405 - val_specificity: 0.9405 - val_balacc: 0.9405\n",
      "Epoch 65/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1083 - tp: 22004.0000 - fp: 996.0000 - tn: 22004.0000 - fn: 996.0000 - accuracy: 0.9567 train_balacc 0.9569286803320346\n",
      " val_balacc 0.9576414774652661\n",
      "\n",
      "Epoch 65: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1077 - tp: 22595.0000 - fp: 1017.0000 - tn: 22595.0000 - fn: 1017.0000 - accuracy: 0.9569 - val_loss: 0.1159 - val_tp: 5652.0000 - val_fp: 250.0000 - val_tn: 5652.0000 - val_fn: 250.0000 - val_accuracy: 0.9576 - train_sensitivity: 0.9569 - train_specificity: 0.9569 - train_balacc: 0.9569 - val_sensitivity: 0.9576 - val_specificity: 0.9576 - val_balacc: 0.9576\n",
      "Epoch 66/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1071 - tp: 21907.0000 - fp: 893.0000 - tn: 21907.0000 - fn: 893.0000 - accuracy: 0.9608 train_balacc 0.9606555988480434\n",
      " val_balacc 0.8561504574720433\n",
      "\n",
      "Epoch 66: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1078 - tp: 22683.0000 - fp: 929.0000 - tn: 22683.0000 - fn: 929.0000 - accuracy: 0.9607 - val_loss: 0.3698 - val_tp: 5053.0000 - val_fp: 849.0000 - val_tn: 5053.0000 - val_fn: 849.0000 - val_accuracy: 0.8562 - train_sensitivity: 0.9607 - train_specificity: 0.9607 - train_balacc: 0.9607 - val_sensitivity: 0.8562 - val_specificity: 0.8562 - val_balacc: 0.8562\n",
      "Epoch 67/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1103 - tp: 22142.0000 - fp: 958.0000 - tn: 22142.0000 - fn: 958.0000 - accuracy: 0.9585 train_balacc 0.9586650855497205\n",
      " val_balacc 0.97610979329041\n",
      "\n",
      "Epoch 67: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1102 - tp: 22636.0000 - fp: 976.0000 - tn: 22636.0000 - fn: 976.0000 - accuracy: 0.9587 - val_loss: 0.0790 - val_tp: 5761.0000 - val_fp: 141.0000 - val_tn: 5761.0000 - val_fn: 141.0000 - val_accuracy: 0.9761 - train_sensitivity: 0.9587 - train_specificity: 0.9587 - train_balacc: 0.9587 - val_sensitivity: 0.9761 - val_specificity: 0.9761 - val_balacc: 0.9761\n",
      "Epoch 68/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1090 - tp: 22559.0000 - fp: 941.0000 - tn: 22559.0000 - fn: 941.0000 - accuracy: 0.9600 train_balacc 0.9598085719125868\n",
      " val_balacc 0.9796679091833277\n",
      "\n",
      "Epoch 68: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1094 - tp: 22663.0000 - fp: 949.0000 - tn: 22663.0000 - fn: 949.0000 - accuracy: 0.9598 - val_loss: 0.0711 - val_tp: 5782.0000 - val_fp: 120.0000 - val_tn: 5782.0000 - val_fn: 120.0000 - val_accuracy: 0.9797 - train_sensitivity: 0.9598 - train_specificity: 0.9598 - train_balacc: 0.9598 - val_sensitivity: 0.9797 - val_specificity: 0.9797 - val_balacc: 0.9797\n",
      "Epoch 69/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1072 - tp: 21850.0000 - fp: 950.0000 - tn: 21850.0000 - fn: 950.0000 - accuracy: 0.9583 train_balacc 0.9584109774690835\n",
      " val_balacc 0.9610301592680447\n",
      "\n",
      "Epoch 69: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1088 - tp: 22630.0000 - fp: 982.0000 - tn: 22630.0000 - fn: 982.0000 - accuracy: 0.9584 - val_loss: 0.1158 - val_tp: 5672.0000 - val_fp: 230.0000 - val_tn: 5672.0000 - val_fn: 230.0000 - val_accuracy: 0.9610 - train_sensitivity: 0.9584 - train_specificity: 0.9584 - train_balacc: 0.9584 - val_sensitivity: 0.9610 - val_specificity: 0.9610 - val_balacc: 0.9610\n",
      "Epoch 70/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1064 - tp: 22050.0000 - fp: 950.0000 - tn: 22050.0000 - fn: 950.0000 - accuracy: 0.9587 train_balacc 0.9589615449771303\n",
      " val_balacc 0.9640799728905456\n",
      "\n",
      "Epoch 70: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1059 - tp: 22643.0000 - fp: 969.0000 - tn: 22643.0000 - fn: 969.0000 - accuracy: 0.9590 - val_loss: 0.0911 - val_tp: 5690.0000 - val_fp: 212.0000 - val_tn: 5690.0000 - val_fn: 212.0000 - val_accuracy: 0.9641 - train_sensitivity: 0.9590 - train_specificity: 0.9590 - train_balacc: 0.9590 - val_sensitivity: 0.9641 - val_specificity: 0.9641 - val_balacc: 0.9641\n",
      "Epoch 71/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1101 - tp: 22423.0000 - fp: 977.0000 - tn: 22423.0000 - fn: 977.0000 - accuracy: 0.9582 train_balacc 0.9582415720819922\n",
      " val_balacc 0.910199932226364\n",
      "\n",
      "Epoch 71: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1100 - tp: 22626.0000 - fp: 986.0000 - tn: 22626.0000 - fn: 986.0000 - accuracy: 0.9582 - val_loss: 0.2401 - val_tp: 5372.0000 - val_fp: 530.0000 - val_tn: 5372.0000 - val_fn: 530.0000 - val_accuracy: 0.9102 - train_sensitivity: 0.9582 - train_specificity: 0.9582 - train_balacc: 0.9582 - val_sensitivity: 0.9102 - val_specificity: 0.9102 - val_balacc: 0.9102\n",
      "Epoch 72/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1084 - tp: 22145.0000 - fp: 955.0000 - tn: 22145.0000 - fn: 955.0000 - accuracy: 0.9587 train_balacc 0.9583262747755379\n",
      " val_balacc 0.9666214842426296\n",
      "\n",
      "Epoch 72: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1090 - tp: 22628.0000 - fp: 984.0000 - tn: 22628.0000 - fn: 984.0000 - accuracy: 0.9583 - val_loss: 0.0993 - val_tp: 5705.0000 - val_fp: 197.0000 - val_tn: 5705.0000 - val_fn: 197.0000 - val_accuracy: 0.9666 - train_sensitivity: 0.9583 - train_specificity: 0.9583 - train_balacc: 0.9583 - val_sensitivity: 0.9666 - val_specificity: 0.9666 - val_balacc: 0.9666\n",
      "Epoch 73/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1115 - tp: 22282.0000 - fp: 1018.0000 - tn: 22282.0000 - fn: 1018.0000 - accuracy: 0.9563 train_balacc 0.9564204641707607\n",
      " val_balacc 0.9698407319552694\n",
      "\n",
      "Epoch 73: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1111 - tp: 22583.0000 - fp: 1029.0000 - tn: 22583.0000 - fn: 1029.0000 - accuracy: 0.9564 - val_loss: 0.0874 - val_tp: 5724.0000 - val_fp: 178.0000 - val_tn: 5724.0000 - val_fn: 178.0000 - val_accuracy: 0.9698 - train_sensitivity: 0.9564 - train_specificity: 0.9564 - train_balacc: 0.9564 - val_sensitivity: 0.9698 - val_specificity: 0.9698 - val_balacc: 0.9698\n",
      "Epoch 74/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1043 - tp: 22357.0000 - fp: 943.0000 - tn: 22357.0000 - fn: 943.0000 - accuracy: 0.9595 train_balacc 0.9591733017109945\n",
      " val_balacc 0.9596746865469332\n",
      "\n",
      "Epoch 74: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1051 - tp: 22648.0000 - fp: 964.0000 - tn: 22648.0000 - fn: 964.0000 - accuracy: 0.9592 - val_loss: 0.1021 - val_tp: 5664.0000 - val_fp: 238.0000 - val_tn: 5664.0000 - val_fn: 238.0000 - val_accuracy: 0.9597 - train_sensitivity: 0.9592 - train_specificity: 0.9592 - train_balacc: 0.9592 - val_sensitivity: 0.9597 - val_specificity: 0.9597 - val_balacc: 0.9597\n",
      "Epoch 75/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1086 - tp: 22102.0000 - fp: 998.0000 - tn: 22102.0000 - fn: 998.0000 - accuracy: 0.9568 train_balacc 0.9569286803320346\n",
      " val_balacc 0.936462216197899\n",
      "\n",
      "Epoch 75: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1081 - tp: 22595.0000 - fp: 1017.0000 - tn: 22595.0000 - fn: 1017.0000 - accuracy: 0.9569 - val_loss: 0.1653 - val_tp: 5527.0000 - val_fp: 375.0000 - val_tn: 5527.0000 - val_fn: 375.0000 - val_accuracy: 0.9365 - train_sensitivity: 0.9569 - train_specificity: 0.9569 - train_balacc: 0.9569 - val_sensitivity: 0.9365 - val_specificity: 0.9365 - val_balacc: 0.9365\n",
      "Epoch 76/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1047 - tp: 22155.0000 - fp: 945.0000 - tn: 22155.0000 - fn: 945.0000 - accuracy: 0.9591 train_balacc 0.9586227342029476\n",
      " val_balacc 0.9484920365977635\n",
      "\n",
      "Epoch 76: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1050 - tp: 22635.0000 - fp: 977.0000 - tn: 22635.0000 - fn: 977.0000 - accuracy: 0.9586 - val_loss: 0.1196 - val_tp: 5598.0000 - val_fp: 304.0000 - val_tn: 5598.0000 - val_fn: 304.0000 - val_accuracy: 0.9485 - train_sensitivity: 0.9586 - train_specificity: 0.9586 - train_balacc: 0.9586 - val_sensitivity: 0.9485 - val_specificity: 0.9485 - val_balacc: 0.9485\n",
      "Epoch 77/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1096 - tp: 21862.0000 - fp: 938.0000 - tn: 21862.0000 - fn: 938.0000 - accuracy: 0.9589 train_balacc 0.9588768422835846\n",
      " val_balacc 0.9789901728227719\n",
      "\n",
      "Epoch 77: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1088 - tp: 22641.0000 - fp: 971.0000 - tn: 22641.0000 - fn: 971.0000 - accuracy: 0.9589 - val_loss: 0.0717 - val_tp: 5778.0000 - val_fp: 124.0000 - val_tn: 5778.0000 - val_fn: 124.0000 - val_accuracy: 0.9790 - train_sensitivity: 0.9589 - train_specificity: 0.9589 - train_balacc: 0.9589 - val_sensitivity: 0.9790 - val_specificity: 0.9790 - val_balacc: 0.9790\n",
      "Epoch 78/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1083 - tp: 21857.0000 - fp: 943.0000 - tn: 21857.0000 - fn: 943.0000 - accuracy: 0.9586 train_balacc 0.9583686261223107\n",
      " val_balacc 0.9617078956286005\n",
      "\n",
      "Epoch 78: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1082 - tp: 22629.0000 - fp: 983.0000 - tn: 22629.0000 - fn: 983.0000 - accuracy: 0.9584 - val_loss: 0.0980 - val_tp: 5676.0000 - val_fp: 226.0000 - val_tn: 5676.0000 - val_fn: 226.0000 - val_accuracy: 0.9617 - train_sensitivity: 0.9584 - train_specificity: 0.9584 - train_balacc: 0.9584 - val_sensitivity: 0.9617 - val_specificity: 0.9617 - val_balacc: 0.9617\n",
      "Epoch 79/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1049 - tp: 22100.0000 - fp: 900.0000 - tn: 22100.0000 - fn: 900.0000 - accuracy: 0.9609 train_balacc 0.9609944096222259\n",
      " val_balacc 0.973568281938326\n",
      "\n",
      "Epoch 79: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1042 - tp: 22691.0000 - fp: 921.0000 - tn: 22691.0000 - fn: 921.0000 - accuracy: 0.9610 - val_loss: 0.0871 - val_tp: 5746.0000 - val_fp: 156.0000 - val_tn: 5746.0000 - val_fn: 156.0000 - val_accuracy: 0.9736 - train_sensitivity: 0.9610 - train_specificity: 0.9610 - train_balacc: 0.9610 - val_sensitivity: 0.9736 - val_specificity: 0.9736 - val_balacc: 0.9736\n",
      "Epoch 80/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1079 - tp: 22225.0000 - fp: 975.0000 - tn: 22225.0000 - fn: 975.0000 - accuracy: 0.9580 train_balacc 0.9576486532271726\n",
      " val_balacc 0.9705184683158251\n",
      "\n",
      "Epoch 80: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1081 - tp: 22612.0000 - fp: 1000.0000 - tn: 22612.0000 - fn: 1000.0000 - accuracy: 0.9576 - val_loss: 0.0984 - val_tp: 5728.0000 - val_fp: 174.0000 - val_tn: 5728.0000 - val_fn: 174.0000 - val_accuracy: 0.9705 - train_sensitivity: 0.9576 - train_specificity: 0.9576 - train_balacc: 0.9576 - val_sensitivity: 0.9705 - val_specificity: 0.9705 - val_balacc: 0.9705\n",
      "Epoch 81/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1003 - tp: 22033.0000 - fp: 867.0000 - tn: 22033.0000 - fn: 867.0000 - accuracy: 0.9621 train_balacc 0.9623496527189564\n",
      " val_balacc 0.8546255506607929\n",
      "\n",
      "Epoch 81: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0996 - tp: 22723.0000 - fp: 889.0000 - tn: 22723.0000 - fn: 889.0000 - accuracy: 0.9623 - val_loss: 0.4295 - val_tp: 5044.0000 - val_fp: 858.0000 - val_tn: 5044.0000 - val_fn: 858.0000 - val_accuracy: 0.8546 - train_sensitivity: 0.9623 - train_specificity: 0.9623 - train_balacc: 0.9623 - val_sensitivity: 0.8546 - val_specificity: 0.8546 - val_balacc: 0.8546\n",
      "Epoch 82/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1101 - tp: 22433.0000 - fp: 967.0000 - tn: 22433.0000 - fn: 967.0000 - accuracy: 0.9587 train_balacc 0.9587074368964933\n",
      " val_balacc 0.9622161978990172\n",
      "\n",
      "Epoch 82: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1099 - tp: 22637.0000 - fp: 975.0000 - tn: 22637.0000 - fn: 975.0000 - accuracy: 0.9587 - val_loss: 0.0920 - val_tp: 5679.0000 - val_fp: 223.0000 - val_tn: 5679.0000 - val_fn: 223.0000 - val_accuracy: 0.9622 - train_sensitivity: 0.9587 - train_specificity: 0.9587 - train_balacc: 0.9587 - val_sensitivity: 0.9622 - val_specificity: 0.9622 - val_balacc: 0.9622\n",
      "Epoch 83/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1039 - tp: 21983.0000 - fp: 917.0000 - tn: 21983.0000 - fn: 917.0000 - accuracy: 0.9600 train_balacc 0.9593850584448586\n",
      " val_balacc 0.9510335479498475\n",
      "\n",
      "Epoch 83: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1050 - tp: 22653.0000 - fp: 959.0000 - tn: 22653.0000 - fn: 959.0000 - accuracy: 0.9594 - val_loss: 0.1140 - val_tp: 5613.0000 - val_fp: 289.0000 - val_tn: 5613.0000 - val_fn: 289.0000 - val_accuracy: 0.9510 - train_sensitivity: 0.9594 - train_specificity: 0.9594 - train_balacc: 0.9594 - val_sensitivity: 0.9510 - val_specificity: 0.9510 - val_balacc: 0.9510\n",
      "Epoch 84/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1017 - tp: 22092.0000 - fp: 908.0000 - tn: 22092.0000 - fn: 908.0000 - accuracy: 0.9605 train_balacc 0.9601050313399966\n",
      " val_balacc 0.9584886479159607\n",
      "\n",
      "Epoch 84: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1024 - tp: 22670.0000 - fp: 942.0000 - tn: 22670.0000 - fn: 942.0000 - accuracy: 0.9601 - val_loss: 0.1153 - val_tp: 5657.0000 - val_fp: 245.0000 - val_tn: 5657.0000 - val_fn: 245.0000 - val_accuracy: 0.9585 - train_sensitivity: 0.9601 - train_specificity: 0.9601 - train_balacc: 0.9601 - val_sensitivity: 0.9585 - val_specificity: 0.9585 - val_balacc: 0.9585\n",
      "Epoch 85/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1067 - tp: 22242.0000 - fp: 958.0000 - tn: 22242.0000 - fn: 958.0000 - accuracy: 0.9587 train_balacc 0.9587497882432662\n",
      " val_balacc 0.9754320569298542\n",
      "\n",
      "Epoch 85: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1069 - tp: 22638.0000 - fp: 974.0000 - tn: 22638.0000 - fn: 974.0000 - accuracy: 0.9587 - val_loss: 0.0753 - val_tp: 5757.0000 - val_fp: 145.0000 - val_tn: 5757.0000 - val_fn: 145.0000 - val_accuracy: 0.9754 - train_sensitivity: 0.9587 - train_specificity: 0.9587 - train_balacc: 0.9587 - val_sensitivity: 0.9754 - val_specificity: 0.9754 - val_balacc: 0.9754\n",
      "Epoch 86/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1073 - tp: 22269.0000 - fp: 931.0000 - tn: 22269.0000 - fn: 931.0000 - accuracy: 0.9599 train_balacc 0.9596391665254955\n",
      " val_balacc 0.9627245001694341\n",
      "\n",
      "Epoch 86: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1077 - tp: 22659.0000 - fp: 953.0000 - tn: 22659.0000 - fn: 953.0000 - accuracy: 0.9596 - val_loss: 0.1084 - val_tp: 5682.0000 - val_fp: 220.0000 - val_tn: 5682.0000 - val_fn: 220.0000 - val_accuracy: 0.9627 - train_sensitivity: 0.9596 - train_specificity: 0.9596 - train_balacc: 0.9596 - val_sensitivity: 0.9627 - val_specificity: 0.9627 - val_balacc: 0.9627\n",
      "Epoch 87/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1082 - tp: 22530.0000 - fp: 970.0000 - tn: 22530.0000 - fn: 970.0000 - accuracy: 0.9587 train_balacc 0.9585803828561749\n",
      " val_balacc 0.9715350728566587\n",
      "\n",
      "Epoch 87: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1086 - tp: 22634.0000 - fp: 978.0000 - tn: 22634.0000 - fn: 978.0000 - accuracy: 0.9586 - val_loss: 0.0976 - val_tp: 5734.0000 - val_fp: 168.0000 - val_tn: 5734.0000 - val_fn: 168.0000 - val_accuracy: 0.9715 - train_sensitivity: 0.9586 - train_specificity: 0.9586 - train_balacc: 0.9586 - val_sensitivity: 0.9715 - val_specificity: 0.9715 - val_balacc: 0.9715\n",
      "Epoch 88/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1116 - tp: 22306.0000 - fp: 994.0000 - tn: 22306.0000 - fn: 994.0000 - accuracy: 0.9573 train_balacc 0.9574792478400813\n",
      " val_balacc 0.9300237207726194\n",
      "\n",
      "Epoch 88: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1121 - tp: 22608.0000 - fp: 1004.0000 - tn: 22608.0000 - fn: 1004.0000 - accuracy: 0.9575 - val_loss: 0.1929 - val_tp: 5489.0000 - val_fp: 413.0000 - val_tn: 5489.0000 - val_fn: 413.0000 - val_accuracy: 0.9300 - train_sensitivity: 0.9575 - train_specificity: 0.9575 - train_balacc: 0.9575 - val_sensitivity: 0.9300 - val_specificity: 0.9300 - val_balacc: 0.9300\n",
      "Epoch 89/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1058 - tp: 21948.0000 - fp: 952.0000 - tn: 21948.0000 - fn: 952.0000 - accuracy: 0.9584 train_balacc 0.9586227342029476\n",
      " val_balacc 0.9483226025076246\n",
      "\n",
      "Epoch 89: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1053 - tp: 22635.0000 - fp: 977.0000 - tn: 22635.0000 - fn: 977.0000 - accuracy: 0.9586 - val_loss: 0.1274 - val_tp: 5597.0000 - val_fp: 305.0000 - val_tn: 5597.0000 - val_fn: 305.0000 - val_accuracy: 0.9483 - train_sensitivity: 0.9586 - train_specificity: 0.9586 - train_balacc: 0.9586 - val_sensitivity: 0.9483 - val_specificity: 0.9483 - val_balacc: 0.9483\n",
      "Epoch 90/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1055 - tp: 22539.0000 - fp: 961.0000 - tn: 22539.0000 - fn: 961.0000 - accuracy: 0.9591 train_balacc 0.9590885990174488\n",
      " val_balacc 0.9632328024398509\n",
      "\n",
      "Epoch 90: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1055 - tp: 22646.0000 - fp: 966.0000 - tn: 22646.0000 - fn: 966.0000 - accuracy: 0.9591 - val_loss: 0.1061 - val_tp: 5685.0000 - val_fp: 217.0000 - val_tn: 5685.0000 - val_fn: 217.0000 - val_accuracy: 0.9632 - train_sensitivity: 0.9591 - train_specificity: 0.9591 - train_balacc: 0.9591 - val_sensitivity: 0.9632 - val_specificity: 0.9632 - val_balacc: 0.9632\n",
      "Epoch 91/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1058 - tp: 22560.0000 - fp: 940.0000 - tn: 22560.0000 - fn: 940.0000 - accuracy: 0.9600 train_balacc 0.9598509232593596\n",
      " val_balacc 0.9550999661131819\n",
      "\n",
      "Epoch 91: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1059 - tp: 22664.0000 - fp: 948.0000 - tn: 22664.0000 - fn: 948.0000 - accuracy: 0.9599 - val_loss: 0.1219 - val_tp: 5637.0000 - val_fp: 265.0000 - val_tn: 5637.0000 - val_fn: 265.0000 - val_accuracy: 0.9551 - train_sensitivity: 0.9599 - train_specificity: 0.9599 - train_balacc: 0.9599 - val_sensitivity: 0.9551 - val_specificity: 0.9551 - val_balacc: 0.9551\n",
      "Epoch 92/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1018 - tp: 22705.0000 - fp: 895.0000 - tn: 22705.0000 - fn: 895.0000 - accuracy: 0.9621 train_balacc 0.9620955446383195\n",
      " val_balacc 0.9722128092172145\n",
      "\n",
      "Epoch 92: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1018 - tp: 22717.0000 - fp: 895.0000 - tn: 22717.0000 - fn: 895.0000 - accuracy: 0.9621 - val_loss: 0.0751 - val_tp: 5738.0000 - val_fp: 164.0000 - val_tn: 5738.0000 - val_fn: 164.0000 - val_accuracy: 0.9722 - train_sensitivity: 0.9621 - train_specificity: 0.9621 - train_balacc: 0.9621 - val_sensitivity: 0.9722 - val_specificity: 0.9722 - val_balacc: 0.9722\n",
      "Epoch 93/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1059 - tp: 22627.0000 - fp: 973.0000 - tn: 22627.0000 - fn: 973.0000 - accuracy: 0.9588 train_balacc 0.9587497882432662\n",
      " val_balacc 0.9525584547610979\n",
      "\n",
      "Epoch 93: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1060 - tp: 22638.0000 - fp: 974.0000 - tn: 22638.0000 - fn: 974.0000 - accuracy: 0.9587 - val_loss: 0.1145 - val_tp: 5622.0000 - val_fp: 280.0000 - val_tn: 5622.0000 - val_fn: 280.0000 - val_accuracy: 0.9526 - train_sensitivity: 0.9587 - train_specificity: 0.9587 - train_balacc: 0.9587 - val_sensitivity: 0.9526 - val_specificity: 0.9526 - val_balacc: 0.9526\n",
      "Epoch 94/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1033 - tp: 22658.0000 - fp: 942.0000 - tn: 22658.0000 - fn: 942.0000 - accuracy: 0.9601 train_balacc 0.9600626799932238\n",
      " val_balacc 0.9467976956963741\n",
      "\n",
      "Epoch 94: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1033 - tp: 22669.0000 - fp: 943.0000 - tn: 22669.0000 - fn: 943.0000 - accuracy: 0.9601 - val_loss: 0.1292 - val_tp: 5588.0000 - val_fp: 314.0000 - val_tn: 5588.0000 - val_fn: 314.0000 - val_accuracy: 0.9468 - train_sensitivity: 0.9601 - train_specificity: 0.9601 - train_balacc: 0.9601 - val_sensitivity: 0.9468 - val_specificity: 0.9468 - val_balacc: 0.9468\n",
      "Epoch 95/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0973 - tp: 22031.0000 - fp: 869.0000 - tn: 22031.0000 - fn: 869.0000 - accuracy: 0.9621 train_balacc 0.9617990852109097\n",
      " val_balacc 0.9257878685191461\n",
      "\n",
      "Epoch 95: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0975 - tp: 22710.0000 - fp: 902.0000 - tn: 22710.0000 - fn: 902.0000 - accuracy: 0.9618 - val_loss: 0.1897 - val_tp: 5464.0000 - val_fp: 438.0000 - val_tn: 5464.0000 - val_fn: 438.0000 - val_accuracy: 0.9258 - train_sensitivity: 0.9618 - train_specificity: 0.9618 - train_balacc: 0.9618 - val_sensitivity: 0.9258 - val_specificity: 0.9258 - val_balacc: 0.9258\n",
      "Epoch 96/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1023 - tp: 22559.0000 - fp: 941.0000 - tn: 22559.0000 - fn: 941.0000 - accuracy: 0.9600 train_balacc 0.9599356259529053\n",
      " val_balacc 0.8390376143680108\n",
      "\n",
      "Epoch 96: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1025 - tp: 22666.0000 - fp: 946.0000 - tn: 22666.0000 - fn: 946.0000 - accuracy: 0.9599 - val_loss: 0.3744 - val_tp: 4952.0000 - val_fp: 950.0000 - val_tn: 4952.0000 - val_fn: 950.0000 - val_accuracy: 0.8390 - train_sensitivity: 0.9599 - train_specificity: 0.9599 - train_balacc: 0.9599 - val_sensitivity: 0.8390 - val_specificity: 0.8390 - val_balacc: 0.8390\n",
      "Epoch 97/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1028 - tp: 22282.0000 - fp: 918.0000 - tn: 22282.0000 - fn: 918.0000 - accuracy: 0.9604 train_balacc 0.9600626799932238\n",
      " val_balacc 0.971026770586242\n",
      "\n",
      "Epoch 97: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1038 - tp: 22669.0000 - fp: 943.0000 - tn: 22669.0000 - fn: 943.0000 - accuracy: 0.9601 - val_loss: 0.0807 - val_tp: 5731.0000 - val_fp: 171.0000 - val_tn: 5731.0000 - val_fn: 171.0000 - val_accuracy: 0.9710 - train_sensitivity: 0.9601 - train_specificity: 0.9601 - train_balacc: 0.9601 - val_sensitivity: 0.9710 - val_specificity: 0.9710 - val_balacc: 0.9710\n",
      "Epoch 98/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1007 - tp: 22672.0000 - fp: 928.0000 - tn: 22672.0000 - fn: 928.0000 - accuracy: 0.9607 train_balacc 0.9606555988480434\n",
      " val_balacc 0.9439173161640122\n",
      "\n",
      "Epoch 98: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1007 - tp: 22683.0000 - fp: 929.0000 - tn: 22683.0000 - fn: 929.0000 - accuracy: 0.9607 - val_loss: 0.1414 - val_tp: 5571.0000 - val_fp: 331.0000 - val_tn: 5571.0000 - val_fn: 331.0000 - val_accuracy: 0.9439 - train_sensitivity: 0.9607 - train_specificity: 0.9607 - train_balacc: 0.9607 - val_sensitivity: 0.9439 - val_specificity: 0.9439 - val_balacc: 0.9439\n",
      "Epoch 99/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1044 - tp: 21890.0000 - fp: 910.0000 - tn: 21890.0000 - fn: 910.0000 - accuracy: 0.9601 train_balacc 0.9599779772996782\n",
      " val_balacc 0.8781768891901051\n",
      "\n",
      "Epoch 99: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1042 - tp: 22667.0000 - fp: 945.0000 - tn: 22667.0000 - fn: 945.0000 - accuracy: 0.9600 - val_loss: 0.2618 - val_tp: 5183.0000 - val_fp: 719.0000 - val_tn: 5183.0000 - val_fn: 719.0000 - val_accuracy: 0.8782 - train_sensitivity: 0.9600 - train_specificity: 0.9600 - train_balacc: 0.9600 - val_sensitivity: 0.8782 - val_specificity: 0.8782 - val_balacc: 0.8782\n",
      "Epoch 100/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1060 - tp: 22082.0000 - fp: 918.0000 - tn: 22082.0000 - fn: 918.0000 - accuracy: 0.9601 train_balacc 0.9603167880738608\n",
      " val_balacc 0.9756014910199933\n",
      "\n",
      "Epoch 100: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1057 - tp: 22675.0000 - fp: 937.0000 - tn: 22675.0000 - fn: 937.0000 - accuracy: 0.9603 - val_loss: 0.0764 - val_tp: 5758.0000 - val_fp: 144.0000 - val_tn: 5758.0000 - val_fn: 144.0000 - val_accuracy: 0.9756 - train_sensitivity: 0.9603 - train_specificity: 0.9603 - train_balacc: 0.9603 - val_sensitivity: 0.9756 - val_specificity: 0.9756 - val_balacc: 0.9756\n",
      "Epoch 101/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.0997 - tp: 22570.0000 - fp: 930.0000 - tn: 22570.0000 - fn: 930.0000 - accuracy: 0.9604 train_balacc 0.9602744367270879\n",
      " val_balacc 0.9290071162317859\n",
      "\n",
      "Epoch 101: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0998 - tp: 22674.0000 - fp: 938.0000 - tn: 22674.0000 - fn: 938.0000 - accuracy: 0.9603 - val_loss: 0.1902 - val_tp: 5483.0000 - val_fp: 419.0000 - val_tn: 5483.0000 - val_fn: 419.0000 - val_accuracy: 0.9290 - train_sensitivity: 0.9603 - train_specificity: 0.9603 - train_balacc: 0.9603 - val_sensitivity: 0.9290 - val_specificity: 0.9290 - val_balacc: 0.9290\n",
      "Epoch 102/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.1014 - tp: 22567.0000 - fp: 933.0000 - tn: 22567.0000 - fn: 933.0000 - accuracy: 0.9603 train_balacc 0.9604861934609521\n",
      " val_balacc 0.9742460182988817\n",
      "\n",
      "Epoch 102: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1011 - tp: 22679.0000 - fp: 933.0000 - tn: 22679.0000 - fn: 933.0000 - accuracy: 0.9605 - val_loss: 0.0742 - val_tp: 5750.0000 - val_fp: 152.0000 - val_tn: 5750.0000 - val_fn: 152.0000 - val_accuracy: 0.9742 - train_sensitivity: 0.9605 - train_specificity: 0.9605 - train_balacc: 0.9605 - val_sensitivity: 0.9742 - val_specificity: 0.9742 - val_balacc: 0.9742\n",
      "Epoch 103/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1078 - tp: 22660.0000 - fp: 940.0000 - tn: 22660.0000 - fn: 940.0000 - accuracy: 0.9602 train_balacc 0.9601897340335422\n",
      " val_balacc 0.968485259234158\n",
      "\n",
      "Epoch 103: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1077 - tp: 22672.0000 - fp: 940.0000 - tn: 22672.0000 - fn: 940.0000 - accuracy: 0.9602 - val_loss: 0.0881 - val_tp: 5716.0000 - val_fp: 186.0000 - val_tn: 5716.0000 - val_fn: 186.0000 - val_accuracy: 0.9685 - train_sensitivity: 0.9602 - train_specificity: 0.9602 - train_balacc: 0.9602 - val_sensitivity: 0.9685 - val_specificity: 0.9685 - val_balacc: 0.9685\n",
      "Epoch 104/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1047 - tp: 22675.0000 - fp: 925.0000 - tn: 22675.0000 - fn: 925.0000 - accuracy: 0.9608 train_balacc 0.9608250042351347\n",
      " val_balacc 0.9661131819722129\n",
      "\n",
      "Epoch 104: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1047 - tp: 22687.0000 - fp: 925.0000 - tn: 22687.0000 - fn: 925.0000 - accuracy: 0.9608 - val_loss: 0.0880 - val_tp: 5702.0000 - val_fp: 200.0000 - val_tn: 5702.0000 - val_fn: 200.0000 - val_accuracy: 0.9661 - train_sensitivity: 0.9608 - train_specificity: 0.9608 - train_balacc: 0.9608 - val_sensitivity: 0.9661 - val_specificity: 0.9661 - val_balacc: 0.9661\n",
      "Epoch 105/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1019 - tp: 21902.0000 - fp: 898.0000 - tn: 21902.0000 - fn: 898.0000 - accuracy: 0.9606 train_balacc 0.9604861934609521\n",
      " val_balacc 0.9591663842765165\n",
      "\n",
      "Epoch 105: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1033 - tp: 22679.0000 - fp: 933.0000 - tn: 22679.0000 - fn: 933.0000 - accuracy: 0.9605 - val_loss: 0.1037 - val_tp: 5661.0000 - val_fp: 241.0000 - val_tn: 5661.0000 - val_fn: 241.0000 - val_accuracy: 0.9592 - train_sensitivity: 0.9605 - train_specificity: 0.9605 - train_balacc: 0.9605 - val_sensitivity: 0.9592 - val_specificity: 0.9592 - val_balacc: 0.9592\n",
      "Epoch 106/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1002 - tp: 22091.0000 - fp: 909.0000 - tn: 22091.0000 - fn: 909.0000 - accuracy: 0.9605 train_balacc 0.9603591394206336\n",
      " val_balacc 0.9535750593019315\n",
      "\n",
      "Epoch 106: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1012 - tp: 22676.0000 - fp: 936.0000 - tn: 22676.0000 - fn: 936.0000 - accuracy: 0.9604 - val_loss: 0.1243 - val_tp: 5628.0000 - val_fp: 274.0000 - val_tn: 5628.0000 - val_fn: 274.0000 - val_accuracy: 0.9536 - train_sensitivity: 0.9604 - train_specificity: 0.9604 - train_balacc: 0.9604 - val_sensitivity: 0.9536 - val_specificity: 0.9536 - val_balacc: 0.9536\n",
      "Epoch 107/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.1062 - tp: 22646.0000 - fp: 954.0000 - tn: 22646.0000 - fn: 954.0000 - accuracy: 0.9596 train_balacc 0.9595544638319499\n",
      " val_balacc 0.9654354456116571\n",
      "\n",
      "Epoch 107: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1062 - tp: 22657.0000 - fp: 955.0000 - tn: 22657.0000 - fn: 955.0000 - accuracy: 0.9596 - val_loss: 0.1044 - val_tp: 5698.0000 - val_fp: 204.0000 - val_tn: 5698.0000 - val_fn: 204.0000 - val_accuracy: 0.9654 - train_sensitivity: 0.9596 - train_specificity: 0.9596 - train_balacc: 0.9596 - val_sensitivity: 0.9654 - val_specificity: 0.9654 - val_balacc: 0.9654\n",
      "Epoch 108/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.0972 - tp: 21927.0000 - fp: 873.0000 - tn: 21927.0000 - fn: 873.0000 - accuracy: 0.9617 train_balacc 0.9617990852109097\n",
      " val_balacc 0.923246357167062\n",
      "\n",
      "Epoch 108: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0974 - tp: 22710.0000 - fp: 902.0000 - tn: 22710.0000 - fn: 902.0000 - accuracy: 0.9618 - val_loss: 0.1690 - val_tp: 5449.0000 - val_fp: 453.0000 - val_tn: 5449.0000 - val_fn: 453.0000 - val_accuracy: 0.9232 - train_sensitivity: 0.9618 - train_specificity: 0.9618 - train_balacc: 0.9618 - val_sensitivity: 0.9232 - val_specificity: 0.9232 - val_balacc: 0.9232\n",
      "Epoch 109/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0968 - tp: 22730.0000 - fp: 870.0000 - tn: 22730.0000 - fn: 870.0000 - accuracy: 0.9631 train_balacc 0.9631119769608674\n",
      " val_balacc 0.9535750593019315\n",
      "\n",
      "Epoch 109: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0969 - tp: 22741.0000 - fp: 871.0000 - tn: 22741.0000 - fn: 871.0000 - accuracy: 0.9631 - val_loss: 0.1160 - val_tp: 5628.0000 - val_fp: 274.0000 - val_tn: 5628.0000 - val_fn: 274.0000 - val_accuracy: 0.9536 - train_sensitivity: 0.9631 - train_specificity: 0.9631 - train_balacc: 0.9631 - val_sensitivity: 0.9536 - val_specificity: 0.9536 - val_balacc: 0.9536\n",
      "Epoch 110/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.0983 - tp: 22621.0000 - fp: 879.0000 - tn: 22621.0000 - fn: 879.0000 - accuracy: 0.9626 train_balacc 0.9626037607995934\n",
      " val_balacc 0.9703490342256862\n",
      "\n",
      "Epoch 110: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0983 - tp: 22729.0000 - fp: 883.0000 - tn: 22729.0000 - fn: 883.0000 - accuracy: 0.9626 - val_loss: 0.0833 - val_tp: 5727.0000 - val_fp: 175.0000 - val_tn: 5727.0000 - val_fn: 175.0000 - val_accuracy: 0.9703 - train_sensitivity: 0.9626 - train_specificity: 0.9626 - train_balacc: 0.9626 - val_sensitivity: 0.9703 - val_specificity: 0.9703 - val_balacc: 0.9703\n",
      "Epoch 111/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1012 - tp: 22039.0000 - fp: 861.0000 - tn: 22039.0000 - fn: 861.0000 - accuracy: 0.9624 train_balacc 0.9626037607995934\n",
      " val_balacc 0.9462893934259573\n",
      "\n",
      "Epoch 111: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1007 - tp: 22729.0000 - fp: 883.0000 - tn: 22729.0000 - fn: 883.0000 - accuracy: 0.9626 - val_loss: 0.1309 - val_tp: 5585.0000 - val_fp: 317.0000 - val_tn: 5585.0000 - val_fn: 317.0000 - val_accuracy: 0.9463 - train_sensitivity: 0.9626 - train_specificity: 0.9626 - train_balacc: 0.9626 - val_sensitivity: 0.9463 - val_specificity: 0.9463 - val_balacc: 0.9463\n",
      "Epoch 112/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.0990 - tp: 22508.0000 - fp: 892.0000 - tn: 22508.0000 - fn: 892.0000 - accuracy: 0.9619 train_balacc 0.9617143825173641\n",
      " val_balacc 0.9791596069129109\n",
      "\n",
      "Epoch 112: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 0.0995 - tp: 22708.0000 - fp: 904.0000 - tn: 22708.0000 - fn: 904.0000 - accuracy: 0.9617 - val_loss: 0.0683 - val_tp: 5779.0000 - val_fp: 123.0000 - val_tn: 5779.0000 - val_fn: 123.0000 - val_accuracy: 0.9792 - train_sensitivity: 0.9617 - train_specificity: 0.9617 - train_balacc: 0.9617 - val_sensitivity: 0.9792 - val_specificity: 0.9792 - val_balacc: 0.9792\n",
      "Epoch 113/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1002 - tp: 22283.0000 - fp: 917.0000 - tn: 22283.0000 - fn: 917.0000 - accuracy: 0.9605 train_balacc 0.9602320853803151\n",
      " val_balacc 0.9300237207726194\n",
      "\n",
      "Epoch 113: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1010 - tp: 22673.0000 - fp: 939.0000 - tn: 22673.0000 - fn: 939.0000 - accuracy: 0.9602 - val_loss: 0.1650 - val_tp: 5489.0000 - val_fp: 413.0000 - val_tn: 5489.0000 - val_fn: 413.0000 - val_accuracy: 0.9300 - train_sensitivity: 0.9602 - train_specificity: 0.9602 - train_balacc: 0.9602 - val_sensitivity: 0.9300 - val_specificity: 0.9300 - val_balacc: 0.9300\n",
      "Epoch 114/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.0949 - tp: 22442.0000 - fp: 858.0000 - tn: 22442.0000 - fn: 858.0000 - accuracy: 0.9632 train_balacc 0.9628155175334575\n",
      " val_balacc 0.9664520501524907\n",
      "\n",
      "Epoch 114: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0955 - tp: 22734.0000 - fp: 878.0000 - tn: 22734.0000 - fn: 878.0000 - accuracy: 0.9628 - val_loss: 0.0885 - val_tp: 5704.0000 - val_fp: 198.0000 - val_tn: 5704.0000 - val_fn: 198.0000 - val_accuracy: 0.9665 - train_sensitivity: 0.9628 - train_specificity: 0.9628 - train_balacc: 0.9628 - val_sensitivity: 0.9665 - val_specificity: 0.9665 - val_balacc: 0.9665\n",
      "Epoch 115/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1019 - tp: 22013.0000 - fp: 887.0000 - tn: 22013.0000 - fn: 887.0000 - accuracy: 0.9613 train_balacc 0.9606979501948162\n",
      " val_balacc 0.9357844798373433\n",
      "\n",
      "Epoch 115: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1029 - tp: 22684.0000 - fp: 928.0000 - tn: 22684.0000 - fn: 928.0000 - accuracy: 0.9607 - val_loss: 0.1524 - val_tp: 5523.0000 - val_fp: 379.0000 - val_tn: 5523.0000 - val_fn: 379.0000 - val_accuracy: 0.9358 - train_sensitivity: 0.9607 - train_specificity: 0.9607 - train_balacc: 0.9607 - val_sensitivity: 0.9358 - val_specificity: 0.9358 - val_balacc: 0.9358\n",
      "Epoch 116/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.0997 - tp: 22473.0000 - fp: 927.0000 - tn: 22473.0000 - fn: 927.0000 - accuracy: 0.9604 train_balacc 0.9604014907674064\n",
      " val_balacc 0.9545916638427652\n",
      "\n",
      "Epoch 116: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0998 - tp: 22677.0000 - fp: 935.0000 - tn: 22677.0000 - fn: 935.0000 - accuracy: 0.9604 - val_loss: 0.1069 - val_tp: 5634.0000 - val_fp: 268.0000 - val_tn: 5634.0000 - val_fn: 268.0000 - val_accuracy: 0.9546 - train_sensitivity: 0.9604 - train_specificity: 0.9604 - train_balacc: 0.9604 - val_sensitivity: 0.9546 - val_specificity: 0.9546 - val_balacc: 0.9546\n",
      "Epoch 117/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1014 - tp: 22400.0000 - fp: 900.0000 - tn: 22400.0000 - fn: 900.0000 - accuracy: 0.9614 train_balacc 0.9615026257834999\n",
      " val_balacc 0.9661131819722129\n",
      "\n",
      "Epoch 117: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1011 - tp: 22703.0000 - fp: 909.0000 - tn: 22703.0000 - fn: 909.0000 - accuracy: 0.9615 - val_loss: 0.1011 - val_tp: 5702.0000 - val_fp: 200.0000 - val_tn: 5702.0000 - val_fn: 200.0000 - val_accuracy: 0.9661 - train_sensitivity: 0.9615 - train_specificity: 0.9615 - train_balacc: 0.9615 - val_sensitivity: 0.9661 - val_specificity: 0.9661 - val_balacc: 0.9661\n",
      "Epoch 118/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1003 - tp: 22106.0000 - fp: 894.0000 - tn: 22106.0000 - fn: 894.0000 - accuracy: 0.9611 train_balacc 0.9615873284770455\n",
      " val_balacc 0.9806845137241613\n",
      "\n",
      "Epoch 118: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0998 - tp: 22705.0000 - fp: 907.0000 - tn: 22705.0000 - fn: 907.0000 - accuracy: 0.9616 - val_loss: 0.0610 - val_tp: 5788.0000 - val_fp: 114.0000 - val_tn: 5788.0000 - val_fn: 114.0000 - val_accuracy: 0.9807 - train_sensitivity: 0.9616 - train_specificity: 0.9616 - train_balacc: 0.9616 - val_sensitivity: 0.9807 - val_specificity: 0.9807 - val_balacc: 0.9807\n",
      "Epoch 119/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0984 - tp: 22255.0000 - fp: 845.0000 - tn: 22255.0000 - fn: 845.0000 - accuracy: 0.9634 train_balacc 0.963196679654413\n",
      " val_balacc 0.9423924093527618\n",
      "\n",
      "Epoch 119: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0990 - tp: 22743.0000 - fp: 869.0000 - tn: 22743.0000 - fn: 869.0000 - accuracy: 0.9632 - val_loss: 0.1395 - val_tp: 5562.0000 - val_fp: 340.0000 - val_tn: 5562.0000 - val_fn: 340.0000 - val_accuracy: 0.9424 - train_sensitivity: 0.9632 - train_specificity: 0.9632 - train_balacc: 0.9632 - val_sensitivity: 0.9424 - val_specificity: 0.9424 - val_balacc: 0.9424\n",
      "Epoch 120/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0994 - tp: 22333.0000 - fp: 867.0000 - tn: 22333.0000 - fn: 867.0000 - accuracy: 0.9626 train_balacc 0.9626037607995934\n",
      " val_balacc 0.9644188410708234\n",
      "\n",
      "Epoch 120: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0992 - tp: 22729.0000 - fp: 883.0000 - tn: 22729.0000 - fn: 883.0000 - accuracy: 0.9626 - val_loss: 0.0955 - val_tp: 5692.0000 - val_fp: 210.0000 - val_tn: 5692.0000 - val_fn: 210.0000 - val_accuracy: 0.9644 - train_sensitivity: 0.9626 - train_specificity: 0.9626 - train_balacc: 0.9626 - val_sensitivity: 0.9644 - val_specificity: 0.9644 - val_balacc: 0.9644\n",
      "Epoch 121/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.1000 - tp: 22054.0000 - fp: 846.0000 - tn: 22054.0000 - fn: 846.0000 - accuracy: 0.9631 train_balacc 0.9630272742673217\n",
      " val_balacc 0.9140969162995595\n",
      "\n",
      "Epoch 121: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1005 - tp: 22739.0000 - fp: 873.0000 - tn: 22739.0000 - fn: 873.0000 - accuracy: 0.9630 - val_loss: 0.2334 - val_tp: 5395.0000 - val_fp: 507.0000 - val_tn: 5395.0000 - val_fn: 507.0000 - val_accuracy: 0.9141 - train_sensitivity: 0.9630 - train_specificity: 0.9630 - train_balacc: 0.9630 - val_sensitivity: 0.9141 - val_specificity: 0.9141 - val_balacc: 0.9141\n",
      "Epoch 122/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0991 - tp: 22220.0000 - fp: 880.0000 - tn: 22220.0000 - fn: 880.0000 - accuracy: 0.9619 train_balacc 0.9617567338641368\n",
      " val_balacc 0.971026770586242\n",
      "\n",
      "Epoch 122: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0995 - tp: 22709.0000 - fp: 903.0000 - tn: 22709.0000 - fn: 903.0000 - accuracy: 0.9618 - val_loss: 0.0765 - val_tp: 5731.0000 - val_fp: 171.0000 - val_tn: 5731.0000 - val_fn: 171.0000 - val_accuracy: 0.9710 - train_sensitivity: 0.9618 - train_specificity: 0.9618 - train_balacc: 0.9618 - val_sensitivity: 0.9710 - val_specificity: 0.9710 - val_balacc: 0.9710\n",
      "Epoch 123/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1011 - tp: 21943.0000 - fp: 857.0000 - tn: 21943.0000 - fn: 857.0000 - accuracy: 0.9624 train_balacc 0.9628155175334575\n",
      " val_balacc 0.9671297865130464\n",
      "\n",
      "Epoch 123: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1000 - tp: 22734.0000 - fp: 878.0000 - tn: 22734.0000 - fn: 878.0000 - accuracy: 0.9628 - val_loss: 0.0942 - val_tp: 5708.0000 - val_fp: 194.0000 - val_tn: 5708.0000 - val_fn: 194.0000 - val_accuracy: 0.9671 - train_sensitivity: 0.9628 - train_specificity: 0.9628 - train_balacc: 0.9628 - val_sensitivity: 0.9671 - val_specificity: 0.9671 - val_balacc: 0.9671\n",
      "Epoch 124/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0962 - tp: 22152.0000 - fp: 848.0000 - tn: 22152.0000 - fn: 848.0000 - accuracy: 0.9631 train_balacc 0.9632813823479587\n",
      " val_balacc 0.9683158251440189\n",
      "\n",
      "Epoch 124: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0957 - tp: 22745.0000 - fp: 867.0000 - tn: 22745.0000 - fn: 867.0000 - accuracy: 0.9633 - val_loss: 0.0929 - val_tp: 5715.0000 - val_fp: 187.0000 - val_tn: 5715.0000 - val_fn: 187.0000 - val_accuracy: 0.9683 - train_sensitivity: 0.9633 - train_specificity: 0.9633 - train_balacc: 0.9633 - val_sensitivity: 0.9683 - val_specificity: 0.9683 - val_balacc: 0.9683\n",
      "Epoch 125/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.0993 - tp: 21955.0000 - fp: 845.0000 - tn: 21955.0000 - fn: 845.0000 - accuracy: 0.9629 train_balacc 0.9630696256140945\n",
      " val_balacc 0.9701796001355473\n",
      "\n",
      "Epoch 125: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0993 - tp: 22740.0000 - fp: 872.0000 - tn: 22740.0000 - fn: 872.0000 - accuracy: 0.9631 - val_loss: 0.0957 - val_tp: 5726.0000 - val_fp: 176.0000 - val_tn: 5726.0000 - val_fn: 176.0000 - val_accuracy: 0.9702 - train_sensitivity: 0.9631 - train_specificity: 0.9631 - train_balacc: 0.9631 - val_sensitivity: 0.9702 - val_specificity: 0.9702 - val_balacc: 0.9702\n",
      "Epoch 126/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1009 - tp: 22121.0000 - fp: 879.0000 - tn: 22121.0000 - fn: 879.0000 - accuracy: 0.9618 train_balacc 0.9616296798238184\n",
      " val_balacc 0.9717045069467977\n",
      "\n",
      "Epoch 126: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1011 - tp: 22706.0000 - fp: 906.0000 - tn: 22706.0000 - fn: 906.0000 - accuracy: 0.9616 - val_loss: 0.0797 - val_tp: 5735.0000 - val_fp: 167.0000 - val_tn: 5735.0000 - val_fn: 167.0000 - val_accuracy: 0.9717 - train_sensitivity: 0.9616 - train_specificity: 0.9616 - train_balacc: 0.9616 - val_sensitivity: 0.9717 - val_specificity: 0.9717 - val_balacc: 0.9717\n",
      "Epoch 127/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.1021 - tp: 22518.0000 - fp: 882.0000 - tn: 22518.0000 - fn: 882.0000 - accuracy: 0.9623 train_balacc 0.962222598678638\n",
      " val_balacc 0.949678075228736\n",
      "\n",
      "Epoch 127: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1019 - tp: 22720.0000 - fp: 892.0000 - tn: 22720.0000 - fn: 892.0000 - accuracy: 0.9622 - val_loss: 0.1282 - val_tp: 5605.0000 - val_fp: 297.0000 - val_tn: 5605.0000 - val_fn: 297.0000 - val_accuracy: 0.9497 - train_sensitivity: 0.9622 - train_specificity: 0.9622 - train_balacc: 0.9622 - val_sensitivity: 0.9497 - val_specificity: 0.9497 - val_balacc: 0.9497\n",
      "Epoch 128/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0963 - tp: 22733.0000 - fp: 867.0000 - tn: 22733.0000 - fn: 867.0000 - accuracy: 0.9633 train_balacc 0.9632390310011858\n",
      " val_balacc 0.9352761775669265\n",
      "\n",
      "Epoch 128: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0963 - tp: 22744.0000 - fp: 868.0000 - tn: 22744.0000 - fn: 868.0000 - accuracy: 0.9632 - val_loss: 0.1770 - val_tp: 5520.0000 - val_fp: 382.0000 - val_tn: 5520.0000 - val_fn: 382.0000 - val_accuracy: 0.9353 - train_sensitivity: 0.9632 - train_specificity: 0.9632 - train_balacc: 0.9632 - val_sensitivity: 0.9353 - val_specificity: 0.9353 - val_balacc: 0.9353\n",
      "Epoch 129/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0988 - tp: 22348.0000 - fp: 852.0000 - tn: 22348.0000 - fn: 852.0000 - accuracy: 0.9633 train_balacc 0.96345078773505\n",
      " val_balacc 0.9666214842426296\n",
      "\n",
      "Epoch 129: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0986 - tp: 22749.0000 - fp: 863.0000 - tn: 22749.0000 - fn: 863.0000 - accuracy: 0.9635 - val_loss: 0.0975 - val_tp: 5705.0000 - val_fp: 197.0000 - val_tn: 5705.0000 - val_fn: 197.0000 - val_accuracy: 0.9666 - train_sensitivity: 0.9635 - train_specificity: 0.9635 - train_balacc: 0.9635 - val_sensitivity: 0.9666 - val_specificity: 0.9666 - val_balacc: 0.9666\n",
      "Epoch 130/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0986 - tp: 22702.0000 - fp: 898.0000 - tn: 22702.0000 - fn: 898.0000 - accuracy: 0.9619 train_balacc 0.9619261392512282\n",
      " val_balacc 0.9730599796679091\n",
      "\n",
      "Epoch 130: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0986 - tp: 22713.0000 - fp: 899.0000 - tn: 22713.0000 - fn: 899.0000 - accuracy: 0.9619 - val_loss: 0.0833 - val_tp: 5743.0000 - val_fp: 159.0000 - val_tn: 5743.0000 - val_fn: 159.0000 - val_accuracy: 0.9731 - train_sensitivity: 0.9619 - train_specificity: 0.9619 - train_balacc: 0.9619 - val_sensitivity: 0.9731 - val_specificity: 0.9731 - val_balacc: 0.9731\n",
      "Epoch 131/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1014 - tp: 22335.0000 - fp: 865.0000 - tn: 22335.0000 - fn: 865.0000 - accuracy: 0.9627 train_balacc 0.9626884634931391\n",
      " val_balacc 0.9754320569298542\n",
      "\n",
      "Epoch 131: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1017 - tp: 22731.0000 - fp: 881.0000 - tn: 22731.0000 - fn: 881.0000 - accuracy: 0.9627 - val_loss: 0.0795 - val_tp: 5757.0000 - val_fp: 145.0000 - val_tn: 5757.0000 - val_fn: 145.0000 - val_accuracy: 0.9754 - train_sensitivity: 0.9627 - train_specificity: 0.9627 - train_balacc: 0.9627 - val_sensitivity: 0.9754 - val_specificity: 0.9754 - val_balacc: 0.9754\n",
      "Epoch 132/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0976 - tp: 22739.0000 - fp: 861.0000 - tn: 22739.0000 - fn: 861.0000 - accuracy: 0.9635 train_balacc 0.9634931390818228\n",
      " val_balacc 0.8891901050491359\n",
      "\n",
      "Epoch 132: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0981 - tp: 22750.0000 - fp: 862.0000 - tn: 22750.0000 - fn: 862.0000 - accuracy: 0.9635 - val_loss: 0.2536 - val_tp: 5248.0000 - val_fp: 654.0000 - val_tn: 5248.0000 - val_fn: 654.0000 - val_accuracy: 0.8892 - train_sensitivity: 0.9635 - train_specificity: 0.9635 - train_balacc: 0.9635 - val_sensitivity: 0.8892 - val_specificity: 0.8892 - val_balacc: 0.8892\n",
      "Epoch 133/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.0997 - tp: 22401.0000 - fp: 899.0000 - tn: 22401.0000 - fn: 899.0000 - accuracy: 0.9614 train_balacc 0.9615873284770455\n",
      " val_balacc 0.9617078956286005\n",
      "\n",
      "Epoch 133: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0995 - tp: 22705.0000 - fp: 907.0000 - tn: 22705.0000 - fn: 907.0000 - accuracy: 0.9616 - val_loss: 0.1038 - val_tp: 5676.0000 - val_fp: 226.0000 - val_tn: 5676.0000 - val_fn: 226.0000 - val_accuracy: 0.9617 - train_sensitivity: 0.9616 - train_specificity: 0.9616 - train_balacc: 0.9616 - val_sensitivity: 0.9617 - val_specificity: 0.9617 - val_balacc: 0.9617\n",
      "Epoch 134/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.1002 - tp: 22417.0000 - fp: 883.0000 - tn: 22417.0000 - fn: 883.0000 - accuracy: 0.9621 train_balacc 0.9621378959850924\n",
      " val_balacc 0.9698407319552694\n",
      "\n",
      "Epoch 134: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1000 - tp: 22718.0000 - fp: 894.0000 - tn: 22718.0000 - fn: 894.0000 - accuracy: 0.9621 - val_loss: 0.0877 - val_tp: 5724.0000 - val_fp: 178.0000 - val_tn: 5724.0000 - val_fn: 178.0000 - val_accuracy: 0.9698 - train_sensitivity: 0.9621 - train_specificity: 0.9621 - train_balacc: 0.9621 - val_sensitivity: 0.9698 - val_specificity: 0.9698 - val_balacc: 0.9698\n",
      "Epoch 135/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1028 - tp: 22332.0000 - fp: 868.0000 - tn: 22332.0000 - fn: 868.0000 - accuracy: 0.9626 train_balacc 0.9626461121463663\n",
      " val_balacc 0.936462216197899\n",
      "\n",
      "Epoch 135: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1025 - tp: 22730.0000 - fp: 882.0000 - tn: 22730.0000 - fn: 882.0000 - accuracy: 0.9626 - val_loss: 0.1537 - val_tp: 5527.0000 - val_fp: 375.0000 - val_tn: 5527.0000 - val_fn: 375.0000 - val_accuracy: 0.9365 - train_sensitivity: 0.9626 - train_specificity: 0.9626 - train_balacc: 0.9626 - val_sensitivity: 0.9365 - val_specificity: 0.9365 - val_balacc: 0.9365\n",
      "Epoch 136/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.0995 - tp: 22619.0000 - fp: 881.0000 - tn: 22619.0000 - fn: 881.0000 - accuracy: 0.9625 train_balacc 0.9626037607995934\n",
      " val_balacc 0.962893934259573\n",
      "\n",
      "Epoch 136: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0993 - tp: 22729.0000 - fp: 883.0000 - tn: 22729.0000 - fn: 883.0000 - accuracy: 0.9626 - val_loss: 0.1069 - val_tp: 5683.0000 - val_fp: 219.0000 - val_tn: 5683.0000 - val_fn: 219.0000 - val_accuracy: 0.9629 - train_sensitivity: 0.9626 - train_specificity: 0.9626 - train_balacc: 0.9626 - val_sensitivity: 0.9629 - val_specificity: 0.9629 - val_balacc: 0.9629\n",
      "Epoch 137/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0997 - tp: 22700.0000 - fp: 900.0000 - tn: 22700.0000 - fn: 900.0000 - accuracy: 0.9619 train_balacc 0.9617990852109097\n",
      " val_balacc 0.9481531684174856\n",
      "\n",
      "Epoch 137: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0998 - tp: 22710.0000 - fp: 902.0000 - tn: 22710.0000 - fn: 902.0000 - accuracy: 0.9618 - val_loss: 0.1394 - val_tp: 5596.0000 - val_fp: 306.0000 - val_tn: 5596.0000 - val_fn: 306.0000 - val_accuracy: 0.9482 - train_sensitivity: 0.9618 - train_specificity: 0.9618 - train_balacc: 0.9618 - val_sensitivity: 0.9482 - val_specificity: 0.9482 - val_balacc: 0.9482\n",
      "Epoch 138/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0969 - tp: 22250.0000 - fp: 850.0000 - tn: 22250.0000 - fn: 850.0000 - accuracy: 0.9632 train_balacc 0.9631119769608674\n",
      " val_balacc 0.9579803456455439\n",
      "\n",
      "Epoch 138: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0970 - tp: 22741.0000 - fp: 871.0000 - tn: 22741.0000 - fn: 871.0000 - accuracy: 0.9631 - val_loss: 0.1043 - val_tp: 5654.0000 - val_fp: 248.0000 - val_tn: 5654.0000 - val_fn: 248.0000 - val_accuracy: 0.9580 - train_sensitivity: 0.9631 - train_specificity: 0.9631 - train_balacc: 0.9631 - val_sensitivity: 0.9580 - val_specificity: 0.9580 - val_balacc: 0.9580\n",
      "Epoch 139/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0952 - tp: 22246.0000 - fp: 854.0000 - tn: 22246.0000 - fn: 854.0000 - accuracy: 0.9630 train_balacc 0.9626884634931391\n",
      " val_balacc 0.9345984412063707\n",
      "\n",
      "Epoch 139: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0953 - tp: 22731.0000 - fp: 881.0000 - tn: 22731.0000 - fn: 881.0000 - accuracy: 0.9627 - val_loss: 0.1650 - val_tp: 5516.0000 - val_fp: 386.0000 - val_tn: 5516.0000 - val_fn: 386.0000 - val_accuracy: 0.9346 - train_sensitivity: 0.9627 - train_specificity: 0.9627 - train_balacc: 0.9627 - val_sensitivity: 0.9346 - val_specificity: 0.9346 - val_balacc: 0.9346\n",
      "Epoch 140/232\n",
      "234/237 [============================>.] - ETA: 0s - loss: 0.0968 - tp: 22534.0000 - fp: 866.0000 - tn: 22534.0000 - fn: 866.0000 - accuracy: 0.9630 train_balacc 0.9629849229205488\n",
      " val_balacc 0.9637411047102677\n",
      "\n",
      "Epoch 140: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0969 - tp: 22738.0000 - fp: 874.0000 - tn: 22738.0000 - fn: 874.0000 - accuracy: 0.9630 - val_loss: 0.0967 - val_tp: 5688.0000 - val_fp: 214.0000 - val_tn: 5688.0000 - val_fn: 214.0000 - val_accuracy: 0.9637 - train_sensitivity: 0.9630 - train_specificity: 0.9630 - train_balacc: 0.9630 - val_sensitivity: 0.9637 - val_specificity: 0.9637 - val_balacc: 0.9637\n",
      "Epoch 141/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0990 - tp: 22226.0000 - fp: 874.0000 - tn: 22226.0000 - fn: 874.0000 - accuracy: 0.9622 train_balacc 0.9623496527189564\n",
      " val_balacc 0.957810911555405\n",
      "\n",
      "Epoch 141: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0986 - tp: 22723.0000 - fp: 889.0000 - tn: 22723.0000 - fn: 889.0000 - accuracy: 0.9623 - val_loss: 0.1212 - val_tp: 5653.0000 - val_fp: 249.0000 - val_tn: 5653.0000 - val_fn: 249.0000 - val_accuracy: 0.9578 - train_sensitivity: 0.9623 - train_specificity: 0.9623 - train_balacc: 0.9623 - val_sensitivity: 0.9578 - val_specificity: 0.9578 - val_balacc: 0.9578\n",
      "Epoch 142/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.0982 - tp: 22620.0000 - fp: 880.0000 - tn: 22620.0000 - fn: 880.0000 - accuracy: 0.9626 train_balacc 0.9625614094528206\n",
      " val_balacc 0.9657743137919349\n",
      "\n",
      "Epoch 142: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0981 - tp: 22728.0000 - fp: 884.0000 - tn: 22728.0000 - fn: 884.0000 - accuracy: 0.9626 - val_loss: 0.0940 - val_tp: 5700.0000 - val_fp: 202.0000 - val_tn: 5700.0000 - val_fn: 202.0000 - val_accuracy: 0.9658 - train_sensitivity: 0.9626 - train_specificity: 0.9626 - train_balacc: 0.9626 - val_sensitivity: 0.9658 - val_specificity: 0.9658 - val_balacc: 0.9658\n",
      "Epoch 143/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.0963 - tp: 22640.0000 - fp: 860.0000 - tn: 22640.0000 - fn: 860.0000 - accuracy: 0.9634 train_balacc 0.9633237336947315\n",
      " val_balacc 0.9012199254490003\n",
      "\n",
      "Epoch 143: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0963 - tp: 22746.0000 - fp: 866.0000 - tn: 22746.0000 - fn: 866.0000 - accuracy: 0.9633 - val_loss: 0.2316 - val_tp: 5319.0000 - val_fp: 583.0000 - val_tn: 5319.0000 - val_fn: 583.0000 - val_accuracy: 0.9012 - train_sensitivity: 0.9633 - train_specificity: 0.9633 - train_balacc: 0.9633 - val_sensitivity: 0.9012 - val_specificity: 0.9012 - val_balacc: 0.9012\n",
      "Epoch 144/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.0916 - tp: 22496.0000 - fp: 804.0000 - tn: 22496.0000 - fn: 804.0000 - accuracy: 0.9655 train_balacc 0.9653565983398272\n",
      " val_balacc 0.9410369366316503\n",
      "\n",
      "Epoch 144: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0917 - tp: 22794.0000 - fp: 818.0000 - tn: 22794.0000 - fn: 818.0000 - accuracy: 0.9654 - val_loss: 0.1513 - val_tp: 5554.0000 - val_fp: 348.0000 - val_tn: 5554.0000 - val_fn: 348.0000 - val_accuracy: 0.9410 - train_sensitivity: 0.9654 - train_specificity: 0.9654 - train_balacc: 0.9654 - val_sensitivity: 0.9410 - val_specificity: 0.9410 - val_balacc: 0.9410\n",
      "Epoch 145/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.0994 - tp: 22450.0000 - fp: 850.0000 - tn: 22450.0000 - fn: 850.0000 - accuracy: 0.9635 train_balacc 0.9636201931221413\n",
      " val_balacc 0.9493392070484582\n",
      "\n",
      "Epoch 145: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0993 - tp: 22753.0000 - fp: 859.0000 - tn: 22753.0000 - fn: 859.0000 - accuracy: 0.9636 - val_loss: 0.1392 - val_tp: 5603.0000 - val_fp: 299.0000 - val_tn: 5603.0000 - val_fn: 299.0000 - val_accuracy: 0.9493 - train_sensitivity: 0.9636 - train_specificity: 0.9636 - train_balacc: 0.9636 - val_sensitivity: 0.9493 - val_specificity: 0.9493 - val_balacc: 0.9493\n",
      "Epoch 146/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0953 - tp: 22160.0000 - fp: 840.0000 - tn: 22160.0000 - fn: 840.0000 - accuracy: 0.9635 train_balacc 0.9635354904285957\n",
      " val_balacc 0.9544222297526262\n",
      "\n",
      "Epoch 146: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0954 - tp: 22751.0000 - fp: 861.0000 - tn: 22751.0000 - fn: 861.0000 - accuracy: 0.9635 - val_loss: 0.1200 - val_tp: 5633.0000 - val_fp: 269.0000 - val_tn: 5633.0000 - val_fn: 269.0000 - val_accuracy: 0.9544 - train_sensitivity: 0.9635 - train_specificity: 0.9635 - train_balacc: 0.9635 - val_sensitivity: 0.9544 - val_specificity: 0.9544 - val_balacc: 0.9544\n",
      "Epoch 147/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.0975 - tp: 21963.0000 - fp: 837.0000 - tn: 21963.0000 - fn: 837.0000 - accuracy: 0.9633 train_balacc 0.9631543283076401\n",
      " val_balacc 0.9244323957980346\n",
      "\n",
      "Epoch 147: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0979 - tp: 22742.0000 - fp: 870.0000 - tn: 22742.0000 - fn: 870.0000 - accuracy: 0.9632 - val_loss: 0.1703 - val_tp: 5456.0000 - val_fp: 446.0000 - val_tn: 5456.0000 - val_fn: 446.0000 - val_accuracy: 0.9244 - train_sensitivity: 0.9632 - train_specificity: 0.9632 - train_balacc: 0.9632 - val_sensitivity: 0.9244 - val_specificity: 0.9244 - val_balacc: 0.9244\n",
      "Epoch 148/232\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0937 - tp: 22787.0000 - fp: 813.0000 - tn: 22787.0000 - fn: 813.0000 - accuracy: 0.9656 train_balacc 0.9655683550736913\n",
      " val_balacc 0.9246018298881735\n",
      "\n",
      "Epoch 148: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0937 - tp: 22799.0000 - fp: 813.0000 - tn: 22799.0000 - fn: 813.0000 - accuracy: 0.9656 - val_loss: 0.1883 - val_tp: 5457.0000 - val_fp: 445.0000 - val_tn: 5457.0000 - val_fn: 445.0000 - val_accuracy: 0.9246 - train_sensitivity: 0.9656 - train_specificity: 0.9656 - train_balacc: 0.9656 - val_sensitivity: 0.9246 - val_specificity: 0.9246 - val_balacc: 0.9246\n",
      "Epoch 149/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1000 - tp: 22201.0000 - fp: 899.0000 - tn: 22201.0000 - fn: 899.0000 - accuracy: 0.9611 train_balacc 0.9612908690496358\n",
      " val_balacc 0.9368010843781769\n",
      "\n",
      "Epoch 149: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.1003 - tp: 22698.0000 - fp: 914.0000 - tn: 22698.0000 - fn: 914.0000 - accuracy: 0.9613 - val_loss: 0.1677 - val_tp: 5529.0000 - val_fp: 373.0000 - val_tn: 5529.0000 - val_fn: 373.0000 - val_accuracy: 0.9368 - train_sensitivity: 0.9613 - train_specificity: 0.9613 - train_balacc: 0.9613 - val_sensitivity: 0.9368 - val_specificity: 0.9368 - val_balacc: 0.9368\n",
      "Epoch 150/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0958 - tp: 22336.0000 - fp: 864.0000 - tn: 22336.0000 - fn: 864.0000 - accuracy: 0.9628 train_balacc 0.9628578688802304\n",
      " val_balacc 0.9711962046763809\n",
      "\n",
      "Epoch 150: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0958 - tp: 22735.0000 - fp: 877.0000 - tn: 22735.0000 - fn: 877.0000 - accuracy: 0.9629 - val_loss: 0.0796 - val_tp: 5732.0000 - val_fp: 170.0000 - val_tn: 5732.0000 - val_fn: 170.0000 - val_accuracy: 0.9712 - train_sensitivity: 0.9629 - train_specificity: 0.9629 - train_balacc: 0.9629 - val_sensitivity: 0.9712 - val_specificity: 0.9712 - val_balacc: 0.9712\n",
      "Epoch 151/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0966 - tp: 22351.0000 - fp: 849.0000 - tn: 22351.0000 - fn: 849.0000 - accuracy: 0.9634 train_balacc 0.9633237336947315\n",
      " val_balacc 0.8669942392409353\n",
      "\n",
      "Epoch 151: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0969 - tp: 22746.0000 - fp: 866.0000 - tn: 22746.0000 - fn: 866.0000 - accuracy: 0.9633 - val_loss: 0.3773 - val_tp: 5117.0000 - val_fp: 785.0000 - val_tn: 5117.0000 - val_fn: 785.0000 - val_accuracy: 0.8670 - train_sensitivity: 0.9633 - train_specificity: 0.9633 - train_balacc: 0.9633 - val_sensitivity: 0.8670 - val_specificity: 0.8670 - val_balacc: 0.8670\n",
      "Epoch 152/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.1000 - tp: 22305.0000 - fp: 895.0000 - tn: 22305.0000 - fn: 895.0000 - accuracy: 0.9614 train_balacc 0.9616720311705912\n",
      " val_balacc 0.9591663842765165\n",
      "\n",
      "Epoch 152: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 0.0998 - tp: 22707.0000 - fp: 905.0000 - tn: 22707.0000 - fn: 905.0000 - accuracy: 0.9617 - val_loss: 0.1083 - val_tp: 5661.0000 - val_fp: 241.0000 - val_tn: 5661.0000 - val_fn: 241.0000 - val_accuracy: 0.9592 - train_sensitivity: 0.9617 - train_specificity: 0.9617 - train_balacc: 0.9617 - val_sensitivity: 0.9592 - val_specificity: 0.9592 - val_balacc: 0.9592\n",
      "Epoch 153/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0957 - tp: 22170.0000 - fp: 830.0000 - tn: 22170.0000 - fn: 830.0000 - accuracy: 0.9639 train_balacc 0.9639590038963239\n",
      " val_balacc 0.9672992206031854\n",
      "\n",
      "Epoch 153: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0952 - tp: 22761.0000 - fp: 851.0000 - tn: 22761.0000 - fn: 851.0000 - accuracy: 0.9640 - val_loss: 0.0981 - val_tp: 5709.0000 - val_fp: 193.0000 - val_tn: 5709.0000 - val_fn: 193.0000 - val_accuracy: 0.9673 - train_sensitivity: 0.9640 - train_specificity: 0.9640 - train_balacc: 0.9640 - val_sensitivity: 0.9673 - val_specificity: 0.9673 - val_balacc: 0.9673\n",
      "Epoch 154/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.0988 - tp: 22410.0000 - fp: 890.0000 - tn: 22410.0000 - fn: 890.0000 - accuracy: 0.9618 train_balacc 0.9615449771302728\n",
      " val_balacc 0.9222297526262284\n",
      "\n",
      "Epoch 154: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0988 - tp: 22704.0000 - fp: 908.0000 - tn: 22704.0000 - fn: 908.0000 - accuracy: 0.9615 - val_loss: 0.1807 - val_tp: 5443.0000 - val_fp: 459.0000 - val_tn: 5443.0000 - val_fn: 459.0000 - val_accuracy: 0.9222 - train_sensitivity: 0.9615 - train_specificity: 0.9615 - train_balacc: 0.9615 - val_sensitivity: 0.9222 - val_specificity: 0.9222 - val_balacc: 0.9222\n",
      "Epoch 155/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0966 - tp: 22345.0000 - fp: 855.0000 - tn: 22345.0000 - fn: 855.0000 - accuracy: 0.9631 train_balacc 0.9631543283076401\n",
      " val_balacc 0.9369705184683158\n",
      "\n",
      "Epoch 155: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0964 - tp: 22742.0000 - fp: 870.0000 - tn: 22742.0000 - fn: 870.0000 - accuracy: 0.9632 - val_loss: 0.1593 - val_tp: 5530.0000 - val_fp: 372.0000 - val_tn: 5530.0000 - val_fn: 372.0000 - val_accuracy: 0.9370 - train_sensitivity: 0.9632 - train_specificity: 0.9632 - train_balacc: 0.9632 - val_sensitivity: 0.9370 - val_specificity: 0.9370 - val_balacc: 0.9370\n",
      "Epoch 156/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.0998 - tp: 22619.0000 - fp: 881.0000 - tn: 22619.0000 - fn: 881.0000 - accuracy: 0.9625 train_balacc 0.9625190581060478\n",
      " val_balacc 0.971026770586242\n",
      "\n",
      "Epoch 156: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0999 - tp: 22727.0000 - fp: 885.0000 - tn: 22727.0000 - fn: 885.0000 - accuracy: 0.9625 - val_loss: 0.0778 - val_tp: 5731.0000 - val_fp: 171.0000 - val_tn: 5731.0000 - val_fn: 171.0000 - val_accuracy: 0.9710 - train_sensitivity: 0.9625 - train_specificity: 0.9625 - train_balacc: 0.9625 - val_sensitivity: 0.9710 - val_specificity: 0.9710 - val_balacc: 0.9710\n",
      "Epoch 157/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.1020 - tp: 22117.0000 - fp: 883.0000 - tn: 22117.0000 - fn: 883.0000 - accuracy: 0.9616 train_balacc 0.9617143825173641\n",
      " val_balacc 0.9473059979667909\n",
      "\n",
      "Epoch 157: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1016 - tp: 22708.0000 - fp: 904.0000 - tn: 22708.0000 - fn: 904.0000 - accuracy: 0.9617 - val_loss: 0.1386 - val_tp: 5591.0000 - val_fp: 311.0000 - val_tn: 5591.0000 - val_fn: 311.0000 - val_accuracy: 0.9473 - train_sensitivity: 0.9617 - train_specificity: 0.9617 - train_balacc: 0.9617 - val_sensitivity: 0.9473 - val_specificity: 0.9473 - val_balacc: 0.9473\n",
      "Epoch 158/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0997 - tp: 22255.0000 - fp: 845.0000 - tn: 22255.0000 - fn: 845.0000 - accuracy: 0.9634 train_balacc 0.9633237336947315\n",
      " val_balacc 0.9083361572348356\n",
      "\n",
      "Epoch 158: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0998 - tp: 22746.0000 - fp: 866.0000 - tn: 22746.0000 - fn: 866.0000 - accuracy: 0.9633 - val_loss: 0.2267 - val_tp: 5361.0000 - val_fp: 541.0000 - val_tn: 5361.0000 - val_fn: 541.0000 - val_accuracy: 0.9083 - train_sensitivity: 0.9633 - train_specificity: 0.9633 - train_balacc: 0.9633 - val_sensitivity: 0.9083 - val_specificity: 0.9083 - val_balacc: 0.9083\n",
      "Epoch 159/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.0971 - tp: 21985.0000 - fp: 815.0000 - tn: 21985.0000 - fn: 815.0000 - accuracy: 0.9643 train_balacc 0.9643825173640522\n",
      " val_balacc 0.9308708912233141\n",
      "\n",
      "Epoch 159: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0968 - tp: 22771.0000 - fp: 841.0000 - tn: 22771.0000 - fn: 841.0000 - accuracy: 0.9644 - val_loss: 0.1721 - val_tp: 5494.0000 - val_fp: 408.0000 - val_tn: 5494.0000 - val_fn: 408.0000 - val_accuracy: 0.9309 - train_sensitivity: 0.9644 - train_specificity: 0.9644 - train_balacc: 0.9644 - val_sensitivity: 0.9309 - val_specificity: 0.9309 - val_balacc: 0.9309\n",
      "Epoch 160/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0935 - tp: 22088.0000 - fp: 812.0000 - tn: 22088.0000 - fn: 812.0000 - accuracy: 0.9645 train_balacc 0.9647213281382347\n",
      " val_balacc 0.9454422229752626\n",
      "\n",
      "Epoch 160: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0929 - tp: 22779.0000 - fp: 833.0000 - tn: 22779.0000 - fn: 833.0000 - accuracy: 0.9647 - val_loss: 0.1336 - val_tp: 5580.0000 - val_fp: 322.0000 - val_tn: 5580.0000 - val_fn: 322.0000 - val_accuracy: 0.9454 - train_sensitivity: 0.9647 - train_specificity: 0.9647 - train_balacc: 0.9647 - val_sensitivity: 0.9454 - val_specificity: 0.9454 - val_balacc: 0.9454\n",
      "Epoch 161/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0920 - tp: 22122.0000 - fp: 778.0000 - tn: 22122.0000 - fn: 778.0000 - accuracy: 0.9660 train_balacc 0.9657801118075555\n",
      " val_balacc 0.925957302609285\n",
      "\n",
      "Epoch 161: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0926 - tp: 22804.0000 - fp: 808.0000 - tn: 22804.0000 - fn: 808.0000 - accuracy: 0.9658 - val_loss: 0.1960 - val_tp: 5465.0000 - val_fp: 437.0000 - val_tn: 5465.0000 - val_fn: 437.0000 - val_accuracy: 0.9260 - train_sensitivity: 0.9658 - train_specificity: 0.9658 - train_balacc: 0.9658 - val_sensitivity: 0.9260 - val_specificity: 0.9260 - val_balacc: 0.9260\n",
      "Epoch 162/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.1020 - tp: 21968.0000 - fp: 832.0000 - tn: 21968.0000 - fn: 832.0000 - accuracy: 0.9635 train_balacc 0.9633660850415043\n",
      " val_balacc 0.9598441206370721\n",
      "\n",
      "Epoch 162: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1016 - tp: 22747.0000 - fp: 865.0000 - tn: 22747.0000 - fn: 865.0000 - accuracy: 0.9634 - val_loss: 0.1023 - val_tp: 5665.0000 - val_fp: 237.0000 - val_tn: 5665.0000 - val_fn: 237.0000 - val_accuracy: 0.9598 - train_sensitivity: 0.9634 - train_specificity: 0.9634 - train_balacc: 0.9634 - val_sensitivity: 0.9598 - val_specificity: 0.9598 - val_balacc: 0.9598\n",
      "Epoch 163/232\n",
      "227/237 [===========================>..] - ETA: 0s - loss: 0.0947 - tp: 21880.0000 - fp: 820.0000 - tn: 21880.0000 - fn: 820.0000 - accuracy: 0.9639 train_balacc 0.9637472471624597\n",
      " val_balacc 0.9554388342934599\n",
      "\n",
      "Epoch 163: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0958 - tp: 22756.0000 - fp: 856.0000 - tn: 22756.0000 - fn: 856.0000 - accuracy: 0.9637 - val_loss: 0.1052 - val_tp: 5639.0000 - val_fp: 263.0000 - val_tn: 5639.0000 - val_fn: 263.0000 - val_accuracy: 0.9554 - train_sensitivity: 0.9637 - train_specificity: 0.9637 - train_balacc: 0.9637 - val_sensitivity: 0.9554 - val_specificity: 0.9554 - val_balacc: 0.9554\n",
      "Epoch 164/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0941 - tp: 22262.0000 - fp: 838.0000 - tn: 22262.0000 - fn: 838.0000 - accuracy: 0.9637 train_balacc 0.9631543283076401\n",
      " val_balacc 0.9525584547610979\n",
      "\n",
      "Epoch 164: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0951 - tp: 22742.0000 - fp: 870.0000 - tn: 22742.0000 - fn: 870.0000 - accuracy: 0.9632 - val_loss: 0.1233 - val_tp: 5622.0000 - val_fp: 280.0000 - val_tn: 5622.0000 - val_fn: 280.0000 - val_accuracy: 0.9526 - train_sensitivity: 0.9632 - train_specificity: 0.9632 - train_balacc: 0.9632 - val_sensitivity: 0.9526 - val_specificity: 0.9526 - val_balacc: 0.9526\n",
      "Epoch 165/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.0949 - tp: 22678.0000 - fp: 822.0000 - tn: 22678.0000 - fn: 822.0000 - accuracy: 0.9650 train_balacc 0.9651024902591903\n",
      " val_balacc 0.9203659776347001\n",
      "\n",
      "Epoch 165: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0948 - tp: 22788.0000 - fp: 824.0000 - tn: 22788.0000 - fn: 824.0000 - accuracy: 0.9651 - val_loss: 0.2259 - val_tp: 5432.0000 - val_fp: 470.0000 - val_tn: 5432.0000 - val_fn: 470.0000 - val_accuracy: 0.9204 - train_sensitivity: 0.9651 - train_specificity: 0.9651 - train_balacc: 0.9651 - val_sensitivity: 0.9204 - val_specificity: 0.9204 - val_balacc: 0.9204\n",
      "Epoch 166/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.0989 - tp: 21986.0000 - fp: 814.0000 - tn: 21986.0000 - fn: 814.0000 - accuracy: 0.9643 train_balacc 0.9641284092834153\n",
      " val_balacc 0.9639105388004067\n",
      "\n",
      "Epoch 166: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0992 - tp: 22765.0000 - fp: 847.0000 - tn: 22765.0000 - fn: 847.0000 - accuracy: 0.9641 - val_loss: 0.0880 - val_tp: 5689.0000 - val_fp: 213.0000 - val_tn: 5689.0000 - val_fn: 213.0000 - val_accuracy: 0.9639 - train_sensitivity: 0.9641 - train_specificity: 0.9641 - train_balacc: 0.9641 - val_sensitivity: 0.9639 - val_specificity: 0.9639 - val_balacc: 0.9639\n",
      "Epoch 167/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0939 - tp: 22180.0000 - fp: 820.0000 - tn: 22180.0000 - fn: 820.0000 - accuracy: 0.9643 train_balacc 0.9643401660172793\n",
      " val_balacc 0.8422568620806506\n",
      "\n",
      "Epoch 167: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0938 - tp: 22770.0000 - fp: 842.0000 - tn: 22770.0000 - fn: 842.0000 - accuracy: 0.9643 - val_loss: 0.4082 - val_tp: 4971.0000 - val_fp: 931.0000 - val_tn: 4971.0000 - val_fn: 931.0000 - val_accuracy: 0.8423 - train_sensitivity: 0.9643 - train_specificity: 0.9643 - train_balacc: 0.9643 - val_sensitivity: 0.8423 - val_specificity: 0.8423 - val_balacc: 0.8423\n",
      "Epoch 168/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0922 - tp: 22199.0000 - fp: 801.0000 - tn: 22199.0000 - fn: 801.0000 - accuracy: 0.9652 train_balacc 0.9649754362188717\n",
      " val_balacc 0.9151135208403931\n",
      "\n",
      "Epoch 168: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0929 - tp: 22785.0000 - fp: 827.0000 - tn: 22785.0000 - fn: 827.0000 - accuracy: 0.9650 - val_loss: 0.1957 - val_tp: 5401.0000 - val_fp: 501.0000 - val_tn: 5401.0000 - val_fn: 501.0000 - val_accuracy: 0.9151 - train_sensitivity: 0.9650 - train_specificity: 0.9650 - train_balacc: 0.9650 - val_sensitivity: 0.9151 - val_specificity: 0.9151 - val_balacc: 0.9151\n",
      "Epoch 169/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0884 - tp: 22216.0000 - fp: 784.0000 - tn: 22216.0000 - fn: 784.0000 - accuracy: 0.9659 train_balacc 0.9657377604607826\n",
      " val_balacc 0.9505252456794308\n",
      "\n",
      "Epoch 169: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0891 - tp: 22803.0000 - fp: 809.0000 - tn: 22803.0000 - fn: 809.0000 - accuracy: 0.9657 - val_loss: 0.1234 - val_tp: 5610.0000 - val_fp: 292.0000 - val_tn: 5610.0000 - val_fn: 292.0000 - val_accuracy: 0.9505 - train_sensitivity: 0.9657 - train_specificity: 0.9657 - train_balacc: 0.9657 - val_sensitivity: 0.9505 - val_specificity: 0.9505 - val_balacc: 0.9505\n",
      "Epoch 170/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0996 - tp: 22069.0000 - fp: 831.0000 - tn: 22069.0000 - fn: 831.0000 - accuracy: 0.9637 train_balacc 0.9632813823479587\n",
      " val_balacc 0.9718739410369366\n",
      "\n",
      "Epoch 170: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1002 - tp: 22745.0000 - fp: 867.0000 - tn: 22745.0000 - fn: 867.0000 - accuracy: 0.9633 - val_loss: 0.0866 - val_tp: 5736.0000 - val_fp: 166.0000 - val_tn: 5736.0000 - val_fn: 166.0000 - val_accuracy: 0.9719 - train_sensitivity: 0.9633 - train_specificity: 0.9633 - train_balacc: 0.9633 - val_sensitivity: 0.9719 - val_specificity: 0.9719 - val_balacc: 0.9719\n",
      "Epoch 171/232\n",
      "233/237 [============================>.] - ETA: 0s - loss: 0.0918 - tp: 22481.0000 - fp: 819.0000 - tn: 22481.0000 - fn: 819.0000 - accuracy: 0.9648 train_balacc 0.9647213281382347\n",
      " val_balacc 0.9720433751270756\n",
      "\n",
      "Epoch 171: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0918 - tp: 22779.0000 - fp: 833.0000 - tn: 22779.0000 - fn: 833.0000 - accuracy: 0.9647 - val_loss: 0.0805 - val_tp: 5737.0000 - val_fp: 165.0000 - val_tn: 5737.0000 - val_fn: 165.0000 - val_accuracy: 0.9720 - train_sensitivity: 0.9647 - train_specificity: 0.9647 - train_balacc: 0.9647 - val_sensitivity: 0.9720 - val_specificity: 0.9720 - val_balacc: 0.9720\n",
      "Epoch 172/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0942 - tp: 22373.0000 - fp: 827.0000 - tn: 22373.0000 - fn: 827.0000 - accuracy: 0.9644 train_balacc 0.9643401660172793\n",
      " val_balacc 0.9613690274483226\n",
      "\n",
      "Epoch 172: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0940 - tp: 22770.0000 - fp: 842.0000 - tn: 22770.0000 - fn: 842.0000 - accuracy: 0.9643 - val_loss: 0.1116 - val_tp: 5674.0000 - val_fp: 228.0000 - val_tn: 5674.0000 - val_fn: 228.0000 - val_accuracy: 0.9614 - train_sensitivity: 0.9643 - train_specificity: 0.9643 - train_balacc: 0.9643 - val_sensitivity: 0.9614 - val_specificity: 0.9614 - val_balacc: 0.9614\n",
      "Epoch 173/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.0926 - tp: 22004.0000 - fp: 796.0000 - tn: 22004.0000 - fn: 796.0000 - accuracy: 0.9651 train_balacc 0.9648907335253261\n",
      " val_balacc 0.9473059979667909\n",
      "\n",
      "Epoch 173: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0928 - tp: 22783.0000 - fp: 829.0000 - tn: 22783.0000 - fn: 829.0000 - accuracy: 0.9649 - val_loss: 0.1266 - val_tp: 5591.0000 - val_fp: 311.0000 - val_tn: 5591.0000 - val_fn: 311.0000 - val_accuracy: 0.9473 - train_sensitivity: 0.9649 - train_specificity: 0.9649 - train_balacc: 0.9649 - val_sensitivity: 0.9473 - val_specificity: 0.9473 - val_balacc: 0.9473\n",
      "Epoch 174/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.1006 - tp: 22256.0000 - fp: 844.0000 - tn: 22256.0000 - fn: 844.0000 - accuracy: 0.9635 train_balacc 0.9634931390818228\n",
      " val_balacc 0.963063368349712\n",
      "\n",
      "Epoch 174: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.1005 - tp: 22750.0000 - fp: 862.0000 - tn: 22750.0000 - fn: 862.0000 - accuracy: 0.9635 - val_loss: 0.0951 - val_tp: 5684.0000 - val_fp: 218.0000 - val_tn: 5684.0000 - val_fn: 218.0000 - val_accuracy: 0.9631 - train_sensitivity: 0.9635 - train_specificity: 0.9635 - train_balacc: 0.9635 - val_sensitivity: 0.9631 - val_specificity: 0.9631 - val_balacc: 0.9631\n",
      "Epoch 175/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0945 - tp: 22180.0000 - fp: 820.0000 - tn: 22180.0000 - fn: 820.0000 - accuracy: 0.9643 train_balacc 0.9640437065898696\n",
      " val_balacc 0.849203659776347\n",
      "\n",
      "Epoch 175: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0954 - tp: 22763.0000 - fp: 849.0000 - tn: 22763.0000 - fn: 849.0000 - accuracy: 0.9640 - val_loss: 0.3894 - val_tp: 5012.0000 - val_fp: 890.0000 - val_tn: 5012.0000 - val_fn: 890.0000 - val_accuracy: 0.8492 - train_sensitivity: 0.9640 - train_specificity: 0.9640 - train_balacc: 0.9640 - val_sensitivity: 0.8492 - val_specificity: 0.8492 - val_balacc: 0.8492\n",
      "Epoch 176/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0966 - tp: 22258.0000 - fp: 842.0000 - tn: 22258.0000 - fn: 842.0000 - accuracy: 0.9635 train_balacc 0.9636625444689141\n",
      " val_balacc 0.9664520501524907\n",
      "\n",
      "Epoch 176: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0966 - tp: 22754.0000 - fp: 858.0000 - tn: 22754.0000 - fn: 858.0000 - accuracy: 0.9637 - val_loss: 0.0896 - val_tp: 5704.0000 - val_fp: 198.0000 - val_tn: 5704.0000 - val_fn: 198.0000 - val_accuracy: 0.9665 - train_sensitivity: 0.9637 - train_specificity: 0.9637 - train_balacc: 0.9637 - val_sensitivity: 0.9665 - val_specificity: 0.9665 - val_balacc: 0.9665\n",
      "Epoch 177/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0967 - tp: 22224.0000 - fp: 776.0000 - tn: 22224.0000 - fn: 776.0000 - accuracy: 0.9663 train_balacc 0.9661612739285109\n",
      " val_balacc 0.955269400203321\n",
      "\n",
      "Epoch 177: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0971 - tp: 22813.0000 - fp: 799.0000 - tn: 22813.0000 - fn: 799.0000 - accuracy: 0.9662 - val_loss: 0.1129 - val_tp: 5638.0000 - val_fp: 264.0000 - val_tn: 5638.0000 - val_fn: 264.0000 - val_accuracy: 0.9553 - train_sensitivity: 0.9662 - train_specificity: 0.9662 - train_balacc: 0.9662 - val_sensitivity: 0.9553 - val_specificity: 0.9553 - val_balacc: 0.9553\n",
      "Epoch 178/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0937 - tp: 22199.0000 - fp: 801.0000 - tn: 22199.0000 - fn: 801.0000 - accuracy: 0.9652 train_balacc 0.9653989496866\n",
      " val_balacc 0.9491697729583192\n",
      "\n",
      "Epoch 178: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0939 - tp: 22795.0000 - fp: 817.0000 - tn: 22795.0000 - fn: 817.0000 - accuracy: 0.9654 - val_loss: 0.1315 - val_tp: 5602.0000 - val_fp: 300.0000 - val_tn: 5602.0000 - val_fn: 300.0000 - val_accuracy: 0.9492 - train_sensitivity: 0.9654 - train_specificity: 0.9654 - train_balacc: 0.9654 - val_sensitivity: 0.9492 - val_specificity: 0.9492 - val_balacc: 0.9492\n",
      "Epoch 179/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0911 - tp: 22195.0000 - fp: 805.0000 - tn: 22195.0000 - fn: 805.0000 - accuracy: 0.9650 train_balacc 0.965144841605963\n",
      " val_balacc 0.9593358183666554\n",
      "\n",
      "Epoch 179: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0918 - tp: 22789.0000 - fp: 823.0000 - tn: 22789.0000 - fn: 823.0000 - accuracy: 0.9651 - val_loss: 0.1083 - val_tp: 5662.0000 - val_fp: 240.0000 - val_tn: 5662.0000 - val_fn: 240.0000 - val_accuracy: 0.9593 - train_sensitivity: 0.9651 - train_specificity: 0.9651 - train_balacc: 0.9651 - val_sensitivity: 0.9593 - val_specificity: 0.9593 - val_balacc: 0.9593\n",
      "Epoch 180/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0934 - tp: 22373.0000 - fp: 827.0000 - tn: 22373.0000 - fn: 827.0000 - accuracy: 0.9644 train_balacc 0.964424868710825\n",
      " val_balacc 0.9733988478481871\n",
      "\n",
      "Epoch 180: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0930 - tp: 22772.0000 - fp: 840.0000 - tn: 22772.0000 - fn: 840.0000 - accuracy: 0.9644 - val_loss: 0.0741 - val_tp: 5745.0000 - val_fp: 157.0000 - val_tn: 5745.0000 - val_fn: 157.0000 - val_accuracy: 0.9734 - train_sensitivity: 0.9644 - train_specificity: 0.9644 - train_balacc: 0.9644 - val_sensitivity: 0.9734 - val_specificity: 0.9734 - val_balacc: 0.9734\n",
      "Epoch 181/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0919 - tp: 22200.0000 - fp: 800.0000 - tn: 22200.0000 - fn: 800.0000 - accuracy: 0.9652 train_balacc 0.9651871929527359\n",
      " val_balacc 0.9776347001016604\n",
      "\n",
      "Epoch 181: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0918 - tp: 22790.0000 - fp: 822.0000 - tn: 22790.0000 - fn: 822.0000 - accuracy: 0.9652 - val_loss: 0.0690 - val_tp: 5770.0000 - val_fp: 132.0000 - val_tn: 5770.0000 - val_fn: 132.0000 - val_accuracy: 0.9776 - train_sensitivity: 0.9652 - train_specificity: 0.9652 - train_balacc: 0.9652 - val_sensitivity: 0.9776 - val_specificity: 0.9776 - val_balacc: 0.9776\n",
      "Epoch 182/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0989 - tp: 22193.0000 - fp: 807.0000 - tn: 22193.0000 - fn: 807.0000 - accuracy: 0.9649 train_balacc 0.9647213281382347\n",
      " val_balacc 0.9711962046763809\n",
      "\n",
      "Epoch 182: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0986 - tp: 22779.0000 - fp: 833.0000 - tn: 22779.0000 - fn: 833.0000 - accuracy: 0.9647 - val_loss: 0.0809 - val_tp: 5732.0000 - val_fp: 170.0000 - val_tn: 5732.0000 - val_fn: 170.0000 - val_accuracy: 0.9712 - train_sensitivity: 0.9647 - train_specificity: 0.9647 - train_balacc: 0.9647 - val_sensitivity: 0.9712 - val_specificity: 0.9712 - val_balacc: 0.9712\n",
      "Epoch 183/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0940 - tp: 22324.0000 - fp: 776.0000 - tn: 22324.0000 - fn: 776.0000 - accuracy: 0.9664 train_balacc 0.9665847873962392\n",
      " val_balacc 0.9456116570654015\n",
      "\n",
      "Epoch 183: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0937 - tp: 22823.0000 - fp: 789.0000 - tn: 22823.0000 - fn: 789.0000 - accuracy: 0.9666 - val_loss: 0.1455 - val_tp: 5581.0000 - val_fp: 321.0000 - val_tn: 5581.0000 - val_fn: 321.0000 - val_accuracy: 0.9456 - train_sensitivity: 0.9666 - train_specificity: 0.9666 - train_balacc: 0.9666 - val_sensitivity: 0.9456 - val_specificity: 0.9456 - val_balacc: 0.9456\n",
      "Epoch 184/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0917 - tp: 22109.0000 - fp: 791.0000 - tn: 22109.0000 - fn: 791.0000 - accuracy: 0.9655 train_balacc 0.9652718956462816\n",
      " val_balacc 0.9317180616740088\n",
      "\n",
      "Epoch 184: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0931 - tp: 22792.0000 - fp: 820.0000 - tn: 22792.0000 - fn: 820.0000 - accuracy: 0.9653 - val_loss: 0.1633 - val_tp: 5499.0000 - val_fp: 403.0000 - val_tn: 5499.0000 - val_fn: 403.0000 - val_accuracy: 0.9317 - train_sensitivity: 0.9653 - train_specificity: 0.9653 - train_balacc: 0.9653 - val_sensitivity: 0.9317 - val_specificity: 0.9317 - val_balacc: 0.9317\n",
      "Epoch 185/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0971 - tp: 22155.0000 - fp: 845.0000 - tn: 22155.0000 - fn: 845.0000 - accuracy: 0.9633 train_balacc 0.9631119769608674\n",
      " val_balacc 0.8646221619789902\n",
      "\n",
      "Epoch 185: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0971 - tp: 22741.0000 - fp: 871.0000 - tn: 22741.0000 - fn: 871.0000 - accuracy: 0.9631 - val_loss: 0.3203 - val_tp: 5103.0000 - val_fp: 799.0000 - val_tn: 5103.0000 - val_fn: 799.0000 - val_accuracy: 0.8646 - train_sensitivity: 0.9631 - train_specificity: 0.9631 - train_balacc: 0.9631 - val_sensitivity: 0.8646 - val_specificity: 0.8646 - val_balacc: 0.8646\n",
      "Epoch 186/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0932 - tp: 22172.0000 - fp: 828.0000 - tn: 22172.0000 - fn: 828.0000 - accuracy: 0.9640 train_balacc 0.9637472471624597\n",
      " val_balacc 0.920535411724839\n",
      "\n",
      "Epoch 186: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0940 - tp: 22756.0000 - fp: 856.0000 - tn: 22756.0000 - fn: 856.0000 - accuracy: 0.9637 - val_loss: 0.2334 - val_tp: 5433.0000 - val_fp: 469.0000 - val_tn: 5433.0000 - val_fn: 469.0000 - val_accuracy: 0.9205 - train_sensitivity: 0.9637 - train_specificity: 0.9637 - train_balacc: 0.9637 - val_sensitivity: 0.9205 - val_specificity: 0.9205 - val_balacc: 0.9205\n",
      "Epoch 187/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0948 - tp: 22087.0000 - fp: 813.0000 - tn: 22087.0000 - fn: 813.0000 - accuracy: 0.9645 train_balacc 0.964678976791462\n",
      " val_balacc 0.9657743137919349\n",
      "\n",
      "Epoch 187: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0939 - tp: 22778.0000 - fp: 834.0000 - tn: 22778.0000 - fn: 834.0000 - accuracy: 0.9647 - val_loss: 0.0850 - val_tp: 5700.0000 - val_fp: 202.0000 - val_tn: 5700.0000 - val_fn: 202.0000 - val_accuracy: 0.9658 - train_sensitivity: 0.9647 - train_specificity: 0.9647 - train_balacc: 0.9647 - val_sensitivity: 0.9658 - val_specificity: 0.9658 - val_balacc: 0.9658\n",
      "Epoch 188/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0930 - tp: 22381.0000 - fp: 819.0000 - tn: 22381.0000 - fn: 819.0000 - accuracy: 0.9647 train_balacc 0.9647213281382347\n",
      " val_balacc 0.8746187732971874\n",
      "\n",
      "Epoch 188: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0932 - tp: 22779.0000 - fp: 833.0000 - tn: 22779.0000 - fn: 833.0000 - accuracy: 0.9647 - val_loss: 0.3121 - val_tp: 5162.0000 - val_fp: 740.0000 - val_tn: 5162.0000 - val_fn: 740.0000 - val_accuracy: 0.8746 - train_sensitivity: 0.9647 - train_specificity: 0.9647 - train_balacc: 0.9647 - val_sensitivity: 0.8746 - val_specificity: 0.8746 - val_balacc: 0.8746\n",
      "Epoch 189/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.0955 - tp: 22001.0000 - fp: 799.0000 - tn: 22001.0000 - fn: 799.0000 - accuracy: 0.9650 train_balacc 0.964933084872099\n",
      " val_balacc 0.9390037275499831\n",
      "\n",
      "Epoch 189: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0957 - tp: 22784.0000 - fp: 828.0000 - tn: 22784.0000 - fn: 828.0000 - accuracy: 0.9649 - val_loss: 0.1450 - val_tp: 5542.0000 - val_fp: 360.0000 - val_tn: 5542.0000 - val_fn: 360.0000 - val_accuracy: 0.9390 - train_sensitivity: 0.9649 - train_specificity: 0.9649 - train_balacc: 0.9649 - val_sensitivity: 0.9390 - val_specificity: 0.9390 - val_balacc: 0.9390\n",
      "Epoch 190/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0936 - tp: 22277.0000 - fp: 823.0000 - tn: 22277.0000 - fn: 823.0000 - accuracy: 0.9644 train_balacc 0.9645942740979163\n",
      " val_balacc 0.9012199254490003\n",
      "\n",
      "Epoch 190: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0932 - tp: 22776.0000 - fp: 836.0000 - tn: 22776.0000 - fn: 836.0000 - accuracy: 0.9646 - val_loss: 0.2769 - val_tp: 5319.0000 - val_fp: 583.0000 - val_tn: 5319.0000 - val_fn: 583.0000 - val_accuracy: 0.9012 - train_sensitivity: 0.9646 - train_specificity: 0.9646 - train_balacc: 0.9646 - val_sensitivity: 0.9012 - val_specificity: 0.9012 - val_balacc: 0.9012\n",
      "Epoch 191/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0960 - tp: 22158.0000 - fp: 842.0000 - tn: 22158.0000 - fn: 842.0000 - accuracy: 0.9634 train_balacc 0.9636625444689141\n",
      " val_balacc 0.9678075228736022\n",
      "\n",
      "Epoch 191: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0955 - tp: 22754.0000 - fp: 858.0000 - tn: 22754.0000 - fn: 858.0000 - accuracy: 0.9637 - val_loss: 0.0816 - val_tp: 5712.0000 - val_fp: 190.0000 - val_tn: 5712.0000 - val_fn: 190.0000 - val_accuracy: 0.9678 - train_sensitivity: 0.9637 - train_specificity: 0.9637 - train_balacc: 0.9637 - val_sensitivity: 0.9678 - val_specificity: 0.9678 - val_balacc: 0.9678\n",
      "Epoch 192/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.0957 - tp: 21960.0000 - fp: 840.0000 - tn: 21960.0000 - fn: 840.0000 - accuracy: 0.9632 train_balacc 0.9635354904285957\n",
      " val_balacc 0.9672992206031854\n",
      "\n",
      "Epoch 192: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0953 - tp: 22751.0000 - fp: 861.0000 - tn: 22751.0000 - fn: 861.0000 - accuracy: 0.9635 - val_loss: 0.0874 - val_tp: 5709.0000 - val_fp: 193.0000 - val_tn: 5709.0000 - val_fn: 193.0000 - val_accuracy: 0.9673 - train_sensitivity: 0.9635 - train_specificity: 0.9635 - train_balacc: 0.9635 - val_sensitivity: 0.9673 - val_specificity: 0.9673 - val_balacc: 0.9673\n",
      "Epoch 193/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0939 - tp: 22098.0000 - fp: 802.0000 - tn: 22098.0000 - fn: 802.0000 - accuracy: 0.9650 train_balacc 0.9646366254446891\n",
      " val_balacc 0.9774652660115215\n",
      "\n",
      "Epoch 193: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0947 - tp: 22777.0000 - fp: 835.0000 - tn: 22777.0000 - fn: 835.0000 - accuracy: 0.9646 - val_loss: 0.0792 - val_tp: 5769.0000 - val_fp: 133.0000 - val_tn: 5769.0000 - val_fn: 133.0000 - val_accuracy: 0.9775 - train_sensitivity: 0.9646 - train_specificity: 0.9646 - train_balacc: 0.9646 - val_sensitivity: 0.9775 - val_specificity: 0.9775 - val_balacc: 0.9775\n",
      "Epoch 194/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0981 - tp: 22180.0000 - fp: 820.0000 - tn: 22180.0000 - fn: 820.0000 - accuracy: 0.9643 train_balacc 0.9644672200575979\n",
      " val_balacc 0.9510335479498475\n",
      "\n",
      "Epoch 194: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0977 - tp: 22773.0000 - fp: 839.0000 - tn: 22773.0000 - fn: 839.0000 - accuracy: 0.9645 - val_loss: 0.1155 - val_tp: 5613.0000 - val_fp: 289.0000 - val_tn: 5613.0000 - val_fn: 289.0000 - val_accuracy: 0.9510 - train_sensitivity: 0.9645 - train_specificity: 0.9645 - train_balacc: 0.9645 - val_sensitivity: 0.9510 - val_specificity: 0.9510 - val_balacc: 0.9510\n",
      "Epoch 195/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0918 - tp: 22114.0000 - fp: 786.0000 - tn: 22114.0000 - fn: 786.0000 - accuracy: 0.9657 train_balacc 0.9661189225817381\n",
      " val_balacc 0.9591663842765165\n",
      "\n",
      "Epoch 195: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0906 - tp: 22812.0000 - fp: 800.0000 - tn: 22812.0000 - fn: 800.0000 - accuracy: 0.9661 - val_loss: 0.1059 - val_tp: 5661.0000 - val_fp: 241.0000 - val_tn: 5661.0000 - val_fn: 241.0000 - val_accuracy: 0.9592 - train_sensitivity: 0.9661 - train_specificity: 0.9661 - train_balacc: 0.9661 - val_sensitivity: 0.9592 - val_specificity: 0.9592 - val_balacc: 0.9592\n",
      "Epoch 196/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0942 - tp: 22257.0000 - fp: 843.0000 - tn: 22257.0000 - fn: 843.0000 - accuracy: 0.9635 train_balacc 0.9635778417753684\n",
      " val_balacc 0.9686546933242969\n",
      "\n",
      "Epoch 196: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0940 - tp: 22752.0000 - fp: 860.0000 - tn: 22752.0000 - fn: 860.0000 - accuracy: 0.9636 - val_loss: 0.0894 - val_tp: 5717.0000 - val_fp: 185.0000 - val_tn: 5717.0000 - val_fn: 185.0000 - val_accuracy: 0.9687 - train_sensitivity: 0.9636 - train_specificity: 0.9636 - train_balacc: 0.9636 - val_sensitivity: 0.9687 - val_specificity: 0.9687 - val_balacc: 0.9687\n",
      "Epoch 197/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0947 - tp: 22377.0000 - fp: 823.0000 - tn: 22377.0000 - fn: 823.0000 - accuracy: 0.9645 train_balacc 0.9642978146705066\n",
      " val_balacc 0.9454422229752626\n",
      "\n",
      "Epoch 197: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0953 - tp: 22769.0000 - fp: 843.0000 - tn: 22769.0000 - fn: 843.0000 - accuracy: 0.9643 - val_loss: 0.1503 - val_tp: 5580.0000 - val_fp: 322.0000 - val_tn: 5580.0000 - val_fn: 322.0000 - val_accuracy: 0.9454 - train_sensitivity: 0.9643 - train_specificity: 0.9643 - train_balacc: 0.9643 - val_sensitivity: 0.9454 - val_specificity: 0.9454 - val_balacc: 0.9454\n",
      "Epoch 198/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0929 - tp: 22110.0000 - fp: 790.0000 - tn: 22110.0000 - fn: 790.0000 - accuracy: 0.9655 train_balacc 0.9654413010333729\n",
      " val_balacc 0.8980006777363606\n",
      "\n",
      "Epoch 198: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0931 - tp: 22796.0000 - fp: 816.0000 - tn: 22796.0000 - fn: 816.0000 - accuracy: 0.9654 - val_loss: 0.2816 - val_tp: 5300.0000 - val_fp: 602.0000 - val_tn: 5300.0000 - val_fn: 602.0000 - val_accuracy: 0.8980 - train_sensitivity: 0.9654 - train_specificity: 0.9654 - train_balacc: 0.9654 - val_sensitivity: 0.8980 - val_specificity: 0.8980 - val_balacc: 0.8980\n",
      "Epoch 199/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0946 - tp: 22192.0000 - fp: 808.0000 - tn: 22192.0000 - fn: 808.0000 - accuracy: 0.9649 train_balacc 0.9649754362188717\n",
      " val_balacc 0.9717045069467977\n",
      "\n",
      "Epoch 199: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0944 - tp: 22785.0000 - fp: 827.0000 - tn: 22785.0000 - fn: 827.0000 - accuracy: 0.9650 - val_loss: 0.0855 - val_tp: 5735.0000 - val_fp: 167.0000 - val_tn: 5735.0000 - val_fn: 167.0000 - val_accuracy: 0.9717 - train_sensitivity: 0.9650 - train_specificity: 0.9650 - train_balacc: 0.9650 - val_sensitivity: 0.9717 - val_specificity: 0.9717 - val_balacc: 0.9717\n",
      "Epoch 200/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0916 - tp: 22238.0000 - fp: 762.0000 - tn: 22238.0000 - fn: 762.0000 - accuracy: 0.9669 train_balacc 0.9665424360494663\n",
      " val_balacc 0.9583192138258217\n",
      "\n",
      "Epoch 200: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0919 - tp: 22822.0000 - fp: 790.0000 - tn: 22822.0000 - fn: 790.0000 - accuracy: 0.9665 - val_loss: 0.1056 - val_tp: 5656.0000 - val_fp: 246.0000 - val_tn: 5656.0000 - val_fn: 246.0000 - val_accuracy: 0.9583 - train_sensitivity: 0.9665 - train_specificity: 0.9665 - train_balacc: 0.9665 - val_sensitivity: 0.9583 - val_specificity: 0.9583 - val_balacc: 0.9583\n",
      "Epoch 201/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0899 - tp: 22297.0000 - fp: 803.0000 - tn: 22297.0000 - fn: 803.0000 - accuracy: 0.9652 train_balacc 0.9650601389124174\n",
      " val_balacc 0.9662826160623518\n",
      "\n",
      "Epoch 201: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0899 - tp: 22787.0000 - fp: 825.0000 - tn: 22787.0000 - fn: 825.0000 - accuracy: 0.9651 - val_loss: 0.0888 - val_tp: 5703.0000 - val_fp: 199.0000 - val_tn: 5703.0000 - val_fn: 199.0000 - val_accuracy: 0.9663 - train_sensitivity: 0.9651 - train_specificity: 0.9651 - train_balacc: 0.9651 - val_sensitivity: 0.9663 - val_specificity: 0.9663 - val_balacc: 0.9663\n",
      "Epoch 202/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0922 - tp: 22321.0000 - fp: 779.0000 - tn: 22321.0000 - fn: 779.0000 - accuracy: 0.9663 train_balacc 0.9660342198881925\n",
      " val_balacc 0.9705184683158251\n",
      "\n",
      "Epoch 202: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0928 - tp: 22810.0000 - fp: 802.0000 - tn: 22810.0000 - fn: 802.0000 - accuracy: 0.9660 - val_loss: 0.0776 - val_tp: 5728.0000 - val_fp: 174.0000 - val_tn: 5728.0000 - val_fn: 174.0000 - val_accuracy: 0.9705 - train_sensitivity: 0.9660 - train_specificity: 0.9660 - train_balacc: 0.9660 - val_sensitivity: 0.9705 - val_specificity: 0.9705 - val_balacc: 0.9705\n",
      "Epoch 203/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0900 - tp: 22099.0000 - fp: 801.0000 - tn: 22099.0000 - fn: 801.0000 - accuracy: 0.9650 train_balacc 0.9647636794850076\n",
      " val_balacc 0.962893934259573\n",
      "\n",
      "Epoch 203: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0909 - tp: 22780.0000 - fp: 832.0000 - tn: 22780.0000 - fn: 832.0000 - accuracy: 0.9648 - val_loss: 0.0983 - val_tp: 5683.0000 - val_fp: 219.0000 - val_tn: 5683.0000 - val_fn: 219.0000 - val_accuracy: 0.9629 - train_sensitivity: 0.9648 - train_specificity: 0.9648 - train_balacc: 0.9648 - val_sensitivity: 0.9629 - val_specificity: 0.9629 - val_balacc: 0.9629\n",
      "Epoch 204/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0945 - tp: 22213.0000 - fp: 787.0000 - tn: 22213.0000 - fn: 787.0000 - accuracy: 0.9658 train_balacc 0.9657377604607826\n",
      " val_balacc 0.9467976956963741\n",
      "\n",
      "Epoch 204: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0945 - tp: 22803.0000 - fp: 809.0000 - tn: 22803.0000 - fn: 809.0000 - accuracy: 0.9657 - val_loss: 0.1271 - val_tp: 5588.0000 - val_fp: 314.0000 - val_tn: 5588.0000 - val_fn: 314.0000 - val_accuracy: 0.9468 - train_sensitivity: 0.9657 - train_specificity: 0.9657 - train_balacc: 0.9657 - val_sensitivity: 0.9468 - val_specificity: 0.9468 - val_balacc: 0.9468\n",
      "Epoch 205/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0906 - tp: 22318.0000 - fp: 782.0000 - tn: 22318.0000 - fn: 782.0000 - accuracy: 0.9661 train_balacc 0.9661189225817381\n",
      " val_balacc 0.9266350389698408\n",
      "\n",
      "Epoch 205: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0912 - tp: 22812.0000 - fp: 800.0000 - tn: 22812.0000 - fn: 800.0000 - accuracy: 0.9661 - val_loss: 0.2006 - val_tp: 5469.0000 - val_fp: 433.0000 - val_tn: 5469.0000 - val_fn: 433.0000 - val_accuracy: 0.9266 - train_sensitivity: 0.9661 - train_specificity: 0.9661 - train_balacc: 0.9661 - val_sensitivity: 0.9266 - val_specificity: 0.9266 - val_balacc: 0.9266\n",
      "Epoch 206/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0884 - tp: 22144.0000 - fp: 756.0000 - tn: 22144.0000 - fn: 756.0000 - accuracy: 0.9670 train_balacc 0.9665000847026936\n",
      " val_balacc 0.9667909183327685\n",
      "\n",
      "Epoch 206: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0911 - tp: 22821.0000 - fp: 791.0000 - tn: 22821.0000 - fn: 791.0000 - accuracy: 0.9665 - val_loss: 0.0889 - val_tp: 5706.0000 - val_fp: 196.0000 - val_tn: 5706.0000 - val_fn: 196.0000 - val_accuracy: 0.9668 - train_sensitivity: 0.9665 - train_specificity: 0.9665 - train_balacc: 0.9665 - val_sensitivity: 0.9668 - val_specificity: 0.9668 - val_balacc: 0.9668\n",
      "Epoch 207/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0932 - tp: 22186.0000 - fp: 814.0000 - tn: 22186.0000 - fn: 814.0000 - accuracy: 0.9646 train_balacc 0.9648060308317804\n",
      " val_balacc 0.9461199593358184\n",
      "\n",
      "Epoch 207: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0924 - tp: 22781.0000 - fp: 831.0000 - tn: 22781.0000 - fn: 831.0000 - accuracy: 0.9648 - val_loss: 0.1455 - val_tp: 5584.0000 - val_fp: 318.0000 - val_tn: 5584.0000 - val_fn: 318.0000 - val_accuracy: 0.9461 - train_sensitivity: 0.9648 - train_specificity: 0.9648 - train_balacc: 0.9648 - val_sensitivity: 0.9461 - val_specificity: 0.9461 - val_balacc: 0.9461\n",
      "Epoch 208/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0937 - tp: 22222.0000 - fp: 778.0000 - tn: 22222.0000 - fn: 778.0000 - accuracy: 0.9662 train_balacc 0.9661612739285109\n",
      " val_balacc 0.8976618095560827\n",
      "\n",
      "Epoch 208: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0935 - tp: 22813.0000 - fp: 799.0000 - tn: 22813.0000 - fn: 799.0000 - accuracy: 0.9662 - val_loss: 0.2728 - val_tp: 5298.0000 - val_fp: 604.0000 - val_tn: 5298.0000 - val_fn: 604.0000 - val_accuracy: 0.8977 - train_sensitivity: 0.9662 - train_specificity: 0.9662 - train_balacc: 0.9662 - val_sensitivity: 0.8977 - val_specificity: 0.8977 - val_balacc: 0.8977\n",
      "Epoch 209/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0918 - tp: 22408.0000 - fp: 792.0000 - tn: 22408.0000 - fn: 792.0000 - accuracy: 0.9659 train_balacc 0.9657377604607826\n",
      " val_balacc 0.9737377160284649\n",
      "\n",
      "Epoch 209: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0920 - tp: 22803.0000 - fp: 809.0000 - tn: 22803.0000 - fn: 809.0000 - accuracy: 0.9657 - val_loss: 0.0799 - val_tp: 5747.0000 - val_fp: 155.0000 - val_tn: 5747.0000 - val_fn: 155.0000 - val_accuracy: 0.9737 - train_sensitivity: 0.9657 - train_specificity: 0.9657 - train_balacc: 0.9657 - val_sensitivity: 0.9737 - val_specificity: 0.9737 - val_balacc: 0.9737\n",
      "Epoch 210/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0882 - tp: 22351.0000 - fp: 749.0000 - tn: 22351.0000 - fn: 749.0000 - accuracy: 0.9676 train_balacc 0.9674318143316958\n",
      " val_balacc 0.9583192138258217\n",
      "\n",
      "Epoch 210: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0887 - tp: 22843.0000 - fp: 769.0000 - tn: 22843.0000 - fn: 769.0000 - accuracy: 0.9674 - val_loss: 0.1098 - val_tp: 5656.0000 - val_fp: 246.0000 - val_tn: 5656.0000 - val_fn: 246.0000 - val_accuracy: 0.9583 - train_sensitivity: 0.9674 - train_specificity: 0.9674 - train_balacc: 0.9674 - val_sensitivity: 0.9583 - val_specificity: 0.9583 - val_balacc: 0.9583\n",
      "Epoch 211/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0935 - tp: 22090.0000 - fp: 810.0000 - tn: 22090.0000 - fn: 810.0000 - accuracy: 0.9646 train_balacc 0.9645942740979163\n",
      " val_balacc 0.9396814639105388\n",
      "\n",
      "Epoch 211: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0934 - tp: 22776.0000 - fp: 836.0000 - tn: 22776.0000 - fn: 836.0000 - accuracy: 0.9646 - val_loss: 0.1601 - val_tp: 5546.0000 - val_fp: 356.0000 - val_tn: 5546.0000 - val_fn: 356.0000 - val_accuracy: 0.9397 - train_sensitivity: 0.9646 - train_specificity: 0.9646 - train_balacc: 0.9646 - val_sensitivity: 0.9397 - val_specificity: 0.9397 - val_balacc: 0.9397\n",
      "Epoch 212/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0884 - tp: 22322.0000 - fp: 778.0000 - tn: 22322.0000 - fn: 778.0000 - accuracy: 0.9663 train_balacc 0.9663306793156022\n",
      " val_balacc 0.9296848525923416\n",
      "\n",
      "Epoch 212: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0884 - tp: 22817.0000 - fp: 795.0000 - tn: 22817.0000 - fn: 795.0000 - accuracy: 0.9663 - val_loss: 0.1708 - val_tp: 5487.0000 - val_fp: 415.0000 - val_tn: 5487.0000 - val_fn: 415.0000 - val_accuracy: 0.9297 - train_sensitivity: 0.9663 - train_specificity: 0.9663 - train_balacc: 0.9663 - val_sensitivity: 0.9297 - val_specificity: 0.9297 - val_balacc: 0.9297\n",
      "Epoch 213/232\n",
      "235/237 [============================>.] - ETA: 0s - loss: 0.0924 - tp: 22694.0000 - fp: 806.0000 - tn: 22694.0000 - fn: 806.0000 - accuracy: 0.9657 train_balacc 0.9656107064204642\n",
      " val_balacc 0.9659437478820738\n",
      "\n",
      "Epoch 213: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0924 - tp: 22800.0000 - fp: 812.0000 - tn: 22800.0000 - fn: 812.0000 - accuracy: 0.9656 - val_loss: 0.0940 - val_tp: 5701.0000 - val_fp: 201.0000 - val_tn: 5701.0000 - val_fn: 201.0000 - val_accuracy: 0.9659 - train_sensitivity: 0.9656 - train_specificity: 0.9656 - train_balacc: 0.9656 - val_sensitivity: 0.9659 - val_specificity: 0.9659 - val_balacc: 0.9659\n",
      "Epoch 214/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0924 - tp: 22319.0000 - fp: 781.0000 - tn: 22319.0000 - fn: 781.0000 - accuracy: 0.9662 train_balacc 0.9663306793156022\n",
      " val_balacc 0.9015587936292783\n",
      "\n",
      "Epoch 214: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0920 - tp: 22817.0000 - fp: 795.0000 - tn: 22817.0000 - fn: 795.0000 - accuracy: 0.9663 - val_loss: 0.2916 - val_tp: 5321.0000 - val_fp: 581.0000 - val_tn: 5321.0000 - val_fn: 581.0000 - val_accuracy: 0.9016 - train_sensitivity: 0.9663 - train_specificity: 0.9663 - train_balacc: 0.9663 - val_sensitivity: 0.9016 - val_specificity: 0.9016 - val_balacc: 0.9016\n",
      "Epoch 215/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0940 - tp: 22280.0000 - fp: 820.0000 - tn: 22280.0000 - fn: 820.0000 - accuracy: 0.9645 train_balacc 0.964424868710825\n",
      " val_balacc 0.9347678752965096\n",
      "\n",
      "Epoch 215: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0938 - tp: 22772.0000 - fp: 840.0000 - tn: 22772.0000 - fn: 840.0000 - accuracy: 0.9644 - val_loss: 0.1819 - val_tp: 5517.0000 - val_fp: 385.0000 - val_tn: 5517.0000 - val_fn: 385.0000 - val_accuracy: 0.9348 - train_sensitivity: 0.9644 - train_specificity: 0.9644 - train_balacc: 0.9644 - val_sensitivity: 0.9348 - val_specificity: 0.9348 - val_balacc: 0.9348\n",
      "Epoch 216/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0945 - tp: 22214.0000 - fp: 786.0000 - tn: 22214.0000 - fn: 786.0000 - accuracy: 0.9658 train_balacc 0.9659918685414196\n",
      " val_balacc 0.9569637411047103\n",
      "\n",
      "Epoch 216: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0940 - tp: 22809.0000 - fp: 803.0000 - tn: 22809.0000 - fn: 803.0000 - accuracy: 0.9660 - val_loss: 0.1148 - val_tp: 5648.0000 - val_fp: 254.0000 - val_tn: 5648.0000 - val_fn: 254.0000 - val_accuracy: 0.9570 - train_sensitivity: 0.9660 - train_specificity: 0.9660 - train_balacc: 0.9660 - val_sensitivity: 0.9570 - val_specificity: 0.9570 - val_balacc: 0.9570\n",
      "Epoch 217/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0898 - tp: 22148.0000 - fp: 752.0000 - tn: 22148.0000 - fn: 752.0000 - accuracy: 0.9672 train_balacc 0.966881246823649\n",
      " val_balacc 0.920704845814978\n",
      "\n",
      "Epoch 217: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0902 - tp: 22830.0000 - fp: 782.0000 - tn: 22830.0000 - fn: 782.0000 - accuracy: 0.9669 - val_loss: 0.1951 - val_tp: 5434.0000 - val_fp: 468.0000 - val_tn: 5434.0000 - val_fn: 468.0000 - val_accuracy: 0.9207 - train_sensitivity: 0.9669 - train_specificity: 0.9669 - train_balacc: 0.9669 - val_sensitivity: 0.9207 - val_specificity: 0.9207 - val_balacc: 0.9207\n",
      "Epoch 218/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0896 - tp: 22329.0000 - fp: 771.0000 - tn: 22329.0000 - fn: 771.0000 - accuracy: 0.9666 train_balacc 0.9669659495171946\n",
      " val_balacc 0.9730599796679091\n",
      "\n",
      "Epoch 218: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0893 - tp: 22832.0000 - fp: 780.0000 - tn: 22832.0000 - fn: 780.0000 - accuracy: 0.9670 - val_loss: 0.0820 - val_tp: 5743.0000 - val_fp: 159.0000 - val_tn: 5743.0000 - val_fn: 159.0000 - val_accuracy: 0.9731 - train_sensitivity: 0.9670 - train_specificity: 0.9670 - train_balacc: 0.9670 - val_sensitivity: 0.9731 - val_specificity: 0.9731 - val_balacc: 0.9731\n",
      "Epoch 219/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0852 - tp: 22180.0000 - fp: 720.0000 - tn: 22180.0000 - fn: 720.0000 - accuracy: 0.9686 train_balacc 0.9680247331865154\n",
      " val_balacc 0.939173161640122\n",
      "\n",
      "Epoch 219: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0862 - tp: 22857.0000 - fp: 755.0000 - tn: 22857.0000 - fn: 755.0000 - accuracy: 0.9680 - val_loss: 0.1527 - val_tp: 5543.0000 - val_fp: 359.0000 - val_tn: 5543.0000 - val_fn: 359.0000 - val_accuracy: 0.9392 - train_sensitivity: 0.9680 - train_specificity: 0.9680 - train_balacc: 0.9680 - val_sensitivity: 0.9392 - val_specificity: 0.9392 - val_balacc: 0.9392\n",
      "Epoch 220/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0888 - tp: 22339.0000 - fp: 761.0000 - tn: 22339.0000 - fn: 761.0000 - accuracy: 0.9671 train_balacc 0.9669659495171946\n",
      " val_balacc 0.9678075228736022\n",
      "\n",
      "Epoch 220: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0890 - tp: 22832.0000 - fp: 780.0000 - tn: 22832.0000 - fn: 780.0000 - accuracy: 0.9670 - val_loss: 0.0846 - val_tp: 5712.0000 - val_fp: 190.0000 - val_tn: 5712.0000 - val_fn: 190.0000 - val_accuracy: 0.9678 - train_sensitivity: 0.9670 - train_specificity: 0.9670 - train_balacc: 0.9670 - val_sensitivity: 0.9678 - val_specificity: 0.9678 - val_balacc: 0.9678\n",
      "Epoch 221/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0889 - tp: 22160.0000 - fp: 740.0000 - tn: 22160.0000 - fn: 740.0000 - accuracy: 0.9677 train_balacc 0.9679400304929697\n",
      " val_balacc 0.9354456116570654\n",
      "\n",
      "Epoch 221: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0881 - tp: 22855.0000 - fp: 757.0000 - tn: 22855.0000 - fn: 757.0000 - accuracy: 0.9679 - val_loss: 0.1850 - val_tp: 5521.0000 - val_fp: 381.0000 - val_tn: 5521.0000 - val_fn: 381.0000 - val_accuracy: 0.9354 - train_sensitivity: 0.9679 - train_specificity: 0.9679 - train_balacc: 0.9679 - val_sensitivity: 0.9354 - val_specificity: 0.9354 - val_balacc: 0.9354\n",
      "Epoch 222/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0928 - tp: 22129.0000 - fp: 771.0000 - tn: 22129.0000 - fn: 771.0000 - accuracy: 0.9663 train_balacc 0.966627138743012\n",
      " val_balacc 0.9266350389698408\n",
      "\n",
      "Epoch 222: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0920 - tp: 22824.0000 - fp: 788.0000 - tn: 22824.0000 - fn: 788.0000 - accuracy: 0.9666 - val_loss: 0.2040 - val_tp: 5469.0000 - val_fp: 433.0000 - val_tn: 5469.0000 - val_fn: 433.0000 - val_accuracy: 0.9266 - train_sensitivity: 0.9666 - train_specificity: 0.9666 - train_balacc: 0.9666 - val_sensitivity: 0.9266 - val_specificity: 0.9266 - val_balacc: 0.9266\n",
      "Epoch 223/232\n",
      "228/237 [===========================>..] - ETA: 0s - loss: 0.0883 - tp: 22064.0000 - fp: 736.0000 - tn: 22064.0000 - fn: 736.0000 - accuracy: 0.9677 train_balacc 0.9672200575978316\n",
      " val_balacc 0.9608607251779058\n",
      "\n",
      "Epoch 223: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0893 - tp: 22838.0000 - fp: 774.0000 - tn: 22838.0000 - fn: 774.0000 - accuracy: 0.9672 - val_loss: 0.1001 - val_tp: 5671.0000 - val_fp: 231.0000 - val_tn: 5671.0000 - val_fn: 231.0000 - val_accuracy: 0.9609 - train_sensitivity: 0.9672 - train_specificity: 0.9672 - train_balacc: 0.9672 - val_sensitivity: 0.9609 - val_specificity: 0.9609 - val_balacc: 0.9609\n",
      "Epoch 224/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0916 - tp: 22223.0000 - fp: 777.0000 - tn: 22223.0000 - fn: 777.0000 - accuracy: 0.9662 train_balacc 0.9664153820091479\n",
      " val_balacc 0.9635716706201287\n",
      "\n",
      "Epoch 224: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0912 - tp: 22819.0000 - fp: 793.0000 - tn: 22819.0000 - fn: 793.0000 - accuracy: 0.9664 - val_loss: 0.0932 - val_tp: 5687.0000 - val_fp: 215.0000 - val_tn: 5687.0000 - val_fn: 215.0000 - val_accuracy: 0.9636 - train_sensitivity: 0.9664 - train_specificity: 0.9664 - train_balacc: 0.9664 - val_sensitivity: 0.9636 - val_specificity: 0.9636 - val_balacc: 0.9636\n",
      "Epoch 225/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0880 - tp: 22116.0000 - fp: 784.0000 - tn: 22116.0000 - fn: 784.0000 - accuracy: 0.9658 train_balacc 0.9661612739285109\n",
      " val_balacc 0.9642494069806845\n",
      "\n",
      "Epoch 225: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0875 - tp: 22813.0000 - fp: 799.0000 - tn: 22813.0000 - fn: 799.0000 - accuracy: 0.9662 - val_loss: 0.0917 - val_tp: 5691.0000 - val_fp: 211.0000 - val_tn: 5691.0000 - val_fn: 211.0000 - val_accuracy: 0.9642 - train_sensitivity: 0.9662 - train_specificity: 0.9662 - train_balacc: 0.9662 - val_sensitivity: 0.9642 - val_specificity: 0.9642 - val_balacc: 0.9642\n",
      "Epoch 226/232\n",
      "229/237 [===========================>..] - ETA: 0s - loss: 0.0895 - tp: 22158.0000 - fp: 742.0000 - tn: 22158.0000 - fn: 742.0000 - accuracy: 0.9676 train_balacc 0.9675165170252414\n",
      " val_balacc 0.8065062690613352\n",
      "\n",
      "Epoch 226: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0898 - tp: 22845.0000 - fp: 767.0000 - tn: 22845.0000 - fn: 767.0000 - accuracy: 0.9675 - val_loss: 0.7301 - val_tp: 4760.0000 - val_fp: 1142.0000 - val_tn: 4760.0000 - val_fn: 1142.0000 - val_accuracy: 0.8065 - train_sensitivity: 0.9675 - train_specificity: 0.9675 - train_balacc: 0.9675 - val_sensitivity: 0.8065 - val_specificity: 0.8065 - val_balacc: 0.8065\n",
      "Epoch 227/232\n",
      "231/237 [============================>.] - ETA: 0s - loss: 0.0908 - tp: 22306.0000 - fp: 794.0000 - tn: 22306.0000 - fn: 794.0000 - accuracy: 0.9656 train_balacc 0.9655683550736913\n",
      " val_balacc 0.9700101660454084\n",
      "\n",
      "Epoch 227: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0906 - tp: 22799.0000 - fp: 813.0000 - tn: 22799.0000 - fn: 813.0000 - accuracy: 0.9656 - val_loss: 0.0810 - val_tp: 5725.0000 - val_fp: 177.0000 - val_tn: 5725.0000 - val_fn: 177.0000 - val_accuracy: 0.9700 - train_sensitivity: 0.9656 - train_specificity: 0.9656 - train_balacc: 0.9656 - val_sensitivity: 0.9700 - val_specificity: 0.9700 - val_balacc: 0.9700\n",
      "Epoch 228/232\n",
      "232/237 [============================>.] - ETA: 0s - loss: 0.0943 - tp: 22396.0000 - fp: 804.0000 - tn: 22396.0000 - fn: 804.0000 - accuracy: 0.9653 train_balacc 0.9651871929527359\n",
      " val_balacc 0.9611995933581836\n",
      "\n",
      "Epoch 228: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0945 - tp: 22790.0000 - fp: 822.0000 - tn: 22790.0000 - fn: 822.0000 - accuracy: 0.9652 - val_loss: 0.1017 - val_tp: 5673.0000 - val_fp: 229.0000 - val_tn: 5673.0000 - val_fn: 229.0000 - val_accuracy: 0.9612 - train_sensitivity: 0.9652 - train_specificity: 0.9652 - train_balacc: 0.9652 - val_sensitivity: 0.9612 - val_specificity: 0.9612 - val_balacc: 0.9612\n",
      "Epoch 229/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0895 - tp: 22823.0000 - fp: 789.0000 - tn: 22823.0000 - fn: 789.0000 - accuracy: 0.9666 train_balacc 0.9665847873962392\n",
      " val_balacc 0.9173161640121993\n",
      "\n",
      "Epoch 229: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0895 - tp: 22823.0000 - fp: 789.0000 - tn: 22823.0000 - fn: 789.0000 - accuracy: 0.9666 - val_loss: 0.2236 - val_tp: 5414.0000 - val_fp: 488.0000 - val_tn: 5414.0000 - val_fn: 488.0000 - val_accuracy: 0.9173 - train_sensitivity: 0.9666 - train_specificity: 0.9666 - train_balacc: 0.9666 - val_sensitivity: 0.9173 - val_specificity: 0.9173 - val_balacc: 0.9173\n",
      "Epoch 230/232\n",
      "227/237 [===========================>..] - ETA: 0s - loss: 0.0925 - tp: 21918.0000 - fp: 782.0000 - tn: 21918.0000 - fn: 782.0000 - accuracy: 0.9656 train_balacc 0.9652295442995087\n",
      " val_balacc 0.970687902405964\n",
      "\n",
      "Epoch 230: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0938 - tp: 22791.0000 - fp: 821.0000 - tn: 22791.0000 - fn: 821.0000 - accuracy: 0.9652 - val_loss: 0.0882 - val_tp: 5729.0000 - val_fp: 173.0000 - val_tn: 5729.0000 - val_fn: 173.0000 - val_accuracy: 0.9707 - train_sensitivity: 0.9652 - train_specificity: 0.9652 - train_balacc: 0.9652 - val_sensitivity: 0.9707 - val_specificity: 0.9707 - val_balacc: 0.9707\n",
      "Epoch 231/232\n",
      "230/237 [============================>.] - ETA: 0s - loss: 0.0930 - tp: 22236.0000 - fp: 764.0000 - tn: 22236.0000 - fn: 764.0000 - accuracy: 0.9668 train_balacc 0.9666694900897849\n",
      " val_balacc 0.9369705184683158\n",
      "\n",
      "Epoch 231: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0931 - tp: 22825.0000 - fp: 787.0000 - tn: 22825.0000 - fn: 787.0000 - accuracy: 0.9667 - val_loss: 0.1539 - val_tp: 5530.0000 - val_fp: 372.0000 - val_tn: 5530.0000 - val_fn: 372.0000 - val_accuracy: 0.9370 - train_sensitivity: 0.9667 - train_specificity: 0.9667 - train_balacc: 0.9667 - val_sensitivity: 0.9370 - val_specificity: 0.9370 - val_balacc: 0.9370\n",
      "Epoch 232/232\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0909 - tp: 22847.0000 - fp: 765.0000 - tn: 22847.0000 - fn: 765.0000 - accuracy: 0.9676 train_balacc 0.9676012197187871\n",
      " val_balacc 0.8802100982717723\n",
      "\n",
      "Epoch 232: val_balacc did not improve from 0.98729\n",
      "237/237 [==============================] - 1s 6ms/step - loss: 0.0909 - tp: 22847.0000 - fp: 765.0000 - tn: 22847.0000 - fn: 765.0000 - accuracy: 0.9676 - val_loss: 0.4146 - val_tp: 5195.0000 - val_fp: 707.0000 - val_tn: 5195.0000 - val_fn: 707.0000 - val_accuracy: 0.8802 - train_sensitivity: 0.9676 - train_specificity: 0.9676 - train_balacc: 0.9676 - val_sensitivity: 0.8802 - val_specificity: 0.8802 - val_balacc: 0.8802\n",
      "Size of the training fold is 23612\n",
      "Size of the validation fold is 5902\n",
      "Class imbalance in Train is 0.46%\n",
      "Class imbalance in Validation is 0.46%\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation with balanced data on the validation set\n",
    "num_nevu, num_mela, nevu_images, melanoma_images, y_nevu, y_mela = split_nevu_mela(x, y)\n",
    "num_mela, X_mela_aug, y_mela_aug = augmentate_melanoma_data(melanoma_images, melanoma_images, y_mela, num_mela)\n",
    "all_images = np.vstack([X_mela_aug, nevu_images])\n",
    "all_labels = np.hstack([y_mela_aug, y_nevu])\n",
    "all_images_aug = np.empty((1,28,28,3), dtype=np.float32)\n",
    "all_labels_aug = np.empty((1,), dtype=np.int8)\n",
    "all_images_aug, all_labels_aug = augmentate_all_data(all_images, all_labels)\n",
    "all_images_aug, all_labels_aug = shuffle(all_images_aug, all_labels_aug, random_state=0)\n",
    "\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "epochs = 232\n",
    "batch_size = 100\n",
    "model_history = []\n",
    "for train_index, val_index in kf.split(all_images_aug, all_labels_aug):\n",
    "    X_train, X_val = all_images_aug[train_index], all_images_aug[val_index]\n",
    "    y_train, y_val = all_labels_aug[train_index], all_labels_aug[val_index]\n",
    "    \n",
    "    y_labels = to_categorical(y_train, 2)\n",
    "    y_val_labels = to_categorical(y_val, 2)\n",
    "    model_history.append(model_cnn.fit(x=X_train ,y=y_labels ,epochs=epochs ,batch_size=batch_size ,validation_data=(X_val,y_val_labels) ,verbose=1,\n",
    "                             callbacks=[keras.callbacks.ModelCheckpoint('cnn_model.h5', verbose=1, monitor= \"val_balanced_accuracy\", save_best_only=True)]))#, keras.callbacks.EarlyStopping(monitor='val_balacc', patience=50, restore_best_weights=True)]))\n",
    "\n",
    "    print(f'Size of the training fold is {len(y_train)}')\n",
    "    print(f'Size of the validation fold is {len(y_val)}')\n",
    "    print(f'Class imbalance in Train is {np.count_nonzero(y_train==1)/len(y_train):2.2f}%')\n",
    "    print(f'Class imbalance in Validation is {np.count_nonzero(y_val==1)/len(y_val):2.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Train Accuracy vs Val Accuracy')\n",
    "plt.plot(model_history[0].history['accuracy'], label='Train Accuracy Fold 1', color='black')\n",
    "plt.plot(model_history[0].history['val_accuracy'], label='Val Accuracy Fold 1', color='black', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[1].history['accuracy'], label='Train Accuracy Fold 2', color='red', )\n",
    "plt.plot(model_history[1].history['val_accuracy'], label='Val Accuracy Fold 2', color='red', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[2].history['accuracy'], label='Train Accuracy Fold 3', color='green', )\n",
    "plt.plot(model_history[2].history['val_accuracy'], label='Val Accuracy Fold 3', color='green', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[3].history['accuracy'], label='Train Accuracy Fold 4', color='blue', )\n",
    "plt.plot(model_history[3].history['val_accuracy'], label='Val Accuracy Fold 4', color='blue', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[4].history['accuracy'], label='Train Accuracy Fold 5', color='cyan', )\n",
    "plt.plot(model_history[4].history['val_accuracy'], label='Val Accuracy Fold 5', color='cyan', linestyle = \"dashdot\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Balanced Accuracy')\n",
    "plt.plot(model_history[0].history['val_balacc'], label='Train Accuracy Fold 1', color='black')\n",
    "plt.plot(model_history[1].history['val_balacc'], label='Train Accuracy Fold 2', color='red', )\n",
    "plt.plot(model_history[2].history['val_balacc'], label='Train Accuracy Fold 3', color='green', )\n",
    "plt.plot(model_history[3].history['val_balacc'], label='Train Accuracy Fold 4', color='blue', )\n",
    "plt.plot(model_history[4].history['val_balacc'], label='Train Accuracy Fold 5', color='cyan', )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_104 (Conv2D)         (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 26, 26, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " average_pooling2d_50 (Avera  (None, 12, 12, 32)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 10, 10, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " average_pooling2d_51 (Avera  (None, 4, 4, 64)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,117,602\n",
      "Trainable params: 1,117,410\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "56/56 [==============================] - 0s 1ms/step\n",
      "Percentage of Melanoma predictions is 20.46%\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model('best_mode.h5', compile=False)\n",
    "best_model.compile(optimizer = optimizers.Adam(learning_rate=1e-3),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics=[balanced_accuracy, precision, recall,['accuracy']])\n",
    "best_model.summary()\n",
    "X_test = np.load('Xtest_Classification1.npy')\n",
    "X_test = np.reshape((X_test).astype('float32')/255.0,(len(X_test),28,28,3))\n",
    "y_test = best_model.predict(X_test)\n",
    "print(f\"Percentage of Melanoma predictions is {np.count_nonzero(y_test[:,1] > 0.5)/len(y_test)*100:2.2f}%\")\n",
    "\n",
    "#y_test = model_cnn.predict(X_test)\n",
    "#print(f\"Percentage of Melanoma predictions is {np.count_nonzero(y_test[:,1] > 0.5)/len(y_test)*100:2.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation with unbalanced data on the validation set\n",
    "num_nevu, num_mela, nevu_images, melanoma_images, y_nevu, y_mela = split_nevu_mela(x, y)\n",
    "all_images = np.vstack([melanoma_images, nevu_images])\n",
    "all_labels = np.hstack([y_mela, y_nevu])\n",
    "\n",
    "all_images_aug, all_labels_aug = augmentate_all_data(all_images, all_labels)\n",
    "all_images_aug, all_labels_aug = shuffle(all_images_aug, all_labels_aug, random_state=0)\n",
    "\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "epochs = 232\n",
    "batch_size = 100\n",
    "model_history = []\n",
    "model_cnn = create_CNN_model()\n",
    "for train_index, val_index in kf.split(all_images_aug, all_labels_aug):\n",
    "    X_train, X_val = all_images_aug[train_index], all_images_aug[val_index]\n",
    "    y_train, y_val = all_labels_aug[train_index], all_labels_aug[val_index]\n",
    "    \n",
    "    X_train = np.reshape(X_train,(len(X_train),2352))\n",
    "    num_nevu, num_mela, nevu_images, melanoma_images, y_nevu, y_mela = split_nevu_mela(X_train, y_train)\n",
    "    num_mela, X_mela_aug, y_mela_aug = augmentate_melanoma_data(melanoma_images, melanoma_images, y_mela, num_mela)\n",
    "    X_train = np.vstack([X_mela_aug, nevu_images])\n",
    "    y_train = np.hstack([y_mela_aug, y_nevu])\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "    y_labels = to_categorical(y_train, 2)\n",
    "    y_val_labels = to_categorical(y_val, 2)\n",
    "    model_history.append(model_cnn.fit(x=X_train ,y=y_labels ,epochs=epochs ,batch_size=batch_size ,validation_data=(X_val,y_val_labels) ,verbose=1,\n",
    "                             callbacks=[keras.callbacks.ModelCheckpoint('cnn_model.h5', verbose=1, monitor= \"val_balanced_accuracy\", save_best_only=True)]))#, keras.callbacks.EarlyStopping(monitor='val_balacc', patience=50, restore_best_weights=True)]))\n",
    "\n",
    "    print(f'Size of the training fold is {len(y_train)}')\n",
    "    print(f'Size of the validation fold is {len(y_val)}')\n",
    "    print(f'Class imbalance in Train is {np.count_nonzero(y_train==1)/len(y_train):2.2f}%')\n",
    "    print(f'Class imbalance in Validation is {np.count_nonzero(y_val==1)/len(y_val):2.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Train Accuracy vs Val Accuracy')\n",
    "plt.plot(model_history[0].history['accuracy'], label='Train Accuracy Fold 1', color='black')\n",
    "plt.plot(model_history[0].history['val_accuracy'], label='Val Accuracy Fold 1', color='black', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[1].history['accuracy'], label='Train Accuracy Fold 2', color='red', )\n",
    "plt.plot(model_history[1].history['val_accuracy'], label='Val Accuracy Fold 2', color='red', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[2].history['accuracy'], label='Train Accuracy Fold 3', color='green', )\n",
    "plt.plot(model_history[2].history['val_accuracy'], label='Val Accuracy Fold 3', color='green', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[3].history['accuracy'], label='Train Accuracy Fold 4', color='blue', )\n",
    "plt.plot(model_history[3].history['val_accuracy'], label='Val Accuracy Fold 4', color='blue', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[4].history['accuracy'], label='Train Accuracy Fold 5', color='cyan', )\n",
    "plt.plot(model_history[4].history['val_accuracy'], label='Val Accuracy Fold 5', color='cyan', linestyle = \"dashdot\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Balanced Accuracy')\n",
    "plt.plot(model_history[0].history['val_balacc'], label='Train Accuracy Fold 1', color='black')\n",
    "plt.plot(model_history[1].history['val_balacc'], label='Train Accuracy Fold 2', color='red', )\n",
    "plt.plot(model_history[2].history['val_balacc'], label='Train Accuracy Fold 3', color='green', )\n",
    "plt.plot(model_history[3].history['val_balacc'], label='Train Accuracy Fold 4', color='blue', )\n",
    "plt.plot(model_history[4].history['val_balacc'], label='Train Accuracy Fold 5', color='cyan', )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('cnn_model.h5')\n",
    "X_test = np.load('Xtest_Classification1.npy')\n",
    "X_test = np.reshape((X_test).astype('float32')/255.0,(len(X_test),28,28,3))\n",
    "y_test = best_model.predict(X_test)\n",
    "print(f\"Percentage of Melanoma predictions is {np.count_nonzero(y_test[:,1] > 0.5)/len(y_test)*100:2.2f}%\")\n",
    "\n",
    "y_test = model_cnn.predict(X_test)\n",
    "print(f\"Percentage of Melanoma predictions is {np.count_nonzero(y_test[:,1] > 0.5)/len(y_test)*100:2.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "images = np.reshape((x).astype('float32')/255.0,(len(x),28,28,3))\n",
    "image = images[0]\n",
    "plt.imshow(image, interpolation='nearest')\n",
    "plt.show()\n",
    "output_image = tf.image.resize(image, (32, 32), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR).numpy()\n",
    "plt.imshow(image, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(32,32,3))\n",
    "#conv_base = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(32,32,3))\n",
    "conv_base.trainable = False\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1280, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(learning_rate=1e-4),\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics=[keras.metrics.TruePositives(name='tp'), keras.metrics.FalsePositives(name='fp'), keras.metrics.TrueNegatives(name='tn'), keras.metrics.FalseNegatives(name='fn'),['accuracy']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 232\n",
    "batch_size = 100\n",
    "X_train = tf.image.resize(X_train, (32, 32), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR).numpy()\n",
    "X_val = tf.image.resize(X_val, (32, 32), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR).numpy()\n",
    "y_labels = to_categorical(y_train, 2)\n",
    "y_val_labels = to_categorical(y_val, 2)\n",
    "\n",
    "history_cnn = model.fit(x=X_train ,y=y_labels ,epochs=epochs ,batch_size=batch_size ,validation_data=(X_val,y_val_labels) ,verbose=1,\n",
    "                           callbacks=[TrainBalancedAccuracyCallback(), ValBalancedAccuracyCallback()])#, keras.callbacks.EarlyStopping(monitor='val_balacc', patience=50, restore_best_weights=True)])\n",
    "if first_time:\n",
    "    prev_history = history_cnn\n",
    "    first_time = False\n",
    "display_model_data(history_cnn, prev_history)\n",
    "prev_history = history_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 4s 24ms/step\n",
      "Percentage of Melanoma predictions is 3.29%\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load('Xtest_Classification1.npy')   \n",
    "X_test = np.reshape((X_test).astype('float32')/255.0,(len(X_test),28,28,3))\n",
    "X_test = tf.image.resize(X_test, (32, 32), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR).numpy()\n",
    "y_test = model.predict(X_test)\n",
    "print(f\"Percentage of Melanoma predictions is {np.count_nonzero(y_test[:,1] > 0.5)/len(y_test)*100:2.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Validation Accuracy: 0.789655058813738\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', C=1.0)\n",
    "X_train = np.reshape(X_train, (len(X_train), 2352))\n",
    "svc.fit(X_train, y_train)\n",
    "X_val = np.reshape(X_val, (len(X_val), 2352))\n",
    "\n",
    "balanced_acc = balanced_accuracy_score(y_val, svc.predict(X_val))\n",
    "print(\"Balanced Validation Accuracy:\", balanced_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
